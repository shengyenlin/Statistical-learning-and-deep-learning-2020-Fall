{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計學習與深度學習 HW2\n",
    "### 會計四 B06702064 林聖硯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一題 [Data Preprocessing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料網址 : https://drive.google.com/drive/folders/1SzmDs4FK_V4jPf8WLuz-j26oW0UcHghH?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('adult_data.csv', header = None)\n",
    "#test的資料的第一行跟數據無關，我直接將檔名改成csv檔並且移除\n",
    "x_test = pd.read_csv('adult_test.csv', header = None)\n",
    "x_test.columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'ylabel']\n",
    "x_train.columns = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'ylabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_white_space(df):\n",
    "    for colname in df.columns:\n",
    "        df[colname] = df[colname].apply(lambda x : x.strip() if type(x) == str else x)\n",
    "    return df\n",
    "        \n",
    "def one_hot_on_y(df):\n",
    "    #最後一欄為標籤，將'>50K'與'<=50K'轉成1跟0\n",
    "    if df.shape[0] > 20000:\n",
    "        trans_dict = {'<=50K':0, '>50K':1}\n",
    "        df['ylabel'] = df['ylabel'].apply(lambda x : trans_dict[x])\n",
    "\n",
    "    else:\n",
    "        trans_dict = {'<=50K.':0, '>50K.':1}\n",
    "        df['ylabel'] = df['ylabel'].apply(lambda x : trans_dict[x])\n",
    "    return df \n",
    "    \n",
    "def remove_nan(df):\n",
    "    #把所有含有缺值的Rows刪除\n",
    "    for colname in df.columns:\n",
    "        df = df[df[colname] != '?']\n",
    "    return df\n",
    "\n",
    "def clean_df(df):\n",
    "    df = remove_white_space(df)\n",
    "    df = one_hot_on_y(df)\n",
    "    df = remove_nan(df)\n",
    "    return df\n",
    "\n",
    "def normalize(df, df_used):\n",
    "    conti_var = ['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt']\n",
    "    for var in conti_var:\n",
    "        mean = df_used[var].mean()\n",
    "        std = np.sqrt(np.var(df_used[var], ddof = 0))\n",
    "        df[var] = df[var].apply(lambda x : (x-mean)/std)\n",
    "    return df\n",
    "        \n",
    "def get_dummy(df):\n",
    "    df = pd.get_dummies(df)\n",
    "    if df.shape[0] > 20000:\n",
    "    #只考慮在訓練資料中出現超過(含)10次的特徵值\n",
    "        conti_var = ['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt']\n",
    "        dummy_var = [var for var in df.columns if var not in conti_var]\n",
    "        for var in dummy_var:\n",
    "            summation = df[var].sum()\n",
    "            if summation < 10:\n",
    "                del df[var]\n",
    "    return df\n",
    "            \n",
    "def get_y(df):\n",
    "    y = df['ylabel']\n",
    "    del df['ylabel']\n",
    "    return y\n",
    "        \n",
    "def reset_df(df):\n",
    "    ans_list = ['capital-loss', 'hours-per-week', 'capital-gain',\n",
    "       'educational-num', 'age', 'fnlwgt', 'relationship_Husband',\n",
    "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
    "       'relationship_Own-child', 'relationship_Unmarried',\n",
    "       'relationship_Wife', 'race_Amer-Indian-Eskimo',\n",
    "       'race_Asian-Pac-Islander', 'race_Black', 'race_Other',\n",
    "       'race_White', 'gender_Female', 'gender_Male',\n",
    "       'occupation_Adm-clerical', 'occupation_Craft-repair',\n",
    "       'occupation_Exec-managerial', 'occupation_Farming-fishing',\n",
    "       'occupation_Handlers-cleaners', 'occupation_Machine-op-inspct',\n",
    "       'occupation_Other-service', 'occupation_Priv-house-serv',\n",
    "       'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
    "       'occupation_Sales', 'occupation_Tech-support',\n",
    "       'occupation_Transport-moving', 'education_10th', 'education_11th',\n",
    "       'education_12th', 'education_1st-4th', 'education_5th-6th',\n",
    "       'education_7th-8th', 'education_9th', 'education_Assoc-acdm',\n",
    "       'education_Assoc-voc', 'education_Bachelors',\n",
    "       'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
    "       'education_Preschool', 'education_Prof-school',\n",
    "       'education_Some-college', 'native-country_Cambodia',\n",
    "       'native-country_Canada', 'native-country_China',\n",
    "       'native-country_Columbia', 'native-country_Cuba',\n",
    "       'native-country_Dominican-Republic', 'native-country_Ecuador',\n",
    "       'native-country_El-Salvador', 'native-country_England',\n",
    "       'native-country_France', 'native-country_Germany',\n",
    "       'native-country_Greece', 'native-country_Guatemala',\n",
    "       'native-country_Haiti', 'native-country_Honduras',\n",
    "       'native-country_Hong', 'native-country_Hungary',\n",
    "       'native-country_India', 'native-country_Iran',\n",
    "       'native-country_Ireland', 'native-country_Italy',\n",
    "       'native-country_Jamaica', 'native-country_Japan',\n",
    "       'native-country_Laos', 'native-country_Mexico',\n",
    "       'native-country_Nicaragua',\n",
    "       'native-country_Outlying-US(Guam-USVI-etc)', 'native-country_Peru',\n",
    "       'native-country_Philippines', 'native-country_Poland',\n",
    "       'native-country_Portugal', 'native-country_Puerto-Rico',\n",
    "       'native-country_Scotland', 'native-country_South',\n",
    "       'native-country_Taiwan', 'native-country_Thailand',\n",
    "       'native-country_Trinadad&Tobago', 'native-country_United-States',\n",
    "       'native-country_Vietnam', 'native-country_Yugoslavia',\n",
    "       'workclass_Federal-gov', 'workclass_Local-gov',\n",
    "       'workclass_Private', 'workclass_Self-emp-inc',\n",
    "       'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
    "       'workclass_Without-pay', 'marital-status_Divorced',\n",
    "       'marital-status_Married-AF-spouse',\n",
    "       'marital-status_Married-civ-spouse',\n",
    "       'marital-status_Married-spouse-absent',\n",
    "       'marital-status_Never-married', 'marital-status_Separated',\n",
    "       'marital-status_Widowed']\n",
    "    \n",
    "    df = df[ans_list]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martin\\.conda\\envs\\test\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "x_train = clean_df(x_train)\n",
    "x_test = clean_df(x_test)\n",
    "\n",
    "x_train_copy = x_train.copy()\n",
    "\n",
    "x_train = normalize(x_train, x_train_copy)\n",
    "x_test = normalize(x_test, x_train_copy)\n",
    "\n",
    "x_train = get_dummy(x_train)\n",
    "x_test = get_dummy(x_test)\n",
    "\n",
    "y_train = get_y(x_train)\n",
    "y_test = get_y(x_test)\n",
    "\n",
    "x_train = reset_df(x_train)\n",
    "x_test = reset_df(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult50k = {'x_train': x_train, 'x_test' : x_test, 'y_train' : y_train, 'y_test' : y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dsfile = 'adult_m50k (1).pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50k[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二題 [ROC and AUC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "#train prediction model    \n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C = c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "#make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "#compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0, 1, 1000)\n",
    "TPR_result = []\n",
    "FPR_result = []\n",
    "for threshold in thresholds:\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range(ypredprob.shape[0]):\n",
    "        prob_class_0 = ypredprob[i][0]     \n",
    "        if prob_class_0 >= threshold and adult50kp['y_test'][i] == 0:\n",
    "            TP += 1 \n",
    "        if prob_class_0 < threshold and adult50kp['y_test'][i] == 0:\n",
    "            FN += 1 \n",
    "        if prob_class_0 >= threshold and adult50kp['y_test'][i] == 1:\n",
    "            FP += 1\n",
    "        if prob_class_0 < threshold and adult50kp['y_test'][i] == 1:\n",
    "            TN += 1\n",
    "    TPR = TP / (TP+FN)\n",
    "    FPR = FP / (FP+TN)\n",
    "    TPR_result.append(TPR)\n",
    "    FPR_result.append(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FPR_result, TPR_result)\n",
    "plt.plot([0, 1], [0, 1], color = 'black', linestyle='dashed')\n",
    "plt.title(\"ROC Curve\") \n",
    "plt.ylabel(\"TP Rate\") \n",
    "plt.xlabel(\"FP Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under curve is 0.9034958127141229\n"
     ]
    }
   ],
   "source": [
    "AUC = 0\n",
    "for i in range(1, len(TPR_result)):\n",
    "    area = (1/2) * (TPR_result[i] + TPR_result[i-1]) * (FPR_result[i] - FPR_result[i-1])\n",
    "    AUC += area\n",
    "\n",
    "print(\"Area under curve is\", -AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第三題 [Logistic Regression with L2 Regularization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notations:\n",
    "\n",
    "data matrix : $\\displaystyle \\mathbf{X}_{N \\times (M+1)}$\n",
    "\n",
    "data vector : $\\displaystyle \\mathbf{x}_{i \\text{ }(M+1) \\times 1}$\n",
    "\n",
    "regression coefficient vector : $\\displaystyle \\mathbf{w}_{(M+1) \\times 1}$\n",
    "\n",
    "regularization coefficient matrix $\\displaystyle \\mathbf{\\Lambda}_{(M+1) \\times (M+1)} \\text{  ,where  } \\mathbf{\\Lambda}_{kk} = \\lambda_k$\n",
    "\n",
    "Error function : $E(w) = \\frac{1}{2} w^T \\Lambda w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)],$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\n",
    "$\\displaystyle \\sigma(x) = \\frac{1}{1+e^{-x}}, \\text{  } \\displaystyle z_1 = t_i \\ln [\\sigma(\\mathbf{w}^T \\mathbf{x}_i)], \\text{  } \\displaystyle z_2 = (1-t_i) \\ln [1- \\sigma(\\mathbf{w}^T \\mathbf{x}_i)]$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial z_1}{\\partial \\mathbf{w}} = \\frac{t_i \\sigma(\\mathbf{w}^T \\mathbf{x}_i) (1-\\sigma(\\mathbf{w}^T \\mathbf{x}_i))\\mathbf{x}_i}{\\sigma(\\mathbf{w}^T \\mathbf{x}_i)} = t_i (1 - \\sigma(\\mathbf{w}^T \\mathbf{x}_i)) \\mathbf{x}_i$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial z_2}{\\partial \\mathbf{w}} = \\frac{(t_i - 1)\\sigma(\\mathbf{w}^T \\mathbf{x}_i)(1-\\sigma(\\mathbf{w}^T \\mathbf{x}_i))\\mathbf{x}_i}{1- \\sigma(\\mathbf{w}^T \\mathbf{x}_i)} = (t_i - 1)\\sigma(\\mathbf{w}^T \\mathbf{x}_i) \\mathbf{x}_i$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial z_1}{\\partial \\mathbf{w}} + \\frac{\\partial z_2}{\\partial \\mathbf{w}} = (t_i - \\sigma(\\mathbf{w}^T \\mathbf{x}_i))\\mathbf{x}_i$\n",
    "\n",
    "$\\displaystyle \\frac{\\partial \\frac{1}{2} \\mathbf{w}^T \\Lambda \\mathbf{w}}{\\partial \\mathbf{w}} = \\frac{1}{2} (\\Lambda + \\Lambda^T) \\mathbf{w} = \\Lambda \\mathbf{w}$\n",
    "\n",
    "$\\displaystyle \\Rightarrow \\nabla E(\\mathbf{w}) = \\Lambda \\mathbf{w} - \\sum_{i = 1}^{N} [(t_i - \\sigma (w^T \\mathbf{x}_i)] = \\Lambda \\mathbf{w} + \\sum_{i = 1}^{N} [\\sigma (\\mathbf{w}^T \\mathbf{x}_i) - t_i] \\mathbf{x}_i = \\mathbf{X}^T (\\mathbf{y} - \\mathbf{t}) + \\Lambda \\mathbf{w}$\n",
    "\n",
    "where $\\displaystyle \\mathbf{y} = \\begin{bmatrix} \\sigma(\\mathbf{w}^T x_1) \\\\ \\vdots\n",
    "\\\\ \\sigma(\\mathbf{w}^T x_N) \\end{bmatrix}, \\mathbf{t} = \\begin{bmatrix} \n",
    "t_1\n",
    "\\\\ \\vdots\n",
    "\\\\ t_N \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle \\frac{\\partial \\sigma(  \\mathbf{w}^T \\mathbf{x}_i)}{\\partial \\mathbf{w}} = \\sigma(\\mathbf{w}^T \\mathbf{x}_i) [1-\\sigma(\\mathbf{w}^T \\mathbf{x}_i)] \\mathbf{x}_i$\n",
    "\n",
    "$\\displaystyle \\Rightarrow \\mathbf{H} = \\Lambda \\mathbf{I} + \\sum_{i = 1}^{N} [\\sigma(\\mathbf{w}^T \\mathbf{x}_i) [1-\\sigma(\\mathbf{w}^T \\mathbf{x}_i)] \\mathbf{x}_i \\mathbf{x}_i^{T}] = \\mathbf{X}^T \\mathbf{R} \\mathbf{X} + \\Lambda$\n",
    "\n",
    "where $\\mathbf{R}$ is a diagonal matrix with $\\displaystyle \\mathbf{R}_{nn} = \\sigma(\\mathbf{w}^T \\mathbf{x}_i) [1-\\sigma(\\mathbf{w}^T \\mathbf{x}_i)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 1000, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"\n",
    "        reg_vec: the regularization coefficient vector\n",
    "        reg_vec is a list that contains three different coefficients\n",
    "        [coef for conti variable, coef for binary variable, coef for constant term]\n",
    "        max_iter: maximum number of iteration to run for the Newton method\n",
    "        tol: tolerance for the objective function\n",
    "        add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\n",
    "        \"\"\"\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept      \n",
    "        self.weights = None\n",
    "        \n",
    "    def sigmoid(self, array):\n",
    "        result = 1 / (1 + np.exp(-array)) \n",
    "        return result\n",
    "    \n",
    "    def train_weight(self, x, y_pred, y, Lambda, w):\n",
    "        #gradient\n",
    "        nabla_E = np.dot(x.T, (y_pred - y)) + np.dot(Lambda, w)\n",
    "\n",
    "        #N*N matrix, diagonal elements = y_predicted\n",
    "        R = np.diag(y_pred * (1 - y_pred))\n",
    "        #hessian matrix\n",
    "        H = Lambda + np.dot(np.dot(x.T, R), x)\n",
    "\n",
    "        #update weights\n",
    "        w = w - np.dot(np.linalg.inv(H), nabla_E)\n",
    "        return w\n",
    "    \n",
    "    def create_Lambda(self):\n",
    "        #regularization coefficient matrix (M+1, M+1)\n",
    "        #第0-5個feature是continuous varaible\n",
    "        #第6-101個feature是binary variable\n",
    "        #第102個feautre是1向量(for constant)\n",
    "        conti_array = np.full(6, self.reg_vec[0])\n",
    "        binary_array = np.full(96, self.reg_vec[1])\n",
    "        const_array = np.full(1, self.reg_vec[2])\n",
    "        final_array = np.concatenate((conti_array, binary_array, const_array), axis = None)\n",
    "        Lambda = np.diag(final_array)\n",
    "        return Lambda\n",
    "    \n",
    "    def fit(self, x, y, verbal = False):\n",
    "        \n",
    "        if self.add_intercept == True:\n",
    "            #(N, M+1)\n",
    "            x = np.column_stack((x,np.ones((x.shape[0],1))))\n",
    "        \n",
    "        Lambda = self.create_Lambda()\n",
    "        #b = the average of lambda_i\n",
    "        b = np.sum(Lambda) / Lambda.shape[0]\n",
    "        \n",
    "        #initial vector by using colsed-form solution\n",
    "        #w : (M+1, 1)\n",
    "        w = np.dot(np.linalg.inv(np.dot(x.T, x) + b * np.eye(x.shape[1])), np.dot(x.T, y))\n",
    "        \n",
    "        step_sizes = 5000\n",
    "        iteration = 0\n",
    "        \n",
    "        #algo\n",
    "        while(step_sizes >= self.tol and iteration < self.max_iter):\n",
    "            iteration += 1\n",
    "            #old_weights = np.copy(w)\n",
    "            y_pred = self.sigmoid(np.dot(x, w))\n",
    "            old_loss = 1/2 * (np.dot(np.dot(w.T, Lambda), w)) - (np.dot(np.invert(y == 1), np.log(1-y_pred)) + np.dot(np.log(y_pred), y))\n",
    "\n",
    "            w = self.train_weight(x, y_pred, y, Lambda, w)\n",
    "            y_pred = self.sigmoid(np.dot(x, w))\n",
    "            new_loss = 1/2 * (np.dot(np.dot(w.T, Lambda), w)) - (np.dot(np.invert(y == 1), np.log(1-y_pred)) + np.dot(np.log(y_pred), y))\n",
    "            step_sizes = abs(new_loss - old_loss)\n",
    "            \n",
    "            if verbal == True:\n",
    "                print(\"Iteration (start) : \",iteration)\n",
    "                print(\"\\nTraining loss\\n\", new_loss)\n",
    "                print(\"\\nStep sizes\\n\",step_sizes)\n",
    "                print(\"\\nNew Weights\\n\",w)\n",
    "        \n",
    "        self.weights = w\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"doing prediction\"\"\"\n",
    "        x = np.column_stack((x,np.ones((x.shape[0],1))))\n",
    "        y_pred = self.sigmoid(np.dot(x, self.weights))\n",
    "        y_pred = 1 * (y_pred > 0.5)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = adult50kp['x_train']\n",
    "Y_train = adult50kp['y_train']\n",
    "X_test = adult50kp['x_test']\n",
    "Y_test = adult50kp['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73239,
     "status": "ok",
     "timestamp": 1604391071095,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "ThEz-lPGvrvz",
    "outputId": "34f09f3f-4f9a-4914-da96-287cb53c6408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of case 1 = 0.847875166002656\n",
      "weights =  [ 2.58310749e-01  3.52951378e-01  2.33390152e+00  7.51145211e-01\n",
      "  3.33524430e-01  7.92368680e-02 -2.59305992e-01 -3.31059192e-02\n",
      " -8.02092312e-01 -1.16328375e+00 -1.57480268e-01  1.06974336e+00\n",
      " -6.33846058e-01  1.16732409e-01 -2.31567381e-01 -5.17122207e-01\n",
      " -7.97216465e-02 -1.09949780e+00 -2.46027086e-01  6.19694928e-02\n",
      "  1.26685884e-01  8.62656059e-01 -9.18352843e-01 -6.21226177e-01\n",
      " -2.00740224e-01 -7.51600981e-01 -1.61011588e+00  5.75820911e-01\n",
      "  6.48995283e-01  3.53741434e-01  7.17218474e-01 -2.84494743e-02\n",
      " -9.54820746e-04 -1.96540899e-01 -1.46351640e-01  6.26946275e-01\n",
      "  4.48207080e-01  2.45945819e-02  4.69223657e-02 -4.91067746e-01\n",
      " -2.03035424e-01 -1.63303680e-01 -1.76623501e-02 -1.11328323e-01\n",
      " -9.94618240e-02 -1.17391916e+00  1.80702678e-01 -6.92720004e-02\n",
      "  9.76496905e-01  4.60988601e-01 -4.95440416e-01 -1.27203531e+00\n",
      "  4.86772406e-01 -8.98963733e-01 -6.00542591e-02 -3.50848853e-01\n",
      "  4.32815220e-01  5.94120150e-01  5.82151924e-01 -6.20962283e-01\n",
      " -5.97480378e-02  9.29035250e-02 -1.51892101e-01 -5.38528893e-03\n",
      "  3.41609087e-02 -2.89088236e-01  1.56053911e-01  4.95401243e-01\n",
      "  8.90942264e-01  1.49151436e-01  3.42484779e-01 -3.13312160e-01\n",
      " -3.55939108e-01 -3.62494608e-01 -6.67247475e-01 -4.08831130e-01\n",
      "  4.47489832e-01  1.37768931e-01  1.41351233e-01 -1.16015421e-01\n",
      " -5.61032710e-02 -9.34583042e-01 -2.92596523e-02 -2.99012958e-01\n",
      " -1.50511251e-01  3.52331870e-01 -7.85846536e-01  5.80200207e-01\n",
      "  4.97042311e-01 -1.90320740e-01 -3.47717245e-04  1.74993805e-01\n",
      " -4.88202695e-01 -3.12259616e-01 -1.02643023e+00 -7.22310834e-01\n",
      "  1.44672469e+00  1.15520745e+00 -6.80202902e-01 -1.21195630e+00\n",
      " -7.98338505e-01 -5.34648484e-01 -1.34552489e+00]\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_1 = [1, 1, 1]\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec_1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(X_train, Y_train)\n",
    "ypred_1 = logic1.predict(X_test)\n",
    "acc_1 = np.sum(ypred_1 == Y_test) / len(ypred_1)\n",
    "print(\"Accuracy of case 1 =\", acc_1)\n",
    "print(\"weights = \", logic1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64849,
     "status": "ok",
     "timestamp": 1604391542532,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "T0wuVL2DEqzS",
    "outputId": "0f502aed-b142-420a-9a7c-9fc8e13400fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of case 2 = 0.8477423638778221\n",
      "weights =  [ 0.25833063  0.35307341  2.33348255  0.7378757   0.33385106  0.07926886\n",
      " -0.04219572  0.1998764  -0.58360968 -0.93671312  0.07548468  1.28715744\n",
      " -0.37140327  0.39422898  0.04305748 -0.26147348  0.19559029 -0.42695771\n",
      "  0.42695771  0.16424528  0.22840772  0.96472553 -0.81743779 -0.52074423\n",
      " -0.09910239 -0.64944042 -1.55235098  0.6786798   0.75066429  0.45541098\n",
      "  0.81857112  0.07308911  0.0728464  -0.11752644 -0.06282948  0.67242506\n",
      "  0.5040869   0.08799091  0.11435013 -0.38483984 -0.10196309 -0.05145374\n",
      "  0.10741777 -0.01997934  0.01717544 -1.16567808  0.30082277  0.02715464\n",
      "  1.00831207  0.50210397 -0.45756662 -1.24002555  0.52780939 -0.86832688\n",
      " -0.02771494 -0.31412701  0.47343435  0.62981111  0.62405658 -0.5867506\n",
      " -0.0296708   0.12414401 -0.14376238  0.02434194  0.0621604  -0.24843986\n",
      "  0.19459429  0.52620501  0.93165615  0.18707696  0.37950109 -0.28749402\n",
      " -0.31137357 -0.33290534 -0.65117786 -0.38160106  0.48879121  0.17662205\n",
      "  0.17410342 -0.07343502 -0.0314651  -0.89846776  0.00653561 -0.27232555\n",
      " -0.12442075  0.39697177 -0.75318727  0.61067658  0.70544004  0.01789988\n",
      "  0.2090388   0.382747   -0.2795817  -0.10453082 -0.9310132  -0.52642474\n",
      "  1.61398954  1.36735898 -0.49235221 -1.01493649 -0.60567591 -0.34195917\n",
      " -3.17508577]\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_2 = [1, 1, 0]\n",
    "logic2 = mylogistic_l2(reg_vec = lambda_vec_2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic2.fit(X_train, Y_train)\n",
    "ypred_2 = logic2.predict(X_test)\n",
    "acc_2 = np.sum(ypred_2 == Y_test) / len(ypred_2)\n",
    "print(\"Accuracy of case 2 =\", acc_2)\n",
    "print(\"weights = \", logic2.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125894,
     "status": "ok",
     "timestamp": 1604391606140,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "e-rIZkHSEq8b",
    "outputId": "45f15a97-8430-44b4-b045-682ba79e52ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of case 3 = 0.847675962815405\n",
      "weights =  [ 0.25851661  0.3533387   2.33562764  0.7825921   0.33439916  0.07940036\n",
      " -0.08347988  0.23309134 -0.59278098 -0.9224849   0.11139573  1.25425869\n",
      " -0.38299462  0.41291781  0.04136013 -0.26411462  0.19283128 -0.42890321\n",
      "  0.42890321  0.23635122  0.30021361  1.03810521 -0.75216086 -0.4534137\n",
      " -0.02691157 -0.5825269  -2.00075382  0.75127891  0.82696617  0.52830705\n",
      "  0.89488994  0.14510375  0.18253094 -0.02583999  0.00991404  0.89862004\n",
      "  0.68517002  0.23294385  0.24519931 -0.38363083 -0.08029608 -0.06493444\n",
      "  0.0453608   0.03743376 -0.01295908 -2.09374319  0.25763304  0.06659781\n",
      "  1.18748312  0.55059265 -0.47576613 -1.45842154  0.5822242  -1.0627833\n",
      " -0.00957211 -0.31704572  0.52485137  0.73044517  0.67457228 -0.63624179\n",
      " -0.00967268  0.17339113 -0.2364757   0.0375474   0.10120874 -0.24679341\n",
      "  0.23800627  0.64228457  1.00567032  0.23258941  0.42267607 -0.35336167\n",
      " -0.29178766 -0.38125401 -0.96291964 -0.45007954  0.512985    0.22019382\n",
      "  0.22640627 -0.04989103 -0.01836864 -0.95953334  0.01656804 -0.32741555\n",
      " -0.14011404  0.42856024 -0.84476926  0.75121645  0.76670733  0.07638783\n",
      "  0.26824615  0.44314098 -0.2205815  -0.04631789 -1.28758289 -0.57187068\n",
      "  1.82502287  1.39622511 -0.54691696 -1.05894077 -0.65551468 -0.38800489\n",
      " -3.36269033]\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_3 = [1, 0.5, 0]\n",
    "logic3 = mylogistic_l2(reg_vec = lambda_vec_3, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic3.fit(X_train, Y_train)\n",
    "ypred_3 = logic3.predict(X_test)\n",
    "acc_3 = np.sum(ypred_3 == Y_test) / len(ypred_3)\n",
    "print(\"Accuracy of case 3 =\", acc_3)\n",
    "print(\"weights = \", logic3.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR3vcIgLNvv9"
   },
   "source": [
    "#### Q3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 940,
     "status": "ok",
     "timestamp": 1604488974977,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "NhoAOEovJ-nS"
   },
   "outputs": [],
   "source": [
    "subtrain_ratio = 0.9\n",
    "tuning_ratio = 0.1 \n",
    "X_subtrain, X_tuning = np.split(X_train,[int(0.9 * X_train.shape[0])])\n",
    "Y_subtrain, Y_tuning = np.split(Y_train,[int(0.9 * Y_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 696251,
     "status": "ok",
     "timestamp": 1604420179799,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "G4dBA-AoP1-Y"
   },
   "outputs": [],
   "source": [
    "hyperparam_list = [0.01, 0.05, 0.1, 0.5, 1, 3, 5, 6, 7, 8, 10, 20, 50, 100]\n",
    "acc_list = []\n",
    "max_acc = 0\n",
    "max_a = 0\n",
    "for hyperparam in hyperparam_list:\n",
    "    lambda_vec = [hyperparam, hyperparam, 0]\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(X_subtrain, Y_subtrain)\n",
    "    ypred = logic.predict(X_tuning)\n",
    "    acc = np.sum(ypred == Y_tuning) / len(ypred)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        max_a = hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1604422803745,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "CWgb3dm2WK2B",
    "outputId": "67d74a3d-6e88-4f11-b289-8d59e294efd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.05, 0.1, 0.5, 1, 3, 5, 6, 7, 8, 10, 50, 100]\n",
      "[0.843221743453762, 0.843221743453762, 0.843221743453762, 0.8428902883659264, 0.8428902883659264, 0.8438846536294332, 0.8435531985415976, 0.8435531985415976, 0.8428902883659264, 0.8428902883659264, 0.8415644680145841, 0.8418959231024197, 0.8405701027510772]\n",
      "a_1 star and a_2 star =  3\n",
      "0.8438846536294332\n"
     ]
    }
   ],
   "source": [
    "print(hyperparam_list)\n",
    "print(acc_list)\n",
    "print(\"a_1 star and a_2 star = \", max_a)\n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 704388,
     "status": "ok",
     "timestamp": 1604421309826,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "N0oxdayDcbz1"
   },
   "outputs": [],
   "source": [
    "#fixed a_1, find a_2\n",
    "acc_list_2 = []\n",
    "max_acc_2 = 0\n",
    "max_a_2 = 0\n",
    "a_1_star = 3\n",
    "for hyperparam in hyperparam_list:\n",
    "    lambda_vec = [a_1_star, hyperparam, 0]\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(X_subtrain, Y_subtrain)\n",
    "    ypred = logic.predict(X_tuning)\n",
    "    acc = np.sum(ypred == Y_tuning) / len(ypred)\n",
    "    acc_list_2.append(acc)\n",
    "    if acc > max_acc_2:\n",
    "        max_acc_2 = acc\n",
    "        max_a_2 = hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 703385,
     "status": "ok",
     "timestamp": 1604421309828,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "8-OuspI_coF4",
    "outputId": "df1f2ad5-aea9-478c-9f66-26b1f5f410ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.05, 0.1, 0.5, 1, 3, 5, 6, 7, 8, 10, 50, 100]\n",
      "[0.843221743453762, 0.843221743453762, 0.843221743453762, 0.8428902883659264, 0.8428902883659264, 0.8438846536294332, 0.8435531985415976, 0.8428902883659264, 0.8425588332780908, 0.8435531985415976, 0.8425588332780908, 0.8402386476632416, 0.8402386476632416]\n",
      "a_2 star =  3\n",
      "0.8438846536294332\n"
     ]
    }
   ],
   "source": [
    "print(hyperparam_list)\n",
    "print(acc_list_2)\n",
    "print(\"a_2 star = \", max_a_2)\n",
    "print(max_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 664286,
     "status": "ok",
     "timestamp": 1604422659536,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "hfunHnsgcqJ9"
   },
   "outputs": [],
   "source": [
    "#fixed a_2, find a_1\n",
    "max_acc_1 = 0\n",
    "max_a_1 = 0\n",
    "acc_list_1 = []\n",
    "a_2_star = 3\n",
    "for hyperparam in hyperparam_list:\n",
    "    lambda_vec = [hyperparam, a_2_star, 0]\n",
    "    logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic.fit(X_subtrain, Y_subtrain)\n",
    "    ypred = logic.predict(X_tuning)\n",
    "    acc = np.sum(ypred == Y_tuning) / len(ypred)\n",
    "    acc_list_1.append(acc)\n",
    "    if acc > max_acc_1:\n",
    "        max_acc_1 = acc\n",
    "        max_a_1 = hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1604422660263,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "KH7JUgIec6DZ",
    "outputId": "e5e45634-c63f-416f-a4f4-7c4f089754f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.05, 0.1, 0.5, 1, 3, 5, 6, 7, 8, 10, 50, 100]\n",
      "[0.8438846536294332, 0.8438846536294332, 0.8438846536294332, 0.8442161087172688, 0.8438846536294332, 0.8438846536294332, 0.8435531985415976, 0.8435531985415976, 0.8435531985415976, 0.8438846536294332, 0.8435531985415976, 0.8425588332780908, 0.8422273781902552]\n",
      "a_1 star =  0.5\n",
      "0.8442161087172688\n"
     ]
    }
   ],
   "source": [
    "print(hyperparam_list)\n",
    "print(acc_list_1)\n",
    "print(\"a_1 star = \", max_a_1)\n",
    "print(max_acc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63908,
     "status": "ok",
     "timestamp": 1604423218601,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "MYqZMoopDfHJ",
    "outputId": "8bc32b15-2df0-4d06-c4af-6419ccb82cf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model with optimal hyperparameters = 0.848339973439575\n"
     ]
    }
   ],
   "source": [
    "lambda_vec = [max_a_1, max_a_2, 0]\n",
    "logic = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(X_train, Y_train)\n",
    "ypred = logic.predict(X_test)\n",
    "acc = np.sum(ypred == Y_test) / len(ypred)\n",
    "print(\"Accuracy of model with optimal hyperparameters =\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBHWdRJ2BWem"
   },
   "source": [
    "#### Q3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1400,
     "status": "ok",
     "timestamp": 1604490755558,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "xqnhc29OBV1A"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47482,
     "status": "ok",
     "timestamp": 1604490049432,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "vj8elhwH-QqT",
    "outputId": "d2a52178-fdd3-4059-c27b-3ffd0566d4b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01 , tuning accuracy =  0.8405701027510772\n",
      "C =  0.05 , tuning accuracy =  0.8409015578389128\n",
      "C =  0.1 , tuning accuracy =  0.8415644680145841\n",
      "C =  0.3 , tuning accuracy =  0.8438846536294332\n",
      "C =  0.5 , tuning accuracy =  0.8435531985415976\n",
      "C =  1 , tuning accuracy =  0.8428902883659264\n",
      "C =  3 , tuning accuracy =  0.843221743453762\n",
      "C =  5 , tuning accuracy =  0.843221743453762\n",
      "C =  6 , tuning accuracy =  0.843221743453762\n",
      "C =  7 , tuning accuracy =  0.843221743453762\n",
      "C =  8 , tuning accuracy =  0.843221743453762\n",
      "C =  10 , tuning accuracy =  0.843221743453762\n",
      "C =  50 , tuning accuracy =  0.843221743453762\n",
      "C =  100 , tuning accuracy =  0.843221743453762\n",
      "best hyperparam =  0.3\n"
     ]
    }
   ],
   "source": [
    "#tuning hyperparameter\n",
    "max_hyperparam = 0\n",
    "max_acc = 0\n",
    "hyperparam_list = [0.01, 0.05, 0.1, 0.3, 0.5, 1, 3, 5, 6, 7, 8, 10, 50, 100]\n",
    "for hyperparam in hyperparam_list:\n",
    "    clf = LogisticRegression(max_iter = 1000, C = hyperparam).fit(X_subtrain, Y_subtrain)\n",
    "    ypred = clf.predict(X_tuning)\n",
    "    acc = np.sum(ypred == Y_tuning) / len(ypred)\n",
    "    print(\"C = \", hyperparam, \", tuning accuracy = \", acc)\n",
    "    if acc > max_acc:\n",
    "    max_acc = acc\n",
    "    max_hyperparam = hyperparam\n",
    "\n",
    "print(\"best hyperparam = \", max_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2923,
     "status": "ok",
     "timestamp": 1604491352027,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "0prOeiJIA0Z5",
    "outputId": "7a693f1a-b218-4ffe-c5e9-650390a3b46b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.3 , testing accuracy =  0.8484063745019921\n",
      "weights =  [ 0.25717815  0.35206347  2.2957719   0.6949959   0.33276084  0.07885247\n",
      "  0.05534442  0.11574809 -0.54345152 -0.95582312 -0.01762452  1.34809177\n",
      " -0.32812886  0.33197239  0.04393917 -0.24608439  0.2005868  -0.4160256\n",
      "  0.41831071  0.0769559   0.14074843  0.87112262 -0.87406429 -0.58571522\n",
      " -0.18467969 -0.71712791 -0.85143654  0.58815058  0.64420534  0.36391851\n",
      "  0.71363501 -0.01377867 -0.01320054 -0.18074103 -0.10522397  0.37865295\n",
      "  0.30503309 -0.02937531  0.00349633 -0.35723238 -0.10135421 -0.01768056\n",
      "  0.17348879 -0.05605807  0.06371553 -0.41730796  0.34678634  0.00928611\n",
      "  0.60369953  0.37792185 -0.35993256 -0.77470476  0.38645292 -0.50726529\n",
      " -0.04074784 -0.25856586  0.34529122  0.39456984  0.49221836 -0.41676724\n",
      " -0.04247507  0.04379815 -0.05486178  0.01449856  0.01069122 -0.21499405\n",
      "  0.10749424  0.28136522  0.71710014  0.09669757  0.27525339 -0.14772795\n",
      " -0.33021748 -0.21026652 -0.28397817 -0.22676303  0.43359944  0.09017532\n",
      "  0.07988964 -0.0981511  -0.03323252 -0.67736762  0.00558721 -0.14738936\n",
      " -0.0756681   0.33111023 -0.49990081  0.32133482  0.61687502 -0.05832317\n",
      "  0.12830875  0.29866897 -0.35844037 -0.17861918 -0.44618492 -0.40750728\n",
      "  1.04379098  1.30609419 -0.34745209 -0.89817896 -0.46999131 -0.22447041\n",
      " -2.95920899]\n"
     ]
    }
   ],
   "source": [
    "#final model\n",
    "clf_final = LogisticRegression(max_iter = 1000, C = 0.3).fit(X_train, Y_train)\n",
    "ypred = clf_final.predict(X_test)\n",
    "acc = np.sum(ypred == Y_test) / len(ypred)\n",
    "print(\"C = \", 0.3, \", testing accuracy = \", acc)\n",
    "print(\"weights = \", np.append(clf_final.coef_[0], clf_final.intercept_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64706,
     "status": "ok",
     "timestamp": 1604492475087,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "01728102923423697608"
     },
     "user_tz": -480
    },
    "id": "93pMO1P0GFTP",
    "outputId": "87e442ef-e424-45e2-cd05-221aea11a972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mylogisticl2, lambda = 3.33\n",
      "Accuracy = 0.8484063745019921\n",
      "weights =  [ 2.57160813e-01  3.52083121e-01  2.29568097e+00  6.94652378e-01\n",
      "  3.32757736e-01  7.88271612e-02  5.53529760e-02  1.15569300e-01\n",
      " -5.44742135e-01 -9.56462573e-01 -1.77695628e-02  1.34805199e+00\n",
      " -3.29210432e-01  3.31185097e-01  4.36613178e-02 -2.45637700e-01\n",
      "  2.00001717e-01 -4.17166844e-01  4.17166844e-01  7.66192555e-02\n",
      "  1.40326268e-01  8.70720830e-01 -8.74565778e-01 -5.86059116e-01\n",
      " -1.85121375e-01 -7.17560627e-01 -8.53302536e-01  5.87738623e-01\n",
      "  6.43544965e-01  3.63612391e-01  7.13249464e-01 -1.42610185e-02\n",
      " -1.40850612e-02 -1.81554260e-01 -1.05968552e-01  3.75650550e-01\n",
      "  3.04309800e-01 -3.04178028e-02  2.54679900e-03 -3.57330508e-01\n",
      " -1.01661389e-01 -1.76358348e-02  1.74076184e-01 -5.65461314e-02\n",
      "  6.37936444e-02 -4.11255119e-01  3.47149349e-01  8.92833095e-03\n",
      "  6.03729629e-01  3.78060376e-01 -3.60119508e-01 -7.73824445e-01\n",
      "  3.86802976e-01 -5.07860591e-01 -4.06484434e-02 -2.58266428e-01\n",
      "  3.45630128e-01  3.92889697e-01  4.91598300e-01 -4.15506982e-01\n",
      " -4.23076155e-02  4.42314055e-02 -5.38942684e-02  1.41385460e-02\n",
      "  1.08549585e-02 -2.14792194e-01  1.05863612e-01  2.82311963e-01\n",
      "  7.17601574e-01  9.50246082e-02  2.74435097e-01 -1.48373622e-01\n",
      " -3.30938369e-01 -2.10693191e-01 -2.82403734e-01 -2.27228715e-01\n",
      "  4.33370139e-01  8.79017706e-02  8.02470145e-02 -1.00317179e-01\n",
      " -3.32793657e-02 -6.75923316e-01  5.73641231e-03 -1.47949387e-01\n",
      " -7.58219025e-02  3.30850233e-01 -4.98241587e-01  3.22510663e-01\n",
      "  6.16392864e-01 -5.85330641e-02  1.28093667e-01  2.98429973e-01\n",
      " -3.58678930e-01 -1.78803685e-01 -4.46900824e-01 -4.07689111e-01\n",
      "  1.04362743e+00  1.30567807e+00 -3.47769158e-01 -8.98281317e-01\n",
      " -4.70587580e-01 -2.24978342e-01 -2.95580927e+00]\n"
     ]
    }
   ],
   "source": [
    "lambda_vec_final = [3.33, 3.33, 0]\n",
    "logic_final = mylogistic_l2(reg_vec = lambda_vec_final, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic_final.fit(X_train, Y_train)\n",
    "ypred = logic_final.predict(X_test)\n",
    "acc = np.sum(ypred == Y_test) / len(ypred)\n",
    "print(\"mylogisticl2, lambda = 3.33\")\n",
    "print(\"Accuracy =\", acc)\n",
    "print(\"weights = \", logic_final.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從上述結果可以看出使用sklearn logistic regression model，最佳的參數為$\\displaystyle C = 0.3 \\Rightarrow \\lambda = \\frac{1}{0.3} = 3.33$。\n",
    "與使用mylogisticl2並且設定$\\lambda = 3.33$的結果類似，accuracy相同，但weights有些許差距，可能是因為mylogisticl2的Newton-Raphson method，而sklearn logistic regression使用的是Limited-memory BFGS method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
