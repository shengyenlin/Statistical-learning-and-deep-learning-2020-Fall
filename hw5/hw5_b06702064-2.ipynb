{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計學習與深度學習 HW5\n",
    "### 會計四 B06702064 林聖硯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['train', 'valid', 'test']\n",
    "labels = ['blazer', 'cardigan', 'coat', 'jacket']\n",
    "df = pd.DataFrame(index = labels)\n",
    "for data in datasets:\n",
    "    count = []\n",
    "    for label in labels:\n",
    "        basepath = os.path.join(\"photos\", data, label, \"*.jpg\")\n",
    "        pic_num = len(glob.glob(basepath))\n",
    "        count.append(pic_num)\n",
    "    df[data] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blazer</th>\n",
       "      <td>97</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardigan</th>\n",
       "      <td>237</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coat</th>\n",
       "      <td>296</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jacket</th>\n",
       "      <td>411</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train  valid  test\n",
       "blazer       97      7     9\n",
       "cardigan    237     36    42\n",
       "coat        296     27    43\n",
       "jacket      411     35    52"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========In train datasets==========\n",
      "Total number of pictures is 1041.\n",
      "blazer     97 (9.32%)\n",
      "cardigan  237 (22.77%)\n",
      "coat      296 (28.43%)\n",
      "jacket    411 (39.48%)\n",
      "==========In valid datasets==========\n",
      "Total number of pictures is 105.\n",
      "blazer      7 (6.67%)\n",
      "cardigan   36 (34.29%)\n",
      "coat       27 (25.71%)\n",
      "jacket     35 (33.33%)\n",
      "==========In test datasets==========\n",
      "Total number of pictures is 146.\n",
      "blazer      9 (6.16%)\n",
      "cardigan   42 (28.77%)\n",
      "coat       43 (29.45%)\n",
      "jacket     52 (35.62%)\n"
     ]
    }
   ],
   "source": [
    "for subset in datasets:\n",
    "    category_ttl = df[subset]\n",
    "    subset_ttl = category_ttl.sum()\n",
    "    label_percentage = df.div(df.sum(axis=0), axis=1)[subset] * 100\n",
    "    print(\"=\" * 10 +\"In {} datasets\".format(subset) + \"=\" * 10)\n",
    "    print(\"Total number of pictures is {}.\".format(subset_ttl))\n",
    "    for index, value in label_percentage.iteritems():\n",
    "        print(\"{:<8} {:>4} ({:.2f}%)\".format(index, category_ttl[index], value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從上面的結果可以看出，training dataset各類別的比例從大致小分別為 jacket, coat, cardigan, blazer。因此可以預估jacket, coat和cardigan三個label在預測上的準確度上會比較高，且Jacket應該高於coat，coat應該高於cardigan。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from google.colab import drive\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from timeit import default_timer as timer\n",
    "import helper\n",
    "drive.mount('/content/gdrive') # 此處需要登入google帳號"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(17)\n",
    "url_prefix = '/content/gdrive/My Drive/SLDL/hw5/photos'\n",
    "image_transforms = {'train':transforms.Compose([transforms.Resize(size=256),\n",
    "                     transforms.RandomCrop(size=224),\n",
    "                     transforms.RandomHorizontalFlip(),\n",
    "                     transforms.RandomRotation(degrees = (-20, 20)),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                     ]),\n",
    "            'valid': transforms.Compose([transforms.Resize(size = 256),\n",
    "                    transforms.CenterCrop(size =224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), #??\n",
    "                    ]),\n",
    "            'test': transforms.Compose([transforms.Resize(size = 256),\n",
    "                    transforms.CenterCrop(size =224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), #??\n",
    "                    ])\n",
    "            }\n",
    "data = {'train':datasets.ImageFolder(root=url_prefix + \"/train\", transform=image_transforms['train']),\n",
    "    'valid':datasets.ImageFolder(root=url_prefix + \"/valid\", transform=image_transforms['valid']),\n",
    "    'test':datasets.ImageFolder(root=url_prefix + \"/test\", transform=image_transforms['test'])\n",
    "}\n",
    "\n",
    "batch_size = 32\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(data['valid'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model(isFreeze = False, isPretrained = True):\n",
    "    if isPretrained == True:\n",
    "        model = models.resnet50(pretrained = True)\n",
    "    if isPretrained == False:\n",
    "        model = models.resnet50(pretrained = False)\n",
    "\n",
    "    if isFreeze == True:\n",
    "        # Freeze model weights\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    n_classes = 4 #output : 4 calsses\n",
    "    n_inputs = model.fc.in_features\n",
    "    model.fc = torch.nn.Sequential(\n",
    "      torch.nn.Linear(n_inputs, 256),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Dropout(),\n",
    "      torch.nn.Linear(256, n_classes),\n",
    "      torch.nn.LogSoftmax(dim = 1)\n",
    "    )\n",
    "    return model\n",
    "model = reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1610527011915,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "XDVEw_O6Qj1y",
    "outputId": "80544e26-2dea-48de-a390-b03d4ce3ebc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'blazer'), (1, 'cardigan'), (2, 'coat'), (3, 'jacket')]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.class_to_idx = data['train'].class_to_idx\n",
    "model.idx_to_class = {\n",
    "    idx: class_\n",
    "    for class_, idx in model.class_to_idx.items()\n",
    "}\n",
    "list(model.idx_to_class.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1610527012465,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "N2vE_IAr46qb"
   },
   "outputs": [],
   "source": [
    "#number of output\n",
    "n_classes = 4\n",
    "classnames = [model.idx_to_class[i] for i in range(0, n_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1317,
     "status": "aborted",
     "timestamp": 1610526387365,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "bUijVrgJQku6"
   },
   "outputs": [],
   "source": [
    "class Resnet50():\n",
    "    def __init__(self):\n",
    "        self.trainLoss = list()\n",
    "        self.validLoss = list()\n",
    "        self.trainAcc = list()\n",
    "        self.validAcc = list()\n",
    "        self.criterion = torch.nn.NLLLoss()\n",
    "        self.best_valid_loss = 0\n",
    "\n",
    "    def train(self, train_on_gpu, model, nepoch, optimizer, save_file_name, train_loader, valid_loader, verbose = True):\n",
    "        # Early stopping\n",
    "        min_valid_loss = 10000000\n",
    "        best_epoch = 0\n",
    "        patience = 20\n",
    "        overall_start = 0\n",
    "        for epoch_idx in range(1, nepoch+1):\n",
    "            #1 epoch = 33 batch (1 batch = 32 data points)\n",
    "            # keep track of training and validation loss each epoch\n",
    "            train_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            train_acc = 0\n",
    "            valid_acc = 0\n",
    "            \n",
    "            model.train()\n",
    "            start = timer()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Track train loss by multiplying average loss by number of examples in batch\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "\n",
    "                # Calculate accuracy by finding max log probability\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                # Need to convert correct tensor from int to float to average\n",
    "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "\n",
    "                # Multiply average accuracy times the number of examples in batch\n",
    "                train_acc += accuracy.item() * data.size(0)\n",
    "                #print(train_acc)\n",
    "\n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "            train_acc = train_acc / len(train_loader.dataset)\n",
    "            valid_loss, valid_acc = self.validation(model, train_on_gpu, valid_loader)\n",
    "            self.trainAcc.append(train_acc)\n",
    "            self.trainLoss.append(train_loss)\n",
    "            self.validAcc.append(valid_acc)\n",
    "            self.validLoss.append(valid_loss)\n",
    "      \n",
    "            if verbose == True:\n",
    "                print(\"Epoch {}: {:.3f} seconds elapsed in epoch.\".format(epoch_idx, timer() - start))\n",
    "                print(\"Epoch {}: training loss = {:.3f} (accuracy: {:.3f}%), validation loss = {:.3f} (accuracy: {:.3f}%)\".format(epoch_idx, train_loss, train_acc*100, valid_loss, valid_acc * 100))\n",
    "        \n",
    "            if valid_loss < min_valid_loss:\n",
    "                best_epoch = epoch_idx\n",
    "                min_valid_loss = valid_loss\n",
    "                best_model = model\n",
    "                torch.save(model.state_dict(), save_file_name)\n",
    "\n",
    "            #Early Stopping  \n",
    "            if epoch_idx >= best_epoch + patience and valid_loss > min_valid_loss:\n",
    "                if verbose == True:\n",
    "                total_time = timer() - overall_start\n",
    "                self.best_valid_loss = min_valid_loss\n",
    "                print('Early stopping!')\n",
    "                print('='*50 + 'validation result' + '='*50)\n",
    "                print('the best epoch is {} with minimum validation error = {}'.format(best_epoch, min_valid_loss))\n",
    "                print(\"{:.3f} total second elapsed\".format(total_time)) \n",
    "            return best_model\n",
    "        if verbose == True:\n",
    "            total_time = timer() - overall_start\n",
    "            self.best_valid_loss = min_valid_loss\n",
    "            print('='*50 + 'result' + '='*50)\n",
    "            print('the best epoch is {} with minimum validation error = {}'.format(best_epoch, min_valid_loss))\n",
    "            print(\"{:.3f} total second elapsed\".format(total_time)) \n",
    "        return best_model\n",
    "\n",
    "\n",
    "    def validation(self, model, train_on_gpu, valid_loader):\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            #1 epoch = 4 batch\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):  \n",
    "                if train_on_gpu:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                output = model(data)        \n",
    "                loss = self.criterion(output, target)\n",
    "                # Multiply average loss times the number of examples in batch\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "                # Calculate validation accuracy\n",
    "                _, pred = torch.max(output, dim=1)\n",
    "                correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "                # Multiply average accuracy times the number of examples\n",
    "                valid_acc += accuracy.item() * data.size(0)\n",
    "            valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "            valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "        return valid_loss, valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1610526894929,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "JmJpAMKqrCym"
   },
   "outputs": [],
   "source": [
    "def test(train_on_gpu, model, test_loader):\n",
    "    if train_on_gpu:\n",
    "        model = model.to('cuda')\n",
    "    test_acc = 0\n",
    "    confusion_matrix = torch.zeros(n_classes, n_classes)\n",
    "    classes = []\n",
    "    i = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            if train_on_gpu:\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "            # Raw model output\n",
    "            output = model(data)\n",
    "            _, pred = torch.max(output, dim = 1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            test_acc += accuracy.item() * data.size(0)\n",
    "            #confusion matrix\n",
    "            for t, p in zip(target.view(-1), pred.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "        test_acc = test_acc / len(test_loader.dataset)\n",
    "    return test_acc, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1610527139857,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "4wiZecxqqzAP"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.savefig(f'outputs/confusion_matrix.png')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4M7XhYP-Xku"
   },
   "outputs": [],
   "source": [
    "#load model from folder\n",
    "def load_model(num_question, optimizer, lr, weight):\n",
    "    pos = \"/content/gdrive/My Drive/SLDL/hw5/\"+ num_question + \"/\" + optimizer + \"/resnet50_lr_\" +  str(lr) + \"_weight_\" + str(weight) + \".pt\"\n",
    "    model = torch.load(pos)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXUiJPIP-bCK"
   },
   "outputs": [],
   "source": [
    "def print_result(question_number, optimizer, lr, weight_decay):\n",
    "    #learning rate = 0.00001, weight decay = 0.1 (&weight decay = 0.0)\n",
    "    model = reset_model()\n",
    "    state_dict = load_model(question_number, optimizer, lr, weight_decay)\n",
    "    model.load_state_dict(state_dict)\n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "    test_acc, confusion_matrix = test(train_on_gpu, model, dataloaders['test'])\n",
    "    print(\"=\" * 50 + \"{} result\".format(question_number) + \"=\" * 50)\n",
    "    print(\"when optimizer = {}, learning rate = {}, weight decay = {}, overall testing accuracy = {:.3f}\".format(optimizer, lr, weight_decay, test_acc))\n",
    "    #get per class accuracy\n",
    "    label = [\"blazer\", \"cardigan\", \"coat\", \"jacket\"]\n",
    "    for i in range(n_classes):\n",
    "        num_true = confusion_matrix[i].sum().data.tolist()\n",
    "        num_pred_correct = confusion_matrix[i][i].data.tolist()\n",
    "        acc = num_pred_correct / num_true\n",
    "        print(\"label = {}, per class accuracy = {}\".format(label[i], acc))\n",
    "    plt = plot_confusion_matrix(confusion_matrix, classnames)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下每題的順序都是先Tune Hyperparameters，最後再進行Testing，每個Optimizer我都挑兩個Valid Loss最小的模型進行Testing。到後面有一些模型和前面的learning rate和weight decay不一樣是因為有一些要跑太久，但Accuracy沒有上升，故後面的model把這些不好的hyperparameter去除。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model架構：\n",
    "1. 將Pretrain好的Model，加上一層(input, output)為(n_input, 256)的linear layer，經過一層dropout layer後，最後才進入output layer。\n",
    "2. Loss Function為 Negative Log Likelihood Loss(NLL Loss)，所以對應的output layer的activation function為LogSoftmax function。\n",
    "\n",
    "colab 連結：\n",
    "https://colab.research.google.com/drive/1QBrHfVpvPZ13z30y7FDOkEHMDmVLrLqR?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuGjrBVQS9S3"
   },
   "source": [
    "### Tuning, Optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 27323121,
     "status": "ok",
     "timestamp": 1610266110972,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "aS4Q4sgCTAl3",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0dc56f34-be1c-442c-f1be-d99c519e1009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: learning rate = 0.0005, weight decay = 0\n",
      "Epoch 1: 23.412 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.253 (accuracy: 40.058%), validation loss = 4.007 (accuracy: 31.429%)\n",
      "Epoch 2: 23.988 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.152 (accuracy: 50.528%), validation loss = 1.237 (accuracy: 51.429%)\n",
      "Epoch 3: 23.718 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.025 (accuracy: 56.676%), validation loss = 1.178 (accuracy: 52.381%)\n",
      "Epoch 4: 23.522 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.032 (accuracy: 55.524%), validation loss = 1.067 (accuracy: 59.048%)\n",
      "Epoch 5: 23.683 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.906 (accuracy: 64.073%), validation loss = 1.206 (accuracy: 44.762%)\n",
      "Epoch 6: 23.534 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.902 (accuracy: 63.881%), validation loss = 1.576 (accuracy: 49.524%)\n",
      "Epoch 7: 23.476 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.793 (accuracy: 68.108%), validation loss = 1.070 (accuracy: 57.143%)\n",
      "Epoch 8: 23.738 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.813 (accuracy: 69.645%), validation loss = 0.795 (accuracy: 65.714%)\n",
      "Epoch 9: 23.638 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.769 (accuracy: 69.549%), validation loss = 1.670 (accuracy: 53.333%)\n",
      "Epoch 10: 23.580 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.687 (accuracy: 73.583%), validation loss = 1.011 (accuracy: 60.000%)\n",
      "Epoch 11: 23.444 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.684 (accuracy: 75.504%), validation loss = 2.061 (accuracy: 38.095%)\n",
      "Epoch 12: 23.375 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.729 (accuracy: 72.526%), validation loss = 0.752 (accuracy: 73.333%)\n",
      "Epoch 13: 23.589 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.672 (accuracy: 75.024%), validation loss = 0.915 (accuracy: 60.952%)\n",
      "Epoch 14: 23.520 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.573 (accuracy: 79.347%), validation loss = 1.058 (accuracy: 67.619%)\n",
      "Epoch 15: 23.453 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.598 (accuracy: 78.674%), validation loss = 1.038 (accuracy: 68.571%)\n",
      "Epoch 16: 23.412 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.570 (accuracy: 80.596%), validation loss = 0.960 (accuracy: 68.571%)\n",
      "Epoch 17: 23.497 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.552 (accuracy: 80.019%), validation loss = 0.760 (accuracy: 70.476%)\n",
      "Epoch 18: 23.533 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.512 (accuracy: 80.115%), validation loss = 1.102 (accuracy: 59.048%)\n",
      "Epoch 19: 23.450 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.459 (accuracy: 82.805%), validation loss = 0.747 (accuracy: 68.571%)\n",
      "Epoch 20: 23.648 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.491 (accuracy: 83.958%), validation loss = 1.076 (accuracy: 62.857%)\n",
      "Epoch 21: 23.911 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.515 (accuracy: 82.037%), validation loss = 1.202 (accuracy: 64.762%)\n",
      "Epoch 22: 23.470 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.377 (accuracy: 86.647%), validation loss = 1.226 (accuracy: 65.714%)\n",
      "Epoch 23: 23.532 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.393 (accuracy: 85.399%), validation loss = 1.266 (accuracy: 67.619%)\n",
      "Epoch 24: 23.383 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.389 (accuracy: 85.207%), validation loss = 1.246 (accuracy: 63.810%)\n",
      "Epoch 25: 23.507 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.331 (accuracy: 88.184%), validation loss = 1.467 (accuracy: 60.000%)\n",
      "Epoch 26: 23.435 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.459 (accuracy: 83.381%), validation loss = 1.096 (accuracy: 62.857%)\n",
      "Epoch 27: 23.405 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.367 (accuracy: 88.088%), validation loss = 0.857 (accuracy: 71.429%)\n",
      "Epoch 28: 23.464 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.382 (accuracy: 86.744%), validation loss = 1.017 (accuracy: 66.667%)\n",
      "Epoch 29: 23.405 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.361 (accuracy: 88.280%), validation loss = 1.002 (accuracy: 67.619%)\n",
      "Epoch 30: 23.396 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.313 (accuracy: 89.721%), validation loss = 0.992 (accuracy: 71.429%)\n",
      "Epoch 31: 23.490 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.350 (accuracy: 87.416%), validation loss = 1.190 (accuracy: 70.476%)\n",
      "Epoch 32: 23.386 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.314 (accuracy: 89.721%), validation loss = 0.935 (accuracy: 70.476%)\n",
      "Epoch 33: 23.385 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.283 (accuracy: 90.970%), validation loss = 0.904 (accuracy: 70.476%)\n",
      "Epoch 34: 23.767 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.310 (accuracy: 89.817%), validation loss = 0.841 (accuracy: 73.333%)\n",
      "Epoch 35: 23.508 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.257 (accuracy: 91.643%), validation loss = 1.835 (accuracy: 58.095%)\n",
      "Epoch 36: 23.468 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.282 (accuracy: 89.914%), validation loss = 1.125 (accuracy: 62.857%)\n",
      "Epoch 37: 23.274 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.312 (accuracy: 88.953%), validation loss = 1.267 (accuracy: 62.857%)\n",
      "Epoch 38: 23.465 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.203 (accuracy: 92.699%), validation loss = 1.373 (accuracy: 68.571%)\n",
      "Epoch 39: 23.330 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.299 (accuracy: 90.586%), validation loss = 1.100 (accuracy: 61.905%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 19 with minimum validation error = 0.7474824241229466\n",
      "2242.075 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.1\n",
      "Epoch 1: 23.413 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.223 (accuracy: 45.245%), validation loss = 1.343 (accuracy: 37.143%)\n",
      "Epoch 2: 23.625 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.272 (accuracy: 40.154%), validation loss = 1.326 (accuracy: 33.333%)\n",
      "Epoch 3: 23.535 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.313 (accuracy: 37.464%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 4: 23.551 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.281 (accuracy: 39.289%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 5: 23.579 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.294 (accuracy: 39.097%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 6: 23.593 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.290 (accuracy: 39.289%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 7: 23.305 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.296 (accuracy: 39.481%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 8: 23.887 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 9: 23.427 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.297 (accuracy: 38.905%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 10: 23.440 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.287 (accuracy: 39.385%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 11: 23.232 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 12: 23.265 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.294 (accuracy: 39.385%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 13: 23.417 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.290 (accuracy: 39.481%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 14: 23.289 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.297 (accuracy: 39.481%), validation loss = 1.325 (accuracy: 33.333%)\n",
      "Epoch 15: 23.204 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.298 (accuracy: 39.385%), validation loss = 1.379 (accuracy: 33.333%)\n",
      "Epoch 16: 23.222 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.290 (accuracy: 39.481%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 17: 23.198 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.288 (accuracy: 39.673%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 18: 23.156 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.287 (accuracy: 39.385%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 19: 23.118 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.290 (accuracy: 39.289%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 20: 23.376 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.289 (accuracy: 39.481%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 21: 23.265 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.289 (accuracy: 39.481%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 22: 23.494 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 23: 23.410 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.301 (accuracy: 39.481%), validation loss = 1.334 (accuracy: 33.333%)\n",
      "Epoch 24: 22.938 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 25: 23.048 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 26: 23.024 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.284 (accuracy: 39.481%), validation loss = 1.318 (accuracy: 33.333%)\n",
      "Epoch 27: 23.107 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.284 (accuracy: 39.481%), validation loss = 1.329 (accuracy: 33.333%)\n",
      "Epoch 28: 22.919 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.286 (accuracy: 39.481%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 29: 23.002 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.295 (accuracy: 39.481%), validation loss = 1.316 (accuracy: 33.333%)\n",
      "Epoch 30: 23.049 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.286 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 31: 22.905 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.286 (accuracy: 39.481%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 32: 22.848 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.283 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 33: 22.855 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.279 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 34: 22.908 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.278 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 35: 23.241 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.282 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 36: 22.943 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.280 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 37: 22.838 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.285 (accuracy: 39.481%), validation loss = 1.319 (accuracy: 33.333%)\n",
      "Epoch 38: 22.798 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.275 (accuracy: 39.481%), validation loss = 1.321 (accuracy: 33.333%)\n",
      "Epoch 39: 22.694 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.284 (accuracy: 39.481%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 40: 22.851 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.282 (accuracy: 39.481%), validation loss = 1.318 (accuracy: 33.333%)\n",
      "Epoch 41: 22.798 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 42: 22.686 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.278 (accuracy: 39.481%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 22 with minimum validation error = 1.2848013185319447\n",
      "3219.815 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.2\n",
      "Epoch 1: 23.503 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.267 (accuracy: 41.787%), validation loss = 1.367 (accuracy: 25.714%)\n",
      "Epoch 2: 23.649 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.303 (accuracy: 39.577%), validation loss = 1.326 (accuracy: 33.333%)\n",
      "Epoch 3: 23.609 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.305 (accuracy: 38.136%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 4: 23.509 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.304 (accuracy: 38.905%), validation loss = 2.121 (accuracy: 33.333%)\n",
      "Epoch 5: 23.455 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.294 (accuracy: 39.385%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 6: 23.651 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.301 (accuracy: 39.769%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 7: 23.699 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.291 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 8: 23.306 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.302 (accuracy: 39.481%), validation loss = 1.352 (accuracy: 33.333%)\n",
      "Epoch 9: 23.040 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 10: 22.897 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.310 (accuracy: 39.481%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 11: 22.832 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.295 (accuracy: 39.481%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 12: 22.952 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 13: 23.076 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 14: 22.924 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.290 (accuracy: 39.481%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 15: 22.779 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.305 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 16: 22.864 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 17: 22.778 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.297 (accuracy: 39.481%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 18: 22.739 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 19: 22.779 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.294 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 20: 23.154 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 21: 22.638 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.291 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 22: 22.705 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.299 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 23: 22.655 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 24: 22.585 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.288 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 25: 22.580 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 26: 22.619 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.296 (accuracy: 39.481%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 27: 22.626 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.393 (accuracy: 33.333%)\n",
      "Epoch 28: 22.558 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.295 (accuracy: 39.481%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 29: 22.530 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.290 (accuracy: 39.481%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 30: 22.585 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.316 (accuracy: 33.333%)\n",
      "Epoch 31: 22.466 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.285 (accuracy: 39.481%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 32: 22.447 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.325 (accuracy: 33.333%)\n",
      "Epoch 33: 22.601 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.328 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 13 with minimum validation error = 1.293412672905695\n",
      "3979.965 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.4\n",
      "Epoch 1: 23.205 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.253 (accuracy: 42.267%), validation loss = 1.364 (accuracy: 33.333%)\n",
      "Epoch 2: 23.095 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.277 (accuracy: 41.979%), validation loss = 1.349 (accuracy: 33.333%)\n",
      "Epoch 3: 23.047 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.302 (accuracy: 38.905%), validation loss = 1.348 (accuracy: 33.333%)\n",
      "Epoch 4: 23.177 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.306 (accuracy: 39.481%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 5: 23.082 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.294 (accuracy: 39.481%), validation loss = 1.322 (accuracy: 33.333%)\n",
      "Epoch 6: 22.862 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.295 (accuracy: 39.481%), validation loss = 1.330 (accuracy: 33.333%)\n",
      "Epoch 7: 23.081 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.305 (accuracy: 39.481%), validation loss = 1.335 (accuracy: 33.333%)\n",
      "Epoch 8: 22.907 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.304 (accuracy: 39.481%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 9: 22.806 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.291 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 10: 22.934 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.296 (accuracy: 39.481%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 11: 22.838 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.296 (accuracy: 39.481%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 12: 22.927 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.297 (accuracy: 39.481%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 13: 22.890 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.294 (accuracy: 39.481%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 14: 23.108 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.307 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 15: 22.714 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.306 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 16: 22.653 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.307 (accuracy: 39.481%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 17: 22.630 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.300 (accuracy: 39.481%), validation loss = 1.319 (accuracy: 33.333%)\n",
      "Epoch 18: 22.729 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.304 (accuracy: 39.481%), validation loss = 1.323 (accuracy: 33.333%)\n",
      "Epoch 19: 22.950 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.308 (accuracy: 39.481%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 20: 23.421 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.309 (accuracy: 39.481%), validation loss = 1.331 (accuracy: 33.333%)\n",
      "Epoch 21: 23.477 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.311 (accuracy: 39.481%), validation loss = 1.338 (accuracy: 33.333%)\n",
      "Epoch 22: 23.095 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.328 (accuracy: 39.481%), validation loss = 1.338 (accuracy: 33.333%)\n",
      "Epoch 23: 22.939 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.327 (accuracy: 39.481%), validation loss = 1.344 (accuracy: 33.333%)\n",
      "Epoch 24: 22.885 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.337 (accuracy: 39.481%), validation loss = 1.349 (accuracy: 33.333%)\n",
      "Epoch 25: 22.884 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.342 (accuracy: 39.481%), validation loss = 1.349 (accuracy: 33.333%)\n",
      "Epoch 26: 22.802 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.341 (accuracy: 39.481%), validation loss = 1.348 (accuracy: 33.333%)\n",
      "Epoch 27: 23.079 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.340 (accuracy: 39.481%), validation loss = 1.347 (accuracy: 33.333%)\n",
      "Epoch 28: 22.894 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.338 (accuracy: 39.481%), validation loss = 1.346 (accuracy: 33.333%)\n",
      "Epoch 29: 22.671 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.337 (accuracy: 39.481%), validation loss = 1.345 (accuracy: 33.333%)\n",
      "Epoch 30: 22.585 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.336 (accuracy: 39.481%), validation loss = 1.344 (accuracy: 33.333%)\n",
      "Epoch 31: 22.516 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.334 (accuracy: 39.481%), validation loss = 1.344 (accuracy: 33.333%)\n",
      "Epoch 32: 22.563 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.333 (accuracy: 39.481%), validation loss = 1.343 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 12 with minimum validation error = 1.3034743195488339\n",
      "4716.684 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.9\n",
      "Epoch 1: 23.276 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.296 (accuracy: 38.040%), validation loss = 1.367 (accuracy: 33.333%)\n",
      "Epoch 2: 23.342 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.314 (accuracy: 40.250%), validation loss = 1.379 (accuracy: 31.429%)\n",
      "Epoch 3: 23.062 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.341 (accuracy: 39.001%), validation loss = 1.375 (accuracy: 33.333%)\n",
      "Epoch 4: 23.251 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.335 (accuracy: 39.385%), validation loss = 1.369 (accuracy: 33.333%)\n",
      "Epoch 5: 23.100 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.316 (accuracy: 39.481%), validation loss = 1.369 (accuracy: 33.333%)\n",
      "Epoch 6: 23.032 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.317 (accuracy: 39.481%), validation loss = 1.365 (accuracy: 33.333%)\n",
      "Epoch 7: 23.334 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.340 (accuracy: 39.481%), validation loss = 1.350 (accuracy: 33.333%)\n",
      "Epoch 8: 23.537 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.327 (accuracy: 39.481%), validation loss = 1.347 (accuracy: 33.333%)\n",
      "Epoch 9: 23.735 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.336 (accuracy: 39.481%), validation loss = 1.350 (accuracy: 33.333%)\n",
      "Epoch 10: 23.221 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.343 (accuracy: 39.481%), validation loss = 1.356 (accuracy: 33.333%)\n",
      "Epoch 11: 23.136 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.338 (accuracy: 39.481%), validation loss = 1.356 (accuracy: 33.333%)\n",
      "Epoch 12: 23.054 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.362 (accuracy: 33.333%)\n",
      "Epoch 13: 23.028 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.360 (accuracy: 39.481%), validation loss = 1.365 (accuracy: 33.333%)\n",
      "Epoch 14: 22.912 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.359 (accuracy: 39.481%), validation loss = 1.363 (accuracy: 33.333%)\n",
      "Epoch 15: 22.785 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.357 (accuracy: 39.481%), validation loss = 1.362 (accuracy: 33.333%)\n",
      "Epoch 16: 22.680 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.356 (accuracy: 39.481%), validation loss = 1.361 (accuracy: 33.333%)\n",
      "Epoch 17: 22.665 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.355 (accuracy: 39.481%), validation loss = 1.360 (accuracy: 33.333%)\n",
      "Epoch 18: 22.732 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.354 (accuracy: 39.481%), validation loss = 1.360 (accuracy: 33.333%)\n",
      "Epoch 19: 22.647 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 20: 22.649 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.358 (accuracy: 33.333%)\n",
      "Epoch 21: 22.780 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.358 (accuracy: 33.333%)\n",
      "Epoch 22: 22.840 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.351 (accuracy: 39.481%), validation loss = 1.358 (accuracy: 33.333%)\n",
      "Epoch 23: 22.739 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.351 (accuracy: 39.481%), validation loss = 1.357 (accuracy: 33.333%)\n",
      "Epoch 24: 23.293 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.351 (accuracy: 39.481%), validation loss = 1.357 (accuracy: 33.333%)\n",
      "Epoch 25: 23.460 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.350 (accuracy: 39.481%), validation loss = 1.357 (accuracy: 33.333%)\n",
      "Epoch 26: 23.044 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.350 (accuracy: 39.481%), validation loss = 1.357 (accuracy: 33.333%)\n",
      "Epoch 27: 22.935 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.350 (accuracy: 39.481%), validation loss = 1.357 (accuracy: 33.333%)\n",
      "Epoch 28: 22.924 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.350 (accuracy: 39.481%), validation loss = 1.357 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 8 with minimum validation error = 1.3470738388243175\n",
      "5364.018 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 1\n",
      "Epoch 1: 23.566 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.277 (accuracy: 38.809%), validation loss = 1.360 (accuracy: 34.286%)\n",
      "Epoch 2: 23.675 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.291 (accuracy: 39.577%), validation loss = 1.371 (accuracy: 34.286%)\n",
      "Epoch 3: 23.537 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.349 (accuracy: 38.713%), validation loss = 1.368 (accuracy: 33.333%)\n",
      "Epoch 4: 23.400 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.321 (accuracy: 39.481%), validation loss = 1.366 (accuracy: 33.333%)\n",
      "Epoch 5: 23.301 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.320 (accuracy: 39.481%), validation loss = 1.365 (accuracy: 33.333%)\n",
      "Epoch 6: 23.362 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.336 (accuracy: 39.481%), validation loss = 1.363 (accuracy: 33.333%)\n",
      "Epoch 7: 23.452 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.330 (accuracy: 39.481%), validation loss = 1.362 (accuracy: 33.333%)\n",
      "Epoch 8: 23.638 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.346 (accuracy: 39.481%), validation loss = 1.363 (accuracy: 33.333%)\n",
      "Epoch 9: 23.218 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.351 (accuracy: 39.481%), validation loss = 1.364 (accuracy: 33.333%)\n",
      "Epoch 10: 23.320 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.357 (accuracy: 39.481%), validation loss = 1.363 (accuracy: 33.333%)\n",
      "Epoch 11: 23.196 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.358 (accuracy: 39.481%), validation loss = 1.362 (accuracy: 33.333%)\n",
      "Epoch 12: 23.182 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.357 (accuracy: 39.481%), validation loss = 1.361 (accuracy: 33.333%)\n",
      "Epoch 13: 23.102 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.356 (accuracy: 39.481%), validation loss = 1.360 (accuracy: 33.333%)\n",
      "Epoch 14: 23.257 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.355 (accuracy: 39.481%), validation loss = 1.360 (accuracy: 33.333%)\n",
      "Epoch 15: 23.069 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.354 (accuracy: 39.481%), validation loss = 1.360 (accuracy: 33.333%)\n",
      "Epoch 16: 23.173 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.354 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 17: 22.985 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 18: 23.048 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 19: 23.400 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 20: 23.760 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 21: 23.777 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 22: 23.131 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 23: 23.214 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.353 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 24: 23.263 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 25: 22.937 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 26: 23.038 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 27: 22.875 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 28: 22.757 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 29: 22.683 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 30: 22.810 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 31: 22.689 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 32: 22.743 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.358 (accuracy: 33.333%)\n",
      "Epoch 33: 22.779 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.358 (accuracy: 33.333%)\n",
      "Epoch 34: 22.759 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 35: 22.651 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 36: 22.493 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 37: 22.409 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 38: 22.450 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 39: 22.570 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 40: 22.699 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 41: 22.640 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 42: 22.555 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 43: 22.357 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 44: 22.613 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 45: 22.646 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 46: 22.582 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 47: 22.460 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 48: 22.955 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 49: 22.647 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 50: 22.656 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 51: 22.549 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Epoch 52: 22.806 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.352 (accuracy: 39.481%), validation loss = 1.359 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 32 with minimum validation error = 1.35843513466063\n",
      "6564.113 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0\n",
      "Epoch 1: 23.823 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.215 (accuracy: 46.013%), validation loss = 1.039 (accuracy: 51.429%)\n",
      "Epoch 2: 23.985 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 0.842 (accuracy: 66.282%), validation loss = 0.663 (accuracy: 73.333%)\n",
      "Epoch 3: 24.002 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 0.616 (accuracy: 77.041%), validation loss = 0.817 (accuracy: 68.571%)\n",
      "Epoch 4: 23.933 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 0.461 (accuracy: 84.054%), validation loss = 0.575 (accuracy: 80.952%)\n",
      "Epoch 5: 24.003 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.314 (accuracy: 88.953%), validation loss = 0.706 (accuracy: 71.429%)\n",
      "Epoch 6: 23.845 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.270 (accuracy: 90.106%), validation loss = 0.608 (accuracy: 77.143%)\n",
      "Epoch 7: 23.937 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.207 (accuracy: 93.084%), validation loss = 0.800 (accuracy: 74.286%)\n",
      "Epoch 8: 23.784 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.220 (accuracy: 92.315%), validation loss = 0.659 (accuracy: 75.238%)\n",
      "Epoch 9: 24.131 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.200 (accuracy: 92.699%), validation loss = 0.846 (accuracy: 70.476%)\n",
      "Epoch 10: 23.911 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.174 (accuracy: 93.660%), validation loss = 0.951 (accuracy: 63.810%)\n",
      "Epoch 11: 23.800 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.118 (accuracy: 95.869%), validation loss = 0.788 (accuracy: 78.095%)\n",
      "Epoch 12: 23.789 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.138 (accuracy: 95.197%), validation loss = 0.785 (accuracy: 75.238%)\n",
      "Epoch 13: 23.884 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.121 (accuracy: 96.158%), validation loss = 0.812 (accuracy: 77.143%)\n",
      "Epoch 14: 23.957 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.119 (accuracy: 96.061%), validation loss = 1.079 (accuracy: 76.190%)\n",
      "Epoch 15: 23.885 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.088 (accuracy: 97.406%), validation loss = 0.954 (accuracy: 75.238%)\n",
      "Epoch 16: 23.913 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.051 (accuracy: 98.751%), validation loss = 1.014 (accuracy: 76.190%)\n",
      "Epoch 17: 23.945 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.072 (accuracy: 97.791%), validation loss = 1.017 (accuracy: 76.190%)\n",
      "Epoch 18: 23.888 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.096 (accuracy: 97.022%), validation loss = 1.088 (accuracy: 69.524%)\n",
      "Epoch 19: 23.979 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.092 (accuracy: 97.118%), validation loss = 0.946 (accuracy: 73.333%)\n",
      "Epoch 20: 24.032 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.129 (accuracy: 95.869%), validation loss = 0.944 (accuracy: 75.238%)\n",
      "Epoch 21: 23.899 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.080 (accuracy: 97.310%), validation loss = 0.828 (accuracy: 78.095%)\n",
      "Epoch 22: 24.214 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.077 (accuracy: 97.598%), validation loss = 0.786 (accuracy: 77.143%)\n",
      "Epoch 23: 24.048 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.073 (accuracy: 97.406%), validation loss = 0.876 (accuracy: 77.143%)\n",
      "Epoch 24: 24.031 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.070 (accuracy: 98.175%), validation loss = 0.723 (accuracy: 76.190%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 4 with minimum validation error = 0.5754261380150205\n",
      "7140.616 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.1\n",
      "Epoch 1: 24.025 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.269 (accuracy: 40.346%), validation loss = 1.228 (accuracy: 35.238%)\n",
      "Epoch 2: 24.241 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.074 (accuracy: 54.179%), validation loss = 0.886 (accuracy: 61.905%)\n",
      "Epoch 3: 24.339 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 0.802 (accuracy: 68.972%), validation loss = 0.857 (accuracy: 66.667%)\n",
      "Epoch 4: 24.325 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 0.603 (accuracy: 77.522%), validation loss = 0.904 (accuracy: 64.762%)\n",
      "Epoch 5: 24.197 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.547 (accuracy: 80.692%), validation loss = 0.756 (accuracy: 74.286%)\n",
      "Epoch 6: 24.390 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.483 (accuracy: 84.150%), validation loss = 0.830 (accuracy: 68.571%)\n",
      "Epoch 7: 24.168 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.427 (accuracy: 84.822%), validation loss = 0.676 (accuracy: 78.095%)\n",
      "Epoch 8: 24.316 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.489 (accuracy: 82.421%), validation loss = 0.708 (accuracy: 69.524%)\n",
      "Epoch 9: 24.297 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.458 (accuracy: 83.958%), validation loss = 1.045 (accuracy: 59.048%)\n",
      "Epoch 10: 24.264 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.474 (accuracy: 83.189%), validation loss = 0.801 (accuracy: 67.619%)\n",
      "Epoch 11: 24.539 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.542 (accuracy: 81.940%), validation loss = 0.772 (accuracy: 74.286%)\n",
      "Epoch 12: 24.179 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.435 (accuracy: 84.822%), validation loss = 0.666 (accuracy: 78.095%)\n",
      "Epoch 13: 24.409 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.511 (accuracy: 81.268%), validation loss = 1.125 (accuracy: 58.095%)\n",
      "Epoch 14: 24.255 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.482 (accuracy: 84.054%), validation loss = 1.197 (accuracy: 62.857%)\n",
      "Epoch 15: 24.122 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.513 (accuracy: 83.285%), validation loss = 0.844 (accuracy: 67.619%)\n",
      "Epoch 16: 24.216 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.528 (accuracy: 81.556%), validation loss = 1.397 (accuracy: 57.143%)\n",
      "Epoch 17: 24.240 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.493 (accuracy: 82.997%), validation loss = 0.720 (accuracy: 74.286%)\n",
      "Epoch 18: 24.149 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.498 (accuracy: 82.133%), validation loss = 0.779 (accuracy: 70.476%)\n",
      "Epoch 19: 24.171 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.539 (accuracy: 81.268%), validation loss = 0.787 (accuracy: 70.476%)\n",
      "Epoch 20: 24.153 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.518 (accuracy: 81.556%), validation loss = 0.906 (accuracy: 68.571%)\n",
      "Epoch 21: 24.226 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.486 (accuracy: 83.862%), validation loss = 1.184 (accuracy: 67.619%)\n",
      "Epoch 22: 24.169 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.593 (accuracy: 80.788%), validation loss = 1.001 (accuracy: 62.857%)\n",
      "Epoch 23: 24.254 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.540 (accuracy: 80.500%), validation loss = 1.178 (accuracy: 55.238%)\n",
      "Epoch 24: 24.482 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.522 (accuracy: 81.364%), validation loss = 0.797 (accuracy: 66.667%)\n",
      "Epoch 25: 24.177 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.585 (accuracy: 79.539%), validation loss = 0.796 (accuracy: 73.333%)\n",
      "Epoch 26: 24.242 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.533 (accuracy: 82.133%), validation loss = 1.173 (accuracy: 60.952%)\n",
      "Epoch 27: 24.190 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.476 (accuracy: 83.381%), validation loss = 0.876 (accuracy: 64.762%)\n",
      "Epoch 28: 24.202 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.556 (accuracy: 80.884%), validation loss = 0.801 (accuracy: 72.381%)\n",
      "Epoch 29: 24.258 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.452 (accuracy: 84.534%), validation loss = 1.083 (accuracy: 58.095%)\n",
      "Epoch 30: 24.223 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.514 (accuracy: 81.940%), validation loss = 0.872 (accuracy: 70.476%)\n",
      "Epoch 31: 24.181 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.489 (accuracy: 82.037%), validation loss = 1.223 (accuracy: 59.048%)\n",
      "Epoch 32: 24.211 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.594 (accuracy: 78.963%), validation loss = 1.119 (accuracy: 63.810%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 12 with minimum validation error = 0.6655184663477398\n",
      "7919.536 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.2\n",
      "Epoch 1: 24.242 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.287 (accuracy: 39.385%), validation loss = 1.251 (accuracy: 35.238%)\n",
      "Epoch 2: 24.453 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.168 (accuracy: 48.319%), validation loss = 1.076 (accuracy: 46.667%)\n",
      "Epoch 3: 24.461 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 0.936 (accuracy: 63.401%), validation loss = 0.792 (accuracy: 70.476%)\n",
      "Epoch 4: 24.520 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 0.747 (accuracy: 72.142%), validation loss = 0.791 (accuracy: 73.333%)\n",
      "Epoch 5: 24.627 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.634 (accuracy: 77.618%), validation loss = 0.668 (accuracy: 76.190%)\n",
      "Epoch 6: 24.393 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.610 (accuracy: 78.578%), validation loss = 0.814 (accuracy: 70.476%)\n",
      "Epoch 7: 24.354 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.618 (accuracy: 78.674%), validation loss = 0.899 (accuracy: 67.619%)\n",
      "Epoch 8: 24.228 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.565 (accuracy: 81.364%), validation loss = 0.897 (accuracy: 63.810%)\n",
      "Epoch 9: 24.234 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.625 (accuracy: 78.674%), validation loss = 0.906 (accuracy: 69.524%)\n",
      "Epoch 10: 24.285 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.613 (accuracy: 78.098%), validation loss = 0.854 (accuracy: 72.381%)\n",
      "Epoch 11: 24.248 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.537 (accuracy: 82.997%), validation loss = 0.903 (accuracy: 66.667%)\n",
      "Epoch 12: 24.270 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.674 (accuracy: 76.561%), validation loss = 0.805 (accuracy: 66.667%)\n",
      "Epoch 13: 24.282 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.672 (accuracy: 76.657%), validation loss = 0.999 (accuracy: 56.190%)\n",
      "Epoch 14: 24.371 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.676 (accuracy: 75.504%), validation loss = 1.088 (accuracy: 66.667%)\n",
      "Epoch 15: 24.249 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.616 (accuracy: 78.290%), validation loss = 1.860 (accuracy: 53.333%)\n",
      "Epoch 16: 24.257 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.646 (accuracy: 77.233%), validation loss = 1.111 (accuracy: 60.952%)\n",
      "Epoch 17: 24.645 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.760 (accuracy: 73.583%), validation loss = 1.276 (accuracy: 54.286%)\n",
      "Epoch 18: 24.332 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.687 (accuracy: 75.793%), validation loss = 1.091 (accuracy: 54.286%)\n",
      "Epoch 19: 24.300 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.745 (accuracy: 74.159%), validation loss = 1.903 (accuracy: 40.952%)\n",
      "Epoch 20: 24.339 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.724 (accuracy: 73.679%), validation loss = 0.815 (accuracy: 68.571%)\n",
      "Epoch 21: 24.340 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.730 (accuracy: 73.103%), validation loss = 0.938 (accuracy: 64.762%)\n",
      "Epoch 22: 24.247 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.723 (accuracy: 72.911%), validation loss = 1.020 (accuracy: 59.048%)\n",
      "Epoch 23: 24.296 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.775 (accuracy: 71.470%), validation loss = 1.049 (accuracy: 56.190%)\n",
      "Epoch 24: 24.243 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.761 (accuracy: 73.103%), validation loss = 1.018 (accuracy: 65.714%)\n",
      "Epoch 25: 24.022 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.768 (accuracy: 71.085%), validation loss = 0.948 (accuracy: 60.952%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 5 with minimum validation error = 0.6682022213935852\n",
      "8530.526 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.4\n",
      "Epoch 1: 23.927 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.305 (accuracy: 37.944%), validation loss = 1.256 (accuracy: 35.238%)\n",
      "Epoch 2: 24.123 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.234 (accuracy: 43.708%), validation loss = 1.237 (accuracy: 36.190%)\n",
      "Epoch 3: 23.912 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.134 (accuracy: 51.393%), validation loss = 1.113 (accuracy: 54.286%)\n",
      "Epoch 4: 23.962 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 0.964 (accuracy: 64.169%), validation loss = 0.888 (accuracy: 65.714%)\n",
      "Epoch 5: 24.330 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.801 (accuracy: 70.029%), validation loss = 0.901 (accuracy: 62.857%)\n",
      "Epoch 6: 23.791 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.802 (accuracy: 69.549%), validation loss = 1.000 (accuracy: 61.905%)\n",
      "Epoch 7: 23.733 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.773 (accuracy: 72.142%), validation loss = 0.874 (accuracy: 69.524%)\n",
      "Epoch 8: 23.882 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.814 (accuracy: 70.125%), validation loss = 1.037 (accuracy: 56.190%)\n",
      "Epoch 9: 23.767 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.819 (accuracy: 68.204%), validation loss = 0.994 (accuracy: 55.238%)\n",
      "Epoch 10: 23.650 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.763 (accuracy: 73.007%), validation loss = 1.025 (accuracy: 64.762%)\n",
      "Epoch 11: 23.683 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.846 (accuracy: 69.645%), validation loss = 1.145 (accuracy: 64.762%)\n",
      "Epoch 12: 23.758 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.822 (accuracy: 70.317%), validation loss = 0.995 (accuracy: 64.762%)\n",
      "Epoch 13: 23.673 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.826 (accuracy: 69.452%), validation loss = 1.021 (accuracy: 46.667%)\n",
      "Epoch 14: 23.769 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.859 (accuracy: 68.876%), validation loss = 1.238 (accuracy: 52.381%)\n",
      "Epoch 15: 23.823 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.827 (accuracy: 70.221%), validation loss = 1.088 (accuracy: 62.857%)\n",
      "Epoch 16: 23.705 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.931 (accuracy: 64.938%), validation loss = 0.983 (accuracy: 65.714%)\n",
      "Epoch 17: 23.708 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.918 (accuracy: 64.457%), validation loss = 1.073 (accuracy: 61.905%)\n",
      "Epoch 18: 24.031 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.944 (accuracy: 64.745%), validation loss = 1.252 (accuracy: 43.810%)\n",
      "Epoch 19: 23.665 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.975 (accuracy: 61.768%), validation loss = 1.109 (accuracy: 60.000%)\n",
      "Epoch 20: 23.543 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.959 (accuracy: 65.898%), validation loss = 1.176 (accuracy: 52.381%)\n",
      "Epoch 21: 23.376 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.926 (accuracy: 65.130%), validation loss = 1.106 (accuracy: 55.238%)\n",
      "Epoch 22: 23.647 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.014 (accuracy: 59.078%), validation loss = 0.994 (accuracy: 61.905%)\n",
      "Epoch 23: 23.546 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.975 (accuracy: 62.536%), validation loss = 1.034 (accuracy: 59.048%)\n",
      "Epoch 24: 23.605 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.968 (accuracy: 64.361%), validation loss = 1.051 (accuracy: 58.095%)\n",
      "Epoch 25: 23.583 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.052 (accuracy: 58.598%), validation loss = 1.214 (accuracy: 50.476%)\n",
      "Epoch 26: 23.537 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.013 (accuracy: 61.671%), validation loss = 1.334 (accuracy: 43.810%)\n",
      "Epoch 27: 23.439 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.058 (accuracy: 59.750%), validation loss = 1.329 (accuracy: 50.476%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 7 with minimum validation error = 0.8739600272405715\n",
      "9174.360 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.9\n",
      "Epoch 1: 23.516 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.321 (accuracy: 36.119%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 2: 23.743 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.279 (accuracy: 39.577%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 3: 23.224 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.264 (accuracy: 41.595%), validation loss = 1.287 (accuracy: 34.286%)\n",
      "Epoch 4: 23.794 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.226 (accuracy: 43.516%), validation loss = 1.263 (accuracy: 34.286%)\n",
      "Epoch 5: 23.649 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.193 (accuracy: 45.437%), validation loss = 1.228 (accuracy: 40.000%)\n",
      "Epoch 6: 23.446 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.149 (accuracy: 50.817%), validation loss = 1.265 (accuracy: 41.905%)\n",
      "Epoch 7: 23.246 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.100 (accuracy: 53.602%), validation loss = 1.144 (accuracy: 48.571%)\n",
      "Epoch 8: 23.438 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.081 (accuracy: 55.427%), validation loss = 1.163 (accuracy: 40.952%)\n",
      "Epoch 9: 23.303 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.058 (accuracy: 58.213%), validation loss = 1.190 (accuracy: 57.143%)\n",
      "Epoch 10: 23.190 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.029 (accuracy: 62.248%), validation loss = 1.261 (accuracy: 40.000%)\n",
      "Epoch 11: 23.225 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.087 (accuracy: 59.174%), validation loss = 1.193 (accuracy: 55.238%)\n",
      "Epoch 12: 23.287 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.065 (accuracy: 60.615%), validation loss = 1.291 (accuracy: 48.571%)\n",
      "Epoch 13: 23.265 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.091 (accuracy: 58.309%), validation loss = 1.310 (accuracy: 36.190%)\n",
      "Epoch 14: 23.124 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.106 (accuracy: 59.846%), validation loss = 1.231 (accuracy: 49.524%)\n",
      "Epoch 15: 23.123 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.111 (accuracy: 57.061%), validation loss = 1.299 (accuracy: 39.048%)\n",
      "Epoch 16: 23.220 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.124 (accuracy: 57.445%), validation loss = 1.250 (accuracy: 50.476%)\n",
      "Epoch 17: 23.212 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.147 (accuracy: 54.947%), validation loss = 1.338 (accuracy: 35.238%)\n",
      "Epoch 18: 23.538 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.146 (accuracy: 54.851%), validation loss = 1.599 (accuracy: 29.524%)\n",
      "Epoch 19: 23.453 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.247 (accuracy: 47.646%), validation loss = 1.334 (accuracy: 41.905%)\n",
      "Epoch 20: 23.385 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.184 (accuracy: 52.065%), validation loss = 1.329 (accuracy: 42.857%)\n",
      "Epoch 21: 23.192 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.220 (accuracy: 50.817%), validation loss = 1.302 (accuracy: 35.238%)\n",
      "Epoch 22: 23.129 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.217 (accuracy: 51.489%), validation loss = 1.320 (accuracy: 37.143%)\n",
      "Epoch 23: 23.264 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.235 (accuracy: 51.297%), validation loss = 1.396 (accuracy: 27.619%)\n",
      "Epoch 24: 23.194 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.257 (accuracy: 46.110%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 25: 23.148 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.285 (accuracy: 43.612%), validation loss = 1.351 (accuracy: 37.143%)\n",
      "Epoch 26: 23.469 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.278 (accuracy: 46.110%), validation loss = 1.322 (accuracy: 44.762%)\n",
      "Epoch 27: 23.442 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.259 (accuracy: 45.725%), validation loss = 1.331 (accuracy: 37.143%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 7 with minimum validation error = 1.1435248619034177\n",
      "9807.211 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 1\n",
      "Epoch 1: 23.541 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.337 (accuracy: 35.062%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 2: 23.624 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.296 (accuracy: 38.713%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 3: 23.755 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.271 (accuracy: 40.154%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 4: 23.828 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.248 (accuracy: 40.826%), validation loss = 1.283 (accuracy: 33.333%)\n",
      "Epoch 5: 23.592 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.215 (accuracy: 40.634%), validation loss = 1.270 (accuracy: 33.333%)\n",
      "Epoch 6: 23.756 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.190 (accuracy: 41.499%), validation loss = 1.243 (accuracy: 37.143%)\n",
      "Epoch 7: 23.688 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.179 (accuracy: 43.228%), validation loss = 1.285 (accuracy: 43.810%)\n",
      "Epoch 8: 23.541 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.173 (accuracy: 46.398%), validation loss = 1.205 (accuracy: 41.905%)\n",
      "Epoch 9: 23.835 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.141 (accuracy: 50.817%), validation loss = 1.167 (accuracy: 45.714%)\n",
      "Epoch 10: 23.819 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.188 (accuracy: 48.607%), validation loss = 1.272 (accuracy: 40.952%)\n",
      "Epoch 11: 23.513 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.179 (accuracy: 49.952%), validation loss = 1.273 (accuracy: 37.143%)\n",
      "Epoch 12: 23.692 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.160 (accuracy: 49.664%), validation loss = 1.378 (accuracy: 41.905%)\n",
      "Epoch 13: 23.728 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.204 (accuracy: 50.432%), validation loss = 1.313 (accuracy: 40.952%)\n",
      "Epoch 14: 23.628 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.219 (accuracy: 48.607%), validation loss = 1.326 (accuracy: 40.952%)\n",
      "Epoch 15: 23.628 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.270 (accuracy: 44.765%), validation loss = 1.267 (accuracy: 36.190%)\n",
      "Epoch 16: 23.680 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.274 (accuracy: 43.900%), validation loss = 1.356 (accuracy: 38.095%)\n",
      "Epoch 17: 23.983 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.271 (accuracy: 42.267%), validation loss = 1.320 (accuracy: 31.429%)\n",
      "Epoch 18: 23.677 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.285 (accuracy: 41.210%), validation loss = 1.377 (accuracy: 34.286%)\n",
      "Epoch 19: 23.749 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.294 (accuracy: 40.154%), validation loss = 1.357 (accuracy: 36.190%)\n",
      "Epoch 20: 23.669 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.281 (accuracy: 40.346%), validation loss = 1.372 (accuracy: 22.857%)\n",
      "Epoch 21: 23.620 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.302 (accuracy: 39.385%), validation loss = 1.370 (accuracy: 33.333%)\n",
      "Epoch 22: 23.713 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.300 (accuracy: 39.577%), validation loss = 1.370 (accuracy: 33.333%)\n",
      "Epoch 23: 23.728 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.302 (accuracy: 39.481%), validation loss = 1.366 (accuracy: 33.333%)\n",
      "Epoch 24: 23.726 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.309 (accuracy: 39.481%), validation loss = 2.228 (accuracy: 33.333%)\n",
      "Epoch 25: 23.835 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.308 (accuracy: 39.481%), validation loss = 1.357 (accuracy: 33.333%)\n",
      "Epoch 26: 23.779 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.328 (accuracy: 39.481%), validation loss = 1.753 (accuracy: 33.333%)\n",
      "Epoch 27: 23.685 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.311 (accuracy: 39.481%), validation loss = 1.346 (accuracy: 33.333%)\n",
      "Epoch 28: 23.744 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.310 (accuracy: 39.481%), validation loss = 1.368 (accuracy: 33.333%)\n",
      "Epoch 29: 23.696 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.302 (accuracy: 39.481%), validation loss = 1.365 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 9 with minimum validation error = 1.1666011344818843\n",
      "10498.144 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0\n",
      "Epoch 1: 24.139 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.266 (accuracy: 38.425%), validation loss = 1.151 (accuracy: 40.952%)\n",
      "Epoch 2: 23.945 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.008 (accuracy: 59.654%), validation loss = 0.865 (accuracy: 64.762%)\n",
      "Epoch 3: 23.954 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 0.719 (accuracy: 72.046%), validation loss = 0.687 (accuracy: 80.000%)\n",
      "Epoch 4: 24.023 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 0.505 (accuracy: 82.709%), validation loss = 0.605 (accuracy: 77.143%)\n",
      "Epoch 5: 23.936 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.340 (accuracy: 89.433%), validation loss = 0.654 (accuracy: 77.143%)\n",
      "Epoch 6: 23.703 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.267 (accuracy: 91.354%), validation loss = 0.819 (accuracy: 73.333%)\n",
      "Epoch 7: 23.774 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.236 (accuracy: 91.931%), validation loss = 0.641 (accuracy: 79.048%)\n",
      "Epoch 8: 23.699 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.205 (accuracy: 92.507%), validation loss = 0.510 (accuracy: 80.000%)\n",
      "Epoch 9: 24.032 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.140 (accuracy: 96.061%), validation loss = 0.595 (accuracy: 79.048%)\n",
      "Epoch 10: 23.735 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.110 (accuracy: 96.926%), validation loss = 0.672 (accuracy: 79.048%)\n",
      "Epoch 11: 23.572 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.110 (accuracy: 96.638%), validation loss = 0.592 (accuracy: 78.095%)\n",
      "Epoch 12: 23.226 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.125 (accuracy: 96.542%), validation loss = 0.647 (accuracy: 80.000%)\n",
      "Epoch 13: 23.226 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.084 (accuracy: 97.598%), validation loss = 0.815 (accuracy: 75.238%)\n",
      "Epoch 14: 23.481 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.079 (accuracy: 97.598%), validation loss = 0.690 (accuracy: 80.000%)\n",
      "Epoch 15: 23.153 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.073 (accuracy: 97.791%), validation loss = 0.749 (accuracy: 80.000%)\n",
      "Epoch 16: 23.062 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.091 (accuracy: 97.118%), validation loss = 0.583 (accuracy: 80.952%)\n",
      "Epoch 17: 22.966 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.065 (accuracy: 97.791%), validation loss = 0.642 (accuracy: 80.952%)\n",
      "Epoch 18: 22.897 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.078 (accuracy: 97.695%), validation loss = 1.084 (accuracy: 74.286%)\n",
      "Epoch 19: 22.881 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.081 (accuracy: 97.598%), validation loss = 0.863 (accuracy: 76.190%)\n",
      "Epoch 20: 22.815 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.111 (accuracy: 96.638%), validation loss = 0.805 (accuracy: 74.286%)\n",
      "Epoch 21: 22.896 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.072 (accuracy: 97.695%), validation loss = 0.705 (accuracy: 80.952%)\n",
      "Epoch 22: 22.935 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.071 (accuracy: 98.559%), validation loss = 0.862 (accuracy: 76.190%)\n",
      "Epoch 23: 22.724 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.049 (accuracy: 98.559%), validation loss = 0.786 (accuracy: 76.190%)\n",
      "Epoch 24: 22.770 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.042 (accuracy: 98.751%), validation loss = 0.850 (accuracy: 74.286%)\n",
      "Epoch 25: 22.762 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.031 (accuracy: 98.943%), validation loss = 0.883 (accuracy: 78.095%)\n",
      "Epoch 26: 22.733 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.038 (accuracy: 99.039%), validation loss = 0.990 (accuracy: 73.333%)\n",
      "Epoch 27: 22.959 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.050 (accuracy: 98.271%), validation loss = 0.794 (accuracy: 76.190%)\n",
      "Epoch 28: 22.913 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.026 (accuracy: 99.232%), validation loss = 0.791 (accuracy: 80.952%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 8 with minimum validation error = 0.510392492441904\n",
      "11153.857 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.1\n",
      "Epoch 1: 22.807 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.277 (accuracy: 37.752%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 2: 22.884 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.201 (accuracy: 45.725%), validation loss = 1.125 (accuracy: 53.333%)\n",
      "Epoch 3: 23.119 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.041 (accuracy: 59.270%), validation loss = 0.927 (accuracy: 68.571%)\n",
      "Epoch 4: 22.974 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 0.832 (accuracy: 67.819%), validation loss = 0.711 (accuracy: 76.190%)\n",
      "Epoch 5: 22.879 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.609 (accuracy: 78.098%), validation loss = 0.673 (accuracy: 76.190%)\n",
      "Epoch 6: 22.884 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.468 (accuracy: 83.381%), validation loss = 0.717 (accuracy: 70.476%)\n",
      "Epoch 7: 22.937 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.356 (accuracy: 89.529%), validation loss = 0.520 (accuracy: 80.952%)\n",
      "Epoch 8: 22.820 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.303 (accuracy: 90.586%), validation loss = 0.516 (accuracy: 82.857%)\n",
      "Epoch 9: 22.875 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.305 (accuracy: 90.682%), validation loss = 0.809 (accuracy: 70.476%)\n",
      "Epoch 10: 22.789 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.299 (accuracy: 90.490%), validation loss = 0.626 (accuracy: 78.095%)\n",
      "Epoch 11: 22.776 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.226 (accuracy: 92.891%), validation loss = 0.580 (accuracy: 81.905%)\n",
      "Epoch 12: 22.729 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.232 (accuracy: 93.564%), validation loss = 0.580 (accuracy: 80.952%)\n",
      "Epoch 13: 23.019 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.223 (accuracy: 92.027%), validation loss = 0.747 (accuracy: 74.286%)\n",
      "Epoch 14: 22.758 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.181 (accuracy: 94.909%), validation loss = 0.697 (accuracy: 78.095%)\n",
      "Epoch 15: 22.639 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.207 (accuracy: 93.372%), validation loss = 0.780 (accuracy: 71.429%)\n",
      "Epoch 16: 22.742 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.197 (accuracy: 93.660%), validation loss = 0.836 (accuracy: 69.524%)\n",
      "Epoch 17: 22.825 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.225 (accuracy: 92.988%), validation loss = 0.763 (accuracy: 76.190%)\n",
      "Epoch 18: 22.991 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.237 (accuracy: 92.603%), validation loss = 0.777 (accuracy: 76.190%)\n",
      "Epoch 19: 23.007 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.211 (accuracy: 93.660%), validation loss = 0.712 (accuracy: 72.381%)\n",
      "Epoch 20: 22.914 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.202 (accuracy: 94.621%), validation loss = 0.744 (accuracy: 75.238%)\n",
      "Epoch 21: 23.031 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.172 (accuracy: 94.524%), validation loss = 0.679 (accuracy: 73.333%)\n",
      "Epoch 22: 22.800 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.224 (accuracy: 93.180%), validation loss = 0.774 (accuracy: 73.333%)\n",
      "Epoch 23: 22.773 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.245 (accuracy: 92.219%), validation loss = 0.919 (accuracy: 67.619%)\n",
      "Epoch 24: 22.842 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.214 (accuracy: 93.948%), validation loss = 0.829 (accuracy: 76.190%)\n",
      "Epoch 25: 22.799 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.207 (accuracy: 93.948%), validation loss = 0.714 (accuracy: 75.238%)\n",
      "Epoch 26: 22.997 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.222 (accuracy: 92.411%), validation loss = 0.948 (accuracy: 72.381%)\n",
      "Epoch 27: 22.851 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.206 (accuracy: 93.660%), validation loss = 0.775 (accuracy: 75.238%)\n",
      "Epoch 28: 22.810 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.199 (accuracy: 93.852%), validation loss = 0.959 (accuracy: 68.571%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 8 with minimum validation error = 0.5158656653903779\n",
      "11797.373 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.2\n",
      "Epoch 1: 22.772 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.302 (accuracy: 35.831%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 2: 22.863 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.241 (accuracy: 40.634%), validation loss = 1.240 (accuracy: 36.190%)\n",
      "Epoch 3: 22.923 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.186 (accuracy: 46.398%), validation loss = 1.159 (accuracy: 40.952%)\n",
      "Epoch 4: 22.924 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.072 (accuracy: 55.812%), validation loss = 0.958 (accuracy: 63.810%)\n",
      "Epoch 5: 22.925 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 0.901 (accuracy: 63.977%), validation loss = 0.852 (accuracy: 64.762%)\n",
      "Epoch 6: 22.993 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 0.741 (accuracy: 73.775%), validation loss = 0.703 (accuracy: 79.048%)\n",
      "Epoch 7: 23.004 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.609 (accuracy: 79.827%), validation loss = 0.688 (accuracy: 73.333%)\n",
      "Epoch 8: 22.892 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.490 (accuracy: 86.263%), validation loss = 0.628 (accuracy: 77.143%)\n",
      "Epoch 9: 22.876 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.435 (accuracy: 85.399%), validation loss = 0.678 (accuracy: 74.286%)\n",
      "Epoch 10: 22.787 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.396 (accuracy: 87.704%), validation loss = 0.681 (accuracy: 78.095%)\n",
      "Epoch 11: 22.779 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.342 (accuracy: 89.625%), validation loss = 0.846 (accuracy: 67.619%)\n",
      "Epoch 12: 23.002 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.309 (accuracy: 90.778%), validation loss = 0.666 (accuracy: 75.238%)\n",
      "Epoch 13: 22.717 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.411 (accuracy: 86.359%), validation loss = 0.721 (accuracy: 75.238%)\n",
      "Epoch 14: 22.821 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.374 (accuracy: 88.280%), validation loss = 0.560 (accuracy: 78.095%)\n",
      "Epoch 15: 22.862 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.331 (accuracy: 88.953%), validation loss = 0.757 (accuracy: 73.333%)\n",
      "Epoch 16: 22.740 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.310 (accuracy: 91.354%), validation loss = 0.687 (accuracy: 74.286%)\n",
      "Epoch 17: 22.767 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.300 (accuracy: 90.874%), validation loss = 0.624 (accuracy: 75.238%)\n",
      "Epoch 18: 22.720 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.324 (accuracy: 88.569%), validation loss = 0.746 (accuracy: 77.143%)\n",
      "Epoch 19: 22.835 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.313 (accuracy: 90.586%), validation loss = 0.659 (accuracy: 77.143%)\n",
      "Epoch 20: 22.685 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.292 (accuracy: 91.354%), validation loss = 0.670 (accuracy: 78.095%)\n",
      "Epoch 21: 22.779 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.323 (accuracy: 90.298%), validation loss = 0.866 (accuracy: 71.429%)\n",
      "Epoch 22: 22.735 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.352 (accuracy: 89.625%), validation loss = 0.800 (accuracy: 74.286%)\n",
      "Epoch 23: 22.711 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.314 (accuracy: 91.066%), validation loss = 0.699 (accuracy: 77.143%)\n",
      "Epoch 24: 22.713 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.289 (accuracy: 91.547%), validation loss = 0.724 (accuracy: 78.095%)\n",
      "Epoch 25: 22.931 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.331 (accuracy: 90.586%), validation loss = 0.624 (accuracy: 73.333%)\n",
      "Epoch 26: 22.837 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.342 (accuracy: 88.953%), validation loss = 0.715 (accuracy: 75.238%)\n",
      "Epoch 27: 22.705 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.359 (accuracy: 90.010%), validation loss = 0.696 (accuracy: 72.381%)\n",
      "Epoch 28: 22.742 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.368 (accuracy: 87.704%), validation loss = 0.816 (accuracy: 66.667%)\n",
      "Epoch 29: 22.700 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.317 (accuracy: 91.258%), validation loss = 0.778 (accuracy: 72.381%)\n",
      "Epoch 30: 22.673 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.317 (accuracy: 90.490%), validation loss = 0.829 (accuracy: 64.762%)\n",
      "Epoch 31: 22.706 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.280 (accuracy: 92.315%), validation loss = 1.215 (accuracy: 60.952%)\n",
      "Epoch 32: 22.821 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.323 (accuracy: 90.394%), validation loss = 0.707 (accuracy: 75.238%)\n",
      "Epoch 33: 22.733 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.379 (accuracy: 88.280%), validation loss = 0.946 (accuracy: 66.667%)\n",
      "Epoch 34: 22.644 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.317 (accuracy: 90.778%), validation loss = 0.910 (accuracy: 69.524%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 14 with minimum validation error = 0.5598407325290499\n",
      "12576.634 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.4\n",
      "Epoch 1: 22.767 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.308 (accuracy: 37.464%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 2: 22.772 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.267 (accuracy: 41.114%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 3: 22.825 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.244 (accuracy: 41.402%), validation loss = 1.239 (accuracy: 35.238%)\n",
      "Epoch 4: 22.850 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.205 (accuracy: 44.669%), validation loss = 1.215 (accuracy: 40.952%)\n",
      "Epoch 5: 23.188 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.135 (accuracy: 51.681%), validation loss = 1.122 (accuracy: 54.286%)\n",
      "Epoch 6: 22.791 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.026 (accuracy: 61.960%), validation loss = 1.001 (accuracy: 57.143%)\n",
      "Epoch 7: 22.811 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.915 (accuracy: 66.090%), validation loss = 0.914 (accuracy: 60.952%)\n",
      "Epoch 8: 22.884 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.793 (accuracy: 70.125%), validation loss = 0.823 (accuracy: 69.524%)\n",
      "Epoch 9: 22.849 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.710 (accuracy: 73.679%), validation loss = 0.838 (accuracy: 69.524%)\n",
      "Epoch 10: 22.684 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.653 (accuracy: 78.770%), validation loss = 0.893 (accuracy: 60.952%)\n",
      "Epoch 11: 22.678 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.607 (accuracy: 80.019%), validation loss = 0.854 (accuracy: 62.857%)\n",
      "Epoch 12: 22.783 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.591 (accuracy: 80.692%), validation loss = 0.721 (accuracy: 76.190%)\n",
      "Epoch 13: 22.797 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.494 (accuracy: 85.879%), validation loss = 0.729 (accuracy: 71.429%)\n",
      "Epoch 14: 22.680 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.514 (accuracy: 84.630%), validation loss = 0.710 (accuracy: 72.381%)\n",
      "Epoch 15: 22.889 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.467 (accuracy: 87.416%), validation loss = 0.684 (accuracy: 73.333%)\n",
      "Epoch 16: 22.822 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.472 (accuracy: 85.303%), validation loss = 0.834 (accuracy: 70.476%)\n",
      "Epoch 17: 22.616 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.453 (accuracy: 85.975%), validation loss = 0.609 (accuracy: 76.190%)\n",
      "Epoch 18: 23.076 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.464 (accuracy: 86.071%), validation loss = 0.855 (accuracy: 67.619%)\n",
      "Epoch 19: 22.912 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.475 (accuracy: 86.936%), validation loss = 0.745 (accuracy: 73.333%)\n",
      "Epoch 20: 22.664 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.445 (accuracy: 87.416%), validation loss = 0.957 (accuracy: 66.667%)\n",
      "Epoch 21: 22.707 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.435 (accuracy: 88.088%), validation loss = 0.874 (accuracy: 64.762%)\n",
      "Epoch 22: 22.746 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.464 (accuracy: 85.303%), validation loss = 0.755 (accuracy: 66.667%)\n",
      "Epoch 23: 22.728 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.425 (accuracy: 87.416%), validation loss = 0.813 (accuracy: 71.429%)\n",
      "Epoch 24: 22.628 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.475 (accuracy: 86.263%), validation loss = 0.870 (accuracy: 67.619%)\n",
      "Epoch 25: 22.750 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.453 (accuracy: 85.879%), validation loss = 0.932 (accuracy: 66.667%)\n",
      "Epoch 26: 22.778 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.514 (accuracy: 83.189%), validation loss = 0.910 (accuracy: 67.619%)\n",
      "Epoch 27: 22.657 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.515 (accuracy: 84.150%), validation loss = 0.800 (accuracy: 68.571%)\n",
      "Epoch 28: 22.707 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.486 (accuracy: 85.014%), validation loss = 0.885 (accuracy: 72.381%)\n",
      "Epoch 29: 22.734 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.553 (accuracy: 82.037%), validation loss = 0.867 (accuracy: 67.619%)\n",
      "Epoch 30: 22.683 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.525 (accuracy: 84.918%), validation loss = 0.771 (accuracy: 71.429%)\n",
      "Epoch 31: 22.673 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.472 (accuracy: 85.975%), validation loss = 1.031 (accuracy: 61.905%)\n",
      "Epoch 32: 22.976 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.508 (accuracy: 84.438%), validation loss = 0.957 (accuracy: 65.714%)\n",
      "Epoch 33: 22.729 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.510 (accuracy: 84.342%), validation loss = 1.053 (accuracy: 55.238%)\n",
      "Epoch 34: 22.620 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.574 (accuracy: 81.652%), validation loss = 0.975 (accuracy: 58.095%)\n",
      "Epoch 35: 22.680 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.500 (accuracy: 83.381%), validation loss = 1.015 (accuracy: 61.905%)\n",
      "Epoch 36: 22.744 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.556 (accuracy: 82.229%), validation loss = 1.156 (accuracy: 59.048%)\n",
      "Epoch 37: 22.689 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.520 (accuracy: 84.822%), validation loss = 0.744 (accuracy: 72.381%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 17 with minimum validation error = 0.6090588297162737\n",
      "13424.282 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.9\n",
      "Epoch 1: 22.746 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.361 (accuracy: 31.796%), validation loss = 1.333 (accuracy: 33.333%)\n",
      "Epoch 2: 22.868 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.311 (accuracy: 36.888%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 3: 22.935 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.288 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 4: 22.838 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.285 (accuracy: 39.673%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 5: 22.786 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.261 (accuracy: 39.385%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 6: 22.926 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.255 (accuracy: 40.346%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 7: 22.802 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.242 (accuracy: 39.962%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 8: 22.896 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.235 (accuracy: 39.577%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 9: 23.155 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.205 (accuracy: 40.058%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 10: 22.762 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.182 (accuracy: 39.673%), validation loss = 1.233 (accuracy: 33.333%)\n",
      "Epoch 11: 22.809 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.161 (accuracy: 40.922%), validation loss = 1.223 (accuracy: 34.286%)\n",
      "Epoch 12: 22.849 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.146 (accuracy: 41.979%), validation loss = 1.212 (accuracy: 39.048%)\n",
      "Epoch 13: 22.931 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.115 (accuracy: 46.206%), validation loss = 1.175 (accuracy: 43.810%)\n",
      "Epoch 14: 22.826 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.097 (accuracy: 53.314%), validation loss = 1.167 (accuracy: 46.667%)\n",
      "Epoch 15: 22.924 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.041 (accuracy: 57.637%), validation loss = 1.124 (accuracy: 48.571%)\n",
      "Epoch 16: 22.834 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.014 (accuracy: 59.174%), validation loss = 1.180 (accuracy: 61.905%)\n",
      "Epoch 17: 22.744 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.992 (accuracy: 64.841%), validation loss = 1.111 (accuracy: 60.000%)\n",
      "Epoch 18: 22.808 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.951 (accuracy: 67.915%), validation loss = 1.060 (accuracy: 62.857%)\n",
      "Epoch 19: 22.872 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.937 (accuracy: 68.396%), validation loss = 1.014 (accuracy: 56.190%)\n",
      "Epoch 20: 22.889 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.926 (accuracy: 66.667%), validation loss = 1.060 (accuracy: 55.238%)\n",
      "Epoch 21: 22.672 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.904 (accuracy: 69.549%), validation loss = 1.113 (accuracy: 57.143%)\n",
      "Epoch 22: 22.966 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.873 (accuracy: 69.933%), validation loss = 1.020 (accuracy: 60.952%)\n",
      "Epoch 23: 22.626 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.877 (accuracy: 70.989%), validation loss = 1.071 (accuracy: 59.048%)\n",
      "Epoch 24: 22.736 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.895 (accuracy: 68.204%), validation loss = 1.064 (accuracy: 57.143%)\n",
      "Epoch 25: 22.666 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.885 (accuracy: 69.933%), validation loss = 1.218 (accuracy: 55.238%)\n",
      "Epoch 26: 22.756 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.862 (accuracy: 69.837%), validation loss = 1.028 (accuracy: 61.905%)\n",
      "Epoch 27: 22.891 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.883 (accuracy: 68.204%), validation loss = 1.159 (accuracy: 53.333%)\n",
      "Epoch 28: 22.910 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.873 (accuracy: 69.741%), validation loss = 1.116 (accuracy: 52.381%)\n",
      "Epoch 29: 22.736 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.826 (accuracy: 72.911%), validation loss = 1.200 (accuracy: 51.429%)\n",
      "Epoch 30: 22.712 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.873 (accuracy: 68.972%), validation loss = 1.116 (accuracy: 57.143%)\n",
      "Epoch 31: 22.732 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.889 (accuracy: 68.012%), validation loss = 1.171 (accuracy: 61.905%)\n",
      "Epoch 32: 22.665 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.894 (accuracy: 68.396%), validation loss = 1.068 (accuracy: 56.190%)\n",
      "Epoch 33: 22.686 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.879 (accuracy: 70.413%), validation loss = 1.042 (accuracy: 58.095%)\n",
      "Epoch 34: 22.762 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.868 (accuracy: 68.492%), validation loss = 1.025 (accuracy: 64.762%)\n",
      "Epoch 35: 22.648 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.894 (accuracy: 68.492%), validation loss = 1.154 (accuracy: 60.000%)\n",
      "Epoch 36: 23.001 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.951 (accuracy: 64.649%), validation loss = 1.145 (accuracy: 46.667%)\n",
      "Epoch 37: 22.645 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.889 (accuracy: 68.876%), validation loss = 1.095 (accuracy: 61.905%)\n",
      "Epoch 38: 22.736 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.892 (accuracy: 68.684%), validation loss = 1.045 (accuracy: 62.857%)\n",
      "Epoch 39: 22.664 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.910 (accuracy: 68.780%), validation loss = 1.126 (accuracy: 62.857%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 19 with minimum validation error = 1.0144642318998065\n",
      "14320.705 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 1\n",
      "Epoch 1: 22.695 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.322 (accuracy: 38.713%), validation loss = 1.319 (accuracy: 33.333%)\n",
      "Epoch 2: 23.018 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.291 (accuracy: 39.481%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 3: 22.837 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.276 (accuracy: 39.673%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 4: 22.849 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.262 (accuracy: 41.210%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 5: 22.851 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.255 (accuracy: 40.442%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 6: 22.890 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.242 (accuracy: 41.595%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 7: 22.831 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.220 (accuracy: 41.499%), validation loss = 1.263 (accuracy: 35.238%)\n",
      "Epoch 8: 22.893 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.203 (accuracy: 41.595%), validation loss = 1.251 (accuracy: 34.286%)\n",
      "Epoch 9: 22.828 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.187 (accuracy: 42.939%), validation loss = 1.231 (accuracy: 39.048%)\n",
      "Epoch 10: 23.154 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.163 (accuracy: 45.917%), validation loss = 1.219 (accuracy: 41.905%)\n",
      "Epoch 11: 22.816 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.141 (accuracy: 47.262%), validation loss = 1.187 (accuracy: 40.000%)\n",
      "Epoch 12: 22.849 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.089 (accuracy: 54.851%), validation loss = 1.186 (accuracy: 43.810%)\n",
      "Epoch 13: 22.842 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.055 (accuracy: 55.331%), validation loss = 1.153 (accuracy: 48.571%)\n",
      "Epoch 14: 22.841 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.020 (accuracy: 58.213%), validation loss = 1.143 (accuracy: 44.762%)\n",
      "Epoch 15: 22.900 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.982 (accuracy: 58.598%), validation loss = 1.077 (accuracy: 49.524%)\n",
      "Epoch 16: 22.914 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.941 (accuracy: 61.383%), validation loss = 1.162 (accuracy: 46.667%)\n",
      "Epoch 17: 22.667 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.948 (accuracy: 60.999%), validation loss = 1.110 (accuracy: 50.476%)\n",
      "Epoch 18: 22.713 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.938 (accuracy: 62.920%), validation loss = 1.148 (accuracy: 51.429%)\n",
      "Epoch 19: 22.701 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.909 (accuracy: 63.785%), validation loss = 1.144 (accuracy: 54.286%)\n",
      "Epoch 20: 22.708 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.953 (accuracy: 62.920%), validation loss = 1.121 (accuracy: 45.714%)\n",
      "Epoch 21: 22.666 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.926 (accuracy: 63.401%), validation loss = 1.118 (accuracy: 49.524%)\n",
      "Epoch 22: 22.671 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.925 (accuracy: 64.361%), validation loss = 1.190 (accuracy: 47.619%)\n",
      "Epoch 23: 22.788 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.930 (accuracy: 64.457%), validation loss = 1.075 (accuracy: 55.238%)\n",
      "Epoch 24: 23.089 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.906 (accuracy: 66.282%), validation loss = 1.101 (accuracy: 51.429%)\n",
      "Epoch 25: 22.681 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.939 (accuracy: 66.186%), validation loss = 1.228 (accuracy: 50.476%)\n",
      "Epoch 26: 22.666 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.969 (accuracy: 64.841%), validation loss = 1.205 (accuracy: 54.286%)\n",
      "Epoch 27: 22.766 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.950 (accuracy: 64.361%), validation loss = 1.168 (accuracy: 49.524%)\n",
      "Epoch 28: 22.720 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.963 (accuracy: 65.034%), validation loss = 1.176 (accuracy: 53.333%)\n",
      "Epoch 29: 22.760 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.941 (accuracy: 65.322%), validation loss = 1.191 (accuracy: 45.714%)\n",
      "Epoch 30: 22.759 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.918 (accuracy: 64.649%), validation loss = 1.186 (accuracy: 56.190%)\n",
      "Epoch 31: 22.705 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.981 (accuracy: 63.401%), validation loss = 1.160 (accuracy: 50.476%)\n",
      "Epoch 32: 22.645 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.996 (accuracy: 61.864%), validation loss = 1.231 (accuracy: 50.476%)\n",
      "Epoch 33: 22.702 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.996 (accuracy: 63.497%), validation loss = 1.192 (accuracy: 56.190%)\n",
      "Epoch 34: 22.714 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.969 (accuracy: 64.457%), validation loss = 1.279 (accuracy: 48.571%)\n",
      "Epoch 35: 22.617 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.968 (accuracy: 63.881%), validation loss = 1.160 (accuracy: 50.476%)\n",
      "Epoch 36: 22.701 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.990 (accuracy: 63.785%), validation loss = 1.172 (accuracy: 56.190%)\n",
      "Epoch 37: 23.008 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.977 (accuracy: 62.152%), validation loss = 1.234 (accuracy: 50.476%)\n",
      "Epoch 38: 22.793 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.990 (accuracy: 62.536%), validation loss = 1.148 (accuracy: 48.571%)\n",
      "Epoch 39: 22.678 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.038 (accuracy: 59.270%), validation loss = 1.297 (accuracy: 48.571%)\n",
      "Epoch 40: 22.654 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.059 (accuracy: 56.676%), validation loss = 1.476 (accuracy: 39.048%)\n",
      "Epoch 41: 22.788 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.002 (accuracy: 60.711%), validation loss = 1.229 (accuracy: 59.048%)\n",
      "Epoch 42: 22.753 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.015 (accuracy: 59.366%), validation loss = 1.206 (accuracy: 52.381%)\n",
      "Epoch 43: 22.640 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.026 (accuracy: 58.598%), validation loss = 1.282 (accuracy: 46.667%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 23 with minimum validation error = 1.0747344266800654\n",
      "15307.052 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0\n",
      "Epoch 1: 22.774 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.310 (accuracy: 37.848%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 2: 22.773 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.250 (accuracy: 40.538%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 3: 22.767 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.214 (accuracy: 44.092%), validation loss = 1.212 (accuracy: 36.190%)\n",
      "Epoch 4: 22.804 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.159 (accuracy: 49.856%), validation loss = 1.155 (accuracy: 46.667%)\n",
      "Epoch 5: 22.958 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.092 (accuracy: 58.694%), validation loss = 1.079 (accuracy: 55.238%)\n",
      "Epoch 6: 22.780 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.003 (accuracy: 61.575%), validation loss = 0.997 (accuracy: 58.095%)\n",
      "Epoch 7: 22.825 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 0.904 (accuracy: 66.475%), validation loss = 0.911 (accuracy: 64.762%)\n",
      "Epoch 8: 23.269 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 0.801 (accuracy: 71.085%), validation loss = 0.857 (accuracy: 66.667%)\n",
      "Epoch 9: 22.866 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 0.721 (accuracy: 74.640%), validation loss = 0.800 (accuracy: 69.524%)\n",
      "Epoch 10: 23.486 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.653 (accuracy: 75.889%), validation loss = 0.741 (accuracy: 77.143%)\n",
      "Epoch 11: 22.805 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.578 (accuracy: 80.403%), validation loss = 0.690 (accuracy: 79.048%)\n",
      "Epoch 12: 22.945 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.523 (accuracy: 81.652%), validation loss = 0.672 (accuracy: 79.048%)\n",
      "Epoch 13: 22.752 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.481 (accuracy: 84.630%), validation loss = 0.629 (accuracy: 78.095%)\n",
      "Epoch 14: 22.751 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.399 (accuracy: 88.953%), validation loss = 0.606 (accuracy: 80.000%)\n",
      "Epoch 15: 23.552 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.357 (accuracy: 89.433%), validation loss = 0.618 (accuracy: 79.048%)\n",
      "Epoch 16: 22.617 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.314 (accuracy: 91.066%), validation loss = 0.582 (accuracy: 80.000%)\n",
      "Epoch 17: 22.780 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.263 (accuracy: 91.931%), validation loss = 0.556 (accuracy: 80.000%)\n",
      "Epoch 18: 22.811 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.239 (accuracy: 94.621%), validation loss = 0.545 (accuracy: 81.905%)\n",
      "Epoch 19: 22.812 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.223 (accuracy: 94.236%), validation loss = 0.569 (accuracy: 80.952%)\n",
      "Epoch 20: 22.608 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.210 (accuracy: 94.524%), validation loss = 0.540 (accuracy: 79.048%)\n",
      "Epoch 21: 23.095 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.183 (accuracy: 95.197%), validation loss = 0.546 (accuracy: 81.905%)\n",
      "Epoch 22: 22.735 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.147 (accuracy: 96.734%), validation loss = 0.534 (accuracy: 80.000%)\n",
      "Epoch 23: 22.745 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.149 (accuracy: 96.446%), validation loss = 0.529 (accuracy: 81.905%)\n",
      "Epoch 24: 22.811 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.120 (accuracy: 96.926%), validation loss = 0.542 (accuracy: 80.000%)\n",
      "Epoch 25: 22.656 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.134 (accuracy: 96.638%), validation loss = 0.563 (accuracy: 80.000%)\n",
      "Epoch 26: 22.800 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.118 (accuracy: 96.830%), validation loss = 0.570 (accuracy: 77.143%)\n",
      "Epoch 27: 22.637 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.090 (accuracy: 98.559%), validation loss = 0.554 (accuracy: 78.095%)\n",
      "Epoch 28: 22.575 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.087 (accuracy: 98.367%), validation loss = 0.530 (accuracy: 81.905%)\n",
      "Epoch 29: 22.692 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.089 (accuracy: 97.983%), validation loss = 0.530 (accuracy: 81.905%)\n",
      "Epoch 30: 22.667 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.091 (accuracy: 97.983%), validation loss = 0.488 (accuracy: 81.905%)\n",
      "Epoch 31: 22.827 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.085 (accuracy: 97.791%), validation loss = 0.504 (accuracy: 82.857%)\n",
      "Epoch 32: 22.662 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.082 (accuracy: 97.791%), validation loss = 0.530 (accuracy: 83.810%)\n",
      "Epoch 33: 22.737 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.075 (accuracy: 98.079%), validation loss = 0.511 (accuracy: 80.952%)\n",
      "Epoch 34: 22.654 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.053 (accuracy: 99.135%), validation loss = 0.535 (accuracy: 80.952%)\n",
      "Epoch 35: 23.022 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.063 (accuracy: 98.559%), validation loss = 0.543 (accuracy: 80.952%)\n",
      "Epoch 36: 22.789 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.058 (accuracy: 98.655%), validation loss = 0.566 (accuracy: 80.952%)\n",
      "Epoch 37: 22.680 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.056 (accuracy: 98.751%), validation loss = 0.496 (accuracy: 85.714%)\n",
      "Epoch 38: 22.684 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.046 (accuracy: 99.424%), validation loss = 0.503 (accuracy: 86.667%)\n",
      "Epoch 39: 22.771 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.054 (accuracy: 98.943%), validation loss = 0.499 (accuracy: 83.810%)\n",
      "Epoch 40: 22.785 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.048 (accuracy: 99.328%), validation loss = 0.550 (accuracy: 80.952%)\n",
      "Epoch 41: 22.701 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.059 (accuracy: 98.367%), validation loss = 0.540 (accuracy: 80.952%)\n",
      "Epoch 42: 22.616 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.040 (accuracy: 99.424%), validation loss = 0.584 (accuracy: 78.095%)\n",
      "Epoch 43: 22.741 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.035 (accuracy: 99.520%), validation loss = 0.575 (accuracy: 78.095%)\n",
      "Epoch 44: 22.666 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.043 (accuracy: 99.135%), validation loss = 0.579 (accuracy: 80.000%)\n",
      "Epoch 45: 22.651 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.029 (accuracy: 99.520%), validation loss = 0.564 (accuracy: 80.000%)\n",
      "Epoch 46: 22.681 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.051 (accuracy: 98.943%), validation loss = 0.587 (accuracy: 77.143%)\n",
      "Epoch 47: 22.778 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.040 (accuracy: 99.135%), validation loss = 0.594 (accuracy: 79.048%)\n",
      "Epoch 48: 22.796 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.035 (accuracy: 99.135%), validation loss = 0.623 (accuracy: 79.048%)\n",
      "Epoch 49: 22.878 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.035 (accuracy: 99.039%), validation loss = 0.621 (accuracy: 76.190%)\n",
      "Epoch 50: 22.781 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.027 (accuracy: 99.616%), validation loss = 0.575 (accuracy: 80.000%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 30 with minimum validation error = 0.48764945552462624\n",
      "16455.483 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.1\n",
      "Epoch 1: 22.934 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.360 (accuracy: 29.971%), validation loss = 1.309 (accuracy: 32.381%)\n",
      "Epoch 2: 23.209 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.295 (accuracy: 38.329%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 3: 23.124 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.273 (accuracy: 39.962%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 4: 23.054 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.256 (accuracy: 40.538%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 5: 22.938 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.239 (accuracy: 42.459%), validation loss = 1.243 (accuracy: 36.190%)\n",
      "Epoch 6: 22.961 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.223 (accuracy: 43.324%), validation loss = 1.227 (accuracy: 36.190%)\n",
      "Epoch 7: 23.089 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.197 (accuracy: 46.302%), validation loss = 1.198 (accuracy: 42.857%)\n",
      "Epoch 8: 22.990 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.168 (accuracy: 49.952%), validation loss = 1.171 (accuracy: 44.762%)\n",
      "Epoch 9: 22.901 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.133 (accuracy: 53.698%), validation loss = 1.137 (accuracy: 47.619%)\n",
      "Epoch 10: 22.879 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.091 (accuracy: 57.925%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 11: 22.983 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.048 (accuracy: 59.942%), validation loss = 1.045 (accuracy: 54.286%)\n",
      "Epoch 12: 23.207 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.997 (accuracy: 61.383%), validation loss = 0.993 (accuracy: 57.143%)\n",
      "Epoch 13: 22.853 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.931 (accuracy: 65.130%), validation loss = 0.937 (accuracy: 59.048%)\n",
      "Epoch 14: 22.950 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.854 (accuracy: 68.972%), validation loss = 0.874 (accuracy: 62.857%)\n",
      "Epoch 15: 22.975 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.803 (accuracy: 70.893%), validation loss = 0.820 (accuracy: 67.619%)\n",
      "Epoch 16: 22.891 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.753 (accuracy: 71.566%), validation loss = 0.775 (accuracy: 69.524%)\n",
      "Epoch 17: 22.903 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.676 (accuracy: 76.081%), validation loss = 0.728 (accuracy: 73.333%)\n",
      "Epoch 18: 22.918 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.628 (accuracy: 78.194%), validation loss = 0.698 (accuracy: 71.429%)\n",
      "Epoch 19: 22.938 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.571 (accuracy: 80.403%), validation loss = 0.671 (accuracy: 75.238%)\n",
      "Epoch 20: 22.914 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.531 (accuracy: 82.805%), validation loss = 0.627 (accuracy: 81.905%)\n",
      "Epoch 21: 22.929 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.486 (accuracy: 85.399%), validation loss = 0.654 (accuracy: 77.143%)\n",
      "Epoch 22: 22.709 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.438 (accuracy: 87.320%), validation loss = 0.618 (accuracy: 78.095%)\n",
      "Epoch 23: 22.848 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.397 (accuracy: 89.433%), validation loss = 0.561 (accuracy: 76.190%)\n",
      "Epoch 24: 22.883 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.376 (accuracy: 90.490%), validation loss = 0.585 (accuracy: 76.190%)\n",
      "Epoch 25: 23.065 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.330 (accuracy: 91.354%), validation loss = 0.553 (accuracy: 76.190%)\n",
      "Epoch 26: 22.860 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.308 (accuracy: 91.835%), validation loss = 0.518 (accuracy: 80.000%)\n",
      "Epoch 27: 22.841 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.263 (accuracy: 93.756%), validation loss = 0.511 (accuracy: 79.048%)\n",
      "Epoch 28: 22.908 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.282 (accuracy: 92.219%), validation loss = 0.531 (accuracy: 79.048%)\n",
      "Epoch 29: 22.803 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.233 (accuracy: 94.621%), validation loss = 0.509 (accuracy: 79.048%)\n",
      "Epoch 30: 22.865 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.224 (accuracy: 94.813%), validation loss = 0.484 (accuracy: 80.952%)\n",
      "Epoch 31: 22.875 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.239 (accuracy: 93.468%), validation loss = 0.491 (accuracy: 80.000%)\n",
      "Epoch 32: 22.749 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.190 (accuracy: 95.869%), validation loss = 0.490 (accuracy: 80.000%)\n",
      "Epoch 33: 22.688 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.158 (accuracy: 97.406%), validation loss = 0.482 (accuracy: 81.905%)\n",
      "Epoch 34: 22.833 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.170 (accuracy: 96.638%), validation loss = 0.510 (accuracy: 80.000%)\n",
      "Epoch 35: 22.788 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.184 (accuracy: 95.965%), validation loss = 0.467 (accuracy: 80.952%)\n",
      "Epoch 36: 22.834 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.152 (accuracy: 96.638%), validation loss = 0.531 (accuracy: 80.952%)\n",
      "Epoch 37: 22.727 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.149 (accuracy: 97.406%), validation loss = 0.519 (accuracy: 81.905%)\n",
      "Epoch 38: 22.721 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.136 (accuracy: 97.118%), validation loss = 0.547 (accuracy: 77.143%)\n",
      "Epoch 39: 23.053 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.112 (accuracy: 98.175%), validation loss = 0.496 (accuracy: 79.048%)\n",
      "Epoch 40: 22.734 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.120 (accuracy: 97.791%), validation loss = 0.569 (accuracy: 80.000%)\n",
      "Epoch 41: 22.696 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.108 (accuracy: 98.175%), validation loss = 0.542 (accuracy: 78.095%)\n",
      "Epoch 42: 22.923 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.109 (accuracy: 98.271%), validation loss = 0.529 (accuracy: 80.000%)\n",
      "Epoch 43: 22.643 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.106 (accuracy: 98.655%), validation loss = 0.491 (accuracy: 80.952%)\n",
      "Epoch 44: 22.650 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.103 (accuracy: 98.463%), validation loss = 0.510 (accuracy: 76.190%)\n",
      "Epoch 45: 22.765 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.094 (accuracy: 98.847%), validation loss = 0.598 (accuracy: 78.095%)\n",
      "Epoch 46: 22.767 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.094 (accuracy: 98.463%), validation loss = 0.549 (accuracy: 76.190%)\n",
      "Epoch 47: 22.661 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.093 (accuracy: 98.367%), validation loss = 0.520 (accuracy: 80.952%)\n",
      "Epoch 48: 22.732 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.084 (accuracy: 98.847%), validation loss = 0.554 (accuracy: 79.048%)\n",
      "Epoch 49: 22.787 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.081 (accuracy: 98.655%), validation loss = 0.559 (accuracy: 78.095%)\n",
      "Epoch 50: 22.709 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.077 (accuracy: 99.232%), validation loss = 0.583 (accuracy: 75.238%)\n",
      "Epoch 51: 22.697 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.073 (accuracy: 99.135%), validation loss = 0.498 (accuracy: 80.000%)\n",
      "Epoch 52: 22.933 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.074 (accuracy: 99.328%), validation loss = 0.614 (accuracy: 74.286%)\n",
      "Epoch 53: 22.804 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.081 (accuracy: 98.751%), validation loss = 0.549 (accuracy: 80.000%)\n",
      "Epoch 54: 22.687 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.079 (accuracy: 98.655%), validation loss = 0.530 (accuracy: 78.095%)\n",
      "Epoch 55: 22.825 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.078 (accuracy: 98.559%), validation loss = 0.495 (accuracy: 84.762%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 35 with minimum validation error = 0.46715561144408724\n",
      "17724.423 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.2\n",
      "Epoch 1: 22.752 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.360 (accuracy: 35.062%), validation loss = 1.356 (accuracy: 33.333%)\n",
      "Epoch 2: 22.794 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.307 (accuracy: 38.713%), validation loss = 1.330 (accuracy: 33.333%)\n",
      "Epoch 3: 22.845 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.292 (accuracy: 39.001%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 4: 22.889 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.281 (accuracy: 38.809%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 5: 22.830 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.266 (accuracy: 39.577%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 6: 22.801 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.252 (accuracy: 41.883%), validation loss = 1.274 (accuracy: 34.286%)\n",
      "Epoch 7: 22.825 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.245 (accuracy: 41.595%), validation loss = 1.269 (accuracy: 36.190%)\n",
      "Epoch 8: 22.952 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.233 (accuracy: 43.900%), validation loss = 1.254 (accuracy: 35.238%)\n",
      "Epoch 9: 22.824 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.218 (accuracy: 45.341%), validation loss = 1.242 (accuracy: 39.048%)\n",
      "Epoch 10: 22.772 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.205 (accuracy: 45.821%), validation loss = 1.223 (accuracy: 40.000%)\n",
      "Epoch 11: 23.161 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.185 (accuracy: 47.166%), validation loss = 1.207 (accuracy: 40.952%)\n",
      "Epoch 12: 22.915 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.170 (accuracy: 49.952%), validation loss = 1.181 (accuracy: 42.857%)\n",
      "Epoch 13: 22.853 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.127 (accuracy: 54.179%), validation loss = 1.163 (accuracy: 44.762%)\n",
      "Epoch 14: 22.811 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.098 (accuracy: 54.083%), validation loss = 1.127 (accuracy: 45.714%)\n",
      "Epoch 15: 22.896 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.059 (accuracy: 57.637%), validation loss = 1.088 (accuracy: 53.333%)\n",
      "Epoch 16: 22.795 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.025 (accuracy: 61.191%), validation loss = 1.061 (accuracy: 55.238%)\n",
      "Epoch 17: 22.844 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.967 (accuracy: 62.248%), validation loss = 1.022 (accuracy: 54.286%)\n",
      "Epoch 18: 22.843 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.923 (accuracy: 64.553%), validation loss = 0.996 (accuracy: 55.238%)\n",
      "Epoch 19: 22.841 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.891 (accuracy: 67.819%), validation loss = 0.956 (accuracy: 60.000%)\n",
      "Epoch 20: 22.804 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.841 (accuracy: 69.452%), validation loss = 0.913 (accuracy: 58.095%)\n",
      "Epoch 21: 22.850 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.800 (accuracy: 71.278%), validation loss = 0.864 (accuracy: 62.857%)\n",
      "Epoch 22: 22.867 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.737 (accuracy: 74.640%), validation loss = 0.845 (accuracy: 63.810%)\n",
      "Epoch 23: 22.814 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.705 (accuracy: 74.928%), validation loss = 0.822 (accuracy: 67.619%)\n",
      "Epoch 24: 23.073 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.671 (accuracy: 77.906%), validation loss = 0.792 (accuracy: 69.524%)\n",
      "Epoch 25: 22.904 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.615 (accuracy: 78.963%), validation loss = 0.740 (accuracy: 71.429%)\n",
      "Epoch 26: 22.836 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.573 (accuracy: 81.844%), validation loss = 0.714 (accuracy: 72.381%)\n",
      "Epoch 27: 22.968 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.524 (accuracy: 82.901%), validation loss = 0.689 (accuracy: 74.286%)\n",
      "Epoch 28: 22.806 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.512 (accuracy: 84.822%), validation loss = 0.659 (accuracy: 76.190%)\n",
      "Epoch 29: 22.886 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.476 (accuracy: 86.071%), validation loss = 0.627 (accuracy: 76.190%)\n",
      "Epoch 30: 22.837 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.444 (accuracy: 87.320%), validation loss = 0.616 (accuracy: 78.095%)\n",
      "Epoch 31: 22.830 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.407 (accuracy: 89.529%), validation loss = 0.606 (accuracy: 76.190%)\n",
      "Epoch 32: 22.880 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.393 (accuracy: 88.761%), validation loss = 0.587 (accuracy: 80.952%)\n",
      "Epoch 33: 22.796 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.369 (accuracy: 91.354%), validation loss = 0.609 (accuracy: 80.952%)\n",
      "Epoch 34: 22.685 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.343 (accuracy: 92.219%), validation loss = 0.565 (accuracy: 80.000%)\n",
      "Epoch 35: 22.863 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.325 (accuracy: 92.315%), validation loss = 0.552 (accuracy: 78.095%)\n",
      "Epoch 36: 22.911 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.299 (accuracy: 94.332%), validation loss = 0.560 (accuracy: 78.095%)\n",
      "Epoch 37: 22.794 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.260 (accuracy: 94.236%), validation loss = 0.543 (accuracy: 79.048%)\n",
      "Epoch 38: 23.018 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.268 (accuracy: 94.428%), validation loss = 0.547 (accuracy: 80.000%)\n",
      "Epoch 39: 22.763 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.257 (accuracy: 94.140%), validation loss = 0.523 (accuracy: 79.048%)\n",
      "Epoch 40: 22.856 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.240 (accuracy: 95.197%), validation loss = 0.514 (accuracy: 83.810%)\n",
      "Epoch 41: 22.823 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.219 (accuracy: 96.061%), validation loss = 0.576 (accuracy: 80.000%)\n",
      "Epoch 42: 22.710 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.203 (accuracy: 96.350%), validation loss = 0.512 (accuracy: 78.095%)\n",
      "Epoch 43: 22.873 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.212 (accuracy: 95.101%), validation loss = 0.553 (accuracy: 78.095%)\n",
      "Epoch 44: 22.690 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.196 (accuracy: 95.965%), validation loss = 0.556 (accuracy: 78.095%)\n",
      "Epoch 45: 22.689 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.192 (accuracy: 96.446%), validation loss = 0.506 (accuracy: 81.905%)\n",
      "Epoch 46: 22.861 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.182 (accuracy: 96.926%), validation loss = 0.498 (accuracy: 80.952%)\n",
      "Epoch 47: 22.825 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.168 (accuracy: 97.598%), validation loss = 0.565 (accuracy: 80.952%)\n",
      "Epoch 48: 22.661 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.152 (accuracy: 97.887%), validation loss = 0.604 (accuracy: 79.048%)\n",
      "Epoch 49: 22.630 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.160 (accuracy: 97.310%), validation loss = 0.545 (accuracy: 82.857%)\n",
      "Epoch 50: 22.696 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.147 (accuracy: 97.791%), validation loss = 0.579 (accuracy: 81.905%)\n",
      "Epoch 51: 22.922 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.174 (accuracy: 96.542%), validation loss = 0.595 (accuracy: 79.048%)\n",
      "Epoch 52: 22.626 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.147 (accuracy: 97.695%), validation loss = 0.620 (accuracy: 79.048%)\n",
      "Epoch 53: 22.860 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.146 (accuracy: 97.598%), validation loss = 0.576 (accuracy: 80.000%)\n",
      "Epoch 54: 22.692 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.164 (accuracy: 97.695%), validation loss = 0.590 (accuracy: 77.143%)\n",
      "Epoch 55: 22.867 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.144 (accuracy: 97.118%), validation loss = 0.594 (accuracy: 78.095%)\n",
      "Epoch 56: 23.058 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.139 (accuracy: 97.598%), validation loss = 0.543 (accuracy: 80.000%)\n",
      "Epoch 57: 23.190 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.143 (accuracy: 97.310%), validation loss = 0.571 (accuracy: 79.048%)\n",
      "Epoch 58: 23.401 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.136 (accuracy: 98.175%), validation loss = 0.540 (accuracy: 79.048%)\n",
      "Epoch 59: 23.402 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.136 (accuracy: 98.559%), validation loss = 0.604 (accuracy: 79.048%)\n",
      "Epoch 60: 23.542 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.123 (accuracy: 97.695%), validation loss = 0.598 (accuracy: 79.048%)\n",
      "Epoch 61: 23.557 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.118 (accuracy: 98.271%), validation loss = 0.540 (accuracy: 77.143%)\n",
      "Epoch 62: 23.587 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.126 (accuracy: 97.598%), validation loss = 0.623 (accuracy: 76.190%)\n",
      "Epoch 63: 23.706 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.116 (accuracy: 98.847%), validation loss = 0.621 (accuracy: 77.143%)\n",
      "Epoch 64: 24.115 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.113 (accuracy: 98.655%), validation loss = 0.638 (accuracy: 76.190%)\n",
      "Epoch 65: 24.127 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.105 (accuracy: 99.135%), validation loss = 0.671 (accuracy: 75.238%)\n",
      "Epoch 66: 24.012 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.108 (accuracy: 98.847%), validation loss = 0.607 (accuracy: 77.143%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 46 with minimum validation error = 0.4982662740207854\n",
      "19255.771 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.4\n",
      "Epoch 1: 24.013 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.355 (accuracy: 32.853%), validation loss = 1.353 (accuracy: 33.333%)\n",
      "Epoch 2: 24.180 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.328 (accuracy: 36.023%), validation loss = 1.331 (accuracy: 33.333%)\n",
      "Epoch 3: 24.261 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.308 (accuracy: 38.329%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 4: 24.405 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.299 (accuracy: 37.944%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 5: 24.365 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.297 (accuracy: 38.809%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 6: 24.316 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.292 (accuracy: 39.289%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 7: 24.405 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.281 (accuracy: 39.962%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 8: 24.456 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.276 (accuracy: 39.962%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 9: 24.360 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.271 (accuracy: 39.001%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 10: 24.807 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.264 (accuracy: 39.866%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 11: 24.753 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.258 (accuracy: 40.922%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 12: 24.547 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.253 (accuracy: 39.673%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 13: 24.456 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.243 (accuracy: 41.402%), validation loss = 1.255 (accuracy: 34.286%)\n",
      "Epoch 14: 24.493 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.238 (accuracy: 40.538%), validation loss = 1.249 (accuracy: 34.286%)\n",
      "Epoch 15: 24.454 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.227 (accuracy: 42.651%), validation loss = 1.244 (accuracy: 34.286%)\n",
      "Epoch 16: 24.314 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.218 (accuracy: 42.843%), validation loss = 1.238 (accuracy: 34.286%)\n",
      "Epoch 17: 24.376 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.208 (accuracy: 44.765%), validation loss = 1.226 (accuracy: 34.286%)\n",
      "Epoch 18: 24.375 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.198 (accuracy: 45.245%), validation loss = 1.215 (accuracy: 38.095%)\n",
      "Epoch 19: 24.356 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.182 (accuracy: 46.110%), validation loss = 1.206 (accuracy: 40.000%)\n",
      "Epoch 20: 24.538 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.173 (accuracy: 47.358%), validation loss = 1.193 (accuracy: 41.905%)\n",
      "Epoch 21: 24.487 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.152 (accuracy: 49.183%), validation loss = 1.182 (accuracy: 43.810%)\n",
      "Epoch 22: 24.535 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.137 (accuracy: 50.432%), validation loss = 1.177 (accuracy: 43.810%)\n",
      "Epoch 23: 24.655 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.122 (accuracy: 54.179%), validation loss = 1.158 (accuracy: 49.524%)\n",
      "Epoch 24: 24.751 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.101 (accuracy: 55.331%), validation loss = 1.135 (accuracy: 51.429%)\n",
      "Epoch 25: 24.663 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.074 (accuracy: 55.716%), validation loss = 1.111 (accuracy: 51.429%)\n",
      "Epoch 26: 24.705 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.051 (accuracy: 59.750%), validation loss = 1.098 (accuracy: 51.429%)\n",
      "Epoch 27: 24.651 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.028 (accuracy: 59.750%), validation loss = 1.074 (accuracy: 52.381%)\n",
      "Epoch 28: 24.603 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.991 (accuracy: 61.960%), validation loss = 1.060 (accuracy: 53.333%)\n",
      "Epoch 29: 24.584 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.957 (accuracy: 64.553%), validation loss = 1.027 (accuracy: 54.286%)\n",
      "Epoch 30: 24.545 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.933 (accuracy: 65.130%), validation loss = 0.982 (accuracy: 58.095%)\n",
      "Epoch 31: 24.483 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.909 (accuracy: 67.723%), validation loss = 0.976 (accuracy: 58.095%)\n",
      "Epoch 32: 24.479 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.865 (accuracy: 68.492%), validation loss = 0.935 (accuracy: 61.905%)\n",
      "Epoch 33: 24.572 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.833 (accuracy: 70.509%), validation loss = 0.917 (accuracy: 62.857%)\n",
      "Epoch 34: 24.519 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.791 (accuracy: 73.103%), validation loss = 0.891 (accuracy: 62.857%)\n",
      "Epoch 35: 24.579 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.757 (accuracy: 74.736%), validation loss = 0.846 (accuracy: 65.714%)\n",
      "Epoch 36: 24.944 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.712 (accuracy: 76.081%), validation loss = 0.811 (accuracy: 68.571%)\n",
      "Epoch 37: 24.783 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.700 (accuracy: 77.041%), validation loss = 0.809 (accuracy: 67.619%)\n",
      "Epoch 38: 24.594 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.671 (accuracy: 77.522%), validation loss = 0.776 (accuracy: 67.619%)\n",
      "Epoch 39: 24.543 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.640 (accuracy: 78.290%), validation loss = 0.753 (accuracy: 69.524%)\n",
      "Epoch 40: 24.608 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.594 (accuracy: 79.923%), validation loss = 0.746 (accuracy: 70.476%)\n",
      "Epoch 41: 24.587 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.571 (accuracy: 81.268%), validation loss = 0.741 (accuracy: 70.476%)\n",
      "Epoch 42: 24.607 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.561 (accuracy: 82.133%), validation loss = 0.711 (accuracy: 73.333%)\n",
      "Epoch 43: 24.632 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.531 (accuracy: 82.901%), validation loss = 0.718 (accuracy: 74.286%)\n",
      "Epoch 44: 24.472 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.527 (accuracy: 82.997%), validation loss = 0.690 (accuracy: 74.286%)\n",
      "Epoch 45: 24.671 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.497 (accuracy: 84.438%), validation loss = 0.717 (accuracy: 74.286%)\n",
      "Epoch 46: 24.510 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.467 (accuracy: 85.303%), validation loss = 0.680 (accuracy: 75.238%)\n",
      "Epoch 47: 24.614 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.465 (accuracy: 85.783%), validation loss = 0.710 (accuracy: 77.143%)\n",
      "Epoch 48: 24.685 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.458 (accuracy: 86.263%), validation loss = 0.637 (accuracy: 79.048%)\n",
      "Epoch 49: 24.816 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.428 (accuracy: 87.896%), validation loss = 0.649 (accuracy: 78.095%)\n",
      "Epoch 50: 24.437 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.415 (accuracy: 88.857%), validation loss = 0.673 (accuracy: 78.095%)\n",
      "Epoch 51: 24.430 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.395 (accuracy: 88.280%), validation loss = 0.691 (accuracy: 80.952%)\n",
      "Epoch 52: 24.383 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.395 (accuracy: 89.529%), validation loss = 0.658 (accuracy: 82.857%)\n",
      "Epoch 53: 24.490 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.380 (accuracy: 91.066%), validation loss = 0.710 (accuracy: 75.238%)\n",
      "Epoch 54: 24.432 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.360 (accuracy: 92.123%), validation loss = 0.668 (accuracy: 75.238%)\n",
      "Epoch 55: 24.448 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.375 (accuracy: 90.682%), validation loss = 0.712 (accuracy: 74.286%)\n",
      "Epoch 56: 24.494 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.336 (accuracy: 92.795%), validation loss = 0.715 (accuracy: 74.286%)\n",
      "Epoch 57: 24.491 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.331 (accuracy: 92.699%), validation loss = 0.679 (accuracy: 78.095%)\n",
      "Epoch 58: 24.497 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.325 (accuracy: 92.411%), validation loss = 0.682 (accuracy: 79.048%)\n",
      "Epoch 59: 24.456 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.320 (accuracy: 93.468%), validation loss = 0.753 (accuracy: 73.333%)\n",
      "Epoch 60: 24.509 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.293 (accuracy: 94.909%), validation loss = 0.630 (accuracy: 80.952%)\n",
      "Epoch 61: 24.917 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.280 (accuracy: 95.485%), validation loss = 0.699 (accuracy: 74.286%)\n",
      "Epoch 62: 24.553 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.297 (accuracy: 94.813%), validation loss = 0.809 (accuracy: 71.429%)\n",
      "Epoch 63: 24.479 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.270 (accuracy: 95.389%), validation loss = 0.704 (accuracy: 76.190%)\n",
      "Epoch 64: 24.420 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.257 (accuracy: 95.869%), validation loss = 0.775 (accuracy: 73.333%)\n",
      "Epoch 65: 24.436 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.269 (accuracy: 94.236%), validation loss = 0.611 (accuracy: 81.905%)\n",
      "Epoch 66: 24.570 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.262 (accuracy: 95.389%), validation loss = 0.659 (accuracy: 80.952%)\n",
      "Epoch 67: 24.440 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.231 (accuracy: 97.406%), validation loss = 0.708 (accuracy: 75.238%)\n",
      "Epoch 68: 24.359 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.226 (accuracy: 96.734%), validation loss = 0.645 (accuracy: 79.048%)\n",
      "Epoch 69: 24.504 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.227 (accuracy: 96.350%), validation loss = 0.733 (accuracy: 73.333%)\n",
      "Epoch 70: 24.441 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.231 (accuracy: 96.446%), validation loss = 0.623 (accuracy: 77.143%)\n",
      "Epoch 71: 24.358 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.224 (accuracy: 96.542%), validation loss = 0.720 (accuracy: 72.381%)\n",
      "Epoch 72: 24.473 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.228 (accuracy: 95.869%), validation loss = 0.602 (accuracy: 83.810%)\n",
      "Epoch 73: 24.631 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.194 (accuracy: 97.887%), validation loss = 0.647 (accuracy: 78.095%)\n",
      "Epoch 74: 24.748 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.209 (accuracy: 97.214%), validation loss = 0.751 (accuracy: 73.333%)\n",
      "Epoch 75: 24.392 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.207 (accuracy: 96.638%), validation loss = 0.787 (accuracy: 76.190%)\n",
      "Epoch 76: 24.402 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.229 (accuracy: 95.677%), validation loss = 0.709 (accuracy: 75.238%)\n",
      "Epoch 77: 24.455 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.200 (accuracy: 97.022%), validation loss = 0.707 (accuracy: 71.429%)\n",
      "Epoch 78: 24.459 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.204 (accuracy: 97.022%), validation loss = 0.711 (accuracy: 80.000%)\n",
      "Epoch 79: 24.448 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.217 (accuracy: 96.158%), validation loss = 0.687 (accuracy: 72.381%)\n",
      "Epoch 80: 24.440 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.195 (accuracy: 97.118%), validation loss = 0.725 (accuracy: 71.429%)\n",
      "Epoch 81: 24.433 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.190 (accuracy: 97.598%), validation loss = 0.662 (accuracy: 74.286%)\n",
      "Epoch 82: 24.478 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.177 (accuracy: 98.271%), validation loss = 0.673 (accuracy: 78.095%)\n",
      "Epoch 83: 24.445 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.192 (accuracy: 96.830%), validation loss = 0.863 (accuracy: 70.476%)\n",
      "Epoch 84: 24.428 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.175 (accuracy: 97.983%), validation loss = 0.683 (accuracy: 71.429%)\n",
      "Epoch 85: 24.456 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.167 (accuracy: 97.887%), validation loss = 0.693 (accuracy: 73.333%)\n",
      "Epoch 86: 24.707 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.211 (accuracy: 96.542%), validation loss = 0.849 (accuracy: 69.524%)\n",
      "Epoch 87: 24.595 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.209 (accuracy: 96.158%), validation loss = 0.638 (accuracy: 79.048%)\n",
      "Epoch 88: 24.462 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.193 (accuracy: 97.310%), validation loss = 0.766 (accuracy: 76.190%)\n",
      "Epoch 89: 24.442 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.184 (accuracy: 97.214%), validation loss = 0.726 (accuracy: 75.238%)\n",
      "Epoch 90: 24.525 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.170 (accuracy: 98.079%), validation loss = 0.635 (accuracy: 77.143%)\n",
      "Epoch 91: 24.498 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.158 (accuracy: 98.271%), validation loss = 0.702 (accuracy: 74.286%)\n",
      "Epoch 92: 24.507 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.183 (accuracy: 97.406%), validation loss = 0.731 (accuracy: 72.381%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 72 with minimum validation error = 0.601907197634379\n",
      "21531.869 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.9\n",
      "Epoch 1: 24.547 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.379 (accuracy: 30.355%), validation loss = 1.365 (accuracy: 27.619%)\n",
      "Epoch 2: 24.587 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.349 (accuracy: 32.757%), validation loss = 1.344 (accuracy: 37.143%)\n",
      "Epoch 3: 24.719 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.329 (accuracy: 34.966%), validation loss = 1.331 (accuracy: 35.238%)\n",
      "Epoch 4: 24.625 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.316 (accuracy: 39.193%), validation loss = 1.321 (accuracy: 34.286%)\n",
      "Epoch 5: 24.614 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.308 (accuracy: 36.407%), validation loss = 1.318 (accuracy: 34.286%)\n",
      "Epoch 6: 24.635 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.305 (accuracy: 37.176%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 7: 24.948 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.298 (accuracy: 38.905%), validation loss = 1.308 (accuracy: 32.381%)\n",
      "Epoch 8: 24.627 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.291 (accuracy: 38.136%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 9: 24.629 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.283 (accuracy: 41.114%), validation loss = 1.303 (accuracy: 32.381%)\n",
      "Epoch 10: 24.648 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.282 (accuracy: 40.154%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 11: 24.640 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.281 (accuracy: 38.809%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 12: 24.595 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.288 (accuracy: 38.425%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 13: 24.607 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.276 (accuracy: 40.634%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 14: 24.651 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.279 (accuracy: 39.866%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 15: 24.500 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.271 (accuracy: 40.058%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 16: 24.523 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.270 (accuracy: 40.442%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 17: 24.578 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.268 (accuracy: 40.730%), validation loss = 1.285 (accuracy: 34.286%)\n",
      "Epoch 18: 24.494 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.262 (accuracy: 41.114%), validation loss = 1.281 (accuracy: 34.286%)\n",
      "Epoch 19: 24.936 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.255 (accuracy: 42.267%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 20: 24.598 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.261 (accuracy: 41.402%), validation loss = 1.279 (accuracy: 35.238%)\n",
      "Epoch 21: 24.753 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.259 (accuracy: 41.787%), validation loss = 1.275 (accuracy: 34.286%)\n",
      "Epoch 22: 24.639 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.246 (accuracy: 41.018%), validation loss = 1.276 (accuracy: 35.238%)\n",
      "Epoch 23: 24.554 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.249 (accuracy: 41.306%), validation loss = 1.273 (accuracy: 35.238%)\n",
      "Epoch 24: 24.704 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.244 (accuracy: 41.210%), validation loss = 1.272 (accuracy: 35.238%)\n",
      "Epoch 25: 24.627 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.240 (accuracy: 42.651%), validation loss = 1.275 (accuracy: 35.238%)\n",
      "Epoch 26: 24.558 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.231 (accuracy: 41.691%), validation loss = 1.273 (accuracy: 35.238%)\n",
      "Epoch 27: 24.492 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.230 (accuracy: 41.499%), validation loss = 1.270 (accuracy: 35.238%)\n",
      "Epoch 28: 24.696 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.227 (accuracy: 42.843%), validation loss = 1.262 (accuracy: 36.190%)\n",
      "Epoch 29: 24.674 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.219 (accuracy: 43.900%), validation loss = 1.259 (accuracy: 36.190%)\n",
      "Epoch 30: 24.665 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.211 (accuracy: 43.420%), validation loss = 1.256 (accuracy: 36.190%)\n",
      "Epoch 31: 24.685 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.210 (accuracy: 43.900%), validation loss = 1.249 (accuracy: 36.190%)\n",
      "Epoch 32: 24.983 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.200 (accuracy: 44.765%), validation loss = 1.249 (accuracy: 38.095%)\n",
      "Epoch 33: 24.636 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.201 (accuracy: 46.110%), validation loss = 1.242 (accuracy: 40.952%)\n",
      "Epoch 34: 24.680 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.185 (accuracy: 45.245%), validation loss = 1.239 (accuracy: 39.048%)\n",
      "Epoch 35: 24.640 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.180 (accuracy: 45.725%), validation loss = 1.235 (accuracy: 39.048%)\n",
      "Epoch 36: 24.793 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.183 (accuracy: 47.070%), validation loss = 1.232 (accuracy: 39.048%)\n",
      "Epoch 37: 24.659 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.167 (accuracy: 46.974%), validation loss = 1.227 (accuracy: 39.048%)\n",
      "Epoch 38: 24.675 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.161 (accuracy: 48.415%), validation loss = 1.218 (accuracy: 40.000%)\n",
      "Epoch 39: 24.669 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.153 (accuracy: 48.319%), validation loss = 1.213 (accuracy: 40.000%)\n",
      "Epoch 40: 24.640 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.146 (accuracy: 49.472%), validation loss = 1.208 (accuracy: 40.000%)\n",
      "Epoch 41: 24.604 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.128 (accuracy: 51.681%), validation loss = 1.199 (accuracy: 41.905%)\n",
      "Epoch 42: 24.746 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.110 (accuracy: 51.585%), validation loss = 1.189 (accuracy: 40.000%)\n",
      "Epoch 43: 24.824 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.103 (accuracy: 53.026%), validation loss = 1.182 (accuracy: 40.000%)\n",
      "Epoch 44: 24.995 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.096 (accuracy: 52.546%), validation loss = 1.171 (accuracy: 40.952%)\n",
      "Epoch 45: 24.674 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.079 (accuracy: 56.388%), validation loss = 1.163 (accuracy: 44.762%)\n",
      "Epoch 46: 24.667 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.060 (accuracy: 55.427%), validation loss = 1.157 (accuracy: 48.571%)\n",
      "Epoch 47: 24.665 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.051 (accuracy: 54.851%), validation loss = 1.150 (accuracy: 48.571%)\n",
      "Epoch 48: 24.741 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.038 (accuracy: 55.139%), validation loss = 1.129 (accuracy: 47.619%)\n",
      "Epoch 49: 24.658 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.023 (accuracy: 56.676%), validation loss = 1.123 (accuracy: 48.571%)\n",
      "Epoch 50: 24.645 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.997 (accuracy: 57.925%), validation loss = 1.098 (accuracy: 48.571%)\n",
      "Epoch 51: 24.706 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.973 (accuracy: 60.423%), validation loss = 1.090 (accuracy: 48.571%)\n",
      "Epoch 52: 24.648 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.970 (accuracy: 59.558%), validation loss = 1.081 (accuracy: 46.667%)\n",
      "Epoch 53: 24.655 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.933 (accuracy: 61.768%), validation loss = 1.095 (accuracy: 48.571%)\n",
      "Epoch 54: 24.548 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.926 (accuracy: 62.056%), validation loss = 1.055 (accuracy: 47.619%)\n",
      "Epoch 55: 24.685 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.923 (accuracy: 63.112%), validation loss = 1.039 (accuracy: 52.381%)\n",
      "Epoch 56: 24.835 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.884 (accuracy: 65.802%), validation loss = 1.038 (accuracy: 54.286%)\n",
      "Epoch 57: 24.842 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.857 (accuracy: 66.090%), validation loss = 1.014 (accuracy: 56.190%)\n",
      "Epoch 58: 24.746 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.856 (accuracy: 67.723%), validation loss = 1.023 (accuracy: 56.190%)\n",
      "Epoch 59: 24.516 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.841 (accuracy: 69.452%), validation loss = 1.033 (accuracy: 58.095%)\n",
      "Epoch 60: 24.541 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.806 (accuracy: 69.452%), validation loss = 1.011 (accuracy: 59.048%)\n",
      "Epoch 61: 24.999 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.793 (accuracy: 71.662%), validation loss = 0.972 (accuracy: 61.905%)\n",
      "Epoch 62: 24.612 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.786 (accuracy: 71.662%), validation loss = 0.969 (accuracy: 60.952%)\n",
      "Epoch 63: 24.735 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.762 (accuracy: 73.007%), validation loss = 0.991 (accuracy: 61.905%)\n",
      "Epoch 64: 24.516 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.752 (accuracy: 75.600%), validation loss = 0.919 (accuracy: 67.619%)\n",
      "Epoch 65: 24.699 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.722 (accuracy: 76.465%), validation loss = 0.904 (accuracy: 63.810%)\n",
      "Epoch 66: 24.764 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.707 (accuracy: 77.714%), validation loss = 0.905 (accuracy: 64.762%)\n",
      "Epoch 67: 24.532 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.708 (accuracy: 76.657%), validation loss = 0.899 (accuracy: 69.524%)\n",
      "Epoch 68: 24.971 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.689 (accuracy: 79.155%), validation loss = 0.939 (accuracy: 62.857%)\n",
      "Epoch 69: 24.775 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.682 (accuracy: 79.155%), validation loss = 0.924 (accuracy: 64.762%)\n",
      "Epoch 70: 24.490 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.661 (accuracy: 79.731%), validation loss = 0.904 (accuracy: 62.857%)\n",
      "Epoch 71: 24.524 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.641 (accuracy: 80.307%), validation loss = 0.921 (accuracy: 68.571%)\n",
      "Epoch 72: 24.524 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.646 (accuracy: 80.500%), validation loss = 0.871 (accuracy: 64.762%)\n",
      "Epoch 73: 24.670 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.608 (accuracy: 82.421%), validation loss = 0.930 (accuracy: 69.524%)\n",
      "Epoch 74: 24.510 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.604 (accuracy: 82.805%), validation loss = 0.917 (accuracy: 69.524%)\n",
      "Epoch 75: 24.572 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.598 (accuracy: 82.037%), validation loss = 0.868 (accuracy: 65.714%)\n",
      "Epoch 76: 24.655 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.572 (accuracy: 83.189%), validation loss = 0.809 (accuracy: 68.571%)\n",
      "Epoch 77: 24.672 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.569 (accuracy: 84.246%), validation loss = 0.832 (accuracy: 66.667%)\n",
      "Epoch 78: 24.472 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.562 (accuracy: 83.477%), validation loss = 0.863 (accuracy: 69.524%)\n",
      "Epoch 79: 24.505 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.553 (accuracy: 84.246%), validation loss = 0.884 (accuracy: 66.667%)\n",
      "Epoch 80: 24.603 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.536 (accuracy: 84.342%), validation loss = 0.846 (accuracy: 67.619%)\n",
      "Epoch 81: 24.596 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.513 (accuracy: 86.263%), validation loss = 0.862 (accuracy: 68.571%)\n",
      "Epoch 82: 24.656 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.507 (accuracy: 85.975%), validation loss = 0.824 (accuracy: 66.667%)\n",
      "Epoch 83: 24.483 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.492 (accuracy: 85.975%), validation loss = 0.891 (accuracy: 68.571%)\n",
      "Epoch 84: 24.470 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.492 (accuracy: 86.071%), validation loss = 0.813 (accuracy: 70.476%)\n",
      "Epoch 85: 24.479 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.507 (accuracy: 84.534%), validation loss = 0.861 (accuracy: 72.381%)\n",
      "Epoch 86: 24.460 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.497 (accuracy: 85.207%), validation loss = 0.848 (accuracy: 67.619%)\n",
      "Epoch 87: 24.511 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.485 (accuracy: 85.687%), validation loss = 0.821 (accuracy: 69.524%)\n",
      "Epoch 88: 24.422 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.490 (accuracy: 85.783%), validation loss = 0.810 (accuracy: 68.571%)\n",
      "Epoch 89: 24.416 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.479 (accuracy: 86.071%), validation loss = 0.887 (accuracy: 66.667%)\n",
      "Epoch 90: 24.516 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.466 (accuracy: 86.071%), validation loss = 0.845 (accuracy: 70.476%)\n",
      "Epoch 91: 24.502 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.454 (accuracy: 87.128%), validation loss = 0.826 (accuracy: 69.524%)\n",
      "Epoch 92: 24.539 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.462 (accuracy: 86.359%), validation loss = 0.856 (accuracy: 66.667%)\n",
      "Epoch 93: 24.567 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.458 (accuracy: 86.744%), validation loss = 0.829 (accuracy: 66.667%)\n",
      "Epoch 94: 24.721 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.448 (accuracy: 86.263%), validation loss = 0.800 (accuracy: 71.429%)\n",
      "Epoch 95: 24.596 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.451 (accuracy: 86.263%), validation loss = 0.820 (accuracy: 66.667%)\n",
      "Epoch 96: 24.442 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 0.461 (accuracy: 85.879%), validation loss = 0.831 (accuracy: 67.619%)\n",
      "Epoch 97: 24.554 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 0.459 (accuracy: 86.071%), validation loss = 0.848 (accuracy: 67.619%)\n",
      "Epoch 98: 24.494 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.438 (accuracy: 86.936%), validation loss = 0.802 (accuracy: 67.619%)\n",
      "Epoch 99: 24.438 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.443 (accuracy: 87.608%), validation loss = 0.984 (accuracy: 61.905%)\n",
      "Epoch 100: 24.528 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.430 (accuracy: 86.647%), validation loss = 0.879 (accuracy: 68.571%)\n",
      "Epoch 101: 24.498 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.412 (accuracy: 87.416%), validation loss = 0.802 (accuracy: 69.524%)\n",
      "Epoch 102: 24.495 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.410 (accuracy: 87.128%), validation loss = 0.777 (accuracy: 72.381%)\n",
      "Epoch 103: 24.767 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.404 (accuracy: 87.800%), validation loss = 0.875 (accuracy: 67.619%)\n",
      "Epoch 104: 24.380 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.399 (accuracy: 88.088%), validation loss = 0.911 (accuracy: 62.857%)\n",
      "Epoch 105: 24.515 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.415 (accuracy: 87.608%), validation loss = 0.861 (accuracy: 71.429%)\n",
      "Epoch 106: 24.436 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.394 (accuracy: 88.280%), validation loss = 0.812 (accuracy: 69.524%)\n",
      "Epoch 107: 24.664 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 0.407 (accuracy: 87.512%), validation loss = 0.809 (accuracy: 70.476%)\n",
      "Epoch 108: 24.448 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.411 (accuracy: 86.840%), validation loss = 1.016 (accuracy: 60.952%)\n",
      "Epoch 109: 24.441 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.406 (accuracy: 87.512%), validation loss = 0.832 (accuracy: 66.667%)\n",
      "Epoch 110: 24.411 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.424 (accuracy: 87.032%), validation loss = 0.793 (accuracy: 66.667%)\n",
      "Epoch 111: 24.477 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.418 (accuracy: 86.647%), validation loss = 0.842 (accuracy: 69.524%)\n",
      "Epoch 112: 24.463 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.391 (accuracy: 87.320%), validation loss = 0.825 (accuracy: 69.524%)\n",
      "Epoch 113: 24.477 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.436 (accuracy: 85.879%), validation loss = 0.851 (accuracy: 67.619%)\n",
      "Epoch 114: 24.479 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.402 (accuracy: 87.608%), validation loss = 0.834 (accuracy: 67.619%)\n",
      "Epoch 115: 24.416 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.394 (accuracy: 87.608%), validation loss = 0.752 (accuracy: 73.333%)\n",
      "Epoch 116: 24.620 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.391 (accuracy: 87.992%), validation loss = 0.827 (accuracy: 66.667%)\n",
      "Epoch 117: 24.561 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.394 (accuracy: 87.800%), validation loss = 0.891 (accuracy: 65.714%)\n",
      "Epoch 118: 24.460 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.395 (accuracy: 87.512%), validation loss = 0.796 (accuracy: 68.571%)\n",
      "Epoch 119: 24.575 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 0.372 (accuracy: 88.665%), validation loss = 0.802 (accuracy: 70.476%)\n",
      "Epoch 120: 24.608 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.388 (accuracy: 87.416%), validation loss = 0.939 (accuracy: 62.857%)\n",
      "Epoch 121: 24.444 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.388 (accuracy: 87.512%), validation loss = 0.859 (accuracy: 65.714%)\n",
      "Epoch 122: 24.544 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.384 (accuracy: 87.416%), validation loss = 0.913 (accuracy: 60.000%)\n",
      "Epoch 123: 24.476 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.379 (accuracy: 87.128%), validation loss = 0.946 (accuracy: 60.952%)\n",
      "Epoch 124: 24.532 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.375 (accuracy: 87.320%), validation loss = 0.921 (accuracy: 61.905%)\n",
      "Epoch 125: 24.568 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.387 (accuracy: 86.840%), validation loss = 1.035 (accuracy: 58.095%)\n",
      "Epoch 126: 24.534 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.392 (accuracy: 87.416%), validation loss = 1.042 (accuracy: 54.286%)\n",
      "Epoch 127: 24.524 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.386 (accuracy: 87.608%), validation loss = 0.997 (accuracy: 61.905%)\n",
      "Epoch 128: 24.510 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.390 (accuracy: 87.032%), validation loss = 0.968 (accuracy: 60.952%)\n",
      "Epoch 129: 24.488 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.378 (accuracy: 87.800%), validation loss = 0.952 (accuracy: 60.952%)\n",
      "Epoch 130: 24.609 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.375 (accuracy: 87.224%), validation loss = 1.116 (accuracy: 58.095%)\n",
      "Epoch 131: 24.472 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.410 (accuracy: 86.840%), validation loss = 0.951 (accuracy: 64.762%)\n",
      "Epoch 132: 24.791 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.382 (accuracy: 88.184%), validation loss = 0.897 (accuracy: 67.619%)\n",
      "Epoch 133: 24.457 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.418 (accuracy: 86.359%), validation loss = 0.966 (accuracy: 60.952%)\n",
      "Epoch 134: 24.405 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.389 (accuracy: 87.320%), validation loss = 0.894 (accuracy: 64.762%)\n",
      "Epoch 135: 24.405 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.379 (accuracy: 87.800%), validation loss = 0.800 (accuracy: 69.524%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 115 with minimum validation error = 0.7523878733317058\n",
      "24880.864 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 1\n",
      "Epoch 1: 24.538 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.383 (accuracy: 29.203%), validation loss = 1.376 (accuracy: 27.619%)\n",
      "Epoch 2: 24.606 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.356 (accuracy: 35.447%), validation loss = 1.358 (accuracy: 33.333%)\n",
      "Epoch 3: 24.649 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.338 (accuracy: 36.311%), validation loss = 1.345 (accuracy: 31.429%)\n",
      "Epoch 4: 24.662 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.332 (accuracy: 36.984%), validation loss = 1.338 (accuracy: 32.381%)\n",
      "Epoch 5: 24.688 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.324 (accuracy: 38.232%), validation loss = 1.333 (accuracy: 32.381%)\n",
      "Epoch 6: 24.692 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.315 (accuracy: 38.329%), validation loss = 1.326 (accuracy: 34.286%)\n",
      "Epoch 7: 24.745 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.311 (accuracy: 38.425%), validation loss = 1.323 (accuracy: 33.333%)\n",
      "Epoch 8: 24.569 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.308 (accuracy: 39.097%), validation loss = 1.318 (accuracy: 33.333%)\n",
      "Epoch 9: 24.641 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.302 (accuracy: 39.097%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 10: 24.940 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.303 (accuracy: 39.577%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 11: 25.039 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.299 (accuracy: 40.154%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 12: 24.733 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.291 (accuracy: 39.481%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 13: 24.615 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 14: 24.638 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.292 (accuracy: 39.289%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 15: 24.545 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.284 (accuracy: 41.979%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 16: 24.573 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.285 (accuracy: 40.058%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 17: 24.629 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.275 (accuracy: 40.250%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 18: 24.412 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.278 (accuracy: 40.154%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 19: 24.454 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.276 (accuracy: 39.866%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 20: 24.464 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.272 (accuracy: 40.634%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 21: 24.602 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.266 (accuracy: 41.210%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 22: 24.668 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.266 (accuracy: 40.346%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 23: 24.600 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.262 (accuracy: 41.402%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 24: 24.631 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.261 (accuracy: 41.210%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 25: 24.475 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.260 (accuracy: 40.250%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 26: 24.602 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.260 (accuracy: 39.673%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 27: 24.424 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.246 (accuracy: 40.922%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 28: 24.557 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.250 (accuracy: 40.538%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 29: 24.555 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.248 (accuracy: 40.922%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 30: 24.319 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.245 (accuracy: 40.826%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 31: 24.439 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.238 (accuracy: 40.346%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 32: 24.591 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.232 (accuracy: 40.058%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 33: 24.240 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.234 (accuracy: 40.442%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 34: 24.063 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.231 (accuracy: 40.826%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 35: 24.792 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.225 (accuracy: 40.634%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 36: 24.758 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.218 (accuracy: 40.538%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 37: 24.789 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.219 (accuracy: 40.826%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 38: 24.383 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.205 (accuracy: 40.346%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 39: 24.234 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.207 (accuracy: 40.538%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 40: 24.196 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.194 (accuracy: 41.210%), validation loss = 1.256 (accuracy: 34.286%)\n",
      "Epoch 41: 23.929 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.186 (accuracy: 40.922%), validation loss = 1.251 (accuracy: 34.286%)\n",
      "Epoch 42: 23.875 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.187 (accuracy: 41.499%), validation loss = 1.249 (accuracy: 34.286%)\n",
      "Epoch 43: 23.877 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.186 (accuracy: 41.114%), validation loss = 1.241 (accuracy: 34.286%)\n",
      "Epoch 44: 23.833 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.179 (accuracy: 42.171%), validation loss = 1.244 (accuracy: 36.190%)\n",
      "Epoch 45: 23.515 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.166 (accuracy: 41.018%), validation loss = 1.238 (accuracy: 35.238%)\n",
      "Epoch 46: 23.633 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.163 (accuracy: 42.459%), validation loss = 1.227 (accuracy: 36.190%)\n",
      "Epoch 47: 24.320 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.152 (accuracy: 42.651%), validation loss = 1.225 (accuracy: 38.095%)\n",
      "Epoch 48: 23.524 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.145 (accuracy: 42.267%), validation loss = 1.218 (accuracy: 38.095%)\n",
      "Epoch 49: 23.463 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.137 (accuracy: 45.629%), validation loss = 1.217 (accuracy: 40.000%)\n",
      "Epoch 50: 23.528 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.130 (accuracy: 44.765%), validation loss = 1.212 (accuracy: 39.048%)\n",
      "Epoch 51: 23.337 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.126 (accuracy: 44.957%), validation loss = 1.202 (accuracy: 40.000%)\n",
      "Epoch 52: 23.262 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.105 (accuracy: 46.686%), validation loss = 1.202 (accuracy: 41.905%)\n",
      "Epoch 53: 23.325 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.094 (accuracy: 46.302%), validation loss = 1.187 (accuracy: 40.952%)\n",
      "Epoch 54: 23.290 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.081 (accuracy: 50.336%), validation loss = 1.181 (accuracy: 42.857%)\n",
      "Epoch 55: 23.120 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.077 (accuracy: 48.799%), validation loss = 1.187 (accuracy: 40.952%)\n",
      "Epoch 56: 22.902 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.060 (accuracy: 52.257%), validation loss = 1.172 (accuracy: 44.762%)\n",
      "Epoch 57: 23.305 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.048 (accuracy: 53.506%), validation loss = 1.163 (accuracy: 45.714%)\n",
      "Epoch 58: 23.170 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.028 (accuracy: 55.139%), validation loss = 1.157 (accuracy: 49.524%)\n",
      "Epoch 59: 23.160 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.012 (accuracy: 56.868%), validation loss = 1.140 (accuracy: 48.571%)\n",
      "Epoch 60: 23.595 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.999 (accuracy: 56.388%), validation loss = 1.137 (accuracy: 49.524%)\n",
      "Epoch 61: 23.284 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.979 (accuracy: 57.157%), validation loss = 1.124 (accuracy: 51.429%)\n",
      "Epoch 62: 23.060 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.968 (accuracy: 58.886%), validation loss = 1.112 (accuracy: 52.381%)\n",
      "Epoch 63: 23.273 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.951 (accuracy: 58.886%), validation loss = 1.108 (accuracy: 50.476%)\n",
      "Epoch 64: 23.453 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.935 (accuracy: 60.231%), validation loss = 1.080 (accuracy: 50.476%)\n",
      "Epoch 65: 23.156 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.910 (accuracy: 62.056%), validation loss = 1.087 (accuracy: 53.333%)\n",
      "Epoch 66: 23.056 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.892 (accuracy: 62.248%), validation loss = 1.078 (accuracy: 52.381%)\n",
      "Epoch 67: 23.341 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.879 (accuracy: 63.112%), validation loss = 1.071 (accuracy: 52.381%)\n",
      "Epoch 68: 23.297 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.863 (accuracy: 64.265%), validation loss = 1.041 (accuracy: 50.476%)\n",
      "Epoch 69: 23.240 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.865 (accuracy: 62.824%), validation loss = 1.082 (accuracy: 50.476%)\n",
      "Epoch 70: 23.166 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.852 (accuracy: 64.745%), validation loss = 1.022 (accuracy: 52.381%)\n",
      "Epoch 71: 23.266 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.835 (accuracy: 64.745%), validation loss = 1.077 (accuracy: 54.286%)\n",
      "Epoch 72: 23.090 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.838 (accuracy: 65.706%), validation loss = 0.993 (accuracy: 50.476%)\n",
      "Epoch 73: 23.357 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.817 (accuracy: 65.898%), validation loss = 1.020 (accuracy: 56.190%)\n",
      "Epoch 74: 23.385 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.796 (accuracy: 66.667%), validation loss = 1.050 (accuracy: 56.190%)\n",
      "Epoch 75: 23.054 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.791 (accuracy: 68.396%), validation loss = 1.035 (accuracy: 55.238%)\n",
      "Epoch 76: 23.125 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.777 (accuracy: 68.780%), validation loss = 1.040 (accuracy: 56.190%)\n",
      "Epoch 77: 23.244 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.778 (accuracy: 69.068%), validation loss = 1.058 (accuracy: 54.286%)\n",
      "Epoch 78: 23.208 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.761 (accuracy: 70.029%), validation loss = 1.080 (accuracy: 55.238%)\n",
      "Epoch 79: 23.376 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.751 (accuracy: 71.470%), validation loss = 1.109 (accuracy: 52.381%)\n",
      "Epoch 80: 23.481 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.741 (accuracy: 70.221%), validation loss = 0.994 (accuracy: 61.905%)\n",
      "Epoch 81: 23.793 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.740 (accuracy: 73.391%), validation loss = 1.020 (accuracy: 56.190%)\n",
      "Epoch 82: 23.762 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.728 (accuracy: 71.662%), validation loss = 1.029 (accuracy: 57.143%)\n",
      "Epoch 83: 23.877 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.725 (accuracy: 75.504%), validation loss = 1.038 (accuracy: 55.238%)\n",
      "Epoch 84: 23.764 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.715 (accuracy: 74.352%), validation loss = 1.009 (accuracy: 58.095%)\n",
      "Epoch 85: 23.557 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.711 (accuracy: 75.024%), validation loss = 1.031 (accuracy: 57.143%)\n",
      "Epoch 86: 23.488 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.689 (accuracy: 76.561%), validation loss = 0.999 (accuracy: 65.714%)\n",
      "Epoch 87: 23.716 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.698 (accuracy: 77.714%), validation loss = 0.956 (accuracy: 63.810%)\n",
      "Epoch 88: 23.435 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.706 (accuracy: 76.657%), validation loss = 0.968 (accuracy: 59.048%)\n",
      "Epoch 89: 23.082 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.687 (accuracy: 78.290%), validation loss = 1.072 (accuracy: 56.190%)\n",
      "Epoch 90: 23.156 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.677 (accuracy: 78.290%), validation loss = 1.012 (accuracy: 55.238%)\n",
      "Epoch 91: 23.103 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.664 (accuracy: 81.076%), validation loss = 0.998 (accuracy: 62.857%)\n",
      "Epoch 92: 23.068 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.662 (accuracy: 79.539%), validation loss = 1.033 (accuracy: 60.000%)\n",
      "Epoch 93: 22.977 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.652 (accuracy: 80.019%), validation loss = 1.007 (accuracy: 61.905%)\n",
      "Epoch 94: 23.010 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.652 (accuracy: 79.923%), validation loss = 0.983 (accuracy: 60.000%)\n",
      "Epoch 95: 22.915 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.643 (accuracy: 81.556%), validation loss = 1.014 (accuracy: 62.857%)\n",
      "Epoch 96: 22.985 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 0.649 (accuracy: 80.403%), validation loss = 1.016 (accuracy: 60.952%)\n",
      "Epoch 97: 22.779 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 0.643 (accuracy: 81.364%), validation loss = 1.010 (accuracy: 58.095%)\n",
      "Epoch 98: 22.870 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.631 (accuracy: 81.268%), validation loss = 1.024 (accuracy: 60.952%)\n",
      "Epoch 99: 22.806 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.615 (accuracy: 83.958%), validation loss = 1.001 (accuracy: 60.952%)\n",
      "Epoch 100: 23.280 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.612 (accuracy: 83.862%), validation loss = 1.021 (accuracy: 60.952%)\n",
      "Epoch 101: 22.989 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.587 (accuracy: 85.207%), validation loss = 1.083 (accuracy: 54.286%)\n",
      "Epoch 102: 22.927 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.594 (accuracy: 84.438%), validation loss = 0.988 (accuracy: 55.238%)\n",
      "Epoch 103: 22.852 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.604 (accuracy: 83.670%), validation loss = 1.035 (accuracy: 59.048%)\n",
      "Epoch 104: 22.859 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.597 (accuracy: 84.150%), validation loss = 0.970 (accuracy: 60.000%)\n",
      "Epoch 105: 22.984 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.580 (accuracy: 85.591%), validation loss = 1.131 (accuracy: 55.238%)\n",
      "Epoch 106: 22.954 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.580 (accuracy: 83.958%), validation loss = 0.955 (accuracy: 63.810%)\n",
      "Epoch 107: 23.287 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 0.594 (accuracy: 84.918%), validation loss = 1.024 (accuracy: 60.952%)\n",
      "Epoch 108: 22.864 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.572 (accuracy: 84.918%), validation loss = 0.986 (accuracy: 70.476%)\n",
      "Epoch 109: 22.931 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.560 (accuracy: 85.687%), validation loss = 0.985 (accuracy: 59.048%)\n",
      "Epoch 110: 22.794 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.559 (accuracy: 85.591%), validation loss = 0.974 (accuracy: 64.762%)\n",
      "Epoch 111: 22.761 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.538 (accuracy: 86.167%), validation loss = 0.899 (accuracy: 68.571%)\n",
      "Epoch 112: 23.205 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.534 (accuracy: 85.783%), validation loss = 1.047 (accuracy: 58.095%)\n",
      "Epoch 113: 22.832 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.522 (accuracy: 87.128%), validation loss = 1.037 (accuracy: 56.190%)\n",
      "Epoch 114: 23.085 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.515 (accuracy: 86.455%), validation loss = 1.043 (accuracy: 57.143%)\n",
      "Epoch 115: 22.847 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.516 (accuracy: 86.455%), validation loss = 0.928 (accuracy: 65.714%)\n",
      "Epoch 116: 22.785 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.520 (accuracy: 86.071%), validation loss = 0.957 (accuracy: 66.667%)\n",
      "Epoch 117: 22.743 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.519 (accuracy: 85.303%), validation loss = 1.025 (accuracy: 60.000%)\n",
      "Epoch 118: 22.706 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.504 (accuracy: 86.551%), validation loss = 0.957 (accuracy: 60.952%)\n",
      "Epoch 119: 22.806 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 0.488 (accuracy: 86.551%), validation loss = 0.896 (accuracy: 65.714%)\n",
      "Epoch 120: 22.875 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.477 (accuracy: 87.032%), validation loss = 0.931 (accuracy: 64.762%)\n",
      "Epoch 121: 22.764 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.460 (accuracy: 87.896%), validation loss = 0.984 (accuracy: 60.000%)\n",
      "Epoch 122: 22.826 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.470 (accuracy: 87.128%), validation loss = 0.855 (accuracy: 65.714%)\n",
      "Epoch 123: 22.884 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.479 (accuracy: 86.455%), validation loss = 0.942 (accuracy: 60.952%)\n",
      "Epoch 124: 22.711 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.475 (accuracy: 87.128%), validation loss = 0.882 (accuracy: 65.714%)\n",
      "Epoch 125: 22.735 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.461 (accuracy: 86.936%), validation loss = 0.856 (accuracy: 66.667%)\n",
      "Epoch 126: 22.786 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.484 (accuracy: 85.687%), validation loss = 0.873 (accuracy: 65.714%)\n",
      "Epoch 127: 22.928 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.467 (accuracy: 87.512%), validation loss = 0.943 (accuracy: 66.667%)\n",
      "Epoch 128: 22.816 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.436 (accuracy: 87.800%), validation loss = 0.901 (accuracy: 66.667%)\n",
      "Epoch 129: 22.759 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.435 (accuracy: 88.184%), validation loss = 0.945 (accuracy: 59.048%)\n",
      "Epoch 130: 22.743 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.439 (accuracy: 87.512%), validation loss = 0.893 (accuracy: 67.619%)\n",
      "Epoch 131: 22.715 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.446 (accuracy: 87.416%), validation loss = 0.894 (accuracy: 64.762%)\n",
      "Epoch 132: 22.838 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.457 (accuracy: 86.936%), validation loss = 0.991 (accuracy: 60.000%)\n",
      "Epoch 133: 22.926 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.427 (accuracy: 88.377%), validation loss = 0.916 (accuracy: 63.810%)\n",
      "Epoch 134: 22.778 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.457 (accuracy: 86.455%), validation loss = 0.942 (accuracy: 59.048%)\n",
      "Epoch 135: 22.542 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.441 (accuracy: 86.647%), validation loss = 0.879 (accuracy: 65.714%)\n",
      "Epoch 136: 22.726 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.460 (accuracy: 86.551%), validation loss = 0.894 (accuracy: 65.714%)\n",
      "Epoch 137: 23.089 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.451 (accuracy: 87.032%), validation loss = 0.916 (accuracy: 70.476%)\n",
      "Epoch 138: 22.869 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.467 (accuracy: 85.399%), validation loss = 0.883 (accuracy: 68.571%)\n",
      "Epoch 139: 22.628 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.450 (accuracy: 87.032%), validation loss = 0.842 (accuracy: 66.667%)\n",
      "Epoch 140: 23.016 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.453 (accuracy: 86.744%), validation loss = 0.919 (accuracy: 65.714%)\n",
      "Epoch 141: 23.135 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.443 (accuracy: 86.840%), validation loss = 0.950 (accuracy: 65.714%)\n",
      "Epoch 142: 22.772 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.445 (accuracy: 87.128%), validation loss = 0.980 (accuracy: 58.095%)\n",
      "Epoch 143: 22.829 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.413 (accuracy: 87.224%), validation loss = 0.858 (accuracy: 64.762%)\n",
      "Epoch 144: 22.873 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.402 (accuracy: 87.800%), validation loss = 0.887 (accuracy: 64.762%)\n",
      "Epoch 145: 22.725 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.434 (accuracy: 86.840%), validation loss = 0.955 (accuracy: 61.905%)\n",
      "Epoch 146: 22.767 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.413 (accuracy: 87.608%), validation loss = 0.906 (accuracy: 62.857%)\n",
      "Epoch 147: 22.805 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.429 (accuracy: 87.032%), validation loss = 0.974 (accuracy: 59.048%)\n",
      "Epoch 148: 22.730 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.423 (accuracy: 86.936%), validation loss = 0.915 (accuracy: 62.857%)\n",
      "Epoch 149: 22.855 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.418 (accuracy: 88.088%), validation loss = 0.867 (accuracy: 68.571%)\n",
      "Epoch 150: 22.732 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.427 (accuracy: 86.744%), validation loss = 0.896 (accuracy: 64.762%)\n",
      "Epoch 151: 22.755 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.396 (accuracy: 88.184%), validation loss = 0.866 (accuracy: 65.714%)\n",
      "Epoch 152: 22.755 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.402 (accuracy: 88.377%), validation loss = 0.928 (accuracy: 65.714%)\n",
      "Epoch 153: 22.770 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.424 (accuracy: 85.975%), validation loss = 1.006 (accuracy: 62.857%)\n",
      "Epoch 154: 22.955 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.449 (accuracy: 86.359%), validation loss = 0.957 (accuracy: 62.857%)\n",
      "Epoch 155: 22.891 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.392 (accuracy: 88.761%), validation loss = 0.844 (accuracy: 63.810%)\n",
      "Epoch 156: 22.714 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.402 (accuracy: 88.473%), validation loss = 0.874 (accuracy: 63.810%)\n",
      "Epoch 157: 22.730 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 0.400 (accuracy: 87.800%), validation loss = 0.972 (accuracy: 58.095%)\n",
      "Epoch 158: 22.851 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 0.416 (accuracy: 87.320%), validation loss = 0.874 (accuracy: 64.762%)\n",
      "Epoch 159: 22.773 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 0.416 (accuracy: 86.936%), validation loss = 0.845 (accuracy: 70.476%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 139 with minimum validation error = 0.8417833385013399\n",
      "28639.781 total second elapsed\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.0005, 0.0001, 0.00005, 0.00001]\n",
    "weight_list = [0, 0.1, 0.2, 0.4, 0.9, 1]\n",
    "min_valid_loss_list = []\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "for lr in lr_list:\n",
    "    for weight in weight_list:\n",
    "        save_file_name = \"/content/gdrive/My Drive/SLDL/hw5/Q2/Adam/resnet50_lr_\" + str(lr) + \"_weight_\" + str(weight) + \".pt\"\n",
    "        model = reset_model()\n",
    "        if train_on_gpu:\n",
    "            model = model.to('cuda')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight)\n",
    "        nepoch = 200\n",
    "        Q2_tune_model = Resnet50()\n",
    "        print(\"Start training model: learning rate = {}, weight decay = {}\".format(lr, weight))\n",
    "        model_finish = Q2_tune_model.train(train_on_gpu, model, nepoch, optimizer, save_file_name, dataloaders['train'], dataloaders['val'], verbose = True)\n",
    "        min_valid_loss_list.append(Q2_tune_model.best_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 654,
     "status": "ok",
     "timestamp": 1610266741704,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "pist58-QTUKw",
    "outputId": "49e9503a-f770-46e3-8630-d3178a7709b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-axis: learning rate\n",
      "y-axis: weight decay\n",
      "Best hyperparameters with Adam optimizer : learning rate = 1e-05, weight decay = 0.1\n",
      "      0.00050   0.00010   0.00005   0.00001\n",
      "0.0  0.747482  0.575426  0.510392  0.487649\n",
      "0.1  1.284801  0.665518  0.515866  0.467156\n",
      "0.2  1.293413  0.668202  0.559841  0.498266\n",
      "0.4  1.303474  0.873960  0.609059  0.601907\n",
      "0.9  1.347074  1.143525  1.014464  0.752388\n",
      "1.0  1.358435  1.166601  1.074734  0.841783\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.0005, 0.0001, 0.00005, 0.00001]\n",
    "weight_list = [0, 0.1, 0.2, 0.4, 0.9, 1]\n",
    "count = 0\n",
    "df = pd.DataFrame(index = weight_list)\n",
    "for lr in lr_list:\n",
    "    temp = []\n",
    "    for weight in weight_list:\n",
    "        temp.append(min_valid_loss_list[count])\n",
    "        count +=1 \n",
    "    df[lr] = temp\n",
    "print(\"x-axis: learning rate\")\n",
    "print(\"y-axis: weight decay\")\n",
    "print(\"Best hyperparameters with Adam optimizer : learning rate = {}, weight decay = {}\".format(0.00001, 0.1))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTr7yS3OQmNf"
   },
   "source": [
    "### Tuning, Optimizer = SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "PkIAJZ2hQ5pZ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f7c6cbcd-71dc-4436-dc46-a4bca9797cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: learning rate = 0.005, weight decay = 0\n",
      "Epoch 1: 230.137 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.315 (accuracy: 37.080%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 2: 22.042 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.277 (accuracy: 39.577%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 3: 22.090 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.241 (accuracy: 41.595%), validation loss = 1.241 (accuracy: 42.857%)\n",
      "Epoch 4: 22.381 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.224 (accuracy: 44.476%), validation loss = 1.233 (accuracy: 39.048%)\n",
      "Epoch 5: 22.704 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.205 (accuracy: 47.358%), validation loss = 1.234 (accuracy: 35.238%)\n",
      "Epoch 6: 22.633 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.162 (accuracy: 50.432%), validation loss = 1.169 (accuracy: 42.857%)\n",
      "Epoch 7: 22.951 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.122 (accuracy: 54.179%), validation loss = 1.156 (accuracy: 42.857%)\n",
      "Epoch 8: 22.642 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.076 (accuracy: 57.253%), validation loss = 1.082 (accuracy: 52.381%)\n",
      "Epoch 9: 22.732 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.039 (accuracy: 58.694%), validation loss = 1.042 (accuracy: 56.190%)\n",
      "Epoch 10: 22.717 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 0.984 (accuracy: 61.383%), validation loss = 0.985 (accuracy: 58.095%)\n",
      "Epoch 11: 22.724 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 0.921 (accuracy: 64.745%), validation loss = 0.916 (accuracy: 63.810%)\n",
      "Epoch 12: 22.765 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.863 (accuracy: 67.819%), validation loss = 0.870 (accuracy: 65.714%)\n",
      "Epoch 13: 22.784 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.816 (accuracy: 68.492%), validation loss = 0.852 (accuracy: 60.000%)\n",
      "Epoch 14: 22.843 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.761 (accuracy: 70.509%), validation loss = 0.826 (accuracy: 63.810%)\n",
      "Epoch 15: 22.736 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.699 (accuracy: 73.583%), validation loss = 0.772 (accuracy: 65.714%)\n",
      "Epoch 16: 22.758 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.665 (accuracy: 74.640%), validation loss = 0.771 (accuracy: 65.714%)\n",
      "Epoch 17: 22.657 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.608 (accuracy: 76.657%), validation loss = 0.682 (accuracy: 73.333%)\n",
      "Epoch 18: 22.798 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.538 (accuracy: 79.347%), validation loss = 0.687 (accuracy: 70.476%)\n",
      "Epoch 19: 22.768 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.506 (accuracy: 81.172%), validation loss = 0.658 (accuracy: 71.429%)\n",
      "Epoch 20: 22.633 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.466 (accuracy: 83.477%), validation loss = 0.632 (accuracy: 73.333%)\n",
      "Epoch 21: 22.647 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.403 (accuracy: 86.167%), validation loss = 0.620 (accuracy: 75.238%)\n",
      "Epoch 22: 22.674 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.373 (accuracy: 86.744%), validation loss = 0.606 (accuracy: 76.190%)\n",
      "Epoch 23: 22.768 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.373 (accuracy: 86.551%), validation loss = 0.607 (accuracy: 78.095%)\n",
      "Epoch 24: 22.453 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.335 (accuracy: 89.817%), validation loss = 0.645 (accuracy: 73.333%)\n",
      "Epoch 25: 22.648 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.312 (accuracy: 88.569%), validation loss = 0.553 (accuracy: 74.286%)\n",
      "Epoch 26: 22.697 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.267 (accuracy: 90.490%), validation loss = 0.610 (accuracy: 75.238%)\n",
      "Epoch 27: 22.476 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.240 (accuracy: 92.123%), validation loss = 0.545 (accuracy: 77.143%)\n",
      "Epoch 28: 22.638 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.213 (accuracy: 93.468%), validation loss = 0.605 (accuracy: 77.143%)\n",
      "Epoch 29: 22.426 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.235 (accuracy: 91.739%), validation loss = 0.577 (accuracy: 75.238%)\n",
      "Epoch 30: 22.508 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.194 (accuracy: 93.852%), validation loss = 0.579 (accuracy: 74.286%)\n",
      "Epoch 31: 22.516 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.166 (accuracy: 94.813%), validation loss = 0.533 (accuracy: 77.143%)\n",
      "Epoch 32: 22.970 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.143 (accuracy: 96.446%), validation loss = 0.572 (accuracy: 76.190%)\n",
      "Epoch 33: 22.470 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.153 (accuracy: 95.293%), validation loss = 0.556 (accuracy: 77.143%)\n",
      "Epoch 34: 22.508 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.110 (accuracy: 97.118%), validation loss = 0.568 (accuracy: 77.143%)\n",
      "Epoch 35: 22.527 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.136 (accuracy: 95.869%), validation loss = 0.570 (accuracy: 77.143%)\n",
      "Epoch 36: 22.515 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.124 (accuracy: 96.158%), validation loss = 0.658 (accuracy: 80.000%)\n",
      "Epoch 37: 22.544 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.122 (accuracy: 95.773%), validation loss = 0.618 (accuracy: 80.000%)\n",
      "Epoch 38: 22.449 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.090 (accuracy: 97.406%), validation loss = 0.566 (accuracy: 78.095%)\n",
      "Epoch 39: 22.654 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.119 (accuracy: 96.542%), validation loss = 0.583 (accuracy: 79.048%)\n",
      "Epoch 40: 22.477 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.098 (accuracy: 97.214%), validation loss = 0.567 (accuracy: 80.000%)\n",
      "Epoch 41: 22.533 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.086 (accuracy: 97.406%), validation loss = 0.682 (accuracy: 77.143%)\n",
      "Epoch 42: 22.466 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.075 (accuracy: 97.695%), validation loss = 0.640 (accuracy: 77.143%)\n",
      "Epoch 43: 22.535 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.067 (accuracy: 97.791%), validation loss = 0.573 (accuracy: 80.000%)\n",
      "Epoch 44: 22.482 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.073 (accuracy: 98.271%), validation loss = 0.628 (accuracy: 77.143%)\n",
      "Epoch 45: 22.521 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.051 (accuracy: 98.655%), validation loss = 0.579 (accuracy: 79.048%)\n",
      "Epoch 46: 22.682 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.055 (accuracy: 98.751%), validation loss = 0.612 (accuracy: 80.000%)\n",
      "Epoch 47: 22.467 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.049 (accuracy: 98.943%), validation loss = 0.653 (accuracy: 80.000%)\n",
      "Epoch 48: 22.485 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.055 (accuracy: 98.847%), validation loss = 0.634 (accuracy: 78.095%)\n",
      "Epoch 49: 22.435 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.047 (accuracy: 98.943%), validation loss = 0.595 (accuracy: 80.000%)\n",
      "Epoch 50: 22.491 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.057 (accuracy: 98.367%), validation loss = 0.597 (accuracy: 78.095%)\n",
      "Epoch 51: 22.447 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.052 (accuracy: 98.751%), validation loss = 0.662 (accuracy: 80.952%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 31 with minimum validation error = 0.5334286772069476\n",
      "1670.120 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0.1\n",
      "Epoch 1: 22.540 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.319 (accuracy: 34.870%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 2: 22.757 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.284 (accuracy: 39.097%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 3: 22.710 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.261 (accuracy: 40.250%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 4: 22.544 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.252 (accuracy: 42.939%), validation loss = 1.244 (accuracy: 33.333%)\n",
      "Epoch 5: 22.616 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.227 (accuracy: 42.843%), validation loss = 1.225 (accuracy: 38.095%)\n",
      "Epoch 6: 22.764 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.209 (accuracy: 47.358%), validation loss = 1.222 (accuracy: 36.190%)\n",
      "Epoch 7: 22.698 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.185 (accuracy: 47.262%), validation loss = 1.198 (accuracy: 43.810%)\n",
      "Epoch 8: 22.778 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.157 (accuracy: 52.834%), validation loss = 1.170 (accuracy: 44.762%)\n",
      "Epoch 9: 22.877 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.129 (accuracy: 53.698%), validation loss = 1.137 (accuracy: 51.429%)\n",
      "Epoch 10: 22.740 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.092 (accuracy: 55.908%), validation loss = 1.092 (accuracy: 55.238%)\n",
      "Epoch 11: 22.693 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.045 (accuracy: 60.134%), validation loss = 1.045 (accuracy: 60.952%)\n",
      "Epoch 12: 22.788 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 0.998 (accuracy: 62.056%), validation loss = 0.995 (accuracy: 62.857%)\n",
      "Epoch 13: 22.746 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 0.945 (accuracy: 65.034%), validation loss = 0.957 (accuracy: 61.905%)\n",
      "Epoch 14: 22.639 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.886 (accuracy: 65.994%), validation loss = 0.903 (accuracy: 63.810%)\n",
      "Epoch 15: 22.777 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.815 (accuracy: 70.317%), validation loss = 0.876 (accuracy: 64.762%)\n",
      "Epoch 16: 22.641 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.770 (accuracy: 70.893%), validation loss = 0.846 (accuracy: 64.762%)\n",
      "Epoch 17: 22.627 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.711 (accuracy: 73.487%), validation loss = 0.809 (accuracy: 66.667%)\n",
      "Epoch 18: 22.668 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.680 (accuracy: 74.640%), validation loss = 0.786 (accuracy: 69.524%)\n",
      "Epoch 19: 22.819 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.606 (accuracy: 78.482%), validation loss = 0.771 (accuracy: 71.429%)\n",
      "Epoch 20: 22.738 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.572 (accuracy: 78.674%), validation loss = 0.751 (accuracy: 72.381%)\n",
      "Epoch 21: 22.781 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.540 (accuracy: 78.866%), validation loss = 0.727 (accuracy: 73.333%)\n",
      "Epoch 22: 22.968 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.504 (accuracy: 81.172%), validation loss = 0.710 (accuracy: 69.524%)\n",
      "Epoch 23: 22.828 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.431 (accuracy: 84.534%), validation loss = 0.702 (accuracy: 71.429%)\n",
      "Epoch 24: 22.635 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.378 (accuracy: 86.744%), validation loss = 0.740 (accuracy: 70.476%)\n",
      "Epoch 25: 22.508 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.396 (accuracy: 85.591%), validation loss = 0.884 (accuracy: 66.667%)\n",
      "Epoch 26: 22.531 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.377 (accuracy: 85.975%), validation loss = 0.679 (accuracy: 74.286%)\n",
      "Epoch 27: 22.771 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.335 (accuracy: 88.665%), validation loss = 0.696 (accuracy: 73.333%)\n",
      "Epoch 28: 22.620 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.300 (accuracy: 90.586%), validation loss = 0.599 (accuracy: 76.190%)\n",
      "Epoch 29: 22.745 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.295 (accuracy: 90.970%), validation loss = 0.580 (accuracy: 77.143%)\n",
      "Epoch 30: 22.689 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.276 (accuracy: 91.258%), validation loss = 0.741 (accuracy: 75.238%)\n",
      "Epoch 31: 22.580 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.247 (accuracy: 93.276%), validation loss = 0.699 (accuracy: 75.238%)\n",
      "Epoch 32: 22.506 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.236 (accuracy: 94.621%), validation loss = 0.652 (accuracy: 73.333%)\n",
      "Epoch 33: 22.577 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.222 (accuracy: 95.389%), validation loss = 0.783 (accuracy: 74.286%)\n",
      "Epoch 34: 22.634 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.222 (accuracy: 94.813%), validation loss = 0.719 (accuracy: 74.286%)\n",
      "Epoch 35: 22.628 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.182 (accuracy: 96.830%), validation loss = 0.662 (accuracy: 75.238%)\n",
      "Epoch 36: 22.744 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.176 (accuracy: 96.926%), validation loss = 0.618 (accuracy: 76.190%)\n",
      "Epoch 37: 22.601 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.162 (accuracy: 97.695%), validation loss = 0.659 (accuracy: 76.190%)\n",
      "Epoch 38: 22.555 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.172 (accuracy: 97.598%), validation loss = 0.775 (accuracy: 71.429%)\n",
      "Epoch 39: 22.529 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.163 (accuracy: 97.406%), validation loss = 1.227 (accuracy: 60.000%)\n",
      "Epoch 40: 22.531 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.172 (accuracy: 96.542%), validation loss = 0.725 (accuracy: 75.238%)\n",
      "Epoch 41: 22.554 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.154 (accuracy: 98.079%), validation loss = 0.648 (accuracy: 77.143%)\n",
      "Epoch 42: 22.548 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.149 (accuracy: 98.079%), validation loss = 0.710 (accuracy: 77.143%)\n",
      "Epoch 43: 22.495 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.154 (accuracy: 97.310%), validation loss = 0.651 (accuracy: 77.143%)\n",
      "Epoch 44: 22.471 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.118 (accuracy: 98.655%), validation loss = 0.605 (accuracy: 81.905%)\n",
      "Epoch 45: 22.531 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.117 (accuracy: 98.655%), validation loss = 0.644 (accuracy: 76.190%)\n",
      "Epoch 46: 22.566 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.111 (accuracy: 98.751%), validation loss = 0.716 (accuracy: 78.095%)\n",
      "Epoch 47: 22.539 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.117 (accuracy: 98.367%), validation loss = 0.647 (accuracy: 75.238%)\n",
      "Epoch 48: 22.611 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.125 (accuracy: 98.559%), validation loss = 0.712 (accuracy: 76.190%)\n",
      "Epoch 49: 22.780 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.117 (accuracy: 98.559%), validation loss = 0.636 (accuracy: 77.143%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 29 with minimum validation error = 0.5799030792145502\n",
      "2790.308 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0.2\n",
      "Epoch 1: 22.748 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.309 (accuracy: 37.368%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 2: 22.849 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.284 (accuracy: 38.425%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 3: 22.771 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.267 (accuracy: 40.250%), validation loss = 1.274 (accuracy: 34.286%)\n",
      "Epoch 4: 22.748 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.248 (accuracy: 40.922%), validation loss = 1.259 (accuracy: 36.190%)\n",
      "Epoch 5: 22.673 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.238 (accuracy: 41.595%), validation loss = 1.239 (accuracy: 40.000%)\n",
      "Epoch 6: 22.739 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.219 (accuracy: 43.420%), validation loss = 1.232 (accuracy: 39.048%)\n",
      "Epoch 7: 22.620 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.211 (accuracy: 45.149%), validation loss = 1.217 (accuracy: 40.952%)\n",
      "Epoch 8: 22.634 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.191 (accuracy: 46.206%), validation loss = 1.191 (accuracy: 45.714%)\n",
      "Epoch 9: 22.769 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.172 (accuracy: 48.703%), validation loss = 1.182 (accuracy: 45.714%)\n",
      "Epoch 10: 22.741 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.147 (accuracy: 53.794%), validation loss = 1.151 (accuracy: 47.619%)\n",
      "Epoch 11: 22.677 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.095 (accuracy: 58.021%), validation loss = 1.123 (accuracy: 46.667%)\n",
      "Epoch 12: 22.592 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.055 (accuracy: 59.078%), validation loss = 1.070 (accuracy: 58.095%)\n",
      "Epoch 13: 22.811 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.010 (accuracy: 63.785%), validation loss = 1.031 (accuracy: 57.143%)\n",
      "Epoch 14: 23.068 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 0.958 (accuracy: 63.977%), validation loss = 0.989 (accuracy: 58.095%)\n",
      "Epoch 15: 22.642 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 0.914 (accuracy: 65.994%), validation loss = 0.957 (accuracy: 60.000%)\n",
      "Epoch 16: 22.660 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 0.862 (accuracy: 68.780%), validation loss = 0.905 (accuracy: 62.857%)\n",
      "Epoch 17: 22.653 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.806 (accuracy: 72.142%), validation loss = 0.863 (accuracy: 65.714%)\n",
      "Epoch 18: 22.740 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.753 (accuracy: 74.159%), validation loss = 0.848 (accuracy: 68.571%)\n",
      "Epoch 19: 22.740 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.712 (accuracy: 76.561%), validation loss = 0.801 (accuracy: 72.381%)\n",
      "Epoch 20: 22.680 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.656 (accuracy: 78.194%), validation loss = 0.767 (accuracy: 78.095%)\n",
      "Epoch 21: 22.609 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.608 (accuracy: 79.923%), validation loss = 0.755 (accuracy: 71.429%)\n",
      "Epoch 22: 22.680 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.565 (accuracy: 81.940%), validation loss = 0.728 (accuracy: 69.524%)\n",
      "Epoch 23: 22.951 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.528 (accuracy: 82.229%), validation loss = 0.686 (accuracy: 75.238%)\n",
      "Epoch 24: 22.675 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.506 (accuracy: 83.285%), validation loss = 0.744 (accuracy: 70.476%)\n",
      "Epoch 25: 22.489 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.467 (accuracy: 84.534%), validation loss = 0.709 (accuracy: 72.381%)\n",
      "Epoch 26: 22.566 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.440 (accuracy: 86.167%), validation loss = 0.618 (accuracy: 76.190%)\n",
      "Epoch 27: 22.797 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.419 (accuracy: 87.128%), validation loss = 0.659 (accuracy: 76.190%)\n",
      "Epoch 28: 22.630 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.404 (accuracy: 87.416%), validation loss = 0.629 (accuracy: 79.048%)\n",
      "Epoch 29: 22.795 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.392 (accuracy: 86.840%), validation loss = 0.662 (accuracy: 79.048%)\n",
      "Epoch 30: 22.509 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.374 (accuracy: 88.280%), validation loss = 0.727 (accuracy: 70.476%)\n",
      "Epoch 31: 22.561 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.359 (accuracy: 88.473%), validation loss = 0.713 (accuracy: 72.381%)\n",
      "Epoch 32: 22.548 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.365 (accuracy: 87.800%), validation loss = 0.697 (accuracy: 72.381%)\n",
      "Epoch 33: 22.523 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.355 (accuracy: 88.473%), validation loss = 0.701 (accuracy: 73.333%)\n",
      "Epoch 34: 22.508 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.338 (accuracy: 88.761%), validation loss = 0.758 (accuracy: 75.238%)\n",
      "Epoch 35: 22.462 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.338 (accuracy: 89.241%), validation loss = 0.717 (accuracy: 73.333%)\n",
      "Epoch 36: 22.542 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.355 (accuracy: 88.377%), validation loss = 0.764 (accuracy: 66.667%)\n",
      "Epoch 37: 22.496 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.357 (accuracy: 88.473%), validation loss = 0.737 (accuracy: 70.476%)\n",
      "Epoch 38: 22.584 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.350 (accuracy: 88.569%), validation loss = 0.831 (accuracy: 66.667%)\n",
      "Epoch 39: 22.525 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.330 (accuracy: 89.145%), validation loss = 0.722 (accuracy: 70.476%)\n",
      "Epoch 40: 22.528 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.347 (accuracy: 89.914%), validation loss = 0.813 (accuracy: 68.571%)\n",
      "Epoch 41: 22.766 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.381 (accuracy: 88.953%), validation loss = 0.752 (accuracy: 70.476%)\n",
      "Epoch 42: 22.520 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.372 (accuracy: 91.066%), validation loss = 0.823 (accuracy: 66.667%)\n",
      "Epoch 43: 22.522 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.395 (accuracy: 89.817%), validation loss = 0.905 (accuracy: 64.762%)\n",
      "Epoch 44: 22.452 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.408 (accuracy: 89.049%), validation loss = 0.813 (accuracy: 65.714%)\n",
      "Epoch 45: 22.528 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.384 (accuracy: 92.795%), validation loss = 1.114 (accuracy: 53.333%)\n",
      "Epoch 46: 22.438 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.448 (accuracy: 89.625%), validation loss = 1.004 (accuracy: 59.048%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 26 with minimum validation error = 0.6177906978698003\n",
      "3841.501 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0.5\n",
      "Epoch 1: 22.513 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.318 (accuracy: 36.503%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 2: 22.720 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.283 (accuracy: 39.577%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 3: 22.737 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.273 (accuracy: 39.769%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 4: 22.719 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.268 (accuracy: 39.962%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 5: 22.567 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.257 (accuracy: 39.769%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 6: 22.615 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.253 (accuracy: 39.577%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 7: 22.683 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.251 (accuracy: 39.769%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 8: 22.561 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.249 (accuracy: 39.481%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 9: 22.723 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.242 (accuracy: 39.481%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 10: 22.557 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.240 (accuracy: 39.481%), validation loss = 1.283 (accuracy: 33.333%)\n",
      "Epoch 11: 22.504 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.234 (accuracy: 39.577%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 12: 22.462 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.226 (accuracy: 39.481%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 13: 22.558 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.220 (accuracy: 39.481%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 14: 22.544 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.207 (accuracy: 39.481%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 15: 22.525 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.201 (accuracy: 39.481%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 16: 22.457 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.190 (accuracy: 39.481%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 17: 22.495 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.192 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 18: 22.474 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.191 (accuracy: 39.481%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 19: 22.357 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.197 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 20: 22.484 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.216 (accuracy: 39.481%), validation loss = 1.334 (accuracy: 33.333%)\n",
      "Epoch 21: 22.548 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.232 (accuracy: 39.481%), validation loss = 1.333 (accuracy: 33.333%)\n",
      "Epoch 22: 22.412 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.246 (accuracy: 39.481%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 23: 22.609 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.265 (accuracy: 39.481%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 3 with minimum validation error = 1.2772524390901838\n",
      "4362.043 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0\n",
      "Epoch 1: 22.647 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.323 (accuracy: 34.006%), validation loss = 1.312 (accuracy: 34.286%)\n",
      "Epoch 2: 22.700 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.305 (accuracy: 37.176%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 3: 22.776 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.291 (accuracy: 38.329%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 4: 22.664 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.290 (accuracy: 38.329%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 5: 22.640 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.270 (accuracy: 39.289%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 6: 22.652 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.274 (accuracy: 39.962%), validation loss = 1.270 (accuracy: 33.333%)\n",
      "Epoch 7: 22.576 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.265 (accuracy: 40.250%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 8: 22.565 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.258 (accuracy: 40.154%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 9: 22.620 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.262 (accuracy: 39.962%), validation loss = 1.257 (accuracy: 34.286%)\n",
      "Epoch 10: 22.626 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.258 (accuracy: 40.346%), validation loss = 1.255 (accuracy: 34.286%)\n",
      "Epoch 11: 22.605 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.247 (accuracy: 40.922%), validation loss = 1.252 (accuracy: 36.190%)\n",
      "Epoch 12: 22.681 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.240 (accuracy: 44.092%), validation loss = 1.248 (accuracy: 35.238%)\n",
      "Epoch 13: 22.709 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.233 (accuracy: 42.555%), validation loss = 1.244 (accuracy: 36.190%)\n",
      "Epoch 14: 22.605 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.238 (accuracy: 42.171%), validation loss = 1.239 (accuracy: 37.143%)\n",
      "Epoch 15: 22.614 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.237 (accuracy: 41.883%), validation loss = 1.232 (accuracy: 38.095%)\n",
      "Epoch 16: 22.480 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.220 (accuracy: 43.420%), validation loss = 1.228 (accuracy: 38.095%)\n",
      "Epoch 17: 22.744 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.226 (accuracy: 43.900%), validation loss = 1.223 (accuracy: 38.095%)\n",
      "Epoch 18: 22.555 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.221 (accuracy: 43.420%), validation loss = 1.218 (accuracy: 40.000%)\n",
      "Epoch 19: 22.739 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.209 (accuracy: 43.132%), validation loss = 1.213 (accuracy: 41.905%)\n",
      "Epoch 20: 22.599 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.202 (accuracy: 45.821%), validation loss = 1.211 (accuracy: 42.857%)\n",
      "Epoch 21: 22.682 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.203 (accuracy: 44.957%), validation loss = 1.203 (accuracy: 43.810%)\n",
      "Epoch 22: 22.746 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.190 (accuracy: 45.725%), validation loss = 1.199 (accuracy: 45.714%)\n",
      "Epoch 23: 22.549 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.189 (accuracy: 47.839%), validation loss = 1.190 (accuracy: 43.810%)\n",
      "Epoch 24: 22.858 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.185 (accuracy: 47.454%), validation loss = 1.189 (accuracy: 43.810%)\n",
      "Epoch 25: 22.727 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.174 (accuracy: 47.743%), validation loss = 1.184 (accuracy: 43.810%)\n",
      "Epoch 26: 22.815 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.165 (accuracy: 48.991%), validation loss = 1.175 (accuracy: 43.810%)\n",
      "Epoch 27: 22.770 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.162 (accuracy: 49.472%), validation loss = 1.165 (accuracy: 44.762%)\n",
      "Epoch 28: 22.574 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.152 (accuracy: 51.681%), validation loss = 1.159 (accuracy: 44.762%)\n",
      "Epoch 29: 22.681 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.151 (accuracy: 49.760%), validation loss = 1.153 (accuracy: 45.714%)\n",
      "Epoch 30: 22.584 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.148 (accuracy: 51.201%), validation loss = 1.145 (accuracy: 48.571%)\n",
      "Epoch 31: 22.680 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.124 (accuracy: 52.738%), validation loss = 1.139 (accuracy: 47.619%)\n",
      "Epoch 32: 22.674 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.114 (accuracy: 55.716%), validation loss = 1.137 (accuracy: 45.714%)\n",
      "Epoch 33: 22.679 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.118 (accuracy: 52.546%), validation loss = 1.124 (accuracy: 49.524%)\n",
      "Epoch 34: 22.776 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.113 (accuracy: 53.794%), validation loss = 1.116 (accuracy: 49.524%)\n",
      "Epoch 35: 22.592 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.100 (accuracy: 56.388%), validation loss = 1.102 (accuracy: 49.524%)\n",
      "Epoch 36: 22.793 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.085 (accuracy: 55.908%), validation loss = 1.096 (accuracy: 51.429%)\n",
      "Epoch 37: 22.855 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.074 (accuracy: 56.676%), validation loss = 1.092 (accuracy: 50.476%)\n",
      "Epoch 38: 22.708 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.063 (accuracy: 56.388%), validation loss = 1.078 (accuracy: 51.429%)\n",
      "Epoch 39: 22.678 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.073 (accuracy: 55.235%), validation loss = 1.068 (accuracy: 52.381%)\n",
      "Epoch 40: 22.845 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.047 (accuracy: 58.021%), validation loss = 1.061 (accuracy: 51.429%)\n",
      "Epoch 41: 22.726 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.039 (accuracy: 60.134%), validation loss = 1.050 (accuracy: 55.238%)\n",
      "Epoch 42: 22.535 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.030 (accuracy: 59.462%), validation loss = 1.039 (accuracy: 57.143%)\n",
      "Epoch 43: 22.748 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.010 (accuracy: 58.501%), validation loss = 1.030 (accuracy: 57.143%)\n",
      "Epoch 44: 22.751 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.002 (accuracy: 57.829%), validation loss = 1.016 (accuracy: 58.095%)\n",
      "Epoch 45: 22.616 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.984 (accuracy: 60.519%), validation loss = 1.006 (accuracy: 59.048%)\n",
      "Epoch 46: 22.657 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.967 (accuracy: 63.208%), validation loss = 0.995 (accuracy: 62.857%)\n",
      "Epoch 47: 22.587 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.946 (accuracy: 63.305%), validation loss = 0.974 (accuracy: 63.810%)\n",
      "Epoch 48: 22.679 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.953 (accuracy: 62.728%), validation loss = 0.966 (accuracy: 63.810%)\n",
      "Epoch 49: 22.698 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.937 (accuracy: 61.960%), validation loss = 0.955 (accuracy: 64.762%)\n",
      "Epoch 50: 22.698 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.944 (accuracy: 62.056%), validation loss = 0.952 (accuracy: 63.810%)\n",
      "Epoch 51: 22.755 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.900 (accuracy: 65.706%), validation loss = 0.935 (accuracy: 62.857%)\n",
      "Epoch 52: 22.571 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.894 (accuracy: 65.514%), validation loss = 0.920 (accuracy: 64.762%)\n",
      "Epoch 53: 22.719 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.895 (accuracy: 64.553%), validation loss = 0.905 (accuracy: 67.619%)\n",
      "Epoch 54: 22.657 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.875 (accuracy: 65.130%), validation loss = 0.900 (accuracy: 65.714%)\n",
      "Epoch 55: 22.721 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.856 (accuracy: 66.955%), validation loss = 0.890 (accuracy: 67.619%)\n",
      "Epoch 56: 22.734 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.840 (accuracy: 67.147%), validation loss = 0.878 (accuracy: 68.571%)\n",
      "Epoch 57: 22.633 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.839 (accuracy: 66.378%), validation loss = 0.863 (accuracy: 70.476%)\n",
      "Epoch 58: 22.672 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.822 (accuracy: 69.645%), validation loss = 0.859 (accuracy: 69.524%)\n",
      "Epoch 59: 22.555 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.793 (accuracy: 70.029%), validation loss = 0.849 (accuracy: 70.476%)\n",
      "Epoch 60: 22.792 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.785 (accuracy: 69.549%), validation loss = 0.837 (accuracy: 70.476%)\n",
      "Epoch 61: 22.764 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.781 (accuracy: 69.068%), validation loss = 0.827 (accuracy: 71.429%)\n",
      "Epoch 62: 22.653 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.765 (accuracy: 70.221%), validation loss = 0.814 (accuracy: 75.238%)\n",
      "Epoch 63: 22.897 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.764 (accuracy: 70.509%), validation loss = 0.810 (accuracy: 69.524%)\n",
      "Epoch 64: 22.795 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.744 (accuracy: 70.701%), validation loss = 0.810 (accuracy: 69.524%)\n",
      "Epoch 65: 22.721 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.726 (accuracy: 71.758%), validation loss = 0.788 (accuracy: 72.381%)\n",
      "Epoch 66: 22.692 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.714 (accuracy: 73.199%), validation loss = 0.782 (accuracy: 72.381%)\n",
      "Epoch 67: 22.959 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.710 (accuracy: 73.199%), validation loss = 0.777 (accuracy: 72.381%)\n",
      "Epoch 68: 22.620 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.708 (accuracy: 72.430%), validation loss = 0.761 (accuracy: 75.238%)\n",
      "Epoch 69: 22.576 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.698 (accuracy: 73.679%), validation loss = 0.766 (accuracy: 74.286%)\n",
      "Epoch 70: 22.497 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.670 (accuracy: 74.832%), validation loss = 0.756 (accuracy: 75.238%)\n",
      "Epoch 71: 22.707 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.665 (accuracy: 75.312%), validation loss = 0.745 (accuracy: 75.238%)\n",
      "Epoch 72: 22.578 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.639 (accuracy: 75.504%), validation loss = 0.733 (accuracy: 77.143%)\n",
      "Epoch 73: 22.704 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.660 (accuracy: 74.640%), validation loss = 0.733 (accuracy: 77.143%)\n",
      "Epoch 74: 22.647 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.627 (accuracy: 77.041%), validation loss = 0.729 (accuracy: 74.286%)\n",
      "Epoch 75: 22.706 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.617 (accuracy: 78.098%), validation loss = 0.715 (accuracy: 75.238%)\n",
      "Epoch 76: 22.601 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.612 (accuracy: 78.002%), validation loss = 0.711 (accuracy: 75.238%)\n",
      "Epoch 77: 22.765 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.600 (accuracy: 77.522%), validation loss = 0.710 (accuracy: 75.238%)\n",
      "Epoch 78: 22.748 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.576 (accuracy: 79.827%), validation loss = 0.695 (accuracy: 73.333%)\n",
      "Epoch 79: 22.550 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.564 (accuracy: 78.963%), validation loss = 0.683 (accuracy: 76.190%)\n",
      "Epoch 80: 22.740 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.550 (accuracy: 79.347%), validation loss = 0.685 (accuracy: 75.238%)\n",
      "Epoch 81: 22.493 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.556 (accuracy: 80.403%), validation loss = 0.672 (accuracy: 76.190%)\n",
      "Epoch 82: 22.609 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.537 (accuracy: 80.307%), validation loss = 0.677 (accuracy: 75.238%)\n",
      "Epoch 83: 22.457 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.539 (accuracy: 79.443%), validation loss = 0.660 (accuracy: 74.286%)\n",
      "Epoch 84: 22.712 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.510 (accuracy: 82.133%), validation loss = 0.655 (accuracy: 76.190%)\n",
      "Epoch 85: 22.757 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.514 (accuracy: 81.172%), validation loss = 0.666 (accuracy: 76.190%)\n",
      "Epoch 86: 22.553 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.506 (accuracy: 81.940%), validation loss = 0.654 (accuracy: 75.238%)\n",
      "Epoch 87: 22.708 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.484 (accuracy: 83.766%), validation loss = 0.654 (accuracy: 73.333%)\n",
      "Epoch 88: 22.508 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.463 (accuracy: 85.591%), validation loss = 0.637 (accuracy: 77.143%)\n",
      "Epoch 89: 22.729 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.449 (accuracy: 84.534%), validation loss = 0.634 (accuracy: 77.143%)\n",
      "Epoch 90: 22.676 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.459 (accuracy: 82.325%), validation loss = 0.623 (accuracy: 75.238%)\n",
      "Epoch 91: 22.701 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.433 (accuracy: 84.246%), validation loss = 0.631 (accuracy: 76.190%)\n",
      "Epoch 92: 22.680 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.447 (accuracy: 83.862%), validation loss = 0.631 (accuracy: 76.190%)\n",
      "Epoch 93: 22.465 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.436 (accuracy: 83.862%), validation loss = 0.640 (accuracy: 75.238%)\n",
      "Epoch 94: 22.819 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.425 (accuracy: 84.438%), validation loss = 0.622 (accuracy: 76.190%)\n",
      "Epoch 95: 22.729 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.424 (accuracy: 85.303%), validation loss = 0.621 (accuracy: 76.190%)\n",
      "Epoch 96: 22.863 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 0.411 (accuracy: 85.303%), validation loss = 0.614 (accuracy: 75.238%)\n",
      "Epoch 97: 22.769 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 0.390 (accuracy: 86.744%), validation loss = 0.602 (accuracy: 74.286%)\n",
      "Epoch 98: 22.679 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.383 (accuracy: 86.936%), validation loss = 0.608 (accuracy: 75.238%)\n",
      "Epoch 99: 22.562 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.356 (accuracy: 87.032%), validation loss = 0.609 (accuracy: 75.238%)\n",
      "Epoch 100: 22.471 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.378 (accuracy: 86.455%), validation loss = 0.596 (accuracy: 77.143%)\n",
      "Epoch 101: 22.805 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.363 (accuracy: 87.128%), validation loss = 0.608 (accuracy: 73.333%)\n",
      "Epoch 102: 22.493 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.371 (accuracy: 87.416%), validation loss = 0.603 (accuracy: 76.190%)\n",
      "Epoch 103: 22.499 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.341 (accuracy: 88.473%), validation loss = 0.577 (accuracy: 75.238%)\n",
      "Epoch 104: 22.740 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.333 (accuracy: 89.145%), validation loss = 0.587 (accuracy: 74.286%)\n",
      "Epoch 105: 22.486 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.320 (accuracy: 89.433%), validation loss = 0.579 (accuracy: 75.238%)\n",
      "Epoch 106: 22.620 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.308 (accuracy: 88.953%), validation loss = 0.585 (accuracy: 76.190%)\n",
      "Epoch 107: 22.454 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 0.329 (accuracy: 89.145%), validation loss = 0.569 (accuracy: 74.286%)\n",
      "Epoch 108: 22.827 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.299 (accuracy: 89.241%), validation loss = 0.576 (accuracy: 74.286%)\n",
      "Epoch 109: 22.472 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.299 (accuracy: 90.586%), validation loss = 0.561 (accuracy: 76.190%)\n",
      "Epoch 110: 22.668 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.316 (accuracy: 88.953%), validation loss = 0.568 (accuracy: 74.286%)\n",
      "Epoch 111: 22.526 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.279 (accuracy: 90.778%), validation loss = 0.568 (accuracy: 76.190%)\n",
      "Epoch 112: 22.399 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.297 (accuracy: 90.106%), validation loss = 0.564 (accuracy: 73.333%)\n",
      "Epoch 113: 22.610 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.297 (accuracy: 89.337%), validation loss = 0.574 (accuracy: 75.238%)\n",
      "Epoch 114: 22.483 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.262 (accuracy: 92.411%), validation loss = 0.569 (accuracy: 76.190%)\n",
      "Epoch 115: 22.609 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.269 (accuracy: 91.066%), validation loss = 0.582 (accuracy: 78.095%)\n",
      "Epoch 116: 22.472 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.242 (accuracy: 92.411%), validation loss = 0.545 (accuracy: 80.000%)\n",
      "Epoch 117: 22.667 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.282 (accuracy: 90.682%), validation loss = 0.574 (accuracy: 78.095%)\n",
      "Epoch 118: 22.511 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.248 (accuracy: 91.931%), validation loss = 0.561 (accuracy: 78.095%)\n",
      "Epoch 119: 22.514 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 0.236 (accuracy: 92.123%), validation loss = 0.556 (accuracy: 78.095%)\n",
      "Epoch 120: 22.514 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.235 (accuracy: 93.180%), validation loss = 0.544 (accuracy: 78.095%)\n",
      "Epoch 121: 22.723 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.224 (accuracy: 92.411%), validation loss = 0.553 (accuracy: 78.095%)\n",
      "Epoch 122: 22.543 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.234 (accuracy: 92.027%), validation loss = 0.556 (accuracy: 77.143%)\n",
      "Epoch 123: 22.517 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.210 (accuracy: 94.332%), validation loss = 0.544 (accuracy: 76.190%)\n",
      "Epoch 124: 22.599 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.209 (accuracy: 93.660%), validation loss = 0.544 (accuracy: 77.143%)\n",
      "Epoch 125: 22.584 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.223 (accuracy: 92.988%), validation loss = 0.552 (accuracy: 76.190%)\n",
      "Epoch 126: 22.591 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.208 (accuracy: 93.660%), validation loss = 0.547 (accuracy: 78.095%)\n",
      "Epoch 127: 22.658 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.202 (accuracy: 93.180%), validation loss = 0.545 (accuracy: 78.095%)\n",
      "Epoch 128: 22.561 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.202 (accuracy: 93.468%), validation loss = 0.545 (accuracy: 76.190%)\n",
      "Epoch 129: 22.628 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.206 (accuracy: 93.180%), validation loss = 0.558 (accuracy: 77.143%)\n",
      "Epoch 130: 22.512 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.197 (accuracy: 93.564%), validation loss = 0.542 (accuracy: 79.048%)\n",
      "Epoch 131: 22.780 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.185 (accuracy: 93.564%), validation loss = 0.543 (accuracy: 78.095%)\n",
      "Epoch 132: 22.446 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.179 (accuracy: 94.236%), validation loss = 0.548 (accuracy: 77.143%)\n",
      "Epoch 133: 22.532 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.171 (accuracy: 95.101%), validation loss = 0.547 (accuracy: 78.095%)\n",
      "Epoch 134: 22.425 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.172 (accuracy: 94.236%), validation loss = 0.538 (accuracy: 78.095%)\n",
      "Epoch 135: 22.881 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.166 (accuracy: 95.485%), validation loss = 0.547 (accuracy: 78.095%)\n",
      "Epoch 136: 22.517 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.160 (accuracy: 95.293%), validation loss = 0.555 (accuracy: 76.190%)\n",
      "Epoch 137: 22.561 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.154 (accuracy: 95.485%), validation loss = 0.535 (accuracy: 78.095%)\n",
      "Epoch 138: 22.977 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.153 (accuracy: 94.813%), validation loss = 0.549 (accuracy: 77.143%)\n",
      "Epoch 139: 22.639 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.142 (accuracy: 95.389%), validation loss = 0.550 (accuracy: 76.190%)\n",
      "Epoch 140: 22.643 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.141 (accuracy: 96.350%), validation loss = 0.550 (accuracy: 77.143%)\n",
      "Epoch 141: 22.683 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.147 (accuracy: 95.293%), validation loss = 0.545 (accuracy: 79.048%)\n",
      "Epoch 142: 22.601 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.140 (accuracy: 95.293%), validation loss = 0.568 (accuracy: 76.190%)\n",
      "Epoch 143: 22.621 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.146 (accuracy: 96.350%), validation loss = 0.546 (accuracy: 79.048%)\n",
      "Epoch 144: 22.644 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.126 (accuracy: 96.542%), validation loss = 0.574 (accuracy: 77.143%)\n",
      "Epoch 145: 22.623 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.133 (accuracy: 96.350%), validation loss = 0.559 (accuracy: 80.000%)\n",
      "Epoch 146: 22.554 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.150 (accuracy: 94.524%), validation loss = 0.561 (accuracy: 79.048%)\n",
      "Epoch 147: 22.456 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.131 (accuracy: 95.389%), validation loss = 0.572 (accuracy: 78.095%)\n",
      "Epoch 148: 22.460 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.146 (accuracy: 95.581%), validation loss = 0.583 (accuracy: 77.143%)\n",
      "Epoch 149: 22.681 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.105 (accuracy: 97.983%), validation loss = 0.580 (accuracy: 76.190%)\n",
      "Epoch 150: 22.449 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.119 (accuracy: 96.638%), validation loss = 0.567 (accuracy: 79.048%)\n",
      "Epoch 151: 22.542 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.102 (accuracy: 97.695%), validation loss = 0.542 (accuracy: 79.048%)\n",
      "Epoch 152: 22.593 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.130 (accuracy: 96.158%), validation loss = 0.568 (accuracy: 78.095%)\n",
      "Epoch 153: 22.462 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.097 (accuracy: 97.695%), validation loss = 0.568 (accuracy: 79.048%)\n",
      "Epoch 154: 22.437 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.133 (accuracy: 95.965%), validation loss = 0.579 (accuracy: 78.095%)\n",
      "Epoch 155: 22.551 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.115 (accuracy: 96.926%), validation loss = 0.570 (accuracy: 80.952%)\n",
      "Epoch 156: 22.606 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.126 (accuracy: 96.446%), validation loss = 0.621 (accuracy: 78.095%)\n",
      "Epoch 157: 22.644 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 0.105 (accuracy: 97.695%), validation loss = 0.578 (accuracy: 78.095%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 137 with minimum validation error = 0.5351527074972788\n",
      "7954.125 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0.1\n",
      "Epoch 1: 22.720 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.361 (accuracy: 31.796%), validation loss = 1.336 (accuracy: 32.381%)\n",
      "Epoch 2: 22.789 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.312 (accuracy: 39.673%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 3: 22.710 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.301 (accuracy: 38.040%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 4: 22.824 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.283 (accuracy: 39.577%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 5: 22.778 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.277 (accuracy: 39.385%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 6: 22.614 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.275 (accuracy: 39.769%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 7: 22.550 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.271 (accuracy: 39.481%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 8: 22.537 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.271 (accuracy: 39.097%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 9: 22.607 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.268 (accuracy: 39.866%), validation loss = 1.269 (accuracy: 33.333%)\n",
      "Epoch 10: 22.685 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.256 (accuracy: 40.538%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 11: 22.682 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.257 (accuracy: 41.499%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 12: 22.675 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.251 (accuracy: 41.306%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 13: 22.754 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.252 (accuracy: 40.538%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 14: 22.670 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.254 (accuracy: 40.826%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 15: 22.675 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.239 (accuracy: 40.730%), validation loss = 1.247 (accuracy: 33.333%)\n",
      "Epoch 16: 22.621 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.239 (accuracy: 42.939%), validation loss = 1.245 (accuracy: 33.333%)\n",
      "Epoch 17: 22.667 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.236 (accuracy: 41.499%), validation loss = 1.243 (accuracy: 33.333%)\n",
      "Epoch 18: 22.566 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.234 (accuracy: 41.883%), validation loss = 1.240 (accuracy: 33.333%)\n",
      "Epoch 19: 22.863 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.231 (accuracy: 42.555%), validation loss = 1.236 (accuracy: 33.333%)\n",
      "Epoch 20: 22.612 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.222 (accuracy: 42.843%), validation loss = 1.233 (accuracy: 33.333%)\n",
      "Epoch 21: 22.576 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.223 (accuracy: 43.324%), validation loss = 1.228 (accuracy: 35.238%)\n",
      "Epoch 22: 22.529 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.222 (accuracy: 43.516%), validation loss = 1.227 (accuracy: 35.238%)\n",
      "Epoch 23: 22.703 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.208 (accuracy: 45.053%), validation loss = 1.221 (accuracy: 36.190%)\n",
      "Epoch 24: 22.644 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.210 (accuracy: 43.324%), validation loss = 1.217 (accuracy: 37.143%)\n",
      "Epoch 25: 22.620 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.201 (accuracy: 46.013%), validation loss = 1.211 (accuracy: 39.048%)\n",
      "Epoch 26: 22.711 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.202 (accuracy: 44.380%), validation loss = 1.205 (accuracy: 41.905%)\n",
      "Epoch 27: 22.732 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.191 (accuracy: 46.878%), validation loss = 1.205 (accuracy: 41.905%)\n",
      "Epoch 28: 22.426 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.190 (accuracy: 46.782%), validation loss = 1.197 (accuracy: 42.857%)\n",
      "Epoch 29: 22.722 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.179 (accuracy: 48.511%), validation loss = 1.193 (accuracy: 41.905%)\n",
      "Epoch 30: 22.780 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.180 (accuracy: 48.127%), validation loss = 1.188 (accuracy: 41.905%)\n",
      "Epoch 31: 22.730 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.167 (accuracy: 48.319%), validation loss = 1.184 (accuracy: 40.952%)\n",
      "Epoch 32: 22.875 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.172 (accuracy: 49.472%), validation loss = 1.177 (accuracy: 42.857%)\n",
      "Epoch 33: 22.806 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.160 (accuracy: 49.472%), validation loss = 1.172 (accuracy: 44.762%)\n",
      "Epoch 34: 22.822 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.143 (accuracy: 52.161%), validation loss = 1.162 (accuracy: 46.667%)\n",
      "Epoch 35: 22.699 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.140 (accuracy: 53.314%), validation loss = 1.162 (accuracy: 46.667%)\n",
      "Epoch 36: 22.601 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.136 (accuracy: 53.602%), validation loss = 1.152 (accuracy: 45.714%)\n",
      "Epoch 37: 22.565 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.131 (accuracy: 52.354%), validation loss = 1.147 (accuracy: 47.619%)\n",
      "Epoch 38: 22.667 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.126 (accuracy: 55.427%), validation loss = 1.141 (accuracy: 48.571%)\n",
      "Epoch 39: 22.625 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.101 (accuracy: 57.733%), validation loss = 1.135 (accuracy: 48.571%)\n",
      "Epoch 40: 22.617 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.118 (accuracy: 55.908%), validation loss = 1.128 (accuracy: 51.429%)\n",
      "Epoch 41: 22.531 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.095 (accuracy: 56.964%), validation loss = 1.118 (accuracy: 54.286%)\n",
      "Epoch 42: 22.502 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.092 (accuracy: 56.964%), validation loss = 1.113 (accuracy: 55.238%)\n",
      "Epoch 43: 22.596 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.077 (accuracy: 57.349%), validation loss = 1.101 (accuracy: 56.190%)\n",
      "Epoch 44: 22.630 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.066 (accuracy: 58.405%), validation loss = 1.096 (accuracy: 57.143%)\n",
      "Epoch 45: 22.676 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.061 (accuracy: 58.790%), validation loss = 1.089 (accuracy: 55.238%)\n",
      "Epoch 46: 22.785 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.051 (accuracy: 59.558%), validation loss = 1.083 (accuracy: 55.238%)\n",
      "Epoch 47: 22.521 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.038 (accuracy: 61.191%), validation loss = 1.070 (accuracy: 60.000%)\n",
      "Epoch 48: 22.608 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.033 (accuracy: 61.960%), validation loss = 1.062 (accuracy: 60.000%)\n",
      "Epoch 49: 22.429 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.029 (accuracy: 61.671%), validation loss = 1.053 (accuracy: 58.095%)\n",
      "Epoch 50: 22.559 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.010 (accuracy: 63.497%), validation loss = 1.037 (accuracy: 60.952%)\n",
      "Epoch 51: 22.506 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.991 (accuracy: 62.824%), validation loss = 1.029 (accuracy: 61.905%)\n",
      "Epoch 52: 22.539 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.991 (accuracy: 62.440%), validation loss = 1.019 (accuracy: 60.000%)\n",
      "Epoch 53: 22.562 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.971 (accuracy: 64.073%), validation loss = 1.004 (accuracy: 63.810%)\n",
      "Epoch 54: 22.648 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.965 (accuracy: 64.169%), validation loss = 1.001 (accuracy: 61.905%)\n",
      "Epoch 55: 22.586 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.949 (accuracy: 64.169%), validation loss = 0.988 (accuracy: 61.905%)\n",
      "Epoch 56: 22.477 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.951 (accuracy: 64.649%), validation loss = 0.978 (accuracy: 62.857%)\n",
      "Epoch 57: 22.422 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.936 (accuracy: 64.745%), validation loss = 0.967 (accuracy: 63.810%)\n",
      "Epoch 58: 22.598 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.910 (accuracy: 66.282%), validation loss = 0.951 (accuracy: 64.762%)\n",
      "Epoch 59: 22.523 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.910 (accuracy: 65.898%), validation loss = 0.942 (accuracy: 65.714%)\n",
      "Epoch 60: 22.712 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.887 (accuracy: 66.475%), validation loss = 0.927 (accuracy: 65.714%)\n",
      "Epoch 61: 22.746 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.879 (accuracy: 66.955%), validation loss = 0.920 (accuracy: 64.762%)\n",
      "Epoch 62: 22.674 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.857 (accuracy: 68.684%), validation loss = 0.909 (accuracy: 66.667%)\n",
      "Epoch 63: 22.721 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.858 (accuracy: 67.531%), validation loss = 0.900 (accuracy: 63.810%)\n",
      "Epoch 64: 22.764 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.840 (accuracy: 70.317%), validation loss = 0.884 (accuracy: 66.667%)\n",
      "Epoch 65: 22.693 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.810 (accuracy: 70.125%), validation loss = 0.875 (accuracy: 65.714%)\n",
      "Epoch 66: 22.561 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.816 (accuracy: 70.893%), validation loss = 0.866 (accuracy: 65.714%)\n",
      "Epoch 67: 22.657 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.783 (accuracy: 71.470%), validation loss = 0.848 (accuracy: 64.762%)\n",
      "Epoch 68: 22.546 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.787 (accuracy: 70.893%), validation loss = 0.844 (accuracy: 66.667%)\n",
      "Epoch 69: 22.525 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.764 (accuracy: 72.046%), validation loss = 0.836 (accuracy: 64.762%)\n",
      "Epoch 70: 22.490 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.764 (accuracy: 71.950%), validation loss = 0.829 (accuracy: 67.619%)\n",
      "Epoch 71: 22.546 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.736 (accuracy: 73.007%), validation loss = 0.821 (accuracy: 66.667%)\n",
      "Epoch 72: 22.685 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.729 (accuracy: 72.142%), validation loss = 0.821 (accuracy: 62.857%)\n",
      "Epoch 73: 22.645 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.713 (accuracy: 74.448%), validation loss = 0.805 (accuracy: 67.619%)\n",
      "Epoch 74: 22.569 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.730 (accuracy: 72.815%), validation loss = 0.800 (accuracy: 65.714%)\n",
      "Epoch 75: 22.604 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.695 (accuracy: 74.928%), validation loss = 0.783 (accuracy: 67.619%)\n",
      "Epoch 76: 22.630 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.677 (accuracy: 75.889%), validation loss = 0.788 (accuracy: 64.762%)\n",
      "Epoch 77: 22.444 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.672 (accuracy: 75.024%), validation loss = 0.772 (accuracy: 67.619%)\n",
      "Epoch 78: 22.654 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.674 (accuracy: 75.120%), validation loss = 0.760 (accuracy: 70.476%)\n",
      "Epoch 79: 22.635 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.646 (accuracy: 75.504%), validation loss = 0.757 (accuracy: 68.571%)\n",
      "Epoch 80: 22.596 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.629 (accuracy: 78.290%), validation loss = 0.751 (accuracy: 67.619%)\n",
      "Epoch 81: 22.592 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.611 (accuracy: 77.618%), validation loss = 0.749 (accuracy: 69.524%)\n",
      "Epoch 82: 22.634 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.611 (accuracy: 78.194%), validation loss = 0.754 (accuracy: 67.619%)\n",
      "Epoch 83: 22.538 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.630 (accuracy: 76.849%), validation loss = 0.728 (accuracy: 69.524%)\n",
      "Epoch 84: 22.621 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.598 (accuracy: 77.810%), validation loss = 0.728 (accuracy: 68.571%)\n",
      "Epoch 85: 22.578 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.566 (accuracy: 79.827%), validation loss = 0.739 (accuracy: 67.619%)\n",
      "Epoch 86: 22.700 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.584 (accuracy: 78.866%), validation loss = 0.723 (accuracy: 69.524%)\n",
      "Epoch 87: 22.884 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.553 (accuracy: 80.788%), validation loss = 0.714 (accuracy: 68.571%)\n",
      "Epoch 88: 22.784 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.557 (accuracy: 80.115%), validation loss = 0.708 (accuracy: 71.429%)\n",
      "Epoch 89: 22.764 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.556 (accuracy: 79.539%), validation loss = 0.705 (accuracy: 71.429%)\n",
      "Epoch 90: 22.790 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.537 (accuracy: 80.692%), validation loss = 0.705 (accuracy: 71.429%)\n",
      "Epoch 91: 22.539 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.528 (accuracy: 80.980%), validation loss = 0.703 (accuracy: 70.476%)\n",
      "Epoch 92: 22.579 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.497 (accuracy: 82.613%), validation loss = 0.693 (accuracy: 71.429%)\n",
      "Epoch 93: 22.650 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.501 (accuracy: 82.517%), validation loss = 0.680 (accuracy: 74.286%)\n",
      "Epoch 94: 22.608 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.486 (accuracy: 83.573%), validation loss = 0.675 (accuracy: 75.238%)\n",
      "Epoch 95: 22.517 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.467 (accuracy: 83.285%), validation loss = 0.669 (accuracy: 75.238%)\n",
      "Epoch 96: 22.614 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 0.472 (accuracy: 84.150%), validation loss = 0.668 (accuracy: 73.333%)\n",
      "Epoch 97: 22.739 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 0.461 (accuracy: 83.958%), validation loss = 0.663 (accuracy: 74.286%)\n",
      "Epoch 98: 22.875 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.456 (accuracy: 83.958%), validation loss = 0.653 (accuracy: 74.286%)\n",
      "Epoch 99: 22.640 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.440 (accuracy: 85.879%), validation loss = 0.661 (accuracy: 75.238%)\n",
      "Epoch 100: 22.717 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.432 (accuracy: 86.551%), validation loss = 0.640 (accuracy: 74.286%)\n",
      "Epoch 101: 22.665 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.408 (accuracy: 86.744%), validation loss = 0.636 (accuracy: 76.190%)\n",
      "Epoch 102: 22.679 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.417 (accuracy: 85.975%), validation loss = 0.617 (accuracy: 77.143%)\n",
      "Epoch 103: 22.549 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.399 (accuracy: 86.167%), validation loss = 0.634 (accuracy: 74.286%)\n",
      "Epoch 104: 22.327 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.394 (accuracy: 87.416%), validation loss = 0.615 (accuracy: 75.238%)\n",
      "Epoch 105: 22.531 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.395 (accuracy: 87.320%), validation loss = 0.621 (accuracy: 76.190%)\n",
      "Epoch 106: 22.379 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.375 (accuracy: 88.184%), validation loss = 0.620 (accuracy: 74.286%)\n",
      "Epoch 107: 22.359 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 0.378 (accuracy: 87.800%), validation loss = 0.623 (accuracy: 73.333%)\n",
      "Epoch 108: 22.286 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.363 (accuracy: 88.953%), validation loss = 0.615 (accuracy: 75.238%)\n",
      "Epoch 109: 22.563 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.348 (accuracy: 90.682%), validation loss = 0.623 (accuracy: 74.286%)\n",
      "Epoch 110: 22.176 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.340 (accuracy: 91.258%), validation loss = 0.612 (accuracy: 74.286%)\n",
      "Epoch 111: 22.572 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.326 (accuracy: 90.970%), validation loss = 0.596 (accuracy: 75.238%)\n",
      "Epoch 112: 22.568 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.322 (accuracy: 90.778%), validation loss = 0.610 (accuracy: 73.333%)\n",
      "Epoch 113: 22.311 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.321 (accuracy: 91.643%), validation loss = 0.600 (accuracy: 78.095%)\n",
      "Epoch 114: 22.456 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.329 (accuracy: 90.298%), validation loss = 0.587 (accuracy: 74.286%)\n",
      "Epoch 115: 22.582 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.320 (accuracy: 90.298%), validation loss = 0.588 (accuracy: 74.286%)\n",
      "Epoch 116: 22.254 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.286 (accuracy: 93.372%), validation loss = 0.558 (accuracy: 76.190%)\n",
      "Epoch 117: 22.420 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.279 (accuracy: 92.123%), validation loss = 0.575 (accuracy: 73.333%)\n",
      "Epoch 118: 22.341 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.305 (accuracy: 92.411%), validation loss = 0.575 (accuracy: 74.286%)\n",
      "Epoch 119: 22.434 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 0.292 (accuracy: 91.835%), validation loss = 0.565 (accuracy: 77.143%)\n",
      "Epoch 120: 22.532 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.284 (accuracy: 91.739%), validation loss = 0.572 (accuracy: 75.238%)\n",
      "Epoch 121: 22.485 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.271 (accuracy: 93.180%), validation loss = 0.587 (accuracy: 74.286%)\n",
      "Epoch 122: 22.486 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.277 (accuracy: 92.027%), validation loss = 0.555 (accuracy: 76.190%)\n",
      "Epoch 123: 22.594 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.261 (accuracy: 93.084%), validation loss = 0.557 (accuracy: 75.238%)\n",
      "Epoch 124: 22.583 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.252 (accuracy: 94.332%), validation loss = 0.544 (accuracy: 78.095%)\n",
      "Epoch 125: 22.806 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.251 (accuracy: 93.660%), validation loss = 0.544 (accuracy: 78.095%)\n",
      "Epoch 126: 22.702 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.243 (accuracy: 94.717%), validation loss = 0.568 (accuracy: 76.190%)\n",
      "Epoch 127: 22.630 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.234 (accuracy: 94.813%), validation loss = 0.566 (accuracy: 78.095%)\n",
      "Epoch 128: 22.524 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.221 (accuracy: 95.389%), validation loss = 0.534 (accuracy: 79.048%)\n",
      "Epoch 129: 22.641 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.230 (accuracy: 94.621%), validation loss = 0.580 (accuracy: 76.190%)\n",
      "Epoch 130: 22.406 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.226 (accuracy: 94.909%), validation loss = 0.585 (accuracy: 77.143%)\n",
      "Epoch 131: 22.342 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.209 (accuracy: 95.293%), validation loss = 0.554 (accuracy: 78.095%)\n",
      "Epoch 132: 22.451 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.206 (accuracy: 95.773%), validation loss = 0.573 (accuracy: 78.095%)\n",
      "Epoch 133: 22.400 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.205 (accuracy: 95.485%), validation loss = 0.545 (accuracy: 79.048%)\n",
      "Epoch 134: 22.377 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.201 (accuracy: 96.061%), validation loss = 0.530 (accuracy: 78.095%)\n",
      "Epoch 135: 22.421 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.202 (accuracy: 95.389%), validation loss = 0.540 (accuracy: 79.048%)\n",
      "Epoch 136: 22.233 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.210 (accuracy: 96.061%), validation loss = 0.540 (accuracy: 79.048%)\n",
      "Epoch 137: 22.247 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.208 (accuracy: 95.485%), validation loss = 0.541 (accuracy: 77.143%)\n",
      "Epoch 138: 22.365 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.197 (accuracy: 96.061%), validation loss = 0.555 (accuracy: 78.095%)\n",
      "Epoch 139: 22.334 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.202 (accuracy: 95.677%), validation loss = 0.549 (accuracy: 77.143%)\n",
      "Epoch 140: 22.229 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.181 (accuracy: 96.734%), validation loss = 0.511 (accuracy: 78.095%)\n",
      "Epoch 141: 22.654 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.185 (accuracy: 96.158%), validation loss = 0.518 (accuracy: 78.095%)\n",
      "Epoch 142: 22.259 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.170 (accuracy: 97.310%), validation loss = 0.512 (accuracy: 79.048%)\n",
      "Epoch 143: 22.271 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.169 (accuracy: 97.022%), validation loss = 0.501 (accuracy: 79.048%)\n",
      "Epoch 144: 22.420 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.182 (accuracy: 96.830%), validation loss = 0.529 (accuracy: 78.095%)\n",
      "Epoch 145: 22.221 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.151 (accuracy: 97.598%), validation loss = 0.498 (accuracy: 80.000%)\n",
      "Epoch 146: 22.493 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.158 (accuracy: 97.695%), validation loss = 0.527 (accuracy: 78.095%)\n",
      "Epoch 147: 22.295 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.162 (accuracy: 97.214%), validation loss = 0.523 (accuracy: 77.143%)\n",
      "Epoch 148: 22.277 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.148 (accuracy: 97.118%), validation loss = 0.522 (accuracy: 80.000%)\n",
      "Epoch 149: 22.209 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.161 (accuracy: 97.214%), validation loss = 0.523 (accuracy: 78.095%)\n",
      "Epoch 150: 22.136 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.151 (accuracy: 97.406%), validation loss = 0.525 (accuracy: 76.190%)\n",
      "Epoch 151: 22.224 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.152 (accuracy: 97.310%), validation loss = 0.535 (accuracy: 75.238%)\n",
      "Epoch 152: 22.160 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.140 (accuracy: 97.695%), validation loss = 0.539 (accuracy: 75.238%)\n",
      "Epoch 153: 22.141 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.138 (accuracy: 97.695%), validation loss = 0.527 (accuracy: 79.048%)\n",
      "Epoch 154: 22.245 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.136 (accuracy: 97.983%), validation loss = 0.534 (accuracy: 76.190%)\n",
      "Epoch 155: 22.281 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.143 (accuracy: 97.791%), validation loss = 0.550 (accuracy: 77.143%)\n",
      "Epoch 156: 22.173 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.133 (accuracy: 98.079%), validation loss = 0.560 (accuracy: 77.143%)\n",
      "Epoch 157: 22.286 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 0.137 (accuracy: 97.983%), validation loss = 0.554 (accuracy: 79.048%)\n",
      "Epoch 158: 22.205 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 0.131 (accuracy: 98.463%), validation loss = 0.556 (accuracy: 76.190%)\n",
      "Epoch 159: 22.182 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 0.129 (accuracy: 98.367%), validation loss = 0.519 (accuracy: 78.095%)\n",
      "Epoch 160: 22.268 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 0.120 (accuracy: 98.655%), validation loss = 0.538 (accuracy: 77.143%)\n",
      "Epoch 161: 22.200 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 0.145 (accuracy: 97.118%), validation loss = 0.563 (accuracy: 77.143%)\n",
      "Epoch 162: 22.271 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 0.132 (accuracy: 97.695%), validation loss = 0.530 (accuracy: 78.095%)\n",
      "Epoch 163: 22.320 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 0.127 (accuracy: 98.463%), validation loss = 0.515 (accuracy: 78.095%)\n",
      "Epoch 164: 22.234 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 0.127 (accuracy: 98.271%), validation loss = 0.546 (accuracy: 78.095%)\n",
      "Epoch 165: 22.322 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 0.109 (accuracy: 98.751%), validation loss = 0.574 (accuracy: 78.095%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 145 with minimum validation error = 0.49755979095186503\n",
      "11715.394 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0.2\n",
      "Epoch 1: 22.296 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.336 (accuracy: 35.447%), validation loss = 1.304 (accuracy: 34.286%)\n",
      "Epoch 2: 22.355 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.299 (accuracy: 38.713%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 3: 22.549 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.291 (accuracy: 38.136%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 4: 22.681 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.277 (accuracy: 38.809%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 5: 22.690 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.271 (accuracy: 39.193%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 6: 22.786 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.270 (accuracy: 39.097%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 7: 22.870 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.265 (accuracy: 41.210%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 8: 22.760 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.269 (accuracy: 39.481%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 9: 22.672 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.257 (accuracy: 41.210%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 10: 22.962 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.255 (accuracy: 39.673%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 11: 22.724 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.247 (accuracy: 41.210%), validation loss = 1.252 (accuracy: 33.333%)\n",
      "Epoch 12: 22.816 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.257 (accuracy: 41.018%), validation loss = 1.248 (accuracy: 33.333%)\n",
      "Epoch 13: 22.815 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.250 (accuracy: 40.826%), validation loss = 1.249 (accuracy: 33.333%)\n",
      "Epoch 14: 22.713 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.234 (accuracy: 40.442%), validation loss = 1.245 (accuracy: 33.333%)\n",
      "Epoch 15: 22.779 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.237 (accuracy: 40.826%), validation loss = 1.243 (accuracy: 33.333%)\n",
      "Epoch 16: 22.512 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.239 (accuracy: 41.499%), validation loss = 1.244 (accuracy: 33.333%)\n",
      "Epoch 17: 22.700 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.233 (accuracy: 41.114%), validation loss = 1.239 (accuracy: 33.333%)\n",
      "Epoch 18: 22.656 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.233 (accuracy: 40.442%), validation loss = 1.236 (accuracy: 33.333%)\n",
      "Epoch 19: 22.594 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.233 (accuracy: 40.538%), validation loss = 1.232 (accuracy: 34.286%)\n",
      "Epoch 20: 22.696 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.216 (accuracy: 42.939%), validation loss = 1.228 (accuracy: 33.333%)\n",
      "Epoch 21: 22.529 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.225 (accuracy: 41.595%), validation loss = 1.224 (accuracy: 35.238%)\n",
      "Epoch 22: 22.658 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.227 (accuracy: 43.612%), validation loss = 1.223 (accuracy: 35.238%)\n",
      "Epoch 23: 22.783 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.217 (accuracy: 43.996%), validation loss = 1.220 (accuracy: 36.190%)\n",
      "Epoch 24: 22.784 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.205 (accuracy: 45.053%), validation loss = 1.218 (accuracy: 36.190%)\n",
      "Epoch 25: 22.758 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.203 (accuracy: 44.861%), validation loss = 1.214 (accuracy: 39.048%)\n",
      "Epoch 26: 22.802 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.205 (accuracy: 43.996%), validation loss = 1.212 (accuracy: 37.143%)\n",
      "Epoch 27: 22.759 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.205 (accuracy: 43.516%), validation loss = 1.207 (accuracy: 40.000%)\n",
      "Epoch 28: 22.698 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.191 (accuracy: 45.629%), validation loss = 1.203 (accuracy: 40.952%)\n",
      "Epoch 29: 22.817 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.195 (accuracy: 44.861%), validation loss = 1.202 (accuracy: 40.000%)\n",
      "Epoch 30: 22.725 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.186 (accuracy: 45.629%), validation loss = 1.198 (accuracy: 40.952%)\n",
      "Epoch 31: 22.891 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.189 (accuracy: 46.686%), validation loss = 1.193 (accuracy: 42.857%)\n",
      "Epoch 32: 22.586 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.181 (accuracy: 46.878%), validation loss = 1.191 (accuracy: 45.714%)\n",
      "Epoch 33: 22.514 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.180 (accuracy: 47.070%), validation loss = 1.186 (accuracy: 46.667%)\n",
      "Epoch 34: 24.774 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.176 (accuracy: 47.070%), validation loss = 1.182 (accuracy: 46.667%)\n",
      "Epoch 35: 22.487 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.167 (accuracy: 47.839%), validation loss = 1.179 (accuracy: 46.667%)\n",
      "Epoch 36: 22.620 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.155 (accuracy: 51.009%), validation loss = 1.174 (accuracy: 48.571%)\n",
      "Epoch 37: 22.703 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.161 (accuracy: 49.472%), validation loss = 1.170 (accuracy: 48.571%)\n",
      "Epoch 38: 22.676 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.152 (accuracy: 50.624%), validation loss = 1.164 (accuracy: 50.476%)\n",
      "Epoch 39: 22.615 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.146 (accuracy: 51.105%), validation loss = 1.161 (accuracy: 50.476%)\n",
      "Epoch 40: 22.731 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.147 (accuracy: 51.777%), validation loss = 1.155 (accuracy: 49.524%)\n",
      "Epoch 41: 22.703 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.136 (accuracy: 51.969%), validation loss = 1.152 (accuracy: 49.524%)\n",
      "Epoch 42: 22.586 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.122 (accuracy: 54.467%), validation loss = 1.147 (accuracy: 50.476%)\n",
      "Epoch 43: 22.648 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.135 (accuracy: 52.257%), validation loss = 1.141 (accuracy: 54.286%)\n",
      "Epoch 44: 22.807 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.127 (accuracy: 54.371%), validation loss = 1.134 (accuracy: 53.333%)\n",
      "Epoch 45: 22.818 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.111 (accuracy: 56.676%), validation loss = 1.129 (accuracy: 53.333%)\n",
      "Epoch 46: 22.604 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.106 (accuracy: 56.772%), validation loss = 1.122 (accuracy: 54.286%)\n",
      "Epoch 47: 22.529 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.101 (accuracy: 55.524%), validation loss = 1.114 (accuracy: 55.238%)\n",
      "Epoch 48: 22.673 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.091 (accuracy: 57.733%), validation loss = 1.111 (accuracy: 54.286%)\n",
      "Epoch 49: 22.699 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.083 (accuracy: 58.886%), validation loss = 1.102 (accuracy: 59.048%)\n",
      "Epoch 50: 22.732 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.073 (accuracy: 60.231%), validation loss = 1.095 (accuracy: 60.000%)\n",
      "Epoch 51: 22.651 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.063 (accuracy: 60.711%), validation loss = 1.089 (accuracy: 60.000%)\n",
      "Epoch 52: 22.664 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.057 (accuracy: 59.846%), validation loss = 1.083 (accuracy: 60.952%)\n",
      "Epoch 53: 22.771 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.053 (accuracy: 61.864%), validation loss = 1.077 (accuracy: 60.952%)\n",
      "Epoch 54: 22.691 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.044 (accuracy: 61.960%), validation loss = 1.068 (accuracy: 60.952%)\n",
      "Epoch 55: 22.615 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.031 (accuracy: 62.632%), validation loss = 1.060 (accuracy: 64.762%)\n",
      "Epoch 56: 22.666 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.014 (accuracy: 61.575%), validation loss = 1.051 (accuracy: 63.810%)\n",
      "Epoch 57: 22.610 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.020 (accuracy: 62.920%), validation loss = 1.045 (accuracy: 63.810%)\n",
      "Epoch 58: 22.899 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.995 (accuracy: 65.610%), validation loss = 1.037 (accuracy: 64.762%)\n",
      "Epoch 59: 22.694 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.989 (accuracy: 64.361%), validation loss = 1.028 (accuracy: 65.714%)\n",
      "Epoch 60: 22.604 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.981 (accuracy: 66.282%), validation loss = 1.016 (accuracy: 64.762%)\n",
      "Epoch 61: 22.637 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.962 (accuracy: 66.378%), validation loss = 1.012 (accuracy: 63.810%)\n",
      "Epoch 62: 22.720 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.951 (accuracy: 66.282%), validation loss = 1.001 (accuracy: 63.810%)\n",
      "Epoch 63: 22.753 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.951 (accuracy: 65.706%), validation loss = 0.984 (accuracy: 66.667%)\n",
      "Epoch 64: 22.774 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.935 (accuracy: 67.339%), validation loss = 0.979 (accuracy: 65.714%)\n",
      "Epoch 65: 22.731 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.922 (accuracy: 67.531%), validation loss = 0.971 (accuracy: 65.714%)\n",
      "Epoch 66: 22.625 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.912 (accuracy: 68.396%), validation loss = 0.960 (accuracy: 65.714%)\n",
      "Epoch 67: 22.651 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.908 (accuracy: 68.012%), validation loss = 0.949 (accuracy: 66.667%)\n",
      "Epoch 68: 22.678 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.895 (accuracy: 68.588%), validation loss = 0.942 (accuracy: 65.714%)\n",
      "Epoch 69: 22.805 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.884 (accuracy: 69.164%), validation loss = 0.932 (accuracy: 66.667%)\n",
      "Epoch 70: 22.692 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.873 (accuracy: 69.164%), validation loss = 0.919 (accuracy: 66.667%)\n",
      "Epoch 71: 22.829 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.846 (accuracy: 70.893%), validation loss = 0.908 (accuracy: 66.667%)\n",
      "Epoch 72: 22.743 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.838 (accuracy: 70.797%), validation loss = 0.895 (accuracy: 66.667%)\n",
      "Epoch 73: 22.775 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.827 (accuracy: 72.334%), validation loss = 0.887 (accuracy: 67.619%)\n",
      "Epoch 74: 22.542 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.808 (accuracy: 71.566%), validation loss = 0.884 (accuracy: 66.667%)\n",
      "Epoch 75: 22.624 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.803 (accuracy: 72.142%), validation loss = 0.873 (accuracy: 67.619%)\n",
      "Epoch 76: 22.730 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.793 (accuracy: 73.007%), validation loss = 0.868 (accuracy: 68.571%)\n",
      "Epoch 77: 22.633 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.768 (accuracy: 74.159%), validation loss = 0.847 (accuracy: 68.571%)\n",
      "Epoch 78: 22.735 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.772 (accuracy: 73.487%), validation loss = 0.843 (accuracy: 67.619%)\n",
      "Epoch 79: 22.596 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.759 (accuracy: 73.967%), validation loss = 0.835 (accuracy: 67.619%)\n",
      "Epoch 80: 22.655 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.746 (accuracy: 73.967%), validation loss = 0.833 (accuracy: 66.667%)\n",
      "Epoch 81: 22.547 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.725 (accuracy: 76.177%), validation loss = 0.819 (accuracy: 68.571%)\n",
      "Epoch 82: 22.621 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.710 (accuracy: 77.329%), validation loss = 0.818 (accuracy: 69.524%)\n",
      "Epoch 83: 22.724 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.697 (accuracy: 77.618%), validation loss = 0.811 (accuracy: 67.619%)\n",
      "Epoch 84: 22.629 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.686 (accuracy: 76.081%), validation loss = 0.794 (accuracy: 70.476%)\n",
      "Epoch 85: 22.943 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.690 (accuracy: 76.561%), validation loss = 0.788 (accuracy: 70.476%)\n",
      "Epoch 86: 22.766 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.669 (accuracy: 77.137%), validation loss = 0.785 (accuracy: 69.524%)\n",
      "Epoch 87: 22.723 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.652 (accuracy: 77.618%), validation loss = 0.783 (accuracy: 71.429%)\n",
      "Epoch 88: 22.607 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.660 (accuracy: 76.945%), validation loss = 0.767 (accuracy: 68.571%)\n",
      "Epoch 89: 22.813 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.641 (accuracy: 78.290%), validation loss = 0.763 (accuracy: 69.524%)\n",
      "Epoch 90: 22.778 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.630 (accuracy: 79.731%), validation loss = 0.763 (accuracy: 71.429%)\n",
      "Epoch 91: 22.501 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.620 (accuracy: 79.539%), validation loss = 0.760 (accuracy: 70.476%)\n",
      "Epoch 92: 22.624 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.603 (accuracy: 80.884%), validation loss = 0.742 (accuracy: 71.429%)\n",
      "Epoch 93: 22.754 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.577 (accuracy: 82.037%), validation loss = 0.741 (accuracy: 70.476%)\n",
      "Epoch 94: 22.851 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.566 (accuracy: 81.940%), validation loss = 0.730 (accuracy: 71.429%)\n",
      "Epoch 95: 22.703 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.586 (accuracy: 79.827%), validation loss = 0.732 (accuracy: 71.429%)\n",
      "Epoch 96: 22.533 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 0.564 (accuracy: 81.268%), validation loss = 0.714 (accuracy: 73.333%)\n",
      "Epoch 97: 22.664 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 0.546 (accuracy: 82.037%), validation loss = 0.705 (accuracy: 73.333%)\n",
      "Epoch 98: 22.903 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.527 (accuracy: 83.285%), validation loss = 0.713 (accuracy: 72.381%)\n",
      "Epoch 99: 22.580 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.539 (accuracy: 81.748%), validation loss = 0.703 (accuracy: 72.381%)\n",
      "Epoch 100: 22.751 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.516 (accuracy: 82.613%), validation loss = 0.702 (accuracy: 74.286%)\n",
      "Epoch 101: 22.708 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.514 (accuracy: 84.054%), validation loss = 0.696 (accuracy: 73.333%)\n",
      "Epoch 102: 22.752 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.493 (accuracy: 84.726%), validation loss = 0.682 (accuracy: 74.286%)\n",
      "Epoch 103: 22.736 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.479 (accuracy: 85.303%), validation loss = 0.696 (accuracy: 70.476%)\n",
      "Epoch 104: 22.643 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.477 (accuracy: 84.534%), validation loss = 0.672 (accuracy: 75.238%)\n",
      "Epoch 105: 22.646 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.452 (accuracy: 86.359%), validation loss = 0.674 (accuracy: 74.286%)\n",
      "Epoch 106: 22.518 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.464 (accuracy: 85.591%), validation loss = 0.667 (accuracy: 75.238%)\n",
      "Epoch 107: 22.682 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 0.468 (accuracy: 84.438%), validation loss = 0.656 (accuracy: 73.333%)\n",
      "Epoch 108: 22.700 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.442 (accuracy: 85.879%), validation loss = 0.661 (accuracy: 75.238%)\n",
      "Epoch 109: 22.483 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.430 (accuracy: 85.975%), validation loss = 0.672 (accuracy: 73.333%)\n",
      "Epoch 110: 22.501 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.417 (accuracy: 87.416%), validation loss = 0.670 (accuracy: 74.286%)\n",
      "Epoch 111: 22.500 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.418 (accuracy: 87.416%), validation loss = 0.657 (accuracy: 73.333%)\n",
      "Epoch 112: 22.690 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.415 (accuracy: 86.263%), validation loss = 0.639 (accuracy: 76.190%)\n",
      "Epoch 113: 22.666 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.407 (accuracy: 87.320%), validation loss = 0.642 (accuracy: 74.286%)\n",
      "Epoch 114: 22.484 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.400 (accuracy: 86.744%), validation loss = 0.646 (accuracy: 75.238%)\n",
      "Epoch 115: 22.613 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.388 (accuracy: 87.800%), validation loss = 0.634 (accuracy: 77.143%)\n",
      "Epoch 116: 22.741 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.381 (accuracy: 88.280%), validation loss = 0.636 (accuracy: 75.238%)\n",
      "Epoch 117: 22.508 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.389 (accuracy: 88.184%), validation loss = 0.653 (accuracy: 75.238%)\n",
      "Epoch 118: 22.571 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.369 (accuracy: 88.857%), validation loss = 0.637 (accuracy: 74.286%)\n",
      "Epoch 119: 22.593 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 0.379 (accuracy: 88.473%), validation loss = 0.624 (accuracy: 74.286%)\n",
      "Epoch 120: 22.748 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.372 (accuracy: 88.953%), validation loss = 0.626 (accuracy: 74.286%)\n",
      "Epoch 121: 22.547 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.357 (accuracy: 89.049%), validation loss = 0.611 (accuracy: 77.143%)\n",
      "Epoch 122: 22.807 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.350 (accuracy: 89.145%), validation loss = 0.593 (accuracy: 79.048%)\n",
      "Epoch 123: 22.715 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.370 (accuracy: 88.857%), validation loss = 0.612 (accuracy: 75.238%)\n",
      "Epoch 124: 22.530 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.348 (accuracy: 89.145%), validation loss = 0.610 (accuracy: 76.190%)\n",
      "Epoch 125: 22.672 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.339 (accuracy: 90.586%), validation loss = 0.621 (accuracy: 75.238%)\n",
      "Epoch 126: 22.602 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.333 (accuracy: 90.586%), validation loss = 0.606 (accuracy: 75.238%)\n",
      "Epoch 127: 22.572 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.343 (accuracy: 89.721%), validation loss = 0.604 (accuracy: 76.190%)\n",
      "Epoch 128: 22.552 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.338 (accuracy: 89.433%), validation loss = 0.609 (accuracy: 77.143%)\n",
      "Epoch 129: 22.727 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.324 (accuracy: 90.298%), validation loss = 0.600 (accuracy: 77.143%)\n",
      "Epoch 130: 22.567 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.328 (accuracy: 90.682%), validation loss = 0.591 (accuracy: 78.095%)\n",
      "Epoch 131: 22.768 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.326 (accuracy: 91.835%), validation loss = 0.598 (accuracy: 77.143%)\n",
      "Epoch 132: 22.552 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.327 (accuracy: 89.817%), validation loss = 0.589 (accuracy: 77.143%)\n",
      "Epoch 133: 22.740 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.316 (accuracy: 90.874%), validation loss = 0.591 (accuracy: 79.048%)\n",
      "Epoch 134: 22.570 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.323 (accuracy: 90.106%), validation loss = 0.609 (accuracy: 77.143%)\n",
      "Epoch 135: 22.562 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.305 (accuracy: 90.874%), validation loss = 0.594 (accuracy: 78.095%)\n",
      "Epoch 136: 22.676 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.309 (accuracy: 91.451%), validation loss = 0.584 (accuracy: 78.095%)\n",
      "Epoch 137: 22.664 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.304 (accuracy: 91.547%), validation loss = 0.585 (accuracy: 78.095%)\n",
      "Epoch 138: 22.599 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.309 (accuracy: 91.931%), validation loss = 0.587 (accuracy: 78.095%)\n",
      "Epoch 139: 22.631 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.309 (accuracy: 91.451%), validation loss = 0.611 (accuracy: 75.238%)\n",
      "Epoch 140: 22.638 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.303 (accuracy: 91.451%), validation loss = 0.589 (accuracy: 79.048%)\n",
      "Epoch 141: 22.630 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.305 (accuracy: 91.354%), validation loss = 0.608 (accuracy: 75.238%)\n",
      "Epoch 142: 22.510 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.296 (accuracy: 92.603%), validation loss = 0.595 (accuracy: 78.095%)\n",
      "Epoch 143: 22.721 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.301 (accuracy: 91.931%), validation loss = 0.598 (accuracy: 78.095%)\n",
      "Epoch 144: 22.536 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.287 (accuracy: 92.411%), validation loss = 0.624 (accuracy: 78.095%)\n",
      "Epoch 145: 22.468 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.306 (accuracy: 92.699%), validation loss = 0.597 (accuracy: 78.095%)\n",
      "Epoch 146: 22.525 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.285 (accuracy: 92.891%), validation loss = 0.602 (accuracy: 76.190%)\n",
      "Epoch 147: 22.584 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.291 (accuracy: 92.123%), validation loss = 0.592 (accuracy: 75.238%)\n",
      "Epoch 148: 22.465 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.298 (accuracy: 92.123%), validation loss = 0.606 (accuracy: 80.952%)\n",
      "Epoch 149: 22.534 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.301 (accuracy: 91.931%), validation loss = 0.620 (accuracy: 73.333%)\n",
      "Epoch 150: 22.588 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.306 (accuracy: 92.988%), validation loss = 0.613 (accuracy: 77.143%)\n",
      "Epoch 151: 22.538 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.289 (accuracy: 92.315%), validation loss = 0.602 (accuracy: 77.143%)\n",
      "Epoch 152: 22.594 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.297 (accuracy: 93.660%), validation loss = 0.606 (accuracy: 79.048%)\n",
      "Epoch 153: 22.695 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.296 (accuracy: 93.180%), validation loss = 0.633 (accuracy: 77.143%)\n",
      "Epoch 154: 22.571 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.290 (accuracy: 92.795%), validation loss = 0.634 (accuracy: 76.190%)\n",
      "Epoch 155: 22.467 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.283 (accuracy: 93.468%), validation loss = 0.608 (accuracy: 78.095%)\n",
      "Epoch 156: 22.528 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.290 (accuracy: 92.988%), validation loss = 0.615 (accuracy: 76.190%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 136 with minimum validation error = 0.5841582377751668\n",
      "15294.881 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0.5\n",
      "Epoch 1: 22.510 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.352 (accuracy: 32.853%), validation loss = 1.336 (accuracy: 27.619%)\n",
      "Epoch 2: 22.715 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.313 (accuracy: 37.656%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 3: 22.609 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.299 (accuracy: 37.176%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 4: 22.649 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.282 (accuracy: 39.481%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 5: 22.762 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.287 (accuracy: 40.058%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 6: 22.695 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.277 (accuracy: 39.385%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 7: 22.667 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.275 (accuracy: 39.577%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 8: 22.655 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.274 (accuracy: 39.866%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 9: 22.634 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.265 (accuracy: 40.634%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 10: 22.646 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.265 (accuracy: 40.154%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 11: 22.754 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.265 (accuracy: 39.673%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 12: 22.701 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.266 (accuracy: 39.769%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 13: 22.587 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.260 (accuracy: 40.730%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 14: 22.589 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.258 (accuracy: 40.154%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 15: 22.614 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.259 (accuracy: 39.962%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 16: 22.753 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.258 (accuracy: 39.769%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 17: 22.643 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.253 (accuracy: 40.058%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 18: 22.528 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.250 (accuracy: 40.538%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 19: 22.556 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.255 (accuracy: 40.538%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 20: 22.655 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.255 (accuracy: 40.442%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 21: 22.620 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.251 (accuracy: 40.058%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 22: 22.626 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.252 (accuracy: 40.154%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 23: 22.565 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.247 (accuracy: 40.442%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 24: 22.661 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.250 (accuracy: 40.442%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 25: 22.603 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.245 (accuracy: 39.481%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 26: 22.740 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.252 (accuracy: 40.058%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 27: 22.722 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.249 (accuracy: 40.154%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 28: 22.618 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.245 (accuracy: 40.250%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 29: 22.502 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.247 (accuracy: 40.250%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 30: 22.445 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.247 (accuracy: 40.058%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 31: 22.519 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.251 (accuracy: 39.962%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 32: 22.702 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.250 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 33: 22.522 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.245 (accuracy: 39.769%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 34: 22.465 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.243 (accuracy: 39.769%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 35: 22.503 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.242 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 36: 22.460 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.245 (accuracy: 39.481%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 37: 22.635 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.240 (accuracy: 39.962%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 38: 22.586 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.240 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 39: 22.455 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.239 (accuracy: 39.769%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 40: 22.693 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.241 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 41: 22.396 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.238 (accuracy: 39.769%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 42: 22.492 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.238 (accuracy: 39.769%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 43: 22.559 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.237 (accuracy: 39.673%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 44: 22.429 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.235 (accuracy: 39.577%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 45: 22.528 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.235 (accuracy: 39.673%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 46: 22.661 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.234 (accuracy: 39.769%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 47: 22.692 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.229 (accuracy: 39.866%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 48: 22.519 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.231 (accuracy: 39.673%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 49: 22.560 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.233 (accuracy: 39.769%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 50: 22.354 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.228 (accuracy: 39.481%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 51: 22.622 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.230 (accuracy: 39.577%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 52: 22.470 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.229 (accuracy: 39.577%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 53: 22.417 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.224 (accuracy: 39.577%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 54: 22.514 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.222 (accuracy: 39.577%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 55: 22.565 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.219 (accuracy: 39.866%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 56: 22.344 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.224 (accuracy: 39.769%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 57: 22.241 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.216 (accuracy: 39.577%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 58: 22.506 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.218 (accuracy: 39.577%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 59: 22.522 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.213 (accuracy: 39.577%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 60: 22.308 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.209 (accuracy: 39.481%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 61: 22.394 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.207 (accuracy: 39.481%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 62: 22.647 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.210 (accuracy: 39.481%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 63: 22.285 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.205 (accuracy: 39.481%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 64: 22.233 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.198 (accuracy: 39.577%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 65: 22.663 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.200 (accuracy: 39.481%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 66: 22.360 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.192 (accuracy: 39.577%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 67: 22.424 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.194 (accuracy: 39.673%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 68: 22.545 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.190 (accuracy: 39.577%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 69: 22.425 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.189 (accuracy: 39.577%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 70: 22.609 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.185 (accuracy: 39.577%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 71: 22.344 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.183 (accuracy: 39.577%), validation loss = 1.259 (accuracy: 33.333%)\n",
      "Epoch 72: 22.744 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.183 (accuracy: 39.481%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 73: 22.492 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.178 (accuracy: 39.577%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 74: 22.617 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.175 (accuracy: 39.577%), validation loss = 1.253 (accuracy: 33.333%)\n",
      "Epoch 75: 22.724 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.177 (accuracy: 39.673%), validation loss = 1.259 (accuracy: 33.333%)\n",
      "Epoch 76: 22.527 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.168 (accuracy: 39.673%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 77: 22.444 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.167 (accuracy: 40.538%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 78: 22.418 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.162 (accuracy: 40.058%), validation loss = 1.241 (accuracy: 33.333%)\n",
      "Epoch 79: 22.893 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.164 (accuracy: 40.250%), validation loss = 1.261 (accuracy: 34.286%)\n",
      "Epoch 80: 22.521 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.154 (accuracy: 40.826%), validation loss = 1.259 (accuracy: 34.286%)\n",
      "Epoch 81: 22.548 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.153 (accuracy: 41.787%), validation loss = 1.253 (accuracy: 37.143%)\n",
      "Epoch 82: 22.437 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.150 (accuracy: 43.132%), validation loss = 1.246 (accuracy: 34.286%)\n",
      "Epoch 83: 22.585 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.150 (accuracy: 44.284%), validation loss = 1.241 (accuracy: 36.190%)\n",
      "Epoch 84: 22.538 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.144 (accuracy: 45.821%), validation loss = 1.242 (accuracy: 38.095%)\n",
      "Epoch 85: 22.446 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.147 (accuracy: 46.590%), validation loss = 1.246 (accuracy: 41.905%)\n",
      "Epoch 86: 22.527 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.135 (accuracy: 50.048%), validation loss = 1.252 (accuracy: 42.857%)\n",
      "Epoch 87: 22.503 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.137 (accuracy: 53.410%), validation loss = 1.255 (accuracy: 45.714%)\n",
      "Epoch 88: 22.498 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.136 (accuracy: 52.546%), validation loss = 1.245 (accuracy: 45.714%)\n",
      "Epoch 89: 22.402 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.142 (accuracy: 54.179%), validation loss = 1.248 (accuracy: 45.714%)\n",
      "Epoch 90: 22.373 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.137 (accuracy: 55.812%), validation loss = 1.258 (accuracy: 46.667%)\n",
      "Epoch 91: 22.453 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.136 (accuracy: 55.812%), validation loss = 1.262 (accuracy: 49.524%)\n",
      "Epoch 92: 22.344 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.133 (accuracy: 56.196%), validation loss = 1.259 (accuracy: 45.714%)\n",
      "Epoch 93: 22.441 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.132 (accuracy: 58.598%), validation loss = 1.259 (accuracy: 46.667%)\n",
      "Epoch 94: 22.417 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.134 (accuracy: 56.868%), validation loss = 1.233 (accuracy: 47.619%)\n",
      "Epoch 95: 22.520 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.135 (accuracy: 56.196%), validation loss = 1.263 (accuracy: 48.571%)\n",
      "Epoch 96: 22.296 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.133 (accuracy: 58.598%), validation loss = 1.272 (accuracy: 45.714%)\n",
      "Epoch 97: 22.328 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.135 (accuracy: 57.253%), validation loss = 1.287 (accuracy: 44.762%)\n",
      "Epoch 98: 22.301 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.131 (accuracy: 57.637%), validation loss = 1.266 (accuracy: 45.714%)\n",
      "Epoch 99: 22.240 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.144 (accuracy: 57.637%), validation loss = 1.249 (accuracy: 45.714%)\n",
      "Epoch 100: 22.261 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.142 (accuracy: 58.117%), validation loss = 1.280 (accuracy: 41.905%)\n",
      "Epoch 101: 22.392 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.140 (accuracy: 57.829%), validation loss = 1.289 (accuracy: 39.048%)\n",
      "Epoch 102: 22.322 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.143 (accuracy: 56.484%), validation loss = 1.250 (accuracy: 43.810%)\n",
      "Epoch 103: 22.243 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.146 (accuracy: 58.309%), validation loss = 1.261 (accuracy: 43.810%)\n",
      "Epoch 104: 22.235 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.144 (accuracy: 58.598%), validation loss = 1.248 (accuracy: 48.571%)\n",
      "Epoch 105: 22.166 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.145 (accuracy: 57.829%), validation loss = 1.340 (accuracy: 31.429%)\n",
      "Epoch 106: 22.303 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.149 (accuracy: 57.733%), validation loss = 1.272 (accuracy: 40.000%)\n",
      "Epoch 107: 22.310 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.148 (accuracy: 58.117%), validation loss = 1.241 (accuracy: 43.810%)\n",
      "Epoch 108: 22.334 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.157 (accuracy: 56.676%), validation loss = 1.226 (accuracy: 45.714%)\n",
      "Epoch 109: 22.338 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.164 (accuracy: 57.253%), validation loss = 1.254 (accuracy: 47.619%)\n",
      "Epoch 110: 22.204 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.164 (accuracy: 57.157%), validation loss = 1.263 (accuracy: 41.905%)\n",
      "Epoch 111: 22.201 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.172 (accuracy: 57.253%), validation loss = 1.329 (accuracy: 35.238%)\n",
      "Epoch 112: 22.272 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.179 (accuracy: 56.004%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 113: 22.243 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.172 (accuracy: 55.139%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 114: 22.151 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.184 (accuracy: 55.235%), validation loss = 1.232 (accuracy: 45.714%)\n",
      "Epoch 115: 22.221 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.181 (accuracy: 56.388%), validation loss = 1.251 (accuracy: 41.905%)\n",
      "Epoch 116: 22.124 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.192 (accuracy: 54.851%), validation loss = 1.265 (accuracy: 43.810%)\n",
      "Epoch 117: 22.159 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.198 (accuracy: 53.506%), validation loss = 1.257 (accuracy: 41.905%)\n",
      "Epoch 118: 22.034 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.197 (accuracy: 52.546%), validation loss = 1.297 (accuracy: 39.048%)\n",
      "Epoch 119: 22.191 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.206 (accuracy: 51.105%), validation loss = 1.269 (accuracy: 36.190%)\n",
      "Epoch 120: 22.233 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.208 (accuracy: 50.817%), validation loss = 1.314 (accuracy: 42.857%)\n",
      "Epoch 121: 22.211 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.211 (accuracy: 46.494%), validation loss = 1.340 (accuracy: 33.333%)\n",
      "Epoch 122: 22.232 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.214 (accuracy: 42.267%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 123: 22.094 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.213 (accuracy: 43.036%), validation loss = 1.254 (accuracy: 33.333%)\n",
      "Epoch 124: 22.110 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.224 (accuracy: 40.250%), validation loss = 1.325 (accuracy: 33.333%)\n",
      "Epoch 125: 22.129 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 1.228 (accuracy: 40.154%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 126: 22.049 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.241 (accuracy: 39.673%), validation loss = 1.330 (accuracy: 33.333%)\n",
      "Epoch 127: 22.074 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.231 (accuracy: 39.481%), validation loss = 1.316 (accuracy: 33.333%)\n",
      "Epoch 128: 22.104 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.241 (accuracy: 39.481%), validation loss = 1.338 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 108 with minimum validation error = 1.2264824889955066\n",
      "18186.065 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0\n",
      "Epoch 1: 22.295 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.384 (accuracy: 26.129%), validation loss = 1.353 (accuracy: 29.524%)\n",
      "Epoch 2: 22.607 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.343 (accuracy: 31.796%), validation loss = 1.330 (accuracy: 35.238%)\n",
      "Epoch 3: 22.449 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.322 (accuracy: 34.678%), validation loss = 1.318 (accuracy: 35.238%)\n",
      "Epoch 4: 22.529 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.304 (accuracy: 39.673%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 5: 22.568 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.294 (accuracy: 38.809%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 6: 22.862 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.282 (accuracy: 40.154%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 7: 22.637 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.282 (accuracy: 38.713%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 8: 22.637 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.285 (accuracy: 39.866%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 9: 22.584 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.271 (accuracy: 39.769%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 10: 22.618 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.271 (accuracy: 40.154%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 11: 22.524 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.268 (accuracy: 40.634%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 12: 22.521 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.279 (accuracy: 40.250%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 13: 22.608 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.273 (accuracy: 41.979%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 14: 22.621 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.267 (accuracy: 41.787%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 15: 22.569 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.263 (accuracy: 41.306%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 16: 22.637 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.260 (accuracy: 40.058%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 17: 22.599 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.254 (accuracy: 41.018%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 18: 22.624 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.271 (accuracy: 40.730%), validation loss = 1.269 (accuracy: 33.333%)\n",
      "Epoch 19: 22.754 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.255 (accuracy: 40.634%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 20: 22.812 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.255 (accuracy: 41.114%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 21: 22.740 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.251 (accuracy: 41.018%), validation loss = 1.262 (accuracy: 34.286%)\n",
      "Epoch 22: 22.674 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.252 (accuracy: 41.883%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 23: 22.616 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.250 (accuracy: 42.075%), validation loss = 1.259 (accuracy: 34.286%)\n",
      "Epoch 24: 22.621 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.247 (accuracy: 41.306%), validation loss = 1.255 (accuracy: 34.286%)\n",
      "Epoch 25: 22.661 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.248 (accuracy: 41.691%), validation loss = 1.253 (accuracy: 34.286%)\n",
      "Epoch 26: 22.641 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.232 (accuracy: 43.612%), validation loss = 1.251 (accuracy: 34.286%)\n",
      "Epoch 27: 22.631 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.241 (accuracy: 41.306%), validation loss = 1.249 (accuracy: 35.238%)\n",
      "Epoch 28: 22.556 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.240 (accuracy: 39.866%), validation loss = 1.246 (accuracy: 35.238%)\n",
      "Epoch 29: 22.671 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.233 (accuracy: 43.036%), validation loss = 1.244 (accuracy: 35.238%)\n",
      "Epoch 30: 22.578 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.232 (accuracy: 42.555%), validation loss = 1.242 (accuracy: 35.238%)\n",
      "Epoch 31: 22.583 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.233 (accuracy: 42.075%), validation loss = 1.240 (accuracy: 37.143%)\n",
      "Epoch 32: 22.593 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.230 (accuracy: 42.555%), validation loss = 1.237 (accuracy: 37.143%)\n",
      "Epoch 33: 22.772 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.228 (accuracy: 42.651%), validation loss = 1.234 (accuracy: 37.143%)\n",
      "Epoch 34: 22.590 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.227 (accuracy: 43.612%), validation loss = 1.234 (accuracy: 37.143%)\n",
      "Epoch 35: 22.588 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.222 (accuracy: 42.747%), validation loss = 1.229 (accuracy: 38.095%)\n",
      "Epoch 36: 22.763 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.224 (accuracy: 42.843%), validation loss = 1.228 (accuracy: 38.095%)\n",
      "Epoch 37: 22.882 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.222 (accuracy: 43.900%), validation loss = 1.225 (accuracy: 38.095%)\n",
      "Epoch 38: 22.574 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.213 (accuracy: 44.861%), validation loss = 1.219 (accuracy: 38.095%)\n",
      "Epoch 39: 22.579 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.212 (accuracy: 44.957%), validation loss = 1.218 (accuracy: 37.143%)\n",
      "Epoch 40: 22.633 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.209 (accuracy: 45.245%), validation loss = 1.215 (accuracy: 37.143%)\n",
      "Epoch 41: 22.568 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.203 (accuracy: 45.725%), validation loss = 1.212 (accuracy: 36.190%)\n",
      "Epoch 42: 22.663 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.199 (accuracy: 45.245%), validation loss = 1.208 (accuracy: 37.143%)\n",
      "Epoch 43: 22.636 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.197 (accuracy: 48.223%), validation loss = 1.207 (accuracy: 37.143%)\n",
      "Epoch 44: 22.536 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.193 (accuracy: 47.166%), validation loss = 1.206 (accuracy: 36.190%)\n",
      "Epoch 45: 22.613 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.193 (accuracy: 46.974%), validation loss = 1.203 (accuracy: 37.143%)\n",
      "Epoch 46: 22.691 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.194 (accuracy: 45.629%), validation loss = 1.199 (accuracy: 38.095%)\n",
      "Epoch 47: 22.784 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.196 (accuracy: 45.341%), validation loss = 1.195 (accuracy: 40.952%)\n",
      "Epoch 48: 22.661 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.185 (accuracy: 47.262%), validation loss = 1.190 (accuracy: 41.905%)\n",
      "Epoch 49: 22.694 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.178 (accuracy: 49.087%), validation loss = 1.189 (accuracy: 40.000%)\n",
      "Epoch 50: 22.618 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.174 (accuracy: 48.223%), validation loss = 1.184 (accuracy: 42.857%)\n",
      "Epoch 51: 22.636 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.175 (accuracy: 47.550%), validation loss = 1.182 (accuracy: 42.857%)\n",
      "Epoch 52: 22.591 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.175 (accuracy: 48.895%), validation loss = 1.178 (accuracy: 41.905%)\n",
      "Epoch 53: 22.761 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.167 (accuracy: 48.607%), validation loss = 1.175 (accuracy: 43.810%)\n",
      "Epoch 54: 22.596 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.173 (accuracy: 48.991%), validation loss = 1.171 (accuracy: 46.667%)\n",
      "Epoch 55: 22.615 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.159 (accuracy: 51.777%), validation loss = 1.169 (accuracy: 45.714%)\n",
      "Epoch 56: 22.621 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.152 (accuracy: 52.738%), validation loss = 1.165 (accuracy: 46.667%)\n",
      "Epoch 57: 22.549 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.149 (accuracy: 52.930%), validation loss = 1.159 (accuracy: 47.619%)\n",
      "Epoch 58: 22.636 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.150 (accuracy: 51.585%), validation loss = 1.156 (accuracy: 50.476%)\n",
      "Epoch 59: 22.644 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.144 (accuracy: 52.354%), validation loss = 1.150 (accuracy: 49.524%)\n",
      "Epoch 60: 23.004 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.147 (accuracy: 50.528%), validation loss = 1.146 (accuracy: 49.524%)\n",
      "Epoch 61: 22.676 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.133 (accuracy: 51.777%), validation loss = 1.144 (accuracy: 50.476%)\n",
      "Epoch 62: 22.614 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.135 (accuracy: 52.546%), validation loss = 1.140 (accuracy: 50.476%)\n",
      "Epoch 63: 22.678 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.123 (accuracy: 53.506%), validation loss = 1.135 (accuracy: 51.429%)\n",
      "Epoch 64: 22.587 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.124 (accuracy: 53.314%), validation loss = 1.131 (accuracy: 48.571%)\n",
      "Epoch 65: 22.719 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.113 (accuracy: 54.947%), validation loss = 1.128 (accuracy: 49.524%)\n",
      "Epoch 66: 22.773 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.106 (accuracy: 56.676%), validation loss = 1.122 (accuracy: 49.524%)\n",
      "Epoch 67: 22.813 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.114 (accuracy: 53.026%), validation loss = 1.118 (accuracy: 49.524%)\n",
      "Epoch 68: 22.716 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.103 (accuracy: 54.755%), validation loss = 1.116 (accuracy: 50.476%)\n",
      "Epoch 69: 22.563 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.098 (accuracy: 55.908%), validation loss = 1.109 (accuracy: 49.524%)\n",
      "Epoch 70: 22.634 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.097 (accuracy: 55.427%), validation loss = 1.105 (accuracy: 50.476%)\n",
      "Epoch 71: 22.621 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.094 (accuracy: 54.371%), validation loss = 1.099 (accuracy: 51.429%)\n",
      "Epoch 72: 22.619 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.078 (accuracy: 58.117%), validation loss = 1.096 (accuracy: 51.429%)\n",
      "Epoch 73: 22.754 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.079 (accuracy: 54.851%), validation loss = 1.091 (accuracy: 51.429%)\n",
      "Epoch 74: 22.756 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.064 (accuracy: 59.366%), validation loss = 1.087 (accuracy: 52.381%)\n",
      "Epoch 75: 22.722 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.058 (accuracy: 57.925%), validation loss = 1.080 (accuracy: 53.333%)\n",
      "Epoch 76: 22.710 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.075 (accuracy: 56.964%), validation loss = 1.076 (accuracy: 53.333%)\n",
      "Epoch 77: 22.604 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.067 (accuracy: 57.157%), validation loss = 1.072 (accuracy: 52.381%)\n",
      "Epoch 78: 22.585 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.054 (accuracy: 57.733%), validation loss = 1.067 (accuracy: 52.381%)\n",
      "Epoch 79: 22.675 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.045 (accuracy: 57.061%), validation loss = 1.060 (accuracy: 52.381%)\n",
      "Epoch 80: 22.650 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.047 (accuracy: 58.598%), validation loss = 1.054 (accuracy: 54.286%)\n",
      "Epoch 81: 22.618 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.038 (accuracy: 60.711%), validation loss = 1.049 (accuracy: 55.238%)\n",
      "Epoch 82: 22.624 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.038 (accuracy: 59.174%), validation loss = 1.040 (accuracy: 55.238%)\n",
      "Epoch 83: 22.575 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.032 (accuracy: 58.790%), validation loss = 1.039 (accuracy: 53.333%)\n",
      "Epoch 84: 22.627 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.027 (accuracy: 60.615%), validation loss = 1.036 (accuracy: 55.238%)\n",
      "Epoch 85: 22.649 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.015 (accuracy: 60.615%), validation loss = 1.028 (accuracy: 55.238%)\n",
      "Epoch 86: 22.622 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.998 (accuracy: 61.191%), validation loss = 1.023 (accuracy: 54.286%)\n",
      "Epoch 87: 22.980 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.992 (accuracy: 61.095%), validation loss = 1.024 (accuracy: 56.190%)\n",
      "Epoch 88: 22.424 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.996 (accuracy: 59.846%), validation loss = 1.019 (accuracy: 55.238%)\n",
      "Epoch 89: 22.573 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.989 (accuracy: 60.903%), validation loss = 1.008 (accuracy: 57.143%)\n",
      "Epoch 90: 22.500 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.979 (accuracy: 62.440%), validation loss = 1.004 (accuracy: 55.238%)\n",
      "Epoch 91: 22.341 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.968 (accuracy: 62.536%), validation loss = 0.997 (accuracy: 56.190%)\n",
      "Epoch 92: 22.351 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.975 (accuracy: 61.671%), validation loss = 0.996 (accuracy: 59.048%)\n",
      "Epoch 93: 22.560 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.968 (accuracy: 63.208%), validation loss = 0.986 (accuracy: 56.190%)\n",
      "Epoch 94: 22.204 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.953 (accuracy: 62.920%), validation loss = 0.983 (accuracy: 57.143%)\n",
      "Epoch 95: 22.222 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.944 (accuracy: 64.649%), validation loss = 0.974 (accuracy: 56.190%)\n",
      "Epoch 96: 22.234 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 0.952 (accuracy: 62.152%), validation loss = 0.970 (accuracy: 57.143%)\n",
      "Epoch 97: 22.220 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 0.935 (accuracy: 63.881%), validation loss = 0.967 (accuracy: 59.048%)\n",
      "Epoch 98: 22.107 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.921 (accuracy: 64.361%), validation loss = 0.959 (accuracy: 59.048%)\n",
      "Epoch 99: 22.196 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.926 (accuracy: 63.689%), validation loss = 0.958 (accuracy: 58.095%)\n",
      "Epoch 100: 22.165 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.905 (accuracy: 65.802%), validation loss = 0.951 (accuracy: 58.095%)\n",
      "Epoch 101: 22.213 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.909 (accuracy: 65.130%), validation loss = 0.946 (accuracy: 59.048%)\n",
      "Epoch 102: 22.154 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.906 (accuracy: 63.689%), validation loss = 0.939 (accuracy: 58.095%)\n",
      "Epoch 103: 22.182 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.914 (accuracy: 62.152%), validation loss = 0.935 (accuracy: 62.857%)\n",
      "Epoch 104: 21.962 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.884 (accuracy: 66.282%), validation loss = 0.924 (accuracy: 61.905%)\n",
      "Epoch 105: 21.985 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.896 (accuracy: 62.920%), validation loss = 0.923 (accuracy: 64.762%)\n",
      "Epoch 106: 21.991 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.876 (accuracy: 66.090%), validation loss = 0.917 (accuracy: 62.857%)\n",
      "Epoch 107: 22.408 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 0.852 (accuracy: 67.723%), validation loss = 0.920 (accuracy: 60.000%)\n",
      "Epoch 108: 21.838 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.866 (accuracy: 65.898%), validation loss = 0.910 (accuracy: 64.762%)\n",
      "Epoch 109: 22.004 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.867 (accuracy: 67.915%), validation loss = 0.906 (accuracy: 60.952%)\n",
      "Epoch 110: 22.105 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.865 (accuracy: 66.090%), validation loss = 0.900 (accuracy: 62.857%)\n",
      "Epoch 111: 22.001 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.838 (accuracy: 66.667%), validation loss = 0.895 (accuracy: 62.857%)\n",
      "Epoch 112: 21.971 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.847 (accuracy: 68.396%), validation loss = 0.885 (accuracy: 67.619%)\n",
      "Epoch 113: 21.987 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.830 (accuracy: 68.108%), validation loss = 0.883 (accuracy: 65.714%)\n",
      "Epoch 114: 22.198 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.834 (accuracy: 65.514%), validation loss = 0.877 (accuracy: 63.810%)\n",
      "Epoch 115: 22.182 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.828 (accuracy: 66.859%), validation loss = 0.872 (accuracy: 67.619%)\n",
      "Epoch 116: 22.100 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.802 (accuracy: 69.260%), validation loss = 0.869 (accuracy: 63.810%)\n",
      "Epoch 117: 22.080 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.826 (accuracy: 67.339%), validation loss = 0.859 (accuracy: 67.619%)\n",
      "Epoch 118: 22.079 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.795 (accuracy: 68.684%), validation loss = 0.858 (accuracy: 64.762%)\n",
      "Epoch 119: 22.003 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 0.809 (accuracy: 68.492%), validation loss = 0.854 (accuracy: 67.619%)\n",
      "Epoch 120: 22.023 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.795 (accuracy: 68.012%), validation loss = 0.850 (accuracy: 65.714%)\n",
      "Epoch 121: 22.069 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.773 (accuracy: 70.509%), validation loss = 0.847 (accuracy: 64.762%)\n",
      "Epoch 122: 21.982 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.775 (accuracy: 70.701%), validation loss = 0.846 (accuracy: 65.714%)\n",
      "Epoch 123: 22.124 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.766 (accuracy: 71.085%), validation loss = 0.843 (accuracy: 67.619%)\n",
      "Epoch 124: 22.057 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.759 (accuracy: 70.509%), validation loss = 0.829 (accuracy: 68.571%)\n",
      "Epoch 125: 22.091 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.742 (accuracy: 72.142%), validation loss = 0.826 (accuracy: 67.619%)\n",
      "Epoch 126: 21.899 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.761 (accuracy: 70.989%), validation loss = 0.829 (accuracy: 66.667%)\n",
      "Epoch 127: 21.974 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.752 (accuracy: 71.566%), validation loss = 0.819 (accuracy: 67.619%)\n",
      "Epoch 128: 22.111 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.753 (accuracy: 70.797%), validation loss = 0.820 (accuracy: 64.762%)\n",
      "Epoch 129: 21.946 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.750 (accuracy: 70.893%), validation loss = 0.812 (accuracy: 68.571%)\n",
      "Epoch 130: 22.044 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.719 (accuracy: 74.448%), validation loss = 0.809 (accuracy: 68.571%)\n",
      "Epoch 131: 22.050 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.733 (accuracy: 71.854%), validation loss = 0.807 (accuracy: 68.571%)\n",
      "Epoch 132: 22.079 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.702 (accuracy: 74.352%), validation loss = 0.801 (accuracy: 68.571%)\n",
      "Epoch 133: 21.964 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.691 (accuracy: 73.487%), validation loss = 0.800 (accuracy: 66.667%)\n",
      "Epoch 134: 22.029 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.708 (accuracy: 73.679%), validation loss = 0.793 (accuracy: 68.571%)\n",
      "Epoch 135: 22.017 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.700 (accuracy: 72.911%), validation loss = 0.792 (accuracy: 68.571%)\n",
      "Epoch 136: 21.885 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.698 (accuracy: 73.007%), validation loss = 0.791 (accuracy: 68.571%)\n",
      "Epoch 137: 21.920 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.673 (accuracy: 74.544%), validation loss = 0.782 (accuracy: 69.524%)\n",
      "Epoch 138: 21.960 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.687 (accuracy: 73.967%), validation loss = 0.777 (accuracy: 70.476%)\n",
      "Epoch 139: 21.927 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.692 (accuracy: 73.103%), validation loss = 0.778 (accuracy: 70.476%)\n",
      "Epoch 140: 21.813 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.666 (accuracy: 74.736%), validation loss = 0.781 (accuracy: 70.476%)\n",
      "Epoch 141: 21.862 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.681 (accuracy: 74.352%), validation loss = 0.771 (accuracy: 69.524%)\n",
      "Epoch 142: 22.025 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.645 (accuracy: 75.985%), validation loss = 0.769 (accuracy: 70.476%)\n",
      "Epoch 143: 22.312 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.665 (accuracy: 74.063%), validation loss = 0.766 (accuracy: 68.571%)\n",
      "Epoch 144: 22.370 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.659 (accuracy: 73.967%), validation loss = 0.760 (accuracy: 69.524%)\n",
      "Epoch 145: 22.219 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.660 (accuracy: 73.967%), validation loss = 0.759 (accuracy: 68.571%)\n",
      "Epoch 146: 22.115 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.615 (accuracy: 76.945%), validation loss = 0.746 (accuracy: 71.429%)\n",
      "Epoch 147: 22.316 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.660 (accuracy: 73.103%), validation loss = 0.748 (accuracy: 70.476%)\n",
      "Epoch 148: 21.957 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.632 (accuracy: 75.889%), validation loss = 0.745 (accuracy: 72.381%)\n",
      "Epoch 149: 21.977 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.619 (accuracy: 77.329%), validation loss = 0.753 (accuracy: 71.429%)\n",
      "Epoch 150: 21.878 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.618 (accuracy: 77.810%), validation loss = 0.744 (accuracy: 69.524%)\n",
      "Epoch 151: 22.102 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.618 (accuracy: 76.945%), validation loss = 0.753 (accuracy: 68.571%)\n",
      "Epoch 152: 21.758 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.596 (accuracy: 79.347%), validation loss = 0.737 (accuracy: 72.381%)\n",
      "Epoch 153: 21.836 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.595 (accuracy: 78.290%), validation loss = 0.732 (accuracy: 71.429%)\n",
      "Epoch 154: 21.805 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.601 (accuracy: 77.906%), validation loss = 0.736 (accuracy: 70.476%)\n",
      "Epoch 155: 21.753 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.592 (accuracy: 77.137%), validation loss = 0.737 (accuracy: 72.381%)\n",
      "Epoch 156: 21.807 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.574 (accuracy: 79.059%), validation loss = 0.725 (accuracy: 71.429%)\n",
      "Epoch 157: 22.005 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 0.559 (accuracy: 78.963%), validation loss = 0.724 (accuracy: 71.429%)\n",
      "Epoch 158: 21.934 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 0.549 (accuracy: 80.403%), validation loss = 0.736 (accuracy: 71.429%)\n",
      "Epoch 159: 21.742 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 0.594 (accuracy: 77.137%), validation loss = 0.731 (accuracy: 71.429%)\n",
      "Epoch 160: 21.627 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 0.583 (accuracy: 77.618%), validation loss = 0.716 (accuracy: 73.333%)\n",
      "Epoch 161: 21.815 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 0.571 (accuracy: 78.482%), validation loss = 0.714 (accuracy: 74.286%)\n",
      "Epoch 162: 21.931 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 0.562 (accuracy: 78.482%), validation loss = 0.704 (accuracy: 71.429%)\n",
      "Epoch 163: 21.808 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 0.554 (accuracy: 78.386%), validation loss = 0.706 (accuracy: 71.429%)\n",
      "Epoch 164: 21.892 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 0.552 (accuracy: 79.347%), validation loss = 0.709 (accuracy: 70.476%)\n",
      "Epoch 165: 21.804 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 0.511 (accuracy: 81.940%), validation loss = 0.698 (accuracy: 72.381%)\n",
      "Epoch 166: 22.108 seconds elapsed in epoch.\n",
      "Epoch 166: training loss = 0.518 (accuracy: 81.364%), validation loss = 0.691 (accuracy: 72.381%)\n",
      "Epoch 167: 21.900 seconds elapsed in epoch.\n",
      "Epoch 167: training loss = 0.524 (accuracy: 82.229%), validation loss = 0.706 (accuracy: 72.381%)\n",
      "Epoch 168: 21.829 seconds elapsed in epoch.\n",
      "Epoch 168: training loss = 0.504 (accuracy: 81.748%), validation loss = 0.694 (accuracy: 72.381%)\n",
      "Epoch 169: 21.843 seconds elapsed in epoch.\n",
      "Epoch 169: training loss = 0.500 (accuracy: 81.844%), validation loss = 0.681 (accuracy: 72.381%)\n",
      "Epoch 170: 21.985 seconds elapsed in epoch.\n",
      "Epoch 170: training loss = 0.515 (accuracy: 81.652%), validation loss = 0.689 (accuracy: 70.476%)\n",
      "Epoch 171: 21.740 seconds elapsed in epoch.\n",
      "Epoch 171: training loss = 0.507 (accuracy: 82.421%), validation loss = 0.685 (accuracy: 69.524%)\n",
      "Epoch 172: 21.805 seconds elapsed in epoch.\n",
      "Epoch 172: training loss = 0.503 (accuracy: 81.172%), validation loss = 0.684 (accuracy: 72.381%)\n",
      "Epoch 173: 21.721 seconds elapsed in epoch.\n",
      "Epoch 173: training loss = 0.485 (accuracy: 83.477%), validation loss = 0.680 (accuracy: 72.381%)\n",
      "Epoch 174: 21.867 seconds elapsed in epoch.\n",
      "Epoch 174: training loss = 0.509 (accuracy: 81.364%), validation loss = 0.678 (accuracy: 73.333%)\n",
      "Epoch 175: 21.959 seconds elapsed in epoch.\n",
      "Epoch 175: training loss = 0.486 (accuracy: 82.805%), validation loss = 0.680 (accuracy: 70.476%)\n",
      "Epoch 176: 21.664 seconds elapsed in epoch.\n",
      "Epoch 176: training loss = 0.465 (accuracy: 83.862%), validation loss = 0.669 (accuracy: 75.238%)\n",
      "Epoch 177: 21.812 seconds elapsed in epoch.\n",
      "Epoch 177: training loss = 0.466 (accuracy: 84.438%), validation loss = 0.670 (accuracy: 76.190%)\n",
      "Epoch 178: 21.712 seconds elapsed in epoch.\n",
      "Epoch 178: training loss = 0.471 (accuracy: 83.189%), validation loss = 0.664 (accuracy: 72.381%)\n",
      "Epoch 179: 21.849 seconds elapsed in epoch.\n",
      "Epoch 179: training loss = 0.482 (accuracy: 83.285%), validation loss = 0.656 (accuracy: 73.333%)\n",
      "Epoch 180: 21.853 seconds elapsed in epoch.\n",
      "Epoch 180: training loss = 0.455 (accuracy: 84.246%), validation loss = 0.660 (accuracy: 73.333%)\n",
      "Epoch 181: 21.599 seconds elapsed in epoch.\n",
      "Epoch 181: training loss = 0.452 (accuracy: 84.438%), validation loss = 0.659 (accuracy: 73.333%)\n",
      "Epoch 182: 21.800 seconds elapsed in epoch.\n",
      "Epoch 182: training loss = 0.467 (accuracy: 82.325%), validation loss = 0.654 (accuracy: 74.286%)\n",
      "Epoch 183: 22.070 seconds elapsed in epoch.\n",
      "Epoch 183: training loss = 0.434 (accuracy: 85.110%), validation loss = 0.660 (accuracy: 75.238%)\n",
      "Epoch 184: 21.960 seconds elapsed in epoch.\n",
      "Epoch 184: training loss = 0.450 (accuracy: 84.726%), validation loss = 0.654 (accuracy: 74.286%)\n",
      "Epoch 185: 21.879 seconds elapsed in epoch.\n",
      "Epoch 185: training loss = 0.447 (accuracy: 84.438%), validation loss = 0.660 (accuracy: 72.381%)\n",
      "Epoch 186: 21.761 seconds elapsed in epoch.\n",
      "Epoch 186: training loss = 0.420 (accuracy: 86.359%), validation loss = 0.645 (accuracy: 76.190%)\n",
      "Epoch 187: 21.972 seconds elapsed in epoch.\n",
      "Epoch 187: training loss = 0.448 (accuracy: 83.862%), validation loss = 0.640 (accuracy: 74.286%)\n",
      "Epoch 188: 21.937 seconds elapsed in epoch.\n",
      "Epoch 188: training loss = 0.428 (accuracy: 84.630%), validation loss = 0.645 (accuracy: 76.190%)\n",
      "Epoch 189: 21.725 seconds elapsed in epoch.\n",
      "Epoch 189: training loss = 0.410 (accuracy: 85.783%), validation loss = 0.639 (accuracy: 76.190%)\n",
      "Epoch 190: 22.080 seconds elapsed in epoch.\n",
      "Epoch 190: training loss = 0.420 (accuracy: 84.438%), validation loss = 0.635 (accuracy: 78.095%)\n",
      "Epoch 191: 21.951 seconds elapsed in epoch.\n",
      "Epoch 191: training loss = 0.403 (accuracy: 87.608%), validation loss = 0.658 (accuracy: 71.429%)\n",
      "Epoch 192: 21.712 seconds elapsed in epoch.\n",
      "Epoch 192: training loss = 0.390 (accuracy: 86.936%), validation loss = 0.640 (accuracy: 74.286%)\n",
      "Epoch 193: 21.797 seconds elapsed in epoch.\n",
      "Epoch 193: training loss = 0.396 (accuracy: 85.975%), validation loss = 0.642 (accuracy: 74.286%)\n",
      "Epoch 194: 21.881 seconds elapsed in epoch.\n",
      "Epoch 194: training loss = 0.390 (accuracy: 86.071%), validation loss = 0.633 (accuracy: 76.190%)\n",
      "Epoch 195: 21.910 seconds elapsed in epoch.\n",
      "Epoch 195: training loss = 0.412 (accuracy: 84.918%), validation loss = 0.644 (accuracy: 74.286%)\n",
      "Epoch 196: 21.807 seconds elapsed in epoch.\n",
      "Epoch 196: training loss = 0.409 (accuracy: 85.687%), validation loss = 0.644 (accuracy: 75.238%)\n",
      "Epoch 197: 21.835 seconds elapsed in epoch.\n",
      "Epoch 197: training loss = 0.364 (accuracy: 88.184%), validation loss = 0.629 (accuracy: 76.190%)\n",
      "Epoch 198: 22.123 seconds elapsed in epoch.\n",
      "Epoch 198: training loss = 0.366 (accuracy: 88.377%), validation loss = 0.637 (accuracy: 74.286%)\n",
      "Epoch 199: 21.898 seconds elapsed in epoch.\n",
      "Epoch 199: training loss = 0.389 (accuracy: 86.263%), validation loss = 0.632 (accuracy: 75.238%)\n",
      "Epoch 200: 21.675 seconds elapsed in epoch.\n",
      "Epoch 200: training loss = 0.354 (accuracy: 88.665%), validation loss = 0.624 (accuracy: 74.286%)\n",
      "==================================================result==================================================\n",
      "the best epoch is 200 with minimum validation error = 0.624345048268636\n",
      "22710.736 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.1\n",
      "Epoch 1: 21.977 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.369 (accuracy: 28.530%), validation loss = 1.337 (accuracy: 33.333%)\n",
      "Epoch 2: 21.870 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.341 (accuracy: 31.892%), validation loss = 1.319 (accuracy: 36.190%)\n",
      "Epoch 3: 21.895 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.316 (accuracy: 36.695%), validation loss = 1.311 (accuracy: 34.286%)\n",
      "Epoch 4: 21.955 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.302 (accuracy: 37.272%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 5: 21.945 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.292 (accuracy: 37.848%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 6: 21.927 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.286 (accuracy: 39.481%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 7: 22.224 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.285 (accuracy: 39.193%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 8: 21.978 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.291 (accuracy: 38.905%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 9: 21.894 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.280 (accuracy: 38.809%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 10: 22.022 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.271 (accuracy: 39.769%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 11: 22.019 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.271 (accuracy: 40.250%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 12: 22.136 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.267 (accuracy: 41.114%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 13: 21.928 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.270 (accuracy: 39.673%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 14: 21.935 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.266 (accuracy: 38.425%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 15: 21.919 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.276 (accuracy: 40.922%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 16: 21.934 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.263 (accuracy: 40.154%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 17: 21.863 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.268 (accuracy: 40.058%), validation loss = 1.269 (accuracy: 33.333%)\n",
      "Epoch 18: 21.914 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.253 (accuracy: 41.210%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 19: 21.944 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.259 (accuracy: 39.385%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 20: 21.969 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.259 (accuracy: 41.499%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 21: 22.125 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.250 (accuracy: 41.499%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 22: 21.883 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.250 (accuracy: 40.634%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 23: 22.026 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.248 (accuracy: 42.459%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 24: 22.021 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.244 (accuracy: 41.883%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 25: 21.963 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.242 (accuracy: 42.459%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 26: 22.126 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.246 (accuracy: 41.306%), validation loss = 1.253 (accuracy: 33.333%)\n",
      "Epoch 27: 21.956 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.248 (accuracy: 40.538%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 28: 21.864 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.244 (accuracy: 41.114%), validation loss = 1.247 (accuracy: 35.238%)\n",
      "Epoch 29: 22.015 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.236 (accuracy: 42.555%), validation loss = 1.247 (accuracy: 34.286%)\n",
      "Epoch 30: 21.804 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.233 (accuracy: 42.747%), validation loss = 1.245 (accuracy: 33.333%)\n",
      "Epoch 31: 21.867 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.234 (accuracy: 41.402%), validation loss = 1.242 (accuracy: 35.238%)\n",
      "Epoch 32: 21.952 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.230 (accuracy: 43.228%), validation loss = 1.241 (accuracy: 36.190%)\n",
      "Epoch 33: 22.005 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.230 (accuracy: 42.843%), validation loss = 1.240 (accuracy: 36.190%)\n",
      "Epoch 34: 21.922 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.234 (accuracy: 41.883%), validation loss = 1.237 (accuracy: 36.190%)\n",
      "Epoch 35: 21.897 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.227 (accuracy: 44.188%), validation loss = 1.236 (accuracy: 36.190%)\n",
      "Epoch 36: 21.835 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.225 (accuracy: 42.171%), validation loss = 1.235 (accuracy: 36.190%)\n",
      "Epoch 37: 22.031 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.221 (accuracy: 43.708%), validation loss = 1.232 (accuracy: 36.190%)\n",
      "Epoch 38: 21.808 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.221 (accuracy: 43.900%), validation loss = 1.229 (accuracy: 37.143%)\n",
      "Epoch 39: 21.871 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.222 (accuracy: 44.573%), validation loss = 1.229 (accuracy: 37.143%)\n",
      "Epoch 40: 22.050 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.217 (accuracy: 42.363%), validation loss = 1.226 (accuracy: 37.143%)\n",
      "Epoch 41: 21.864 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.216 (accuracy: 44.573%), validation loss = 1.222 (accuracy: 38.095%)\n",
      "Epoch 42: 21.879 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.214 (accuracy: 43.996%), validation loss = 1.222 (accuracy: 38.095%)\n",
      "Epoch 43: 21.776 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.214 (accuracy: 44.284%), validation loss = 1.218 (accuracy: 38.095%)\n",
      "Epoch 44: 21.900 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.209 (accuracy: 45.629%), validation loss = 1.216 (accuracy: 38.095%)\n",
      "Epoch 45: 21.816 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.204 (accuracy: 47.166%), validation loss = 1.215 (accuracy: 38.095%)\n",
      "Epoch 46: 21.853 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.210 (accuracy: 46.686%), validation loss = 1.217 (accuracy: 38.095%)\n",
      "Epoch 47: 21.804 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.208 (accuracy: 45.245%), validation loss = 1.212 (accuracy: 37.143%)\n",
      "Epoch 48: 21.968 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.203 (accuracy: 45.533%), validation loss = 1.209 (accuracy: 36.190%)\n",
      "Epoch 49: 21.916 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.197 (accuracy: 46.494%), validation loss = 1.206 (accuracy: 38.095%)\n",
      "Epoch 50: 21.935 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.192 (accuracy: 47.262%), validation loss = 1.206 (accuracy: 39.048%)\n",
      "Epoch 51: 22.051 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.193 (accuracy: 48.031%), validation loss = 1.205 (accuracy: 39.048%)\n",
      "Epoch 52: 21.840 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.193 (accuracy: 47.262%), validation loss = 1.203 (accuracy: 38.095%)\n",
      "Epoch 53: 21.969 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.195 (accuracy: 45.821%), validation loss = 1.199 (accuracy: 40.952%)\n",
      "Epoch 54: 22.138 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.176 (accuracy: 46.974%), validation loss = 1.195 (accuracy: 40.952%)\n",
      "Epoch 55: 22.105 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.179 (accuracy: 50.432%), validation loss = 1.193 (accuracy: 40.952%)\n",
      "Epoch 56: 22.053 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.182 (accuracy: 49.183%), validation loss = 1.189 (accuracy: 41.905%)\n",
      "Epoch 57: 22.031 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.177 (accuracy: 48.799%), validation loss = 1.190 (accuracy: 40.952%)\n",
      "Epoch 58: 21.794 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.167 (accuracy: 50.624%), validation loss = 1.187 (accuracy: 41.905%)\n",
      "Epoch 59: 21.983 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.177 (accuracy: 47.646%), validation loss = 1.184 (accuracy: 42.857%)\n",
      "Epoch 60: 22.219 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.168 (accuracy: 48.511%), validation loss = 1.183 (accuracy: 41.905%)\n",
      "Epoch 61: 22.331 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.164 (accuracy: 51.585%), validation loss = 1.179 (accuracy: 42.857%)\n",
      "Epoch 62: 22.657 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.164 (accuracy: 50.240%), validation loss = 1.177 (accuracy: 42.857%)\n",
      "Epoch 63: 22.829 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.152 (accuracy: 51.969%), validation loss = 1.173 (accuracy: 44.762%)\n",
      "Epoch 64: 22.705 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.148 (accuracy: 49.568%), validation loss = 1.167 (accuracy: 44.762%)\n",
      "Epoch 65: 22.557 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.155 (accuracy: 51.969%), validation loss = 1.168 (accuracy: 45.714%)\n",
      "Epoch 66: 22.605 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.162 (accuracy: 50.240%), validation loss = 1.165 (accuracy: 45.714%)\n",
      "Epoch 67: 22.895 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.149 (accuracy: 50.817%), validation loss = 1.163 (accuracy: 48.571%)\n",
      "Epoch 68: 22.897 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.144 (accuracy: 52.834%), validation loss = 1.158 (accuracy: 49.524%)\n",
      "Epoch 69: 22.696 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.143 (accuracy: 50.913%), validation loss = 1.157 (accuracy: 46.667%)\n",
      "Epoch 70: 22.554 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.139 (accuracy: 53.122%), validation loss = 1.156 (accuracy: 45.714%)\n",
      "Epoch 71: 22.699 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.141 (accuracy: 53.122%), validation loss = 1.152 (accuracy: 49.524%)\n",
      "Epoch 72: 22.652 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.137 (accuracy: 52.738%), validation loss = 1.146 (accuracy: 51.429%)\n",
      "Epoch 73: 22.627 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.121 (accuracy: 54.467%), validation loss = 1.142 (accuracy: 49.524%)\n",
      "Epoch 74: 22.692 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.120 (accuracy: 53.602%), validation loss = 1.140 (accuracy: 52.381%)\n",
      "Epoch 75: 22.508 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.120 (accuracy: 54.659%), validation loss = 1.137 (accuracy: 50.476%)\n",
      "Epoch 76: 22.737 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.113 (accuracy: 55.524%), validation loss = 1.133 (accuracy: 51.429%)\n",
      "Epoch 77: 22.565 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.114 (accuracy: 54.659%), validation loss = 1.130 (accuracy: 51.429%)\n",
      "Epoch 78: 22.730 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.108 (accuracy: 56.388%), validation loss = 1.130 (accuracy: 51.429%)\n",
      "Epoch 79: 22.680 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.114 (accuracy: 55.139%), validation loss = 1.125 (accuracy: 49.524%)\n",
      "Epoch 80: 22.564 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.100 (accuracy: 57.733%), validation loss = 1.120 (accuracy: 50.476%)\n",
      "Epoch 81: 22.861 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.105 (accuracy: 56.676%), validation loss = 1.120 (accuracy: 51.429%)\n",
      "Epoch 82: 22.742 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.092 (accuracy: 56.676%), validation loss = 1.117 (accuracy: 52.381%)\n",
      "Epoch 83: 22.659 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.082 (accuracy: 59.078%), validation loss = 1.114 (accuracy: 52.381%)\n",
      "Epoch 84: 22.629 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.080 (accuracy: 59.174%), validation loss = 1.109 (accuracy: 51.429%)\n",
      "Epoch 85: 22.560 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.078 (accuracy: 58.405%), validation loss = 1.106 (accuracy: 52.381%)\n",
      "Epoch 86: 22.713 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.070 (accuracy: 59.174%), validation loss = 1.100 (accuracy: 52.381%)\n",
      "Epoch 87: 22.697 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.071 (accuracy: 58.694%), validation loss = 1.097 (accuracy: 52.381%)\n",
      "Epoch 88: 22.536 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.062 (accuracy: 57.733%), validation loss = 1.093 (accuracy: 55.238%)\n",
      "Epoch 89: 22.602 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.057 (accuracy: 60.903%), validation loss = 1.089 (accuracy: 53.333%)\n",
      "Epoch 90: 22.551 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.056 (accuracy: 58.501%), validation loss = 1.087 (accuracy: 53.333%)\n",
      "Epoch 91: 22.747 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.043 (accuracy: 59.942%), validation loss = 1.079 (accuracy: 55.238%)\n",
      "Epoch 92: 22.655 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.047 (accuracy: 61.095%), validation loss = 1.077 (accuracy: 53.333%)\n",
      "Epoch 93: 22.579 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.039 (accuracy: 60.231%), validation loss = 1.071 (accuracy: 55.238%)\n",
      "Epoch 94: 22.724 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.043 (accuracy: 59.366%), validation loss = 1.067 (accuracy: 55.238%)\n",
      "Epoch 95: 22.812 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.038 (accuracy: 62.056%), validation loss = 1.064 (accuracy: 55.238%)\n",
      "Epoch 96: 22.620 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.032 (accuracy: 60.807%), validation loss = 1.058 (accuracy: 58.095%)\n",
      "Epoch 97: 22.632 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.020 (accuracy: 60.807%), validation loss = 1.052 (accuracy: 56.190%)\n",
      "Epoch 98: 22.625 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.015 (accuracy: 61.960%), validation loss = 1.049 (accuracy: 56.190%)\n",
      "Epoch 99: 22.697 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.014 (accuracy: 61.095%), validation loss = 1.046 (accuracy: 56.190%)\n",
      "Epoch 100: 22.481 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.006 (accuracy: 61.191%), validation loss = 1.039 (accuracy: 59.048%)\n",
      "Epoch 101: 22.774 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.010 (accuracy: 61.671%), validation loss = 1.035 (accuracy: 58.095%)\n",
      "Epoch 102: 22.638 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.989 (accuracy: 62.920%), validation loss = 1.033 (accuracy: 60.952%)\n",
      "Epoch 103: 22.668 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.987 (accuracy: 63.977%), validation loss = 1.031 (accuracy: 54.286%)\n",
      "Epoch 104: 22.761 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.982 (accuracy: 64.553%), validation loss = 1.021 (accuracy: 60.000%)\n",
      "Epoch 105: 22.647 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.987 (accuracy: 64.073%), validation loss = 1.014 (accuracy: 60.000%)\n",
      "Epoch 106: 22.685 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.971 (accuracy: 63.401%), validation loss = 1.010 (accuracy: 61.905%)\n",
      "Epoch 107: 22.619 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 0.973 (accuracy: 64.265%), validation loss = 1.007 (accuracy: 59.048%)\n",
      "Epoch 108: 22.862 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.956 (accuracy: 64.265%), validation loss = 1.002 (accuracy: 60.952%)\n",
      "Epoch 109: 22.603 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.957 (accuracy: 63.689%), validation loss = 0.997 (accuracy: 60.952%)\n",
      "Epoch 110: 22.651 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.943 (accuracy: 64.457%), validation loss = 0.990 (accuracy: 62.857%)\n",
      "Epoch 111: 22.734 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.923 (accuracy: 67.339%), validation loss = 0.988 (accuracy: 60.952%)\n",
      "Epoch 112: 22.603 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.934 (accuracy: 64.745%), validation loss = 0.981 (accuracy: 63.810%)\n",
      "Epoch 113: 22.667 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.930 (accuracy: 63.593%), validation loss = 0.975 (accuracy: 65.714%)\n",
      "Epoch 114: 22.658 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.916 (accuracy: 66.186%), validation loss = 0.973 (accuracy: 65.714%)\n",
      "Epoch 115: 22.637 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.906 (accuracy: 67.627%), validation loss = 0.967 (accuracy: 63.810%)\n",
      "Epoch 116: 22.701 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.919 (accuracy: 66.571%), validation loss = 0.961 (accuracy: 62.857%)\n",
      "Epoch 117: 22.686 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.916 (accuracy: 65.802%), validation loss = 0.955 (accuracy: 64.762%)\n",
      "Epoch 118: 22.763 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.906 (accuracy: 66.282%), validation loss = 0.955 (accuracy: 62.857%)\n",
      "Epoch 119: 22.624 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 0.898 (accuracy: 68.876%), validation loss = 0.943 (accuracy: 64.762%)\n",
      "Epoch 120: 22.688 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.892 (accuracy: 67.147%), validation loss = 0.941 (accuracy: 64.762%)\n",
      "Epoch 121: 22.741 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.886 (accuracy: 68.012%), validation loss = 0.931 (accuracy: 64.762%)\n",
      "Epoch 122: 22.853 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.879 (accuracy: 68.204%), validation loss = 0.929 (accuracy: 68.571%)\n",
      "Epoch 123: 22.626 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.869 (accuracy: 66.955%), validation loss = 0.919 (accuracy: 64.762%)\n",
      "Epoch 124: 22.701 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.871 (accuracy: 66.090%), validation loss = 0.916 (accuracy: 65.714%)\n",
      "Epoch 125: 22.727 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.861 (accuracy: 68.492%), validation loss = 0.910 (accuracy: 65.714%)\n",
      "Epoch 126: 22.665 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.858 (accuracy: 68.204%), validation loss = 0.910 (accuracy: 66.667%)\n",
      "Epoch 127: 22.597 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.849 (accuracy: 68.204%), validation loss = 0.900 (accuracy: 66.667%)\n",
      "Epoch 128: 22.604 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.840 (accuracy: 69.164%), validation loss = 0.898 (accuracy: 67.619%)\n",
      "Epoch 129: 22.645 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.827 (accuracy: 69.549%), validation loss = 0.893 (accuracy: 66.667%)\n",
      "Epoch 130: 22.715 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.809 (accuracy: 72.622%), validation loss = 0.883 (accuracy: 67.619%)\n",
      "Epoch 131: 22.695 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.827 (accuracy: 68.972%), validation loss = 0.877 (accuracy: 70.476%)\n",
      "Epoch 132: 22.738 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.819 (accuracy: 69.549%), validation loss = 0.873 (accuracy: 68.571%)\n",
      "Epoch 133: 22.668 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.811 (accuracy: 70.701%), validation loss = 0.871 (accuracy: 68.571%)\n",
      "Epoch 134: 22.643 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.805 (accuracy: 70.509%), validation loss = 0.861 (accuracy: 69.524%)\n",
      "Epoch 135: 22.827 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.786 (accuracy: 71.470%), validation loss = 0.858 (accuracy: 67.619%)\n",
      "Epoch 136: 22.658 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.790 (accuracy: 71.758%), validation loss = 0.857 (accuracy: 66.667%)\n",
      "Epoch 137: 22.587 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.785 (accuracy: 70.893%), validation loss = 0.845 (accuracy: 70.476%)\n",
      "Epoch 138: 22.613 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.766 (accuracy: 71.950%), validation loss = 0.840 (accuracy: 70.476%)\n",
      "Epoch 139: 22.664 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.765 (accuracy: 72.238%), validation loss = 0.841 (accuracy: 70.476%)\n",
      "Epoch 140: 22.502 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.767 (accuracy: 71.950%), validation loss = 0.834 (accuracy: 70.476%)\n",
      "Epoch 141: 22.638 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.771 (accuracy: 72.911%), validation loss = 0.825 (accuracy: 71.429%)\n",
      "Epoch 142: 22.714 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.755 (accuracy: 71.566%), validation loss = 0.823 (accuracy: 71.429%)\n",
      "Epoch 143: 22.643 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.732 (accuracy: 73.391%), validation loss = 0.823 (accuracy: 69.524%)\n",
      "Epoch 144: 22.631 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.737 (accuracy: 72.911%), validation loss = 0.813 (accuracy: 70.476%)\n",
      "Epoch 145: 22.705 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.733 (accuracy: 74.063%), validation loss = 0.810 (accuracy: 69.524%)\n",
      "Epoch 146: 22.843 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.735 (accuracy: 71.374%), validation loss = 0.805 (accuracy: 70.476%)\n",
      "Epoch 147: 22.724 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.712 (accuracy: 74.832%), validation loss = 0.801 (accuracy: 72.381%)\n",
      "Epoch 148: 22.816 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.695 (accuracy: 75.216%), validation loss = 0.794 (accuracy: 71.429%)\n",
      "Epoch 149: 22.969 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.705 (accuracy: 74.159%), validation loss = 0.793 (accuracy: 73.333%)\n",
      "Epoch 150: 22.724 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.692 (accuracy: 75.793%), validation loss = 0.791 (accuracy: 71.429%)\n",
      "Epoch 151: 22.720 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.693 (accuracy: 73.487%), validation loss = 0.788 (accuracy: 69.524%)\n",
      "Epoch 152: 22.664 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.699 (accuracy: 74.159%), validation loss = 0.778 (accuracy: 72.381%)\n",
      "Epoch 153: 22.719 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.685 (accuracy: 74.640%), validation loss = 0.780 (accuracy: 68.571%)\n",
      "Epoch 154: 22.583 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.672 (accuracy: 75.600%), validation loss = 0.777 (accuracy: 69.524%)\n",
      "Epoch 155: 22.694 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.673 (accuracy: 76.657%), validation loss = 0.772 (accuracy: 68.571%)\n",
      "Epoch 156: 22.768 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.669 (accuracy: 75.408%), validation loss = 0.769 (accuracy: 69.524%)\n",
      "Epoch 157: 22.730 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 0.652 (accuracy: 77.329%), validation loss = 0.762 (accuracy: 69.524%)\n",
      "Epoch 158: 22.556 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 0.658 (accuracy: 76.273%), validation loss = 0.764 (accuracy: 70.476%)\n",
      "Epoch 159: 22.546 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 0.641 (accuracy: 75.696%), validation loss = 0.759 (accuracy: 69.524%)\n",
      "Epoch 160: 22.707 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 0.660 (accuracy: 76.273%), validation loss = 0.760 (accuracy: 70.476%)\n",
      "Epoch 161: 22.506 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 0.641 (accuracy: 76.945%), validation loss = 0.756 (accuracy: 71.429%)\n",
      "Epoch 162: 22.842 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 0.626 (accuracy: 76.081%), validation loss = 0.747 (accuracy: 68.571%)\n",
      "Epoch 163: 22.760 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 0.616 (accuracy: 78.386%), validation loss = 0.743 (accuracy: 71.429%)\n",
      "Epoch 164: 22.627 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 0.614 (accuracy: 77.233%), validation loss = 0.746 (accuracy: 71.429%)\n",
      "Epoch 165: 22.496 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 0.615 (accuracy: 77.522%), validation loss = 0.751 (accuracy: 70.476%)\n",
      "Epoch 166: 22.585 seconds elapsed in epoch.\n",
      "Epoch 166: training loss = 0.607 (accuracy: 78.963%), validation loss = 0.737 (accuracy: 67.619%)\n",
      "Epoch 167: 22.807 seconds elapsed in epoch.\n",
      "Epoch 167: training loss = 0.593 (accuracy: 79.443%), validation loss = 0.734 (accuracy: 71.429%)\n",
      "Epoch 168: 22.722 seconds elapsed in epoch.\n",
      "Epoch 168: training loss = 0.594 (accuracy: 80.211%), validation loss = 0.732 (accuracy: 70.476%)\n",
      "Epoch 169: 22.770 seconds elapsed in epoch.\n",
      "Epoch 169: training loss = 0.573 (accuracy: 79.539%), validation loss = 0.727 (accuracy: 69.524%)\n",
      "Epoch 170: 22.781 seconds elapsed in epoch.\n",
      "Epoch 170: training loss = 0.574 (accuracy: 80.019%), validation loss = 0.723 (accuracy: 69.524%)\n",
      "Epoch 171: 22.746 seconds elapsed in epoch.\n",
      "Epoch 171: training loss = 0.572 (accuracy: 80.500%), validation loss = 0.713 (accuracy: 69.524%)\n",
      "Epoch 172: 22.702 seconds elapsed in epoch.\n",
      "Epoch 172: training loss = 0.553 (accuracy: 80.211%), validation loss = 0.715 (accuracy: 71.429%)\n",
      "Epoch 173: 22.562 seconds elapsed in epoch.\n",
      "Epoch 173: training loss = 0.543 (accuracy: 81.652%), validation loss = 0.707 (accuracy: 70.476%)\n",
      "Epoch 174: 22.743 seconds elapsed in epoch.\n",
      "Epoch 174: training loss = 0.554 (accuracy: 79.923%), validation loss = 0.705 (accuracy: 71.429%)\n",
      "Epoch 175: 22.751 seconds elapsed in epoch.\n",
      "Epoch 175: training loss = 0.532 (accuracy: 82.805%), validation loss = 0.705 (accuracy: 71.429%)\n",
      "Epoch 176: 22.704 seconds elapsed in epoch.\n",
      "Epoch 176: training loss = 0.548 (accuracy: 81.460%), validation loss = 0.704 (accuracy: 69.524%)\n",
      "Epoch 177: 22.798 seconds elapsed in epoch.\n",
      "Epoch 177: training loss = 0.548 (accuracy: 79.251%), validation loss = 0.691 (accuracy: 71.429%)\n",
      "Epoch 178: 22.633 seconds elapsed in epoch.\n",
      "Epoch 178: training loss = 0.546 (accuracy: 81.172%), validation loss = 0.693 (accuracy: 71.429%)\n",
      "Epoch 179: 22.650 seconds elapsed in epoch.\n",
      "Epoch 179: training loss = 0.532 (accuracy: 81.940%), validation loss = 0.694 (accuracy: 70.476%)\n",
      "Epoch 180: 22.529 seconds elapsed in epoch.\n",
      "Epoch 180: training loss = 0.521 (accuracy: 82.613%), validation loss = 0.677 (accuracy: 73.333%)\n",
      "Epoch 181: 22.640 seconds elapsed in epoch.\n",
      "Epoch 181: training loss = 0.519 (accuracy: 82.229%), validation loss = 0.686 (accuracy: 70.476%)\n",
      "Epoch 182: 22.559 seconds elapsed in epoch.\n",
      "Epoch 182: training loss = 0.513 (accuracy: 83.189%), validation loss = 0.677 (accuracy: 72.381%)\n",
      "Epoch 183: 22.727 seconds elapsed in epoch.\n",
      "Epoch 183: training loss = 0.513 (accuracy: 82.613%), validation loss = 0.674 (accuracy: 71.429%)\n",
      "Epoch 184: 23.058 seconds elapsed in epoch.\n",
      "Epoch 184: training loss = 0.506 (accuracy: 82.709%), validation loss = 0.676 (accuracy: 70.476%)\n",
      "Epoch 185: 22.712 seconds elapsed in epoch.\n",
      "Epoch 185: training loss = 0.496 (accuracy: 83.477%), validation loss = 0.668 (accuracy: 71.429%)\n",
      "Epoch 186: 22.803 seconds elapsed in epoch.\n",
      "Epoch 186: training loss = 0.488 (accuracy: 82.133%), validation loss = 0.671 (accuracy: 75.238%)\n",
      "Epoch 187: 22.523 seconds elapsed in epoch.\n",
      "Epoch 187: training loss = 0.483 (accuracy: 84.246%), validation loss = 0.660 (accuracy: 73.333%)\n",
      "Epoch 188: 22.697 seconds elapsed in epoch.\n",
      "Epoch 188: training loss = 0.483 (accuracy: 83.285%), validation loss = 0.658 (accuracy: 75.238%)\n",
      "Epoch 189: 22.985 seconds elapsed in epoch.\n",
      "Epoch 189: training loss = 0.464 (accuracy: 84.534%), validation loss = 0.667 (accuracy: 71.429%)\n",
      "Epoch 190: 22.553 seconds elapsed in epoch.\n",
      "Epoch 190: training loss = 0.472 (accuracy: 83.862%), validation loss = 0.657 (accuracy: 75.238%)\n",
      "Epoch 191: 22.704 seconds elapsed in epoch.\n",
      "Epoch 191: training loss = 0.473 (accuracy: 84.150%), validation loss = 0.660 (accuracy: 75.238%)\n",
      "Epoch 192: 22.565 seconds elapsed in epoch.\n",
      "Epoch 192: training loss = 0.469 (accuracy: 84.438%), validation loss = 0.650 (accuracy: 73.333%)\n",
      "Epoch 193: 22.746 seconds elapsed in epoch.\n",
      "Epoch 193: training loss = 0.457 (accuracy: 84.822%), validation loss = 0.647 (accuracy: 77.143%)\n",
      "Epoch 194: 22.723 seconds elapsed in epoch.\n",
      "Epoch 194: training loss = 0.448 (accuracy: 85.783%), validation loss = 0.643 (accuracy: 76.190%)\n",
      "Epoch 195: 22.771 seconds elapsed in epoch.\n",
      "Epoch 195: training loss = 0.437 (accuracy: 86.551%), validation loss = 0.642 (accuracy: 77.143%)\n",
      "Epoch 196: 22.647 seconds elapsed in epoch.\n",
      "Epoch 196: training loss = 0.438 (accuracy: 86.263%), validation loss = 0.643 (accuracy: 74.286%)\n",
      "Epoch 197: 22.566 seconds elapsed in epoch.\n",
      "Epoch 197: training loss = 0.436 (accuracy: 85.591%), validation loss = 0.627 (accuracy: 76.190%)\n",
      "Epoch 198: 22.648 seconds elapsed in epoch.\n",
      "Epoch 198: training loss = 0.435 (accuracy: 85.687%), validation loss = 0.642 (accuracy: 74.286%)\n",
      "Epoch 199: 22.572 seconds elapsed in epoch.\n",
      "Epoch 199: training loss = 0.438 (accuracy: 86.071%), validation loss = 0.620 (accuracy: 75.238%)\n",
      "Epoch 200: 22.699 seconds elapsed in epoch.\n",
      "Epoch 200: training loss = 0.424 (accuracy: 86.359%), validation loss = 0.628 (accuracy: 76.190%)\n",
      "==================================================result==================================================\n",
      "the best epoch is 199 with minimum validation error = 0.6204163295882089\n",
      "27277.395 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.2\n",
      "Epoch 1: 22.520 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.346 (accuracy: 32.085%), validation loss = 1.312 (accuracy: 38.095%)\n",
      "Epoch 2: 22.845 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.324 (accuracy: 35.159%), validation loss = 1.302 (accuracy: 34.286%)\n",
      "Epoch 3: 22.772 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.315 (accuracy: 39.001%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 4: 22.595 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.305 (accuracy: 38.232%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 5: 22.705 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.298 (accuracy: 40.250%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 6: 22.673 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.295 (accuracy: 37.368%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 7: 22.686 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.285 (accuracy: 39.289%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 8: 22.699 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.282 (accuracy: 40.250%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 9: 22.691 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.284 (accuracy: 38.329%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 10: 23.044 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.285 (accuracy: 39.385%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 11: 22.682 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.272 (accuracy: 40.250%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 12: 22.646 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.267 (accuracy: 40.634%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 13: 22.613 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.269 (accuracy: 40.730%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 14: 22.649 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.272 (accuracy: 39.962%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 15: 22.544 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.272 (accuracy: 40.154%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 16: 22.803 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.260 (accuracy: 41.210%), validation loss = 1.270 (accuracy: 33.333%)\n",
      "Epoch 17: 22.691 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.263 (accuracy: 40.922%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 18: 22.714 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.256 (accuracy: 40.442%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 19: 22.636 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.264 (accuracy: 40.442%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 20: 22.662 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.258 (accuracy: 40.250%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 21: 22.616 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.261 (accuracy: 40.826%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 22: 22.618 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.259 (accuracy: 40.922%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 23: 22.880 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.255 (accuracy: 41.979%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 24: 22.744 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.251 (accuracy: 40.826%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 25: 22.660 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.252 (accuracy: 40.826%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 26: 22.919 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.251 (accuracy: 40.634%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 27: 22.814 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.248 (accuracy: 41.210%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 28: 22.706 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.249 (accuracy: 40.634%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 29: 22.639 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.256 (accuracy: 40.538%), validation loss = 1.254 (accuracy: 33.333%)\n",
      "Epoch 30: 22.894 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.248 (accuracy: 41.306%), validation loss = 1.253 (accuracy: 33.333%)\n",
      "Epoch 31: 22.681 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.236 (accuracy: 41.499%), validation loss = 1.252 (accuracy: 33.333%)\n",
      "Epoch 32: 22.704 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.246 (accuracy: 41.018%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 33: 22.737 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.243 (accuracy: 41.691%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 34: 22.613 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.242 (accuracy: 42.459%), validation loss = 1.249 (accuracy: 33.333%)\n",
      "Epoch 35: 22.639 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.244 (accuracy: 40.250%), validation loss = 1.249 (accuracy: 33.333%)\n",
      "Epoch 36: 22.729 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.240 (accuracy: 42.075%), validation loss = 1.247 (accuracy: 33.333%)\n",
      "Epoch 37: 22.710 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.242 (accuracy: 41.499%), validation loss = 1.244 (accuracy: 33.333%)\n",
      "Epoch 38: 22.590 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.230 (accuracy: 41.595%), validation loss = 1.242 (accuracy: 33.333%)\n",
      "Epoch 39: 22.543 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.234 (accuracy: 41.114%), validation loss = 1.243 (accuracy: 33.333%)\n",
      "Epoch 40: 22.561 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.231 (accuracy: 40.826%), validation loss = 1.240 (accuracy: 33.333%)\n",
      "Epoch 41: 22.607 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.234 (accuracy: 42.459%), validation loss = 1.239 (accuracy: 33.333%)\n",
      "Epoch 42: 22.868 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.228 (accuracy: 41.979%), validation loss = 1.239 (accuracy: 33.333%)\n",
      "Epoch 43: 22.672 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.228 (accuracy: 41.883%), validation loss = 1.236 (accuracy: 33.333%)\n",
      "Epoch 44: 22.557 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.231 (accuracy: 43.324%), validation loss = 1.235 (accuracy: 33.333%)\n",
      "Epoch 45: 22.614 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.227 (accuracy: 42.267%), validation loss = 1.234 (accuracy: 33.333%)\n",
      "Epoch 46: 22.566 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.219 (accuracy: 43.420%), validation loss = 1.233 (accuracy: 33.333%)\n",
      "Epoch 47: 22.625 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.220 (accuracy: 42.267%), validation loss = 1.232 (accuracy: 33.333%)\n",
      "Epoch 48: 22.553 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.219 (accuracy: 43.324%), validation loss = 1.230 (accuracy: 33.333%)\n",
      "Epoch 49: 22.597 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.220 (accuracy: 42.747%), validation loss = 1.230 (accuracy: 33.333%)\n",
      "Epoch 50: 22.598 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.225 (accuracy: 42.651%), validation loss = 1.228 (accuracy: 33.333%)\n",
      "Epoch 51: 22.513 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.213 (accuracy: 42.747%), validation loss = 1.227 (accuracy: 33.333%)\n",
      "Epoch 52: 22.618 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.222 (accuracy: 42.843%), validation loss = 1.224 (accuracy: 33.333%)\n",
      "Epoch 53: 22.562 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.220 (accuracy: 43.228%), validation loss = 1.225 (accuracy: 33.333%)\n",
      "Epoch 54: 22.462 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.220 (accuracy: 43.612%), validation loss = 1.222 (accuracy: 33.333%)\n",
      "Epoch 55: 22.527 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.215 (accuracy: 44.188%), validation loss = 1.221 (accuracy: 34.286%)\n",
      "Epoch 56: 22.641 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.212 (accuracy: 42.939%), validation loss = 1.220 (accuracy: 34.286%)\n",
      "Epoch 57: 22.631 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.210 (accuracy: 46.398%), validation loss = 1.218 (accuracy: 35.238%)\n",
      "Epoch 58: 22.627 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.209 (accuracy: 44.476%), validation loss = 1.218 (accuracy: 35.238%)\n",
      "Epoch 59: 22.412 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.206 (accuracy: 44.765%), validation loss = 1.216 (accuracy: 36.190%)\n",
      "Epoch 60: 22.475 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.210 (accuracy: 44.380%), validation loss = 1.214 (accuracy: 37.143%)\n",
      "Epoch 61: 22.483 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.200 (accuracy: 44.188%), validation loss = 1.212 (accuracy: 36.190%)\n",
      "Epoch 62: 22.597 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.202 (accuracy: 44.765%), validation loss = 1.211 (accuracy: 37.143%)\n",
      "Epoch 63: 22.576 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.203 (accuracy: 44.476%), validation loss = 1.209 (accuracy: 37.143%)\n",
      "Epoch 64: 22.415 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.199 (accuracy: 45.437%), validation loss = 1.208 (accuracy: 37.143%)\n",
      "Epoch 65: 22.560 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.196 (accuracy: 46.206%), validation loss = 1.205 (accuracy: 38.095%)\n",
      "Epoch 66: 22.477 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.199 (accuracy: 45.341%), validation loss = 1.206 (accuracy: 38.095%)\n",
      "Epoch 67: 22.258 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.188 (accuracy: 46.782%), validation loss = 1.202 (accuracy: 38.095%)\n",
      "Epoch 68: 22.585 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.196 (accuracy: 46.013%), validation loss = 1.201 (accuracy: 39.048%)\n",
      "Epoch 69: 22.581 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.184 (accuracy: 46.974%), validation loss = 1.198 (accuracy: 40.000%)\n",
      "Epoch 70: 22.724 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.182 (accuracy: 47.743%), validation loss = 1.197 (accuracy: 40.000%)\n",
      "Epoch 71: 22.385 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.186 (accuracy: 46.590%), validation loss = 1.193 (accuracy: 40.952%)\n",
      "Epoch 72: 22.478 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.184 (accuracy: 46.878%), validation loss = 1.193 (accuracy: 40.952%)\n",
      "Epoch 73: 22.497 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.180 (accuracy: 48.223%), validation loss = 1.191 (accuracy: 42.857%)\n",
      "Epoch 74: 22.416 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.174 (accuracy: 47.166%), validation loss = 1.189 (accuracy: 42.857%)\n",
      "Epoch 75: 22.532 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.175 (accuracy: 49.280%), validation loss = 1.188 (accuracy: 42.857%)\n",
      "Epoch 76: 22.475 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.175 (accuracy: 48.703%), validation loss = 1.185 (accuracy: 43.810%)\n",
      "Epoch 77: 22.485 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.173 (accuracy: 47.743%), validation loss = 1.184 (accuracy: 43.810%)\n",
      "Epoch 78: 22.457 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.165 (accuracy: 50.817%), validation loss = 1.184 (accuracy: 44.762%)\n",
      "Epoch 79: 22.226 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.166 (accuracy: 50.720%), validation loss = 1.180 (accuracy: 43.810%)\n",
      "Epoch 80: 22.333 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.159 (accuracy: 49.952%), validation loss = 1.179 (accuracy: 43.810%)\n",
      "Epoch 81: 22.428 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.153 (accuracy: 51.681%), validation loss = 1.175 (accuracy: 45.714%)\n",
      "Epoch 82: 22.449 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.146 (accuracy: 52.065%), validation loss = 1.175 (accuracy: 42.857%)\n",
      "Epoch 83: 22.252 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.151 (accuracy: 50.913%), validation loss = 1.169 (accuracy: 45.714%)\n",
      "Epoch 84: 22.443 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.153 (accuracy: 51.009%), validation loss = 1.167 (accuracy: 45.714%)\n",
      "Epoch 85: 22.405 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.149 (accuracy: 51.585%), validation loss = 1.165 (accuracy: 48.571%)\n",
      "Epoch 86: 22.417 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.149 (accuracy: 51.873%), validation loss = 1.164 (accuracy: 45.714%)\n",
      "Epoch 87: 22.312 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.148 (accuracy: 52.450%), validation loss = 1.160 (accuracy: 49.524%)\n",
      "Epoch 88: 22.272 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.139 (accuracy: 52.450%), validation loss = 1.158 (accuracy: 49.524%)\n",
      "Epoch 89: 22.386 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.135 (accuracy: 51.777%), validation loss = 1.156 (accuracy: 48.571%)\n",
      "Epoch 90: 22.428 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.129 (accuracy: 53.122%), validation loss = 1.155 (accuracy: 49.524%)\n",
      "Epoch 91: 22.329 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.122 (accuracy: 54.755%), validation loss = 1.153 (accuracy: 49.524%)\n",
      "Epoch 92: 22.305 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.129 (accuracy: 54.563%), validation loss = 1.149 (accuracy: 49.524%)\n",
      "Epoch 93: 22.489 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.123 (accuracy: 55.139%), validation loss = 1.145 (accuracy: 50.476%)\n",
      "Epoch 94: 22.379 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.116 (accuracy: 55.812%), validation loss = 1.140 (accuracy: 50.476%)\n",
      "Epoch 95: 22.233 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.119 (accuracy: 54.947%), validation loss = 1.141 (accuracy: 49.524%)\n",
      "Epoch 96: 22.221 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.116 (accuracy: 54.947%), validation loss = 1.137 (accuracy: 51.429%)\n",
      "Epoch 97: 22.514 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.112 (accuracy: 56.100%), validation loss = 1.133 (accuracy: 52.381%)\n",
      "Epoch 98: 22.349 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.105 (accuracy: 57.541%), validation loss = 1.135 (accuracy: 52.381%)\n",
      "Epoch 99: 22.316 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.102 (accuracy: 57.829%), validation loss = 1.127 (accuracy: 52.381%)\n",
      "Epoch 100: 22.425 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.093 (accuracy: 57.253%), validation loss = 1.125 (accuracy: 52.381%)\n",
      "Epoch 101: 22.287 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.098 (accuracy: 58.886%), validation loss = 1.120 (accuracy: 52.381%)\n",
      "Epoch 102: 22.290 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.092 (accuracy: 58.405%), validation loss = 1.120 (accuracy: 51.429%)\n",
      "Epoch 103: 22.376 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.088 (accuracy: 57.541%), validation loss = 1.115 (accuracy: 53.333%)\n",
      "Epoch 104: 22.477 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.086 (accuracy: 58.790%), validation loss = 1.114 (accuracy: 54.286%)\n",
      "Epoch 105: 22.328 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.084 (accuracy: 59.174%), validation loss = 1.109 (accuracy: 52.381%)\n",
      "Epoch 106: 22.256 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.075 (accuracy: 58.213%), validation loss = 1.104 (accuracy: 53.333%)\n",
      "Epoch 107: 22.311 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.070 (accuracy: 60.711%), validation loss = 1.099 (accuracy: 54.286%)\n",
      "Epoch 108: 22.468 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.074 (accuracy: 59.558%), validation loss = 1.098 (accuracy: 55.238%)\n",
      "Epoch 109: 22.289 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.065 (accuracy: 59.942%), validation loss = 1.093 (accuracy: 55.238%)\n",
      "Epoch 110: 22.339 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.059 (accuracy: 59.462%), validation loss = 1.086 (accuracy: 57.143%)\n",
      "Epoch 111: 22.486 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.055 (accuracy: 60.999%), validation loss = 1.083 (accuracy: 58.095%)\n",
      "Epoch 112: 22.456 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.051 (accuracy: 60.999%), validation loss = 1.078 (accuracy: 58.095%)\n",
      "Epoch 113: 22.400 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.040 (accuracy: 61.191%), validation loss = 1.077 (accuracy: 58.095%)\n",
      "Epoch 114: 22.505 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.043 (accuracy: 61.383%), validation loss = 1.074 (accuracy: 58.095%)\n",
      "Epoch 115: 22.500 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.039 (accuracy: 62.536%), validation loss = 1.067 (accuracy: 58.095%)\n",
      "Epoch 116: 22.552 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.038 (accuracy: 61.575%), validation loss = 1.062 (accuracy: 58.095%)\n",
      "Epoch 117: 22.583 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.026 (accuracy: 63.112%), validation loss = 1.057 (accuracy: 58.095%)\n",
      "Epoch 118: 22.435 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.022 (accuracy: 64.073%), validation loss = 1.050 (accuracy: 58.095%)\n",
      "Epoch 119: 22.525 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.014 (accuracy: 63.305%), validation loss = 1.048 (accuracy: 58.095%)\n",
      "Epoch 120: 22.452 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.010 (accuracy: 64.553%), validation loss = 1.046 (accuracy: 58.095%)\n",
      "Epoch 121: 22.448 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.011 (accuracy: 61.768%), validation loss = 1.039 (accuracy: 59.048%)\n",
      "Epoch 122: 22.468 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.002 (accuracy: 64.745%), validation loss = 1.035 (accuracy: 60.000%)\n",
      "Epoch 123: 22.390 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.993 (accuracy: 65.226%), validation loss = 1.031 (accuracy: 60.000%)\n",
      "Epoch 124: 22.564 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.980 (accuracy: 64.169%), validation loss = 1.029 (accuracy: 59.048%)\n",
      "Epoch 125: 22.620 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.978 (accuracy: 63.593%), validation loss = 1.025 (accuracy: 59.048%)\n",
      "Epoch 126: 22.347 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.967 (accuracy: 65.418%), validation loss = 1.017 (accuracy: 60.000%)\n",
      "Epoch 127: 22.362 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.963 (accuracy: 66.282%), validation loss = 1.010 (accuracy: 59.048%)\n",
      "Epoch 128: 22.397 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.950 (accuracy: 67.339%), validation loss = 1.004 (accuracy: 60.952%)\n",
      "Epoch 129: 22.516 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.962 (accuracy: 67.435%), validation loss = 0.999 (accuracy: 60.000%)\n",
      "Epoch 130: 22.543 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.958 (accuracy: 66.090%), validation loss = 0.994 (accuracy: 61.905%)\n",
      "Epoch 131: 22.559 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.950 (accuracy: 67.243%), validation loss = 0.989 (accuracy: 62.857%)\n",
      "Epoch 132: 22.440 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.955 (accuracy: 66.186%), validation loss = 0.987 (accuracy: 62.857%)\n",
      "Epoch 133: 22.309 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.930 (accuracy: 66.378%), validation loss = 0.980 (accuracy: 64.762%)\n",
      "Epoch 134: 22.333 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.938 (accuracy: 66.378%), validation loss = 0.975 (accuracy: 64.762%)\n",
      "Epoch 135: 22.329 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.924 (accuracy: 68.300%), validation loss = 0.976 (accuracy: 60.000%)\n",
      "Epoch 136: 22.227 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.920 (accuracy: 66.571%), validation loss = 0.968 (accuracy: 64.762%)\n",
      "Epoch 137: 22.343 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.913 (accuracy: 69.068%), validation loss = 0.965 (accuracy: 63.810%)\n",
      "Epoch 138: 22.478 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.898 (accuracy: 68.396%), validation loss = 0.957 (accuracy: 64.762%)\n",
      "Epoch 139: 22.500 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.901 (accuracy: 67.819%), validation loss = 0.956 (accuracy: 62.857%)\n",
      "Epoch 140: 22.560 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.895 (accuracy: 69.452%), validation loss = 0.950 (accuracy: 63.810%)\n",
      "Epoch 141: 22.691 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.895 (accuracy: 67.531%), validation loss = 0.941 (accuracy: 65.714%)\n",
      "Epoch 142: 22.670 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.878 (accuracy: 68.684%), validation loss = 0.938 (accuracy: 64.762%)\n",
      "Epoch 143: 22.723 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.872 (accuracy: 69.837%), validation loss = 0.929 (accuracy: 67.619%)\n",
      "Epoch 144: 22.807 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.871 (accuracy: 69.260%), validation loss = 0.927 (accuracy: 68.571%)\n",
      "Epoch 145: 22.596 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.877 (accuracy: 69.260%), validation loss = 0.921 (accuracy: 65.714%)\n",
      "Epoch 146: 23.094 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.864 (accuracy: 69.356%), validation loss = 0.916 (accuracy: 65.714%)\n",
      "Epoch 147: 22.698 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.848 (accuracy: 70.989%), validation loss = 0.912 (accuracy: 67.619%)\n",
      "Epoch 148: 22.544 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.846 (accuracy: 71.854%), validation loss = 0.910 (accuracy: 66.667%)\n",
      "Epoch 149: 22.679 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.845 (accuracy: 70.797%), validation loss = 0.903 (accuracy: 66.667%)\n",
      "Epoch 150: 22.658 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.833 (accuracy: 70.797%), validation loss = 0.897 (accuracy: 68.571%)\n",
      "Epoch 151: 22.586 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.828 (accuracy: 70.989%), validation loss = 0.895 (accuracy: 65.714%)\n",
      "Epoch 152: 22.662 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.824 (accuracy: 71.278%), validation loss = 0.892 (accuracy: 65.714%)\n",
      "Epoch 153: 22.582 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.821 (accuracy: 70.701%), validation loss = 0.884 (accuracy: 67.619%)\n",
      "Epoch 154: 22.579 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.817 (accuracy: 69.356%), validation loss = 0.881 (accuracy: 68.571%)\n",
      "Epoch 155: 22.522 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.809 (accuracy: 71.470%), validation loss = 0.875 (accuracy: 67.619%)\n",
      "Epoch 156: 22.580 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.798 (accuracy: 73.199%), validation loss = 0.875 (accuracy: 66.667%)\n",
      "Epoch 157: 22.636 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 0.789 (accuracy: 73.583%), validation loss = 0.868 (accuracy: 68.571%)\n",
      "Epoch 158: 22.563 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 0.793 (accuracy: 71.566%), validation loss = 0.865 (accuracy: 69.524%)\n",
      "Epoch 159: 22.541 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 0.784 (accuracy: 74.352%), validation loss = 0.861 (accuracy: 68.571%)\n",
      "Epoch 160: 22.553 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 0.770 (accuracy: 73.679%), validation loss = 0.864 (accuracy: 67.619%)\n",
      "Epoch 161: 22.413 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 0.769 (accuracy: 74.063%), validation loss = 0.853 (accuracy: 69.524%)\n",
      "Epoch 162: 22.557 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 0.769 (accuracy: 73.967%), validation loss = 0.851 (accuracy: 70.476%)\n",
      "Epoch 163: 22.666 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 0.763 (accuracy: 72.911%), validation loss = 0.849 (accuracy: 68.571%)\n",
      "Epoch 164: 22.504 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 0.745 (accuracy: 76.369%), validation loss = 0.845 (accuracy: 67.619%)\n",
      "Epoch 165: 22.775 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 0.750 (accuracy: 74.544%), validation loss = 0.840 (accuracy: 69.524%)\n",
      "Epoch 166: 22.635 seconds elapsed in epoch.\n",
      "Epoch 166: training loss = 0.730 (accuracy: 74.256%), validation loss = 0.840 (accuracy: 67.619%)\n",
      "Epoch 167: 22.465 seconds elapsed in epoch.\n",
      "Epoch 167: training loss = 0.724 (accuracy: 76.465%), validation loss = 0.841 (accuracy: 67.619%)\n",
      "Epoch 168: 22.277 seconds elapsed in epoch.\n",
      "Epoch 168: training loss = 0.720 (accuracy: 76.081%), validation loss = 0.835 (accuracy: 66.667%)\n",
      "Epoch 169: 22.546 seconds elapsed in epoch.\n",
      "Epoch 169: training loss = 0.718 (accuracy: 75.408%), validation loss = 0.830 (accuracy: 69.524%)\n",
      "Epoch 170: 22.658 seconds elapsed in epoch.\n",
      "Epoch 170: training loss = 0.706 (accuracy: 75.312%), validation loss = 0.822 (accuracy: 70.476%)\n",
      "Epoch 171: 22.549 seconds elapsed in epoch.\n",
      "Epoch 171: training loss = 0.700 (accuracy: 76.945%), validation loss = 0.820 (accuracy: 70.476%)\n",
      "Epoch 172: 22.607 seconds elapsed in epoch.\n",
      "Epoch 172: training loss = 0.697 (accuracy: 77.618%), validation loss = 0.816 (accuracy: 68.571%)\n",
      "Epoch 173: 22.542 seconds elapsed in epoch.\n",
      "Epoch 173: training loss = 0.692 (accuracy: 76.849%), validation loss = 0.807 (accuracy: 69.524%)\n",
      "Epoch 174: 22.647 seconds elapsed in epoch.\n",
      "Epoch 174: training loss = 0.690 (accuracy: 77.233%), validation loss = 0.805 (accuracy: 69.524%)\n",
      "Epoch 175: 22.478 seconds elapsed in epoch.\n",
      "Epoch 175: training loss = 0.682 (accuracy: 76.753%), validation loss = 0.802 (accuracy: 68.571%)\n",
      "Epoch 176: 22.470 seconds elapsed in epoch.\n",
      "Epoch 176: training loss = 0.679 (accuracy: 77.618%), validation loss = 0.798 (accuracy: 68.571%)\n",
      "Epoch 177: 22.459 seconds elapsed in epoch.\n",
      "Epoch 177: training loss = 0.668 (accuracy: 77.810%), validation loss = 0.796 (accuracy: 69.524%)\n",
      "Epoch 178: 22.768 seconds elapsed in epoch.\n",
      "Epoch 178: training loss = 0.656 (accuracy: 78.098%), validation loss = 0.791 (accuracy: 70.476%)\n",
      "Epoch 179: 22.843 seconds elapsed in epoch.\n",
      "Epoch 179: training loss = 0.661 (accuracy: 77.618%), validation loss = 0.786 (accuracy: 68.571%)\n",
      "Epoch 180: 22.616 seconds elapsed in epoch.\n",
      "Epoch 180: training loss = 0.648 (accuracy: 78.770%), validation loss = 0.780 (accuracy: 70.476%)\n",
      "Epoch 181: 22.636 seconds elapsed in epoch.\n",
      "Epoch 181: training loss = 0.637 (accuracy: 78.770%), validation loss = 0.779 (accuracy: 70.476%)\n",
      "Epoch 182: 22.567 seconds elapsed in epoch.\n",
      "Epoch 182: training loss = 0.641 (accuracy: 78.002%), validation loss = 0.780 (accuracy: 67.619%)\n",
      "Epoch 183: 22.518 seconds elapsed in epoch.\n",
      "Epoch 183: training loss = 0.632 (accuracy: 79.059%), validation loss = 0.770 (accuracy: 70.476%)\n",
      "Epoch 184: 22.754 seconds elapsed in epoch.\n",
      "Epoch 184: training loss = 0.633 (accuracy: 78.482%), validation loss = 0.768 (accuracy: 69.524%)\n",
      "Epoch 185: 22.588 seconds elapsed in epoch.\n",
      "Epoch 185: training loss = 0.613 (accuracy: 80.500%), validation loss = 0.767 (accuracy: 68.571%)\n",
      "Epoch 186: 22.636 seconds elapsed in epoch.\n",
      "Epoch 186: training loss = 0.623 (accuracy: 79.155%), validation loss = 0.762 (accuracy: 69.524%)\n",
      "Epoch 187: 22.622 seconds elapsed in epoch.\n",
      "Epoch 187: training loss = 0.611 (accuracy: 80.884%), validation loss = 0.763 (accuracy: 68.571%)\n",
      "Epoch 188: 22.553 seconds elapsed in epoch.\n",
      "Epoch 188: training loss = 0.599 (accuracy: 80.980%), validation loss = 0.757 (accuracy: 69.524%)\n",
      "Epoch 189: 22.580 seconds elapsed in epoch.\n",
      "Epoch 189: training loss = 0.609 (accuracy: 80.307%), validation loss = 0.764 (accuracy: 68.571%)\n",
      "Epoch 190: 22.523 seconds elapsed in epoch.\n",
      "Epoch 190: training loss = 0.586 (accuracy: 81.364%), validation loss = 0.756 (accuracy: 69.524%)\n",
      "Epoch 191: 22.690 seconds elapsed in epoch.\n",
      "Epoch 191: training loss = 0.585 (accuracy: 80.884%), validation loss = 0.750 (accuracy: 69.524%)\n",
      "Epoch 192: 22.838 seconds elapsed in epoch.\n",
      "Epoch 192: training loss = 0.581 (accuracy: 80.980%), validation loss = 0.748 (accuracy: 70.476%)\n",
      "Epoch 193: 22.492 seconds elapsed in epoch.\n",
      "Epoch 193: training loss = 0.570 (accuracy: 82.133%), validation loss = 0.744 (accuracy: 68.571%)\n",
      "Epoch 194: 22.595 seconds elapsed in epoch.\n",
      "Epoch 194: training loss = 0.558 (accuracy: 82.421%), validation loss = 0.740 (accuracy: 68.571%)\n",
      "Epoch 195: 22.574 seconds elapsed in epoch.\n",
      "Epoch 195: training loss = 0.566 (accuracy: 81.748%), validation loss = 0.734 (accuracy: 68.571%)\n",
      "Epoch 196: 22.669 seconds elapsed in epoch.\n",
      "Epoch 196: training loss = 0.555 (accuracy: 82.421%), validation loss = 0.732 (accuracy: 68.571%)\n",
      "Epoch 197: 22.593 seconds elapsed in epoch.\n",
      "Epoch 197: training loss = 0.559 (accuracy: 81.748%), validation loss = 0.734 (accuracy: 67.619%)\n",
      "Epoch 198: 22.397 seconds elapsed in epoch.\n",
      "Epoch 198: training loss = 0.550 (accuracy: 82.613%), validation loss = 0.736 (accuracy: 68.571%)\n",
      "Epoch 199: 22.333 seconds elapsed in epoch.\n",
      "Epoch 199: training loss = 0.539 (accuracy: 83.477%), validation loss = 0.722 (accuracy: 70.476%)\n",
      "Epoch 200: 22.545 seconds elapsed in epoch.\n",
      "Epoch 200: training loss = 0.539 (accuracy: 82.037%), validation loss = 0.729 (accuracy: 68.571%)\n",
      "==================================================result==================================================\n",
      "the best epoch is 199 with minimum validation error = 0.722193843977792\n",
      "31861.041 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.5\n",
      "Epoch 1: 22.314 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.386 (accuracy: 29.779%), validation loss = 1.368 (accuracy: 33.333%)\n",
      "Epoch 2: 22.646 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.342 (accuracy: 35.351%), validation loss = 1.345 (accuracy: 34.286%)\n",
      "Epoch 3: 22.515 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.322 (accuracy: 37.464%), validation loss = 1.330 (accuracy: 33.333%)\n",
      "Epoch 4: 22.645 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.306 (accuracy: 38.425%), validation loss = 1.321 (accuracy: 33.333%)\n",
      "Epoch 5: 22.592 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.304 (accuracy: 39.193%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 6: 22.609 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.293 (accuracy: 39.769%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 7: 22.442 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.297 (accuracy: 38.617%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 8: 22.401 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.289 (accuracy: 39.385%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 9: 22.688 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.281 (accuracy: 39.673%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 10: 22.543 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.287 (accuracy: 39.289%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 11: 22.464 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.280 (accuracy: 39.289%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 12: 22.621 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.275 (accuracy: 39.193%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 13: 22.734 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.280 (accuracy: 39.962%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 14: 22.805 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.276 (accuracy: 40.538%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 15: 22.647 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.271 (accuracy: 39.962%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 16: 22.754 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.273 (accuracy: 40.058%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 17: 22.670 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.271 (accuracy: 39.577%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 18: 22.644 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.270 (accuracy: 39.289%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 19: 22.724 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.267 (accuracy: 39.962%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 20: 22.630 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.269 (accuracy: 39.866%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 21: 22.609 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.265 (accuracy: 40.250%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 22: 22.682 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.271 (accuracy: 39.866%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 23: 22.787 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.266 (accuracy: 40.058%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 24: 22.764 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.263 (accuracy: 39.385%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 25: 22.633 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.271 (accuracy: 40.346%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 26: 22.770 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.272 (accuracy: 39.769%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 27: 22.582 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.264 (accuracy: 40.634%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 28: 22.656 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.263 (accuracy: 39.673%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 29: 22.563 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.264 (accuracy: 40.058%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 30: 22.665 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.261 (accuracy: 40.250%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 31: 22.524 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.265 (accuracy: 40.154%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 32: 22.798 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.265 (accuracy: 39.962%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 33: 22.727 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.262 (accuracy: 39.866%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 34: 22.649 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.261 (accuracy: 39.481%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 35: 22.637 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.258 (accuracy: 40.058%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 36: 22.709 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.260 (accuracy: 39.962%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 37: 22.744 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.263 (accuracy: 39.769%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 38: 22.605 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.257 (accuracy: 40.154%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 39: 22.477 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.257 (accuracy: 40.058%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 40: 22.665 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.258 (accuracy: 39.673%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 41: 22.651 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.256 (accuracy: 40.346%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 42: 22.575 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.261 (accuracy: 39.577%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 43: 22.523 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.256 (accuracy: 39.866%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 44: 22.669 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.254 (accuracy: 39.577%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 45: 22.660 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.258 (accuracy: 39.962%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 46: 22.673 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.254 (accuracy: 39.866%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 47: 22.700 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.255 (accuracy: 39.866%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 48: 22.538 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.260 (accuracy: 39.866%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 49: 22.580 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.260 (accuracy: 39.866%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 50: 22.570 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.254 (accuracy: 39.481%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 51: 22.566 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.254 (accuracy: 40.058%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 52: 22.718 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.257 (accuracy: 39.673%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 53: 22.542 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.255 (accuracy: 39.866%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 54: 22.611 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.253 (accuracy: 39.769%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 55: 22.601 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.255 (accuracy: 39.577%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 56: 22.485 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.255 (accuracy: 39.577%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 57: 22.542 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.255 (accuracy: 39.577%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 58: 22.515 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.257 (accuracy: 39.481%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 59: 22.582 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.251 (accuracy: 39.577%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 60: 22.797 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.252 (accuracy: 39.673%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 61: 22.560 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.254 (accuracy: 39.673%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 62: 22.665 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.253 (accuracy: 39.866%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 63: 22.528 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.246 (accuracy: 39.673%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 64: 22.578 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.251 (accuracy: 39.481%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 65: 22.560 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.249 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 66: 22.625 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.252 (accuracy: 39.673%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 67: 22.511 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.255 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 68: 22.631 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.251 (accuracy: 39.385%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 69: 22.533 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.252 (accuracy: 39.577%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 70: 22.548 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.252 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 71: 22.602 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.249 (accuracy: 39.577%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 51 with minimum validation error = 1.273225822902861\n",
      "33480.736 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0\n",
      "Epoch 1: 22.483 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.404 (accuracy: 23.919%), validation loss = 1.359 (accuracy: 35.238%)\n",
      "Epoch 2: 22.659 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.390 (accuracy: 26.609%), validation loss = 1.351 (accuracy: 36.190%)\n",
      "Epoch 3: 22.823 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.380 (accuracy: 28.434%), validation loss = 1.345 (accuracy: 33.333%)\n",
      "Epoch 4: 22.554 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.368 (accuracy: 30.740%), validation loss = 1.338 (accuracy: 30.476%)\n",
      "Epoch 5: 22.616 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.368 (accuracy: 29.491%), validation loss = 1.335 (accuracy: 30.476%)\n",
      "Epoch 6: 22.717 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.355 (accuracy: 30.644%), validation loss = 1.330 (accuracy: 36.190%)\n",
      "Epoch 7: 22.597 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.355 (accuracy: 33.910%), validation loss = 1.327 (accuracy: 36.190%)\n",
      "Epoch 8: 22.685 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.350 (accuracy: 32.181%), validation loss = 1.323 (accuracy: 33.333%)\n",
      "Epoch 9: 22.722 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.343 (accuracy: 34.966%), validation loss = 1.320 (accuracy: 31.429%)\n",
      "Epoch 10: 22.708 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.336 (accuracy: 36.311%), validation loss = 1.316 (accuracy: 31.429%)\n",
      "Epoch 11: 22.703 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.334 (accuracy: 37.080%), validation loss = 1.314 (accuracy: 31.429%)\n",
      "Epoch 12: 22.721 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.330 (accuracy: 35.255%), validation loss = 1.313 (accuracy: 32.381%)\n",
      "Epoch 13: 22.605 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.318 (accuracy: 40.250%), validation loss = 1.312 (accuracy: 32.381%)\n",
      "Epoch 14: 22.639 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.318 (accuracy: 38.617%), validation loss = 1.310 (accuracy: 32.381%)\n",
      "Epoch 15: 22.628 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.313 (accuracy: 37.944%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 16: 22.799 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.316 (accuracy: 39.097%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 17: 22.664 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.310 (accuracy: 37.272%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 18: 22.740 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.302 (accuracy: 41.114%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 19: 22.732 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.310 (accuracy: 38.521%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 20: 22.703 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.303 (accuracy: 38.040%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 21: 22.600 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.303 (accuracy: 39.097%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 22: 22.388 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.300 (accuracy: 39.385%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 23: 22.548 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.303 (accuracy: 38.809%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 24: 22.534 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.301 (accuracy: 38.617%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 25: 22.631 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.299 (accuracy: 38.040%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 26: 22.705 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.296 (accuracy: 38.329%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 27: 22.628 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.283 (accuracy: 40.538%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 28: 22.544 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.295 (accuracy: 40.058%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 29: 22.588 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.290 (accuracy: 38.425%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 30: 22.700 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.296 (accuracy: 37.080%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 31: 22.587 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.283 (accuracy: 39.097%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 32: 22.508 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.282 (accuracy: 39.481%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 33: 22.730 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.292 (accuracy: 39.385%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 34: 22.628 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.288 (accuracy: 40.442%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 35: 22.673 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.282 (accuracy: 39.385%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 36: 22.705 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.280 (accuracy: 39.962%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 37: 22.656 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.283 (accuracy: 39.289%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 38: 22.576 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.282 (accuracy: 39.962%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 39: 22.520 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.282 (accuracy: 38.425%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 40: 22.518 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.290 (accuracy: 38.905%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 41: 22.622 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.282 (accuracy: 39.289%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 42: 22.587 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.285 (accuracy: 39.866%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 43: 22.799 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.283 (accuracy: 39.289%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 44: 22.671 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.281 (accuracy: 39.193%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 45: 22.519 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.283 (accuracy: 39.097%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 46: 22.576 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.277 (accuracy: 39.193%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 47: 22.618 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.279 (accuracy: 40.154%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 48: 22.427 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.273 (accuracy: 40.250%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 49: 22.489 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.274 (accuracy: 39.673%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 50: 22.470 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.284 (accuracy: 38.329%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 51: 22.618 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.270 (accuracy: 39.097%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 52: 22.494 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.280 (accuracy: 39.097%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 53: 22.579 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.273 (accuracy: 40.634%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 54: 22.654 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.278 (accuracy: 40.058%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 55: 22.464 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.269 (accuracy: 40.346%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 56: 22.522 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.275 (accuracy: 40.442%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 57: 22.637 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.275 (accuracy: 38.617%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 58: 22.724 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.269 (accuracy: 40.922%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 59: 22.532 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.273 (accuracy: 39.769%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 60: 22.691 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.266 (accuracy: 40.154%), validation loss = 1.275 (accuracy: 33.333%)\n",
      "Epoch 61: 22.574 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.272 (accuracy: 39.385%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 62: 22.562 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.271 (accuracy: 39.193%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 63: 22.488 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.271 (accuracy: 40.346%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 64: 22.418 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.266 (accuracy: 40.922%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 65: 22.598 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.265 (accuracy: 40.442%), validation loss = 1.273 (accuracy: 33.333%)\n",
      "Epoch 66: 22.467 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.264 (accuracy: 40.250%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 67: 22.588 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.274 (accuracy: 39.001%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 68: 22.367 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.270 (accuracy: 40.634%), validation loss = 1.270 (accuracy: 33.333%)\n",
      "Epoch 69: 22.476 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.263 (accuracy: 39.866%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 70: 22.352 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.267 (accuracy: 40.538%), validation loss = 1.270 (accuracy: 33.333%)\n",
      "Epoch 71: 22.723 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.267 (accuracy: 39.001%), validation loss = 1.269 (accuracy: 33.333%)\n",
      "Epoch 72: 22.598 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.276 (accuracy: 39.577%), validation loss = 1.269 (accuracy: 33.333%)\n",
      "Epoch 73: 22.556 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.280 (accuracy: 38.905%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 74: 22.656 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.273 (accuracy: 39.673%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 75: 22.601 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.264 (accuracy: 39.866%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 76: 22.543 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.267 (accuracy: 40.346%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 77: 22.621 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.262 (accuracy: 40.826%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 78: 22.651 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.260 (accuracy: 40.250%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 79: 22.563 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.265 (accuracy: 40.058%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 80: 22.578 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.266 (accuracy: 39.577%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 81: 22.615 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.270 (accuracy: 40.346%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 82: 22.391 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.260 (accuracy: 41.114%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 83: 22.468 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.265 (accuracy: 39.001%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 84: 22.873 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.261 (accuracy: 40.250%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 85: 22.687 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.260 (accuracy: 39.769%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 86: 22.556 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.259 (accuracy: 39.673%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 87: 22.534 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.262 (accuracy: 40.250%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 88: 22.656 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.260 (accuracy: 40.346%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 89: 22.623 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.261 (accuracy: 40.442%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 90: 22.582 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.259 (accuracy: 40.826%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 91: 22.614 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.264 (accuracy: 40.538%), validation loss = 1.259 (accuracy: 33.333%)\n",
      "Epoch 92: 22.555 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.260 (accuracy: 40.250%), validation loss = 1.258 (accuracy: 33.333%)\n",
      "Epoch 93: 22.665 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.258 (accuracy: 41.306%), validation loss = 1.258 (accuracy: 33.333%)\n",
      "Epoch 94: 22.398 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.258 (accuracy: 41.402%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 95: 22.301 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.256 (accuracy: 40.730%), validation loss = 1.258 (accuracy: 33.333%)\n",
      "Epoch 96: 22.089 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.263 (accuracy: 40.058%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 97: 22.374 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.255 (accuracy: 41.210%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 98: 22.418 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.252 (accuracy: 41.402%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 99: 22.206 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.259 (accuracy: 40.730%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 100: 22.248 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.256 (accuracy: 41.114%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 101: 22.027 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.252 (accuracy: 40.730%), validation loss = 1.254 (accuracy: 33.333%)\n",
      "Epoch 102: 22.204 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.250 (accuracy: 40.250%), validation loss = 1.254 (accuracy: 33.333%)\n",
      "Epoch 103: 22.015 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.255 (accuracy: 40.442%), validation loss = 1.253 (accuracy: 33.333%)\n",
      "Epoch 104: 22.100 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.250 (accuracy: 40.922%), validation loss = 1.252 (accuracy: 33.333%)\n",
      "Epoch 105: 22.067 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.251 (accuracy: 40.922%), validation loss = 1.253 (accuracy: 33.333%)\n",
      "Epoch 106: 21.831 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.254 (accuracy: 41.306%), validation loss = 1.253 (accuracy: 33.333%)\n",
      "Epoch 107: 21.939 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.253 (accuracy: 41.595%), validation loss = 1.252 (accuracy: 33.333%)\n",
      "Epoch 108: 22.127 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.251 (accuracy: 41.499%), validation loss = 1.251 (accuracy: 33.333%)\n",
      "Epoch 109: 22.040 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.250 (accuracy: 40.058%), validation loss = 1.249 (accuracy: 33.333%)\n",
      "Epoch 110: 22.026 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.249 (accuracy: 40.826%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 111: 22.005 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.244 (accuracy: 40.826%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 112: 22.031 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.250 (accuracy: 40.442%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 113: 21.975 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.253 (accuracy: 41.210%), validation loss = 1.249 (accuracy: 33.333%)\n",
      "Epoch 114: 22.245 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.257 (accuracy: 40.922%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 115: 22.007 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.247 (accuracy: 40.922%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 116: 21.998 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.254 (accuracy: 40.154%), validation loss = 1.248 (accuracy: 33.333%)\n",
      "Epoch 117: 22.070 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.246 (accuracy: 41.306%), validation loss = 1.246 (accuracy: 33.333%)\n",
      "Epoch 118: 22.207 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.242 (accuracy: 41.595%), validation loss = 1.244 (accuracy: 33.333%)\n",
      "Epoch 119: 22.041 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.250 (accuracy: 41.114%), validation loss = 1.245 (accuracy: 33.333%)\n",
      "Epoch 120: 21.936 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.251 (accuracy: 40.922%), validation loss = 1.245 (accuracy: 33.333%)\n",
      "Epoch 121: 21.814 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.250 (accuracy: 41.306%), validation loss = 1.244 (accuracy: 33.333%)\n",
      "Epoch 122: 21.907 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.252 (accuracy: 41.018%), validation loss = 1.245 (accuracy: 33.333%)\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.005, 0.001, 0.0005]\n",
    "weight_list = [0, 0.1, 0.2, 0.5]\n",
    "min_valid_loss_list_Q2_SGD = []\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "for lr in lr_list:\n",
    "    for weight in weight_list:\n",
    "        save_file_name = \"/content/gdrive/My Drive/SLDL/hw5/Q2/SGD/resnet50_lr_\" + str(lr) + \"_weight_\" + str(weight) + \".pt\"\n",
    "        model = reset_model()\n",
    "        if train_on_gpu:\n",
    "            model = model.to('cuda')\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay = weight)\n",
    "        nepoch = 200\n",
    "        Q2_tune_model = Resnet50()\n",
    "        print(\"Start training model: learning rate = {}, weight decay = {}\".format(lr, weight))\n",
    "        model_finish = Q2_tune_model.train(train_on_gpu, model, nepoch, optimizer, save_file_name, dataloaders['train'], dataloaders['val'], verbose = True)\n",
    "        min_valid_loss_list_Q2_SGD.append(Q2_tune_model.best_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1610355916765,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "cezpODHGrrJA",
    "outputId": "2c4341c2-b1a8-4f3e-eb97-f6151ffef9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-axis: learning rate\n",
      "y-axis: weight decay\n",
      "Best hyperparameters with SGD optimizer : learning rate = 0.001, weight decay = 0.1\n",
      "       0.0050    0.0010    0.0005\n",
      "0.0  0.533429  0.535153  0.624345\n",
      "0.1  0.579903  0.497560  0.620416\n",
      "0.2  0.617791  0.584158  0.722194\n",
      "0.5  1.277252  1.226482  1.273226\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.005, 0.001, 0.0005]\n",
    "weight_list = [0, 0.1, 0.2, 0.5]\n",
    "df = pd.DataFrame(index = weight_list)\n",
    "count = 0\n",
    "for lr in lr_list:\n",
    "    temp = []\n",
    "    for weight in weight_list:\n",
    "        temp.append(min_valid_loss_list_Q2_SGD[count])\n",
    "        count +=1 \n",
    "    df[lr] = temp\n",
    "index = np.unravel_index(np.argmin(df, axis=None), df.shape)\n",
    "row_index = index[0]\n",
    "column_index = index[1]\n",
    "print(\"x-axis: learning rate\")\n",
    "print(\"y-axis: weight decay\")\n",
    "print(\"Best hyperparameters with SGD optimizer : learning rate = {}, weight decay = {}\".format(lr_list[column_index], weight_list[row_index]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU1dqRbLzpa3"
   },
   "source": [
    "## Q2 Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 55998,
     "status": "ok",
     "timestamp": 1610528235193,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "gvn6NGmm8xUX",
    "outputId": "25cc24bd-18c5-4e75-ae37-a7fb9d938793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q2 result==================================================\n",
      "when optimizer = Adam, learning rate = 1e-05, weight decay = 0.1, overall testing accuracy = 0.815\n",
      "label = blazer, per class accuracy = 0.7777777777777778\n",
      "label = cardigan, per class accuracy = 0.7619047619047619\n",
      "label = coat, per class accuracy = 0.8604651162790697\n",
      "label = jacket, per class accuracy = 0.8269230769230769\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q2 result==================================================\n",
      "when optimizer = Adam, learning rate = 1e-05, weight decay = 0, overall testing accuracy = 0.808\n",
      "label = blazer, per class accuracy = 0.5555555555555556\n",
      "label = cardigan, per class accuracy = 0.7142857142857143\n",
      "label = coat, per class accuracy = 0.8372093023255814\n",
      "label = jacket, per class accuracy = 0.9038461538461539\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q2 result==================================================\n",
      "when optimizer = SGD, learning rate = 0.005, weight decay = 0, overall testing accuracy = 0.788\n",
      "label = blazer, per class accuracy = 0.6666666666666666\n",
      "label = cardigan, per class accuracy = 0.7142857142857143\n",
      "label = coat, per class accuracy = 0.8372093023255814\n",
      "label = jacket, per class accuracy = 0.8269230769230769\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q2 result==================================================\n",
      "when optimizer = SGD, learning rate = 0.001, weight decay = 0, overall testing accuracy = 0.801\n",
      "label = blazer, per class accuracy = 0.7777777777777778\n",
      "label = cardigan, per class accuracy = 0.7142857142857143\n",
      "label = coat, per class accuracy = 0.8837209302325582\n",
      "label = jacket, per class accuracy = 0.8076923076923077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q2 Adam\n",
    "#learning rate = 0.00001, weight decay = 0.1 (&weight decay = 0.0)\n",
    "print_result(\"Q2\", \"Adam\", 0.00001, 0.1)\n",
    "print_result(\"Q2\", \"Adam\", 0.00001, 0)\n",
    "#Q2 SGD\n",
    "#learning rate = 0.005, weight_decay = 0.0 & lr = 0.001, weight decay = 0.\n",
    "print_result(\"Q2\", \"SGD\", 0.005, 0)\n",
    "print_result(\"Q2\", \"SGD\", 0.001, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從上圖可以觀察到，結果大約與預測結果相符，但仍有三個模型coat的準確率大於jacket。\n",
    "可能的原因如下：\n",
    "1. dropout layer在訓練過程中，恰巧dropout到一些偏好jacket label的neuron，所以導致此結果。\n",
    "2. coat照片的色彩或對比比較鮮明，轉成tensor之後每個feature的variance較大，所以導致coat這個label的學習效果比較好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF5-yHuTR0ad"
   },
   "source": [
    "### Tuning, Optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2419470,
     "status": "ok",
     "timestamp": 1610377924529,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "hFp6wEUAR4Dn",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "76b7853f-dbef-4697-f25e-084911de6e00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: learning rate = 0.0005, weight decay = 0\n",
      "Epoch 1: 204.005 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.323 (accuracy: 36.695%), validation loss = 1.297 (accuracy: 38.095%)\n",
      "Epoch 2: 16.268 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.232 (accuracy: 44.188%), validation loss = 1.179 (accuracy: 46.667%)\n",
      "Epoch 3: 16.312 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.189 (accuracy: 46.013%), validation loss = 1.158 (accuracy: 48.571%)\n",
      "Epoch 4: 16.204 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.171 (accuracy: 46.494%), validation loss = 1.133 (accuracy: 49.524%)\n",
      "Epoch 5: 16.250 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.151 (accuracy: 49.664%), validation loss = 1.123 (accuracy: 50.476%)\n",
      "Epoch 6: 16.240 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.126 (accuracy: 49.856%), validation loss = 1.085 (accuracy: 51.429%)\n",
      "Epoch 7: 16.423 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.097 (accuracy: 51.585%), validation loss = 1.123 (accuracy: 45.714%)\n",
      "Epoch 8: 16.617 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.084 (accuracy: 51.297%), validation loss = 1.061 (accuracy: 60.000%)\n",
      "Epoch 9: 16.428 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.068 (accuracy: 52.642%), validation loss = 1.067 (accuracy: 50.476%)\n",
      "Epoch 10: 16.151 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.062 (accuracy: 54.947%), validation loss = 1.054 (accuracy: 49.524%)\n",
      "Epoch 11: 16.325 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.044 (accuracy: 55.235%), validation loss = 1.068 (accuracy: 48.571%)\n",
      "Epoch 12: 16.200 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.071 (accuracy: 54.947%), validation loss = 1.019 (accuracy: 60.000%)\n",
      "Epoch 13: 16.372 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.022 (accuracy: 58.309%), validation loss = 0.995 (accuracy: 56.190%)\n",
      "Epoch 14: 16.519 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.022 (accuracy: 57.445%), validation loss = 1.021 (accuracy: 50.476%)\n",
      "Epoch 15: 16.144 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.003 (accuracy: 55.139%), validation loss = 1.045 (accuracy: 53.333%)\n",
      "Epoch 16: 16.086 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.009 (accuracy: 56.100%), validation loss = 1.052 (accuracy: 51.429%)\n",
      "Epoch 17: 16.280 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 0.999 (accuracy: 57.925%), validation loss = 0.983 (accuracy: 56.190%)\n",
      "Epoch 18: 16.343 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 0.975 (accuracy: 59.462%), validation loss = 1.046 (accuracy: 51.429%)\n",
      "Epoch 19: 16.054 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.982 (accuracy: 58.501%), validation loss = 1.002 (accuracy: 57.143%)\n",
      "Epoch 20: 16.031 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.978 (accuracy: 58.694%), validation loss = 1.013 (accuracy: 53.333%)\n",
      "Epoch 21: 16.141 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.007 (accuracy: 58.117%), validation loss = 0.986 (accuracy: 61.905%)\n",
      "Epoch 22: 16.191 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.973 (accuracy: 58.694%), validation loss = 1.065 (accuracy: 49.524%)\n",
      "Epoch 23: 16.015 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.965 (accuracy: 60.134%), validation loss = 0.978 (accuracy: 60.952%)\n",
      "Epoch 24: 16.128 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.941 (accuracy: 60.327%), validation loss = 0.985 (accuracy: 56.190%)\n",
      "Epoch 25: 15.911 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.957 (accuracy: 59.366%), validation loss = 0.986 (accuracy: 58.095%)\n",
      "Epoch 26: 15.911 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.925 (accuracy: 60.423%), validation loss = 0.984 (accuracy: 57.143%)\n",
      "Epoch 27: 16.481 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.928 (accuracy: 62.728%), validation loss = 0.959 (accuracy: 60.000%)\n",
      "Epoch 28: 16.141 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.942 (accuracy: 60.711%), validation loss = 0.976 (accuracy: 56.190%)\n",
      "Epoch 29: 15.865 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.922 (accuracy: 62.920%), validation loss = 0.966 (accuracy: 60.000%)\n",
      "Epoch 30: 15.899 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.943 (accuracy: 60.038%), validation loss = 1.002 (accuracy: 53.333%)\n",
      "Epoch 31: 15.906 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.963 (accuracy: 58.982%), validation loss = 0.962 (accuracy: 59.048%)\n",
      "Epoch 32: 16.069 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.977 (accuracy: 58.886%), validation loss = 0.992 (accuracy: 54.286%)\n",
      "Epoch 33: 15.930 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.928 (accuracy: 60.903%), validation loss = 0.977 (accuracy: 56.190%)\n",
      "Epoch 34: 15.823 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.914 (accuracy: 60.519%), validation loss = 0.967 (accuracy: 59.048%)\n",
      "Epoch 35: 15.764 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.911 (accuracy: 61.864%), validation loss = 0.974 (accuracy: 56.190%)\n",
      "Epoch 36: 15.809 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.918 (accuracy: 60.327%), validation loss = 1.009 (accuracy: 56.190%)\n",
      "Epoch 37: 15.866 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.932 (accuracy: 60.999%), validation loss = 1.018 (accuracy: 55.238%)\n",
      "Epoch 38: 16.002 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.918 (accuracy: 60.807%), validation loss = 0.947 (accuracy: 58.095%)\n",
      "Epoch 39: 16.162 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.882 (accuracy: 62.824%), validation loss = 0.951 (accuracy: 60.952%)\n",
      "Epoch 40: 15.863 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.893 (accuracy: 61.479%), validation loss = 0.974 (accuracy: 55.238%)\n",
      "Epoch 41: 15.882 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.863 (accuracy: 64.361%), validation loss = 0.975 (accuracy: 56.190%)\n",
      "Epoch 42: 15.993 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.922 (accuracy: 60.231%), validation loss = 0.945 (accuracy: 60.952%)\n",
      "Epoch 43: 16.107 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.873 (accuracy: 62.536%), validation loss = 0.979 (accuracy: 58.095%)\n",
      "Epoch 44: 15.892 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.884 (accuracy: 63.401%), validation loss = 0.956 (accuracy: 57.143%)\n",
      "Epoch 45: 15.976 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.878 (accuracy: 63.881%), validation loss = 0.953 (accuracy: 54.286%)\n",
      "Epoch 46: 16.390 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.884 (accuracy: 63.401%), validation loss = 0.942 (accuracy: 60.952%)\n",
      "Epoch 47: 16.252 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.876 (accuracy: 63.305%), validation loss = 0.955 (accuracy: 55.238%)\n",
      "Epoch 48: 15.843 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.935 (accuracy: 61.575%), validation loss = 0.949 (accuracy: 60.000%)\n",
      "Epoch 49: 15.884 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.890 (accuracy: 62.632%), validation loss = 0.998 (accuracy: 55.238%)\n",
      "Epoch 50: 15.876 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.869 (accuracy: 62.248%), validation loss = 0.965 (accuracy: 57.143%)\n",
      "Epoch 51: 15.770 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.880 (accuracy: 63.785%), validation loss = 1.017 (accuracy: 57.143%)\n",
      "Epoch 52: 16.084 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.889 (accuracy: 62.440%), validation loss = 0.942 (accuracy: 61.905%)\n",
      "Epoch 53: 15.820 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.877 (accuracy: 62.632%), validation loss = 1.013 (accuracy: 52.381%)\n",
      "Epoch 54: 15.870 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.871 (accuracy: 62.920%), validation loss = 0.973 (accuracy: 60.952%)\n",
      "Epoch 55: 15.841 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.899 (accuracy: 61.960%), validation loss = 0.944 (accuracy: 60.952%)\n",
      "Epoch 56: 15.897 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.877 (accuracy: 65.034%), validation loss = 1.023 (accuracy: 55.238%)\n",
      "Epoch 57: 15.902 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.869 (accuracy: 62.920%), validation loss = 1.029 (accuracy: 54.286%)\n",
      "Epoch 58: 15.818 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.892 (accuracy: 63.208%), validation loss = 0.965 (accuracy: 59.048%)\n",
      "Epoch 59: 15.816 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.869 (accuracy: 63.112%), validation loss = 0.967 (accuracy: 63.810%)\n",
      "Epoch 60: 15.767 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.898 (accuracy: 63.016%), validation loss = 1.049 (accuracy: 55.238%)\n",
      "Epoch 61: 15.742 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.875 (accuracy: 62.440%), validation loss = 0.962 (accuracy: 56.190%)\n",
      "Epoch 62: 15.965 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.843 (accuracy: 65.514%), validation loss = 0.947 (accuracy: 59.048%)\n",
      "Epoch 63: 15.809 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.847 (accuracy: 65.226%), validation loss = 0.943 (accuracy: 60.000%)\n",
      "Epoch 64: 15.977 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.854 (accuracy: 65.226%), validation loss = 0.954 (accuracy: 54.286%)\n",
      "Epoch 65: 15.940 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.845 (accuracy: 63.497%), validation loss = 1.000 (accuracy: 59.048%)\n",
      "Epoch 66: 16.655 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.890 (accuracy: 61.383%), validation loss = 0.984 (accuracy: 55.238%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 46 with minimum validation error = 0.9422811848776681\n",
      "2194.291 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.1\n",
      "Epoch 1: 15.980 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.305 (accuracy: 38.809%), validation loss = 1.242 (accuracy: 38.095%)\n",
      "Epoch 2: 16.047 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.255 (accuracy: 41.114%), validation loss = 1.178 (accuracy: 42.857%)\n",
      "Epoch 3: 15.998 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.217 (accuracy: 44.573%), validation loss = 1.221 (accuracy: 39.048%)\n",
      "Epoch 4: 15.777 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.215 (accuracy: 45.725%), validation loss = 1.166 (accuracy: 41.905%)\n",
      "Epoch 5: 16.100 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.207 (accuracy: 45.533%), validation loss = 1.147 (accuracy: 56.190%)\n",
      "Epoch 6: 16.016 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.194 (accuracy: 46.206%), validation loss = 1.146 (accuracy: 60.000%)\n",
      "Epoch 7: 15.925 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.204 (accuracy: 43.900%), validation loss = 1.133 (accuracy: 60.000%)\n",
      "Epoch 8: 15.938 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.200 (accuracy: 46.878%), validation loss = 1.171 (accuracy: 42.857%)\n",
      "Epoch 9: 15.732 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.194 (accuracy: 46.686%), validation loss = 1.203 (accuracy: 40.000%)\n",
      "Epoch 10: 15.793 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.182 (accuracy: 48.319%), validation loss = 1.138 (accuracy: 52.381%)\n",
      "Epoch 11: 15.914 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.204 (accuracy: 48.031%), validation loss = 1.149 (accuracy: 45.714%)\n",
      "Epoch 12: 15.777 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.180 (accuracy: 47.839%), validation loss = 1.140 (accuracy: 52.381%)\n",
      "Epoch 13: 15.747 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.181 (accuracy: 49.183%), validation loss = 1.139 (accuracy: 51.429%)\n",
      "Epoch 14: 15.816 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.191 (accuracy: 47.839%), validation loss = 1.147 (accuracy: 51.429%)\n",
      "Epoch 15: 15.754 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.201 (accuracy: 45.341%), validation loss = 1.204 (accuracy: 43.810%)\n",
      "Epoch 16: 15.914 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.201 (accuracy: 45.437%), validation loss = 1.145 (accuracy: 43.810%)\n",
      "Epoch 17: 15.812 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.198 (accuracy: 46.974%), validation loss = 1.207 (accuracy: 38.095%)\n",
      "Epoch 18: 15.838 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.191 (accuracy: 45.821%), validation loss = 1.147 (accuracy: 55.238%)\n",
      "Epoch 19: 16.227 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.173 (accuracy: 48.895%), validation loss = 1.150 (accuracy: 49.524%)\n",
      "Epoch 20: 15.720 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.192 (accuracy: 47.454%), validation loss = 1.232 (accuracy: 36.190%)\n",
      "Epoch 21: 15.836 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.177 (accuracy: 46.782%), validation loss = 1.169 (accuracy: 44.762%)\n",
      "Epoch 22: 15.754 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.194 (accuracy: 47.550%), validation loss = 1.141 (accuracy: 51.429%)\n",
      "Epoch 23: 15.652 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.199 (accuracy: 46.686%), validation loss = 1.133 (accuracy: 51.429%)\n",
      "Epoch 24: 16.052 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.173 (accuracy: 47.454%), validation loss = 1.124 (accuracy: 53.333%)\n",
      "Epoch 25: 15.955 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.185 (accuracy: 48.031%), validation loss = 1.133 (accuracy: 51.429%)\n",
      "Epoch 26: 15.843 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.179 (accuracy: 47.454%), validation loss = 1.150 (accuracy: 47.619%)\n",
      "Epoch 27: 15.745 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.164 (accuracy: 48.703%), validation loss = 1.162 (accuracy: 43.810%)\n",
      "Epoch 28: 15.698 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.208 (accuracy: 44.573%), validation loss = 1.181 (accuracy: 40.952%)\n",
      "Epoch 29: 15.659 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.207 (accuracy: 44.957%), validation loss = 1.145 (accuracy: 56.190%)\n",
      "Epoch 30: 15.641 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.202 (accuracy: 47.070%), validation loss = 1.195 (accuracy: 41.905%)\n",
      "Epoch 31: 15.710 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.164 (accuracy: 48.799%), validation loss = 1.131 (accuracy: 59.048%)\n",
      "Epoch 32: 15.701 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.179 (accuracy: 48.031%), validation loss = 1.125 (accuracy: 54.286%)\n",
      "Epoch 33: 15.621 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.186 (accuracy: 47.070%), validation loss = 1.143 (accuracy: 48.571%)\n",
      "Epoch 34: 15.575 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.173 (accuracy: 45.629%), validation loss = 1.175 (accuracy: 50.476%)\n",
      "Epoch 35: 15.683 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.182 (accuracy: 46.110%), validation loss = 1.142 (accuracy: 48.571%)\n",
      "Epoch 36: 15.735 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.163 (accuracy: 46.878%), validation loss = 1.169 (accuracy: 44.762%)\n",
      "Epoch 37: 15.769 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.192 (accuracy: 48.415%), validation loss = 1.168 (accuracy: 43.810%)\n",
      "Epoch 38: 15.652 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.176 (accuracy: 47.070%), validation loss = 1.178 (accuracy: 46.667%)\n",
      "Epoch 39: 16.022 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.190 (accuracy: 48.031%), validation loss = 1.162 (accuracy: 43.810%)\n",
      "Epoch 40: 15.600 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.193 (accuracy: 45.245%), validation loss = 1.219 (accuracy: 39.048%)\n",
      "Epoch 41: 15.614 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.186 (accuracy: 45.821%), validation loss = 1.169 (accuracy: 40.952%)\n",
      "Epoch 42: 15.656 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.149 (accuracy: 49.664%), validation loss = 1.124 (accuracy: 55.238%)\n",
      "Epoch 43: 15.892 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.202 (accuracy: 45.149%), validation loss = 1.192 (accuracy: 44.762%)\n",
      "Epoch 44: 15.475 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.183 (accuracy: 48.991%), validation loss = 1.129 (accuracy: 51.429%)\n",
      "Epoch 45: 15.425 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.164 (accuracy: 47.070%), validation loss = 1.173 (accuracy: 40.952%)\n",
      "Epoch 46: 15.528 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.183 (accuracy: 46.782%), validation loss = 1.186 (accuracy: 39.048%)\n",
      "Epoch 47: 15.603 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.196 (accuracy: 46.206%), validation loss = 1.148 (accuracy: 45.714%)\n",
      "Epoch 48: 15.503 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.176 (accuracy: 46.110%), validation loss = 1.127 (accuracy: 46.667%)\n",
      "Epoch 49: 15.536 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.187 (accuracy: 46.782%), validation loss = 1.202 (accuracy: 40.952%)\n",
      "Epoch 50: 15.417 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.173 (accuracy: 49.664%), validation loss = 1.132 (accuracy: 55.238%)\n",
      "Epoch 51: 15.433 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.188 (accuracy: 47.166%), validation loss = 1.135 (accuracy: 49.524%)\n",
      "Epoch 52: 15.590 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.184 (accuracy: 46.782%), validation loss = 1.141 (accuracy: 48.571%)\n",
      "Epoch 53: 15.458 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.171 (accuracy: 48.031%), validation loss = 1.253 (accuracy: 40.000%)\n",
      "Epoch 54: 15.342 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.192 (accuracy: 46.302%), validation loss = 1.118 (accuracy: 57.143%)\n",
      "Epoch 55: 15.502 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.188 (accuracy: 45.725%), validation loss = 1.141 (accuracy: 48.571%)\n",
      "Epoch 56: 16.127 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.161 (accuracy: 50.432%), validation loss = 1.130 (accuracy: 47.619%)\n",
      "Epoch 57: 16.038 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.160 (accuracy: 47.550%), validation loss = 1.157 (accuracy: 47.619%)\n",
      "Epoch 58: 16.247 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.157 (accuracy: 49.664%), validation loss = 1.109 (accuracy: 53.333%)\n",
      "Epoch 59: 16.391 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.171 (accuracy: 48.319%), validation loss = 1.155 (accuracy: 44.762%)\n",
      "Epoch 60: 15.744 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.161 (accuracy: 48.895%), validation loss = 1.136 (accuracy: 45.714%)\n",
      "Epoch 61: 15.672 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.158 (accuracy: 49.280%), validation loss = 1.122 (accuracy: 52.381%)\n",
      "Epoch 62: 15.831 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.153 (accuracy: 51.201%), validation loss = 1.112 (accuracy: 51.429%)\n",
      "Epoch 63: 15.761 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.177 (accuracy: 47.743%), validation loss = 1.139 (accuracy: 51.429%)\n",
      "Epoch 64: 15.607 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.172 (accuracy: 47.743%), validation loss = 1.107 (accuracy: 54.286%)\n",
      "Epoch 65: 15.794 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.170 (accuracy: 48.127%), validation loss = 1.146 (accuracy: 45.714%)\n",
      "Epoch 66: 15.551 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.170 (accuracy: 45.341%), validation loss = 1.133 (accuracy: 48.571%)\n",
      "Epoch 67: 15.680 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.153 (accuracy: 48.031%), validation loss = 1.093 (accuracy: 58.095%)\n",
      "Epoch 68: 15.764 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.167 (accuracy: 49.568%), validation loss = 1.132 (accuracy: 50.476%)\n",
      "Epoch 69: 15.575 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.163 (accuracy: 49.183%), validation loss = 1.112 (accuracy: 49.524%)\n",
      "Epoch 70: 15.759 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.162 (accuracy: 48.703%), validation loss = 1.116 (accuracy: 51.429%)\n",
      "Epoch 71: 15.668 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.172 (accuracy: 47.646%), validation loss = 1.108 (accuracy: 63.810%)\n",
      "Epoch 72: 15.984 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.188 (accuracy: 45.821%), validation loss = 1.150 (accuracy: 42.857%)\n",
      "Epoch 73: 15.764 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.146 (accuracy: 50.624%), validation loss = 1.104 (accuracy: 54.286%)\n",
      "Epoch 74: 15.710 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.144 (accuracy: 51.297%), validation loss = 1.147 (accuracy: 48.571%)\n",
      "Epoch 75: 15.867 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.163 (accuracy: 49.183%), validation loss = 1.140 (accuracy: 46.667%)\n",
      "Epoch 76: 15.809 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.136 (accuracy: 51.009%), validation loss = 1.122 (accuracy: 46.667%)\n",
      "Epoch 77: 16.138 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.164 (accuracy: 48.223%), validation loss = 1.145 (accuracy: 45.714%)\n",
      "Epoch 78: 16.334 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.165 (accuracy: 47.646%), validation loss = 1.137 (accuracy: 44.762%)\n",
      "Epoch 79: 15.616 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.164 (accuracy: 48.991%), validation loss = 1.103 (accuracy: 58.095%)\n",
      "Epoch 80: 15.733 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.152 (accuracy: 48.607%), validation loss = 1.151 (accuracy: 41.905%)\n",
      "Epoch 81: 15.640 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.172 (accuracy: 46.782%), validation loss = 1.105 (accuracy: 59.048%)\n",
      "Epoch 82: 15.488 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.147 (accuracy: 48.991%), validation loss = 1.104 (accuracy: 54.286%)\n",
      "Epoch 83: 15.407 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.152 (accuracy: 49.376%), validation loss = 1.104 (accuracy: 57.143%)\n",
      "Epoch 84: 15.275 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.149 (accuracy: 50.528%), validation loss = 1.152 (accuracy: 40.000%)\n",
      "Epoch 85: 15.225 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.164 (accuracy: 48.223%), validation loss = 1.105 (accuracy: 52.381%)\n",
      "Epoch 86: 15.253 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.162 (accuracy: 48.031%), validation loss = 1.187 (accuracy: 41.905%)\n",
      "Epoch 87: 15.221 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.155 (accuracy: 49.280%), validation loss = 1.119 (accuracy: 51.429%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 67 with minimum validation error = 1.0933945428757441\n",
      "3569.299 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.2\n",
      "Epoch 1: 15.339 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.302 (accuracy: 38.232%), validation loss = 1.258 (accuracy: 33.333%)\n",
      "Epoch 2: 15.365 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.278 (accuracy: 38.713%), validation loss = 1.244 (accuracy: 42.857%)\n",
      "Epoch 3: 15.459 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.237 (accuracy: 42.939%), validation loss = 1.262 (accuracy: 38.095%)\n",
      "Epoch 4: 15.165 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.238 (accuracy: 41.787%), validation loss = 1.203 (accuracy: 51.429%)\n",
      "Epoch 5: 15.384 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.251 (accuracy: 41.979%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 6: 15.258 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.259 (accuracy: 39.673%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 7: 15.215 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.247 (accuracy: 41.210%), validation loss = 1.253 (accuracy: 33.333%)\n",
      "Epoch 8: 15.175 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.266 (accuracy: 39.866%), validation loss = 1.251 (accuracy: 33.333%)\n",
      "Epoch 9: 15.186 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.261 (accuracy: 40.730%), validation loss = 1.252 (accuracy: 34.286%)\n",
      "Epoch 10: 15.110 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.261 (accuracy: 37.368%), validation loss = 1.260 (accuracy: 34.286%)\n",
      "Epoch 11: 15.676 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.255 (accuracy: 39.866%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 12: 15.391 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.257 (accuracy: 40.634%), validation loss = 1.250 (accuracy: 34.286%)\n",
      "Epoch 13: 15.228 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.266 (accuracy: 40.826%), validation loss = 1.252 (accuracy: 33.333%)\n",
      "Epoch 14: 15.223 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.247 (accuracy: 40.442%), validation loss = 1.228 (accuracy: 40.952%)\n",
      "Epoch 15: 15.406 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.253 (accuracy: 42.459%), validation loss = 1.231 (accuracy: 33.333%)\n",
      "Epoch 16: 15.296 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.247 (accuracy: 41.114%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 17: 15.231 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.256 (accuracy: 39.962%), validation loss = 1.238 (accuracy: 33.333%)\n",
      "Epoch 18: 15.142 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.261 (accuracy: 41.018%), validation loss = 1.259 (accuracy: 33.333%)\n",
      "Epoch 19: 15.186 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.252 (accuracy: 38.905%), validation loss = 1.270 (accuracy: 40.952%)\n",
      "Epoch 20: 15.168 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.268 (accuracy: 40.826%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 21: 15.263 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.257 (accuracy: 40.250%), validation loss = 1.235 (accuracy: 36.190%)\n",
      "Epoch 22: 15.319 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.252 (accuracy: 39.673%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 23: 15.330 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.252 (accuracy: 39.962%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 24: 15.346 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.261 (accuracy: 39.097%), validation loss = 1.239 (accuracy: 34.286%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 4 with minimum validation error = 1.2025058121908279\n",
      "3937.905 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0\n",
      "Epoch 1: 15.192 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.296 (accuracy: 36.599%), validation loss = 1.260 (accuracy: 36.190%)\n",
      "Epoch 2: 15.524 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.254 (accuracy: 41.691%), validation loss = 1.212 (accuracy: 37.143%)\n",
      "Epoch 3: 15.642 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.208 (accuracy: 45.917%), validation loss = 1.190 (accuracy: 40.952%)\n",
      "Epoch 4: 15.442 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.184 (accuracy: 48.319%), validation loss = 1.151 (accuracy: 50.476%)\n",
      "Epoch 5: 15.453 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.161 (accuracy: 48.607%), validation loss = 1.114 (accuracy: 50.476%)\n",
      "Epoch 6: 15.443 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.145 (accuracy: 49.087%), validation loss = 1.109 (accuracy: 47.619%)\n",
      "Epoch 7: 15.833 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.137 (accuracy: 49.856%), validation loss = 1.136 (accuracy: 45.714%)\n",
      "Epoch 8: 15.486 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.095 (accuracy: 51.777%), validation loss = 1.130 (accuracy: 46.667%)\n",
      "Epoch 9: 15.216 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.094 (accuracy: 53.122%), validation loss = 1.061 (accuracy: 55.238%)\n",
      "Epoch 10: 15.630 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.070 (accuracy: 54.851%), validation loss = 1.103 (accuracy: 46.667%)\n",
      "Epoch 11: 15.286 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.064 (accuracy: 55.427%), validation loss = 1.021 (accuracy: 59.048%)\n",
      "Epoch 12: 15.430 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.040 (accuracy: 56.484%), validation loss = 1.041 (accuracy: 53.333%)\n",
      "Epoch 13: 15.462 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.049 (accuracy: 54.179%), validation loss = 1.059 (accuracy: 49.524%)\n",
      "Epoch 14: 15.251 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.038 (accuracy: 56.388%), validation loss = 1.033 (accuracy: 50.476%)\n",
      "Epoch 15: 15.264 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.031 (accuracy: 56.964%), validation loss = 1.030 (accuracy: 56.190%)\n",
      "Epoch 16: 15.202 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.020 (accuracy: 57.541%), validation loss = 1.065 (accuracy: 50.476%)\n",
      "Epoch 17: 15.210 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.009 (accuracy: 56.868%), validation loss = 1.038 (accuracy: 52.381%)\n",
      "Epoch 18: 15.305 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.012 (accuracy: 57.829%), validation loss = 1.033 (accuracy: 54.286%)\n",
      "Epoch 19: 15.302 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 0.977 (accuracy: 60.999%), validation loss = 1.018 (accuracy: 56.190%)\n",
      "Epoch 20: 15.481 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 0.984 (accuracy: 59.750%), validation loss = 0.992 (accuracy: 60.952%)\n",
      "Epoch 21: 15.495 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 0.968 (accuracy: 60.327%), validation loss = 0.998 (accuracy: 57.143%)\n",
      "Epoch 22: 15.270 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 0.982 (accuracy: 58.405%), validation loss = 1.003 (accuracy: 58.095%)\n",
      "Epoch 23: 15.329 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 0.997 (accuracy: 56.868%), validation loss = 0.983 (accuracy: 60.000%)\n",
      "Epoch 24: 15.540 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.961 (accuracy: 59.270%), validation loss = 0.978 (accuracy: 60.000%)\n",
      "Epoch 25: 15.784 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 0.988 (accuracy: 60.038%), validation loss = 0.993 (accuracy: 57.143%)\n",
      "Epoch 26: 15.539 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.952 (accuracy: 59.078%), validation loss = 0.991 (accuracy: 56.190%)\n",
      "Epoch 27: 15.937 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 0.959 (accuracy: 61.095%), validation loss = 0.976 (accuracy: 59.048%)\n",
      "Epoch 28: 15.845 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.948 (accuracy: 58.501%), validation loss = 0.974 (accuracy: 59.048%)\n",
      "Epoch 29: 15.695 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.936 (accuracy: 60.903%), validation loss = 0.975 (accuracy: 58.095%)\n",
      "Epoch 30: 15.672 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.936 (accuracy: 60.807%), validation loss = 0.974 (accuracy: 56.190%)\n",
      "Epoch 31: 15.603 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.940 (accuracy: 61.479%), validation loss = 0.972 (accuracy: 59.048%)\n",
      "Epoch 32: 15.569 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.916 (accuracy: 64.169%), validation loss = 0.961 (accuracy: 62.857%)\n",
      "Epoch 33: 15.656 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.928 (accuracy: 61.575%), validation loss = 0.990 (accuracy: 60.000%)\n",
      "Epoch 34: 15.624 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.914 (accuracy: 62.056%), validation loss = 1.011 (accuracy: 59.048%)\n",
      "Epoch 35: 15.407 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.938 (accuracy: 60.327%), validation loss = 0.971 (accuracy: 56.190%)\n",
      "Epoch 36: 15.374 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.929 (accuracy: 61.671%), validation loss = 1.003 (accuracy: 56.190%)\n",
      "Epoch 37: 15.299 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.889 (accuracy: 64.361%), validation loss = 0.995 (accuracy: 59.048%)\n",
      "Epoch 38: 15.231 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.913 (accuracy: 62.056%), validation loss = 0.964 (accuracy: 58.095%)\n",
      "Epoch 39: 15.300 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.898 (accuracy: 61.383%), validation loss = 0.964 (accuracy: 56.190%)\n",
      "Epoch 40: 15.173 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.918 (accuracy: 62.728%), validation loss = 0.948 (accuracy: 60.000%)\n",
      "Epoch 41: 15.464 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.909 (accuracy: 62.824%), validation loss = 0.954 (accuracy: 58.095%)\n",
      "Epoch 42: 15.366 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.874 (accuracy: 65.610%), validation loss = 0.992 (accuracy: 59.048%)\n",
      "Epoch 43: 15.227 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.907 (accuracy: 63.112%), validation loss = 0.959 (accuracy: 59.048%)\n",
      "Epoch 44: 15.355 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.899 (accuracy: 63.305%), validation loss = 0.986 (accuracy: 58.095%)\n",
      "Epoch 45: 15.229 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.885 (accuracy: 63.593%), validation loss = 0.977 (accuracy: 59.048%)\n",
      "Epoch 46: 15.247 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.855 (accuracy: 63.208%), validation loss = 0.948 (accuracy: 58.095%)\n",
      "Epoch 47: 15.392 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.893 (accuracy: 65.034%), validation loss = 0.963 (accuracy: 59.048%)\n",
      "Epoch 48: 15.199 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.915 (accuracy: 62.056%), validation loss = 0.977 (accuracy: 58.095%)\n",
      "Epoch 49: 15.259 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.892 (accuracy: 62.824%), validation loss = 1.000 (accuracy: 58.095%)\n",
      "Epoch 50: 15.382 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.883 (accuracy: 62.152%), validation loss = 0.996 (accuracy: 60.000%)\n",
      "Epoch 51: 15.057 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.910 (accuracy: 62.728%), validation loss = 0.959 (accuracy: 57.143%)\n",
      "Epoch 52: 15.039 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.870 (accuracy: 63.785%), validation loss = 0.949 (accuracy: 60.952%)\n",
      "Epoch 53: 15.097 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.893 (accuracy: 63.208%), validation loss = 0.960 (accuracy: 57.143%)\n",
      "Epoch 54: 15.185 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.877 (accuracy: 64.073%), validation loss = 0.970 (accuracy: 60.000%)\n",
      "Epoch 55: 15.210 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.859 (accuracy: 64.073%), validation loss = 0.947 (accuracy: 58.095%)\n",
      "Epoch 56: 15.412 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.893 (accuracy: 64.073%), validation loss = 0.976 (accuracy: 59.048%)\n",
      "Epoch 57: 15.080 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.880 (accuracy: 64.553%), validation loss = 0.950 (accuracy: 59.048%)\n",
      "Epoch 58: 15.218 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.891 (accuracy: 62.344%), validation loss = 0.937 (accuracy: 58.095%)\n",
      "Epoch 59: 15.433 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.819 (accuracy: 65.034%), validation loss = 0.976 (accuracy: 60.000%)\n",
      "Epoch 60: 15.348 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.856 (accuracy: 63.689%), validation loss = 0.938 (accuracy: 60.000%)\n",
      "Epoch 61: 15.097 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.846 (accuracy: 63.881%), validation loss = 0.976 (accuracy: 59.048%)\n",
      "Epoch 62: 15.138 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.862 (accuracy: 63.305%), validation loss = 0.976 (accuracy: 57.143%)\n",
      "Epoch 63: 15.158 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.856 (accuracy: 64.745%), validation loss = 0.953 (accuracy: 59.048%)\n",
      "Epoch 64: 15.273 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.856 (accuracy: 65.034%), validation loss = 0.957 (accuracy: 62.857%)\n",
      "Epoch 65: 15.366 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.849 (accuracy: 66.186%), validation loss = 0.933 (accuracy: 62.857%)\n",
      "Epoch 66: 15.548 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.839 (accuracy: 65.514%), validation loss = 0.951 (accuracy: 59.048%)\n",
      "Epoch 67: 15.467 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.851 (accuracy: 64.649%), validation loss = 0.950 (accuracy: 60.000%)\n",
      "Epoch 68: 15.770 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.866 (accuracy: 64.938%), validation loss = 0.931 (accuracy: 58.095%)\n",
      "Epoch 69: 15.694 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.874 (accuracy: 65.322%), validation loss = 0.939 (accuracy: 61.905%)\n",
      "Epoch 70: 15.478 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.878 (accuracy: 63.401%), validation loss = 0.954 (accuracy: 58.095%)\n",
      "Epoch 71: 15.440 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.836 (accuracy: 67.723%), validation loss = 0.941 (accuracy: 60.952%)\n",
      "Epoch 72: 15.417 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.855 (accuracy: 65.610%), validation loss = 0.940 (accuracy: 62.857%)\n",
      "Epoch 73: 15.342 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.851 (accuracy: 65.610%), validation loss = 0.975 (accuracy: 60.000%)\n",
      "Epoch 74: 15.271 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.871 (accuracy: 63.977%), validation loss = 0.920 (accuracy: 61.905%)\n",
      "Epoch 75: 15.590 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.844 (accuracy: 65.130%), validation loss = 0.953 (accuracy: 60.000%)\n",
      "Epoch 76: 15.394 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.842 (accuracy: 66.090%), validation loss = 0.977 (accuracy: 60.000%)\n",
      "Epoch 77: 15.274 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.841 (accuracy: 64.841%), validation loss = 0.988 (accuracy: 55.238%)\n",
      "Epoch 78: 15.192 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.833 (accuracy: 65.130%), validation loss = 0.960 (accuracy: 60.952%)\n",
      "Epoch 79: 15.256 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.843 (accuracy: 66.186%), validation loss = 0.953 (accuracy: 58.095%)\n",
      "Epoch 80: 15.182 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.844 (accuracy: 65.130%), validation loss = 0.935 (accuracy: 60.000%)\n",
      "Epoch 81: 15.400 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.838 (accuracy: 65.034%), validation loss = 0.946 (accuracy: 58.095%)\n",
      "Epoch 82: 15.219 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.868 (accuracy: 63.689%), validation loss = 0.937 (accuracy: 60.000%)\n",
      "Epoch 83: 15.388 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.853 (accuracy: 65.034%), validation loss = 0.980 (accuracy: 58.095%)\n",
      "Epoch 84: 15.295 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.829 (accuracy: 65.706%), validation loss = 0.950 (accuracy: 61.905%)\n",
      "Epoch 85: 15.314 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.828 (accuracy: 66.571%), validation loss = 0.944 (accuracy: 60.000%)\n",
      "Epoch 86: 15.437 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.833 (accuracy: 65.322%), validation loss = 0.993 (accuracy: 60.000%)\n",
      "Epoch 87: 15.297 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.830 (accuracy: 66.955%), validation loss = 0.944 (accuracy: 61.905%)\n",
      "Epoch 88: 15.795 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.849 (accuracy: 63.593%), validation loss = 0.955 (accuracy: 60.952%)\n",
      "Epoch 89: 15.408 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.837 (accuracy: 65.130%), validation loss = 0.948 (accuracy: 61.905%)\n",
      "Epoch 90: 15.271 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.833 (accuracy: 63.785%), validation loss = 0.960 (accuracy: 62.857%)\n",
      "Epoch 91: 15.408 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.842 (accuracy: 66.859%), validation loss = 0.947 (accuracy: 58.095%)\n",
      "Epoch 92: 15.341 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.821 (accuracy: 65.130%), validation loss = 0.974 (accuracy: 58.095%)\n",
      "Epoch 93: 15.313 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.816 (accuracy: 66.282%), validation loss = 0.965 (accuracy: 57.143%)\n",
      "Epoch 94: 15.251 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.823 (accuracy: 64.841%), validation loss = 0.937 (accuracy: 60.000%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 74 with minimum validation error = 0.9198034155936469\n",
      "5393.113 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.1\n",
      "Epoch 1: 15.435 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.300 (accuracy: 36.407%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 2: 15.503 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.253 (accuracy: 43.324%), validation loss = 1.258 (accuracy: 35.238%)\n",
      "Epoch 3: 15.585 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.228 (accuracy: 43.516%), validation loss = 1.184 (accuracy: 44.762%)\n",
      "Epoch 4: 15.522 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.205 (accuracy: 46.398%), validation loss = 1.202 (accuracy: 41.905%)\n",
      "Epoch 5: 15.294 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.193 (accuracy: 47.358%), validation loss = 1.184 (accuracy: 42.857%)\n",
      "Epoch 6: 15.562 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.170 (accuracy: 47.646%), validation loss = 1.152 (accuracy: 45.714%)\n",
      "Epoch 7: 15.585 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.152 (accuracy: 47.743%), validation loss = 1.158 (accuracy: 41.905%)\n",
      "Epoch 8: 15.357 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.153 (accuracy: 48.991%), validation loss = 1.105 (accuracy: 50.476%)\n",
      "Epoch 9: 15.618 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.135 (accuracy: 50.817%), validation loss = 1.105 (accuracy: 50.476%)\n",
      "Epoch 10: 15.312 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.124 (accuracy: 51.489%), validation loss = 1.084 (accuracy: 53.333%)\n",
      "Epoch 11: 15.529 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.106 (accuracy: 53.890%), validation loss = 1.139 (accuracy: 44.762%)\n",
      "Epoch 12: 15.322 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.113 (accuracy: 50.817%), validation loss = 1.074 (accuracy: 50.476%)\n",
      "Epoch 13: 15.846 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.101 (accuracy: 53.602%), validation loss = 1.071 (accuracy: 49.524%)\n",
      "Epoch 14: 15.956 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.096 (accuracy: 54.179%), validation loss = 1.093 (accuracy: 48.571%)\n",
      "Epoch 15: 15.368 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.102 (accuracy: 53.602%), validation loss = 1.084 (accuracy: 52.381%)\n",
      "Epoch 16: 15.231 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.095 (accuracy: 54.179%), validation loss = 1.078 (accuracy: 49.524%)\n",
      "Epoch 17: 15.230 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.097 (accuracy: 52.738%), validation loss = 1.075 (accuracy: 51.429%)\n",
      "Epoch 18: 15.626 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.092 (accuracy: 54.179%), validation loss = 1.056 (accuracy: 55.238%)\n",
      "Epoch 19: 15.783 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.084 (accuracy: 54.947%), validation loss = 1.079 (accuracy: 48.571%)\n",
      "Epoch 20: 15.453 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.080 (accuracy: 54.563%), validation loss = 1.070 (accuracy: 47.619%)\n",
      "Epoch 21: 15.442 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.081 (accuracy: 54.083%), validation loss = 1.052 (accuracy: 57.143%)\n",
      "Epoch 22: 15.677 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.099 (accuracy: 53.890%), validation loss = 1.107 (accuracy: 47.619%)\n",
      "Epoch 23: 15.461 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.072 (accuracy: 55.235%), validation loss = 1.078 (accuracy: 46.667%)\n",
      "Epoch 24: 15.243 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.054 (accuracy: 56.004%), validation loss = 1.051 (accuracy: 51.429%)\n",
      "Epoch 25: 17.443 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.052 (accuracy: 56.964%), validation loss = 1.039 (accuracy: 54.286%)\n",
      "Epoch 26: 15.581 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.054 (accuracy: 54.275%), validation loss = 1.038 (accuracy: 53.333%)\n",
      "Epoch 27: 15.538 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.073 (accuracy: 55.716%), validation loss = 1.044 (accuracy: 49.524%)\n",
      "Epoch 28: 15.345 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.057 (accuracy: 56.196%), validation loss = 1.059 (accuracy: 49.524%)\n",
      "Epoch 29: 15.336 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.098 (accuracy: 51.393%), validation loss = 1.052 (accuracy: 49.524%)\n",
      "Epoch 30: 15.376 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.060 (accuracy: 56.868%), validation loss = 1.040 (accuracy: 50.476%)\n",
      "Epoch 31: 15.404 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.054 (accuracy: 55.235%), validation loss = 1.053 (accuracy: 53.333%)\n",
      "Epoch 32: 15.292 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.060 (accuracy: 53.602%), validation loss = 1.055 (accuracy: 53.333%)\n",
      "Epoch 33: 15.638 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.060 (accuracy: 55.331%), validation loss = 1.036 (accuracy: 53.333%)\n",
      "Epoch 34: 16.624 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.060 (accuracy: 55.427%), validation loss = 1.024 (accuracy: 57.143%)\n",
      "Epoch 35: 16.331 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.063 (accuracy: 55.524%), validation loss = 1.031 (accuracy: 60.000%)\n",
      "Epoch 36: 16.294 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.053 (accuracy: 56.292%), validation loss = 1.025 (accuracy: 56.190%)\n",
      "Epoch 37: 15.955 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.070 (accuracy: 54.755%), validation loss = 1.062 (accuracy: 51.429%)\n",
      "Epoch 38: 16.558 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.059 (accuracy: 56.100%), validation loss = 1.051 (accuracy: 52.381%)\n",
      "Epoch 39: 16.511 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.041 (accuracy: 57.157%), validation loss = 1.022 (accuracy: 53.333%)\n",
      "Epoch 40: 16.781 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.042 (accuracy: 56.772%), validation loss = 1.062 (accuracy: 51.429%)\n",
      "Epoch 41: 16.508 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.049 (accuracy: 54.467%), validation loss = 1.107 (accuracy: 43.810%)\n",
      "Epoch 42: 16.541 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.061 (accuracy: 54.659%), validation loss = 1.031 (accuracy: 53.333%)\n",
      "Epoch 43: 16.694 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.033 (accuracy: 57.925%), validation loss = 1.067 (accuracy: 49.524%)\n",
      "Epoch 44: 16.705 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.051 (accuracy: 55.908%), validation loss = 1.028 (accuracy: 52.381%)\n",
      "Epoch 45: 16.610 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.051 (accuracy: 55.524%), validation loss = 1.024 (accuracy: 54.286%)\n",
      "Epoch 46: 16.472 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.030 (accuracy: 57.061%), validation loss = 1.025 (accuracy: 54.286%)\n",
      "Epoch 47: 16.523 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.048 (accuracy: 56.964%), validation loss = 1.054 (accuracy: 52.381%)\n",
      "Epoch 48: 16.385 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.056 (accuracy: 55.908%), validation loss = 1.068 (accuracy: 50.476%)\n",
      "Epoch 49: 15.625 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.038 (accuracy: 56.100%), validation loss = 1.033 (accuracy: 52.381%)\n",
      "Epoch 50: 15.580 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.038 (accuracy: 56.580%), validation loss = 1.028 (accuracy: 50.476%)\n",
      "Epoch 51: 15.511 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.037 (accuracy: 56.388%), validation loss = 1.016 (accuracy: 60.952%)\n",
      "Epoch 52: 16.190 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.030 (accuracy: 58.694%), validation loss = 1.021 (accuracy: 50.476%)\n",
      "Epoch 53: 15.881 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.021 (accuracy: 57.829%), validation loss = 1.020 (accuracy: 54.286%)\n",
      "Epoch 54: 15.485 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.028 (accuracy: 57.349%), validation loss = 1.031 (accuracy: 51.429%)\n",
      "Epoch 55: 15.517 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.010 (accuracy: 58.405%), validation loss = 1.048 (accuracy: 49.524%)\n",
      "Epoch 56: 15.496 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.027 (accuracy: 58.021%), validation loss = 1.020 (accuracy: 57.143%)\n",
      "Epoch 57: 15.466 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.042 (accuracy: 55.716%), validation loss = 1.046 (accuracy: 51.429%)\n",
      "Epoch 58: 15.709 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.026 (accuracy: 57.733%), validation loss = 1.043 (accuracy: 51.429%)\n",
      "Epoch 59: 15.556 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.015 (accuracy: 58.694%), validation loss = 1.021 (accuracy: 49.524%)\n",
      "Epoch 60: 15.516 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.045 (accuracy: 55.908%), validation loss = 1.006 (accuracy: 59.048%)\n",
      "Epoch 61: 15.972 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.030 (accuracy: 57.733%), validation loss = 1.034 (accuracy: 48.571%)\n",
      "Epoch 62: 15.744 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.016 (accuracy: 58.694%), validation loss = 1.021 (accuracy: 50.476%)\n",
      "Epoch 63: 15.956 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.030 (accuracy: 57.541%), validation loss = 1.014 (accuracy: 56.190%)\n",
      "Epoch 64: 15.758 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.050 (accuracy: 55.524%), validation loss = 1.043 (accuracy: 56.190%)\n",
      "Epoch 65: 15.646 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.047 (accuracy: 55.139%), validation loss = 1.021 (accuracy: 52.381%)\n",
      "Epoch 66: 15.633 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.039 (accuracy: 54.563%), validation loss = 1.055 (accuracy: 48.571%)\n",
      "Epoch 67: 15.614 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.037 (accuracy: 56.004%), validation loss = 1.086 (accuracy: 47.619%)\n",
      "Epoch 68: 15.778 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.040 (accuracy: 55.235%), validation loss = 1.035 (accuracy: 51.429%)\n",
      "Epoch 69: 15.559 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.032 (accuracy: 57.157%), validation loss = 1.007 (accuracy: 54.286%)\n",
      "Epoch 70: 15.587 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.009 (accuracy: 57.829%), validation loss = 1.021 (accuracy: 55.238%)\n",
      "Epoch 71: 15.802 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.031 (accuracy: 56.772%), validation loss = 1.012 (accuracy: 54.286%)\n",
      "Epoch 72: 16.039 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.037 (accuracy: 57.733%), validation loss = 1.042 (accuracy: 50.476%)\n",
      "Epoch 73: 15.392 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.020 (accuracy: 58.598%), validation loss = 1.044 (accuracy: 52.381%)\n",
      "Epoch 74: 15.340 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.015 (accuracy: 58.694%), validation loss = 1.039 (accuracy: 52.381%)\n",
      "Epoch 75: 15.311 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.017 (accuracy: 56.388%), validation loss = 1.013 (accuracy: 54.286%)\n",
      "Epoch 76: 16.182 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.038 (accuracy: 54.371%), validation loss = 1.008 (accuracy: 58.095%)\n",
      "Epoch 77: 16.121 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.029 (accuracy: 57.061%), validation loss = 1.009 (accuracy: 58.095%)\n",
      "Epoch 78: 16.395 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.051 (accuracy: 55.427%), validation loss = 1.001 (accuracy: 53.333%)\n",
      "Epoch 79: 16.121 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.034 (accuracy: 58.501%), validation loss = 1.036 (accuracy: 51.429%)\n",
      "Epoch 80: 15.891 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.013 (accuracy: 58.117%), validation loss = 1.013 (accuracy: 50.476%)\n",
      "Epoch 81: 15.787 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.023 (accuracy: 56.196%), validation loss = 1.015 (accuracy: 56.190%)\n",
      "Epoch 82: 15.806 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.045 (accuracy: 56.388%), validation loss = 1.005 (accuracy: 56.190%)\n",
      "Epoch 83: 15.946 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.048 (accuracy: 57.541%), validation loss = 1.019 (accuracy: 51.429%)\n",
      "Epoch 84: 15.887 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.012 (accuracy: 59.270%), validation loss = 1.020 (accuracy: 53.333%)\n",
      "Epoch 85: 15.785 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.032 (accuracy: 57.253%), validation loss = 1.032 (accuracy: 48.571%)\n",
      "Epoch 86: 15.828 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.064 (accuracy: 54.083%), validation loss = 1.010 (accuracy: 52.381%)\n",
      "Epoch 87: 15.701 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.039 (accuracy: 56.580%), validation loss = 1.036 (accuracy: 51.429%)\n",
      "Epoch 88: 15.877 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.002 (accuracy: 59.750%), validation loss = 1.016 (accuracy: 57.143%)\n",
      "Epoch 89: 15.741 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.038 (accuracy: 54.659%), validation loss = 1.003 (accuracy: 53.333%)\n",
      "Epoch 90: 15.780 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.046 (accuracy: 54.371%), validation loss = 1.047 (accuracy: 49.524%)\n",
      "Epoch 91: 15.749 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.041 (accuracy: 55.524%), validation loss = 1.023 (accuracy: 51.429%)\n",
      "Epoch 92: 16.234 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.018 (accuracy: 57.637%), validation loss = 1.013 (accuracy: 54.286%)\n",
      "Epoch 93: 15.755 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.029 (accuracy: 56.004%), validation loss = 1.017 (accuracy: 52.381%)\n",
      "Epoch 94: 15.862 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.033 (accuracy: 57.157%), validation loss = 1.116 (accuracy: 46.667%)\n",
      "Epoch 95: 15.697 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.042 (accuracy: 54.467%), validation loss = 1.026 (accuracy: 52.381%)\n",
      "Epoch 96: 15.712 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.013 (accuracy: 56.964%), validation loss = 1.026 (accuracy: 56.190%)\n",
      "Epoch 97: 15.717 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.028 (accuracy: 56.868%), validation loss = 1.032 (accuracy: 50.476%)\n",
      "Epoch 98: 15.794 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.018 (accuracy: 57.541%), validation loss = 1.008 (accuracy: 52.381%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 78 with minimum validation error = 1.0012423742385137\n",
      "6949.873 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.2\n",
      "Epoch 1: 15.872 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.293 (accuracy: 38.905%), validation loss = 1.266 (accuracy: 33.333%)\n",
      "Epoch 2: 15.941 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.278 (accuracy: 39.962%), validation loss = 1.258 (accuracy: 35.238%)\n",
      "Epoch 3: 15.925 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.251 (accuracy: 42.555%), validation loss = 1.237 (accuracy: 33.333%)\n",
      "Epoch 4: 15.920 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.226 (accuracy: 43.228%), validation loss = 1.205 (accuracy: 43.810%)\n",
      "Epoch 5: 15.939 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.222 (accuracy: 43.612%), validation loss = 1.204 (accuracy: 41.905%)\n",
      "Epoch 6: 15.963 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.215 (accuracy: 44.092%), validation loss = 1.172 (accuracy: 46.667%)\n",
      "Epoch 7: 15.894 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.214 (accuracy: 46.013%), validation loss = 1.190 (accuracy: 40.000%)\n",
      "Epoch 8: 15.726 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.188 (accuracy: 47.935%), validation loss = 1.202 (accuracy: 41.905%)\n",
      "Epoch 9: 15.669 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.177 (accuracy: 48.991%), validation loss = 1.154 (accuracy: 45.714%)\n",
      "Epoch 10: 15.923 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.178 (accuracy: 50.144%), validation loss = 1.153 (accuracy: 48.571%)\n",
      "Epoch 11: 15.871 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.180 (accuracy: 49.472%), validation loss = 1.166 (accuracy: 44.762%)\n",
      "Epoch 12: 15.636 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.179 (accuracy: 49.568%), validation loss = 1.202 (accuracy: 36.190%)\n",
      "Epoch 13: 16.213 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.182 (accuracy: 48.703%), validation loss = 1.134 (accuracy: 46.667%)\n",
      "Epoch 14: 15.888 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.176 (accuracy: 49.472%), validation loss = 1.153 (accuracy: 44.762%)\n",
      "Epoch 15: 15.595 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.168 (accuracy: 50.048%), validation loss = 1.127 (accuracy: 48.571%)\n",
      "Epoch 16: 15.914 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.168 (accuracy: 49.664%), validation loss = 1.158 (accuracy: 43.810%)\n",
      "Epoch 17: 15.486 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.166 (accuracy: 50.336%), validation loss = 1.135 (accuracy: 49.524%)\n",
      "Epoch 18: 15.592 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.157 (accuracy: 52.738%), validation loss = 1.157 (accuracy: 45.714%)\n",
      "Epoch 19: 15.534 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.163 (accuracy: 49.472%), validation loss = 1.151 (accuracy: 44.762%)\n",
      "Epoch 20: 15.609 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.154 (accuracy: 49.856%), validation loss = 1.197 (accuracy: 40.000%)\n",
      "Epoch 21: 15.583 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.162 (accuracy: 50.240%), validation loss = 1.194 (accuracy: 40.952%)\n",
      "Epoch 22: 15.537 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.162 (accuracy: 49.856%), validation loss = 1.174 (accuracy: 43.810%)\n",
      "Epoch 23: 15.499 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.158 (accuracy: 51.777%), validation loss = 1.131 (accuracy: 53.333%)\n",
      "Epoch 24: 15.563 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.138 (accuracy: 51.201%), validation loss = 1.136 (accuracy: 48.571%)\n",
      "Epoch 25: 15.484 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.155 (accuracy: 50.624%), validation loss = 1.150 (accuracy: 43.810%)\n",
      "Epoch 26: 15.678 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.158 (accuracy: 48.799%), validation loss = 1.133 (accuracy: 48.571%)\n",
      "Epoch 27: 15.493 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.160 (accuracy: 50.720%), validation loss = 1.171 (accuracy: 42.857%)\n",
      "Epoch 28: 15.556 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.162 (accuracy: 51.201%), validation loss = 1.124 (accuracy: 53.333%)\n",
      "Epoch 29: 15.791 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.155 (accuracy: 51.681%), validation loss = 1.145 (accuracy: 44.762%)\n",
      "Epoch 30: 15.540 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.153 (accuracy: 50.432%), validation loss = 1.118 (accuracy: 59.048%)\n",
      "Epoch 31: 15.870 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.157 (accuracy: 51.297%), validation loss = 1.141 (accuracy: 46.667%)\n",
      "Epoch 32: 15.711 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.150 (accuracy: 49.568%), validation loss = 1.189 (accuracy: 37.143%)\n",
      "Epoch 33: 16.067 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.144 (accuracy: 51.297%), validation loss = 1.142 (accuracy: 52.381%)\n",
      "Epoch 34: 15.576 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.162 (accuracy: 50.144%), validation loss = 1.132 (accuracy: 52.381%)\n",
      "Epoch 35: 15.626 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.149 (accuracy: 50.048%), validation loss = 1.125 (accuracy: 48.571%)\n",
      "Epoch 36: 15.778 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.153 (accuracy: 51.873%), validation loss = 1.192 (accuracy: 40.952%)\n",
      "Epoch 37: 15.620 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.160 (accuracy: 50.817%), validation loss = 1.121 (accuracy: 55.238%)\n",
      "Epoch 38: 15.549 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.157 (accuracy: 51.105%), validation loss = 1.122 (accuracy: 54.286%)\n",
      "Epoch 39: 15.647 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.166 (accuracy: 50.817%), validation loss = 1.125 (accuracy: 50.476%)\n",
      "Epoch 40: 15.658 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.163 (accuracy: 50.336%), validation loss = 1.131 (accuracy: 50.476%)\n",
      "Epoch 41: 15.806 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.151 (accuracy: 54.371%), validation loss = 1.188 (accuracy: 41.905%)\n",
      "Epoch 42: 15.629 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.166 (accuracy: 49.760%), validation loss = 1.161 (accuracy: 41.905%)\n",
      "Epoch 43: 15.661 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.162 (accuracy: 49.856%), validation loss = 1.118 (accuracy: 49.524%)\n",
      "Epoch 44: 15.626 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.149 (accuracy: 51.681%), validation loss = 1.128 (accuracy: 52.381%)\n",
      "Epoch 45: 15.580 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.146 (accuracy: 50.817%), validation loss = 1.157 (accuracy: 42.857%)\n",
      "Epoch 46: 15.759 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.144 (accuracy: 53.026%), validation loss = 1.152 (accuracy: 45.714%)\n",
      "Epoch 47: 15.768 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.156 (accuracy: 49.472%), validation loss = 1.143 (accuracy: 49.524%)\n",
      "Epoch 48: 15.668 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.148 (accuracy: 51.201%), validation loss = 1.133 (accuracy: 51.429%)\n",
      "Epoch 49: 15.655 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.147 (accuracy: 51.201%), validation loss = 1.117 (accuracy: 48.571%)\n",
      "Epoch 50: 15.894 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.145 (accuracy: 52.546%), validation loss = 1.116 (accuracy: 54.286%)\n",
      "Epoch 51: 15.947 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.147 (accuracy: 52.161%), validation loss = 1.126 (accuracy: 49.524%)\n",
      "Epoch 52: 15.976 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.146 (accuracy: 50.817%), validation loss = 1.165 (accuracy: 42.857%)\n",
      "Epoch 53: 15.948 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.130 (accuracy: 53.122%), validation loss = 1.113 (accuracy: 54.286%)\n",
      "Epoch 54: 15.903 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.157 (accuracy: 51.105%), validation loss = 1.146 (accuracy: 50.476%)\n",
      "Epoch 55: 15.636 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.139 (accuracy: 52.642%), validation loss = 1.137 (accuracy: 45.714%)\n",
      "Epoch 56: 15.738 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.141 (accuracy: 53.026%), validation loss = 1.114 (accuracy: 51.429%)\n",
      "Epoch 57: 15.667 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.150 (accuracy: 52.450%), validation loss = 1.116 (accuracy: 60.000%)\n",
      "Epoch 58: 15.606 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.148 (accuracy: 51.201%), validation loss = 1.129 (accuracy: 51.429%)\n",
      "Epoch 59: 15.590 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.146 (accuracy: 52.738%), validation loss = 1.148 (accuracy: 44.762%)\n",
      "Epoch 60: 15.669 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.146 (accuracy: 49.760%), validation loss = 1.125 (accuracy: 50.476%)\n",
      "Epoch 61: 15.643 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.131 (accuracy: 54.083%), validation loss = 1.111 (accuracy: 48.571%)\n",
      "Epoch 62: 15.970 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.150 (accuracy: 52.065%), validation loss = 1.170 (accuracy: 41.905%)\n",
      "Epoch 63: 15.682 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.142 (accuracy: 52.065%), validation loss = 1.128 (accuracy: 48.571%)\n",
      "Epoch 64: 15.731 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.153 (accuracy: 50.144%), validation loss = 1.140 (accuracy: 49.524%)\n",
      "Epoch 65: 15.642 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.144 (accuracy: 51.489%), validation loss = 1.120 (accuracy: 49.524%)\n",
      "Epoch 66: 15.863 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.140 (accuracy: 52.642%), validation loss = 1.120 (accuracy: 49.524%)\n",
      "Epoch 67: 15.929 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.139 (accuracy: 54.371%), validation loss = 1.140 (accuracy: 46.667%)\n",
      "Epoch 68: 15.833 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.149 (accuracy: 51.009%), validation loss = 1.133 (accuracy: 48.571%)\n",
      "Epoch 69: 15.704 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.144 (accuracy: 51.777%), validation loss = 1.120 (accuracy: 47.619%)\n",
      "Epoch 70: 15.709 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.148 (accuracy: 51.777%), validation loss = 1.132 (accuracy: 50.476%)\n",
      "Epoch 71: 15.915 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.142 (accuracy: 51.297%), validation loss = 1.122 (accuracy: 52.381%)\n",
      "Epoch 72: 16.229 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.155 (accuracy: 51.009%), validation loss = 1.166 (accuracy: 43.810%)\n",
      "Epoch 73: 15.702 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.137 (accuracy: 52.834%), validation loss = 1.120 (accuracy: 55.238%)\n",
      "Epoch 74: 15.553 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.139 (accuracy: 53.218%), validation loss = 1.149 (accuracy: 43.810%)\n",
      "Epoch 75: 15.600 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.136 (accuracy: 51.201%), validation loss = 1.145 (accuracy: 44.762%)\n",
      "Epoch 76: 15.662 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.134 (accuracy: 51.297%), validation loss = 1.122 (accuracy: 50.476%)\n",
      "Epoch 77: 15.877 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.145 (accuracy: 52.161%), validation loss = 1.105 (accuracy: 48.571%)\n",
      "Epoch 78: 16.092 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.152 (accuracy: 51.105%), validation loss = 1.147 (accuracy: 43.810%)\n",
      "Epoch 79: 15.815 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.143 (accuracy: 50.336%), validation loss = 1.132 (accuracy: 47.619%)\n",
      "Epoch 80: 15.824 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.145 (accuracy: 51.201%), validation loss = 1.148 (accuracy: 43.810%)\n",
      "Epoch 81: 15.768 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.146 (accuracy: 51.777%), validation loss = 1.134 (accuracy: 49.524%)\n",
      "Epoch 82: 15.904 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.151 (accuracy: 53.218%), validation loss = 1.117 (accuracy: 55.238%)\n",
      "Epoch 83: 15.705 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.149 (accuracy: 50.720%), validation loss = 1.108 (accuracy: 50.476%)\n",
      "Epoch 84: 15.768 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.136 (accuracy: 53.026%), validation loss = 1.132 (accuracy: 47.619%)\n",
      "Epoch 85: 15.749 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.150 (accuracy: 50.624%), validation loss = 1.118 (accuracy: 51.429%)\n",
      "Epoch 86: 15.792 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.139 (accuracy: 51.681%), validation loss = 1.122 (accuracy: 53.333%)\n",
      "Epoch 87: 15.722 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.150 (accuracy: 50.913%), validation loss = 1.138 (accuracy: 46.667%)\n",
      "Epoch 88: 15.554 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.141 (accuracy: 52.738%), validation loss = 1.112 (accuracy: 48.571%)\n",
      "Epoch 89: 15.601 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.148 (accuracy: 51.873%), validation loss = 1.117 (accuracy: 48.571%)\n",
      "Epoch 90: 15.775 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.162 (accuracy: 51.009%), validation loss = 1.129 (accuracy: 50.476%)\n",
      "Epoch 91: 15.611 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.149 (accuracy: 49.760%), validation loss = 1.130 (accuracy: 53.333%)\n",
      "Epoch 92: 16.212 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.143 (accuracy: 52.546%), validation loss = 1.135 (accuracy: 46.667%)\n",
      "Epoch 93: 15.525 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.158 (accuracy: 50.048%), validation loss = 1.136 (accuracy: 45.714%)\n",
      "Epoch 94: 15.531 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.151 (accuracy: 51.009%), validation loss = 1.171 (accuracy: 39.048%)\n",
      "Epoch 95: 15.442 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.139 (accuracy: 54.083%), validation loss = 1.139 (accuracy: 48.571%)\n",
      "Epoch 96: 15.573 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.150 (accuracy: 50.913%), validation loss = 1.139 (accuracy: 48.571%)\n",
      "Epoch 97: 15.545 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.163 (accuracy: 47.550%), validation loss = 1.155 (accuracy: 47.619%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 77 with minimum validation error = 1.1048499765850248\n",
      "8483.474 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0\n",
      "Epoch 1: 15.567 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.286 (accuracy: 37.752%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 2: 15.761 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.263 (accuracy: 40.250%), validation loss = 1.269 (accuracy: 35.238%)\n",
      "Epoch 3: 15.757 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.237 (accuracy: 41.499%), validation loss = 1.221 (accuracy: 36.190%)\n",
      "Epoch 4: 15.714 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.220 (accuracy: 44.380%), validation loss = 1.206 (accuracy: 44.762%)\n",
      "Epoch 5: 15.894 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.203 (accuracy: 45.725%), validation loss = 1.202 (accuracy: 38.095%)\n",
      "Epoch 6: 15.705 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.189 (accuracy: 47.166%), validation loss = 1.154 (accuracy: 51.429%)\n",
      "Epoch 7: 15.703 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.177 (accuracy: 48.223%), validation loss = 1.131 (accuracy: 50.476%)\n",
      "Epoch 8: 15.770 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.152 (accuracy: 51.777%), validation loss = 1.126 (accuracy: 49.524%)\n",
      "Epoch 9: 15.623 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.145 (accuracy: 50.528%), validation loss = 1.107 (accuracy: 54.286%)\n",
      "Epoch 10: 15.773 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.130 (accuracy: 51.489%), validation loss = 1.086 (accuracy: 57.143%)\n",
      "Epoch 11: 15.678 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.113 (accuracy: 51.873%), validation loss = 1.085 (accuracy: 57.143%)\n",
      "Epoch 12: 15.903 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.106 (accuracy: 53.506%), validation loss = 1.079 (accuracy: 51.429%)\n",
      "Epoch 13: 15.820 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.087 (accuracy: 54.371%), validation loss = 1.069 (accuracy: 49.524%)\n",
      "Epoch 14: 16.255 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.093 (accuracy: 53.602%), validation loss = 1.074 (accuracy: 49.524%)\n",
      "Epoch 15: 15.936 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.061 (accuracy: 55.235%), validation loss = 1.072 (accuracy: 48.571%)\n",
      "Epoch 16: 15.745 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.065 (accuracy: 53.987%), validation loss = 1.060 (accuracy: 50.476%)\n",
      "Epoch 17: 15.882 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.061 (accuracy: 56.484%), validation loss = 1.038 (accuracy: 54.286%)\n",
      "Epoch 18: 15.955 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.047 (accuracy: 54.755%), validation loss = 1.038 (accuracy: 56.190%)\n",
      "Epoch 19: 15.600 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.067 (accuracy: 53.794%), validation loss = 1.037 (accuracy: 52.381%)\n",
      "Epoch 20: 15.916 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.048 (accuracy: 56.580%), validation loss = 1.066 (accuracy: 51.429%)\n",
      "Epoch 21: 15.611 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.036 (accuracy: 57.445%), validation loss = 1.019 (accuracy: 55.238%)\n",
      "Epoch 22: 15.834 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.031 (accuracy: 57.253%), validation loss = 1.021 (accuracy: 56.190%)\n",
      "Epoch 23: 15.484 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.015 (accuracy: 58.694%), validation loss = 1.004 (accuracy: 56.190%)\n",
      "Epoch 24: 15.767 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 0.995 (accuracy: 60.038%), validation loss = 1.016 (accuracy: 55.238%)\n",
      "Epoch 25: 15.578 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.005 (accuracy: 58.405%), validation loss = 1.004 (accuracy: 52.381%)\n",
      "Epoch 26: 15.541 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.015 (accuracy: 58.405%), validation loss = 1.011 (accuracy: 54.286%)\n",
      "Epoch 27: 15.541 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.001 (accuracy: 58.790%), validation loss = 0.990 (accuracy: 60.000%)\n",
      "Epoch 28: 15.628 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.003 (accuracy: 58.021%), validation loss = 0.983 (accuracy: 59.048%)\n",
      "Epoch 29: 15.703 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.991 (accuracy: 58.213%), validation loss = 0.990 (accuracy: 57.143%)\n",
      "Epoch 30: 15.547 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.975 (accuracy: 58.886%), validation loss = 0.977 (accuracy: 57.143%)\n",
      "Epoch 31: 15.841 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.966 (accuracy: 60.519%), validation loss = 0.983 (accuracy: 57.143%)\n",
      "Epoch 32: 15.757 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.982 (accuracy: 59.366%), validation loss = 1.001 (accuracy: 55.238%)\n",
      "Epoch 33: 15.450 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.986 (accuracy: 57.445%), validation loss = 0.979 (accuracy: 56.190%)\n",
      "Epoch 34: 15.922 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.959 (accuracy: 60.711%), validation loss = 1.019 (accuracy: 56.190%)\n",
      "Epoch 35: 15.529 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.991 (accuracy: 57.829%), validation loss = 0.977 (accuracy: 58.095%)\n",
      "Epoch 36: 15.580 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.967 (accuracy: 59.750%), validation loss = 0.992 (accuracy: 57.143%)\n",
      "Epoch 37: 15.461 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.967 (accuracy: 59.174%), validation loss = 0.982 (accuracy: 57.143%)\n",
      "Epoch 38: 15.442 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.969 (accuracy: 60.038%), validation loss = 0.994 (accuracy: 56.190%)\n",
      "Epoch 39: 15.508 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.951 (accuracy: 60.038%), validation loss = 0.995 (accuracy: 57.143%)\n",
      "Epoch 40: 15.480 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.965 (accuracy: 59.654%), validation loss = 0.971 (accuracy: 58.095%)\n",
      "Epoch 41: 15.780 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.954 (accuracy: 60.711%), validation loss = 0.999 (accuracy: 56.190%)\n",
      "Epoch 42: 15.532 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.956 (accuracy: 60.038%), validation loss = 0.972 (accuracy: 59.048%)\n",
      "Epoch 43: 15.406 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.939 (accuracy: 60.519%), validation loss = 0.964 (accuracy: 61.905%)\n",
      "Epoch 44: 15.721 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.945 (accuracy: 60.038%), validation loss = 0.991 (accuracy: 54.286%)\n",
      "Epoch 45: 15.400 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.955 (accuracy: 61.095%), validation loss = 0.985 (accuracy: 57.143%)\n",
      "Epoch 46: 15.637 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.959 (accuracy: 58.598%), validation loss = 0.972 (accuracy: 58.095%)\n",
      "Epoch 47: 15.374 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.928 (accuracy: 59.750%), validation loss = 0.983 (accuracy: 57.143%)\n",
      "Epoch 48: 15.449 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.943 (accuracy: 60.327%), validation loss = 0.968 (accuracy: 58.095%)\n",
      "Epoch 49: 15.423 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.926 (accuracy: 61.287%), validation loss = 0.963 (accuracy: 60.952%)\n",
      "Epoch 50: 15.734 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.916 (accuracy: 61.768%), validation loss = 0.978 (accuracy: 56.190%)\n",
      "Epoch 51: 15.693 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.901 (accuracy: 60.999%), validation loss = 0.999 (accuracy: 57.143%)\n",
      "Epoch 52: 15.518 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.911 (accuracy: 62.248%), validation loss = 0.977 (accuracy: 57.143%)\n",
      "Epoch 53: 15.461 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.901 (accuracy: 62.152%), validation loss = 0.981 (accuracy: 58.095%)\n",
      "Epoch 54: 15.986 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.897 (accuracy: 62.920%), validation loss = 0.962 (accuracy: 60.952%)\n",
      "Epoch 55: 15.687 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.930 (accuracy: 61.575%), validation loss = 0.955 (accuracy: 60.000%)\n",
      "Epoch 56: 15.813 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.913 (accuracy: 62.152%), validation loss = 0.956 (accuracy: 58.095%)\n",
      "Epoch 57: 15.428 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.899 (accuracy: 63.689%), validation loss = 0.956 (accuracy: 60.000%)\n",
      "Epoch 58: 15.522 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.909 (accuracy: 61.191%), validation loss = 0.958 (accuracy: 59.048%)\n",
      "Epoch 59: 15.471 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.912 (accuracy: 63.305%), validation loss = 0.959 (accuracy: 59.048%)\n",
      "Epoch 60: 15.565 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.902 (accuracy: 63.593%), validation loss = 0.962 (accuracy: 59.048%)\n",
      "Epoch 61: 15.496 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.892 (accuracy: 63.208%), validation loss = 0.974 (accuracy: 58.095%)\n",
      "Epoch 62: 15.359 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.924 (accuracy: 61.575%), validation loss = 0.966 (accuracy: 60.952%)\n",
      "Epoch 63: 15.363 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.903 (accuracy: 62.248%), validation loss = 0.991 (accuracy: 60.000%)\n",
      "Epoch 64: 15.293 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.901 (accuracy: 63.208%), validation loss = 0.976 (accuracy: 56.190%)\n",
      "Epoch 65: 15.290 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.891 (accuracy: 64.169%), validation loss = 0.958 (accuracy: 61.905%)\n",
      "Epoch 66: 15.422 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.902 (accuracy: 62.632%), validation loss = 0.980 (accuracy: 60.000%)\n",
      "Epoch 67: 15.508 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.898 (accuracy: 61.479%), validation loss = 0.961 (accuracy: 56.190%)\n",
      "Epoch 68: 15.415 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.868 (accuracy: 64.361%), validation loss = 0.978 (accuracy: 57.143%)\n",
      "Epoch 69: 15.452 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.902 (accuracy: 61.671%), validation loss = 0.964 (accuracy: 57.143%)\n",
      "Epoch 70: 15.565 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.893 (accuracy: 62.056%), validation loss = 0.961 (accuracy: 60.952%)\n",
      "Epoch 71: 15.616 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.901 (accuracy: 61.960%), validation loss = 0.970 (accuracy: 57.143%)\n",
      "Epoch 72: 15.563 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.872 (accuracy: 63.305%), validation loss = 0.955 (accuracy: 60.952%)\n",
      "Epoch 73: 15.411 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.872 (accuracy: 65.034%), validation loss = 0.973 (accuracy: 58.095%)\n",
      "Epoch 74: 15.985 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.887 (accuracy: 64.169%), validation loss = 0.970 (accuracy: 55.238%)\n",
      "Epoch 75: 15.475 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.875 (accuracy: 65.322%), validation loss = 0.961 (accuracy: 58.095%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 55 with minimum validation error = 0.9545706618399847\n",
      "9665.841 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.1\n",
      "Epoch 1: 15.456 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.291 (accuracy: 36.695%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 2: 15.726 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.267 (accuracy: 41.499%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 3: 15.647 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.252 (accuracy: 41.402%), validation loss = 1.256 (accuracy: 33.333%)\n",
      "Epoch 4: 15.661 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.232 (accuracy: 43.804%), validation loss = 1.217 (accuracy: 40.952%)\n",
      "Epoch 5: 15.652 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.223 (accuracy: 44.861%), validation loss = 1.183 (accuracy: 43.810%)\n",
      "Epoch 6: 15.701 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.210 (accuracy: 46.398%), validation loss = 1.181 (accuracy: 45.714%)\n",
      "Epoch 7: 15.887 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.184 (accuracy: 50.240%), validation loss = 1.199 (accuracy: 38.095%)\n",
      "Epoch 8: 15.504 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.175 (accuracy: 49.568%), validation loss = 1.169 (accuracy: 45.714%)\n",
      "Epoch 9: 15.722 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.155 (accuracy: 51.393%), validation loss = 1.139 (accuracy: 48.571%)\n",
      "Epoch 10: 15.847 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.155 (accuracy: 50.336%), validation loss = 1.153 (accuracy: 44.762%)\n",
      "Epoch 11: 15.613 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.155 (accuracy: 50.240%), validation loss = 1.141 (accuracy: 45.714%)\n",
      "Epoch 12: 15.672 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.148 (accuracy: 51.297%), validation loss = 1.129 (accuracy: 48.571%)\n",
      "Epoch 13: 15.839 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.145 (accuracy: 51.297%), validation loss = 1.116 (accuracy: 48.571%)\n",
      "Epoch 14: 15.867 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.124 (accuracy: 53.026%), validation loss = 1.103 (accuracy: 50.476%)\n",
      "Epoch 15: 16.010 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.107 (accuracy: 54.467%), validation loss = 1.113 (accuracy: 47.619%)\n",
      "Epoch 16: 15.651 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.114 (accuracy: 54.947%), validation loss = 1.090 (accuracy: 49.524%)\n",
      "Epoch 17: 15.901 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.115 (accuracy: 53.122%), validation loss = 1.083 (accuracy: 47.619%)\n",
      "Epoch 18: 16.325 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.105 (accuracy: 54.083%), validation loss = 1.095 (accuracy: 50.476%)\n",
      "Epoch 19: 15.720 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.102 (accuracy: 54.467%), validation loss = 1.089 (accuracy: 50.476%)\n",
      "Epoch 20: 15.675 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.099 (accuracy: 53.698%), validation loss = 1.064 (accuracy: 54.286%)\n",
      "Epoch 21: 15.775 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.085 (accuracy: 56.964%), validation loss = 1.074 (accuracy: 51.429%)\n",
      "Epoch 22: 15.869 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.105 (accuracy: 53.506%), validation loss = 1.059 (accuracy: 51.429%)\n",
      "Epoch 23: 15.988 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.074 (accuracy: 56.772%), validation loss = 1.064 (accuracy: 53.333%)\n",
      "Epoch 24: 15.635 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.087 (accuracy: 54.563%), validation loss = 1.057 (accuracy: 53.333%)\n",
      "Epoch 25: 16.055 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.096 (accuracy: 53.314%), validation loss = 1.047 (accuracy: 55.238%)\n",
      "Epoch 26: 15.919 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.089 (accuracy: 55.139%), validation loss = 1.071 (accuracy: 51.429%)\n",
      "Epoch 27: 15.774 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.079 (accuracy: 54.947%), validation loss = 1.047 (accuracy: 53.333%)\n",
      "Epoch 28: 15.917 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.074 (accuracy: 53.794%), validation loss = 1.047 (accuracy: 50.476%)\n",
      "Epoch 29: 15.785 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.083 (accuracy: 54.947%), validation loss = 1.050 (accuracy: 53.333%)\n",
      "Epoch 30: 15.732 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.077 (accuracy: 54.275%), validation loss = 1.046 (accuracy: 52.381%)\n",
      "Epoch 31: 16.055 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.063 (accuracy: 55.524%), validation loss = 1.035 (accuracy: 56.190%)\n",
      "Epoch 32: 16.035 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.065 (accuracy: 55.139%), validation loss = 1.035 (accuracy: 56.190%)\n",
      "Epoch 33: 15.897 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.056 (accuracy: 56.292%), validation loss = 1.032 (accuracy: 53.333%)\n",
      "Epoch 34: 16.050 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.047 (accuracy: 57.925%), validation loss = 1.024 (accuracy: 57.143%)\n",
      "Epoch 35: 15.808 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.059 (accuracy: 55.908%), validation loss = 1.024 (accuracy: 56.190%)\n",
      "Epoch 36: 15.862 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.055 (accuracy: 57.157%), validation loss = 1.037 (accuracy: 52.381%)\n",
      "Epoch 37: 15.975 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.046 (accuracy: 56.580%), validation loss = 1.048 (accuracy: 52.381%)\n",
      "Epoch 38: 15.992 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.061 (accuracy: 55.139%), validation loss = 1.065 (accuracy: 50.476%)\n",
      "Epoch 39: 15.574 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.053 (accuracy: 56.676%), validation loss = 1.050 (accuracy: 54.286%)\n",
      "Epoch 40: 15.639 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.058 (accuracy: 56.196%), validation loss = 1.045 (accuracy: 52.381%)\n",
      "Epoch 41: 15.723 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.030 (accuracy: 58.213%), validation loss = 1.030 (accuracy: 51.429%)\n",
      "Epoch 42: 15.813 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.043 (accuracy: 56.388%), validation loss = 1.018 (accuracy: 57.143%)\n",
      "Epoch 43: 15.894 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.027 (accuracy: 58.790%), validation loss = 1.012 (accuracy: 59.048%)\n",
      "Epoch 44: 15.807 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.050 (accuracy: 55.139%), validation loss = 1.030 (accuracy: 50.476%)\n",
      "Epoch 45: 15.678 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.055 (accuracy: 55.716%), validation loss = 1.060 (accuracy: 55.238%)\n",
      "Epoch 46: 15.670 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.032 (accuracy: 57.157%), validation loss = 1.023 (accuracy: 52.381%)\n",
      "Epoch 47: 15.735 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.040 (accuracy: 55.716%), validation loss = 1.029 (accuracy: 55.238%)\n",
      "Epoch 48: 15.636 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.040 (accuracy: 57.253%), validation loss = 1.048 (accuracy: 50.476%)\n",
      "Epoch 49: 15.723 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.037 (accuracy: 58.117%), validation loss = 1.075 (accuracy: 48.571%)\n",
      "Epoch 50: 15.779 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.028 (accuracy: 56.580%), validation loss = 1.012 (accuracy: 59.048%)\n",
      "Epoch 51: 15.982 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.043 (accuracy: 56.100%), validation loss = 1.025 (accuracy: 50.476%)\n",
      "Epoch 52: 15.773 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.025 (accuracy: 58.886%), validation loss = 1.020 (accuracy: 54.286%)\n",
      "Epoch 53: 15.804 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.030 (accuracy: 60.038%), validation loss = 1.044 (accuracy: 54.286%)\n",
      "Epoch 54: 15.404 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.043 (accuracy: 57.157%), validation loss = 1.009 (accuracy: 57.143%)\n",
      "Epoch 55: 15.744 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.018 (accuracy: 58.117%), validation loss = 1.029 (accuracy: 55.238%)\n",
      "Epoch 56: 15.612 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.034 (accuracy: 56.292%), validation loss = 1.050 (accuracy: 48.571%)\n",
      "Epoch 57: 16.604 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.024 (accuracy: 58.405%), validation loss = 1.062 (accuracy: 48.571%)\n",
      "Epoch 58: 16.279 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.033 (accuracy: 58.021%), validation loss = 1.047 (accuracy: 53.333%)\n",
      "Epoch 59: 16.203 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.029 (accuracy: 57.733%), validation loss = 1.028 (accuracy: 52.381%)\n",
      "Epoch 60: 15.862 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.022 (accuracy: 58.501%), validation loss = 1.029 (accuracy: 53.333%)\n",
      "Epoch 61: 15.922 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.026 (accuracy: 57.253%), validation loss = 1.032 (accuracy: 55.238%)\n",
      "Epoch 62: 16.033 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.019 (accuracy: 57.829%), validation loss = 1.043 (accuracy: 51.429%)\n",
      "Epoch 63: 15.843 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.030 (accuracy: 57.253%), validation loss = 1.048 (accuracy: 48.571%)\n",
      "Epoch 64: 15.918 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.033 (accuracy: 57.061%), validation loss = 1.034 (accuracy: 48.571%)\n",
      "Epoch 65: 15.821 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.029 (accuracy: 56.676%), validation loss = 1.026 (accuracy: 51.429%)\n",
      "Epoch 66: 15.867 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.017 (accuracy: 57.157%), validation loss = 1.039 (accuracy: 52.381%)\n",
      "Epoch 67: 16.020 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.024 (accuracy: 59.270%), validation loss = 1.017 (accuracy: 51.429%)\n",
      "Epoch 68: 15.882 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.035 (accuracy: 58.501%), validation loss = 1.024 (accuracy: 55.238%)\n",
      "Epoch 69: 15.794 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.023 (accuracy: 59.654%), validation loss = 1.008 (accuracy: 53.333%)\n",
      "Epoch 70: 16.077 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.028 (accuracy: 59.366%), validation loss = 1.010 (accuracy: 55.238%)\n",
      "Epoch 71: 15.880 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.030 (accuracy: 57.061%), validation loss = 1.022 (accuracy: 52.381%)\n",
      "Epoch 72: 16.101 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.013 (accuracy: 58.886%), validation loss = 1.032 (accuracy: 51.429%)\n",
      "Epoch 73: 15.883 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.019 (accuracy: 57.445%), validation loss = 1.039 (accuracy: 49.524%)\n",
      "Epoch 74: 15.860 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.011 (accuracy: 57.925%), validation loss = 1.013 (accuracy: 56.190%)\n",
      "Epoch 75: 15.874 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.039 (accuracy: 54.947%), validation loss = 1.009 (accuracy: 56.190%)\n",
      "Epoch 76: 16.045 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.012 (accuracy: 58.405%), validation loss = 1.003 (accuracy: 54.286%)\n",
      "Epoch 77: 16.434 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.025 (accuracy: 57.925%), validation loss = 1.019 (accuracy: 51.429%)\n",
      "Epoch 78: 15.841 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.015 (accuracy: 58.213%), validation loss = 1.000 (accuracy: 57.143%)\n",
      "Epoch 79: 16.048 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.014 (accuracy: 59.558%), validation loss = 1.046 (accuracy: 51.429%)\n",
      "Epoch 80: 15.754 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.003 (accuracy: 57.733%), validation loss = 1.005 (accuracy: 55.238%)\n",
      "Epoch 81: 15.822 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.024 (accuracy: 58.598%), validation loss = 1.026 (accuracy: 52.381%)\n",
      "Epoch 82: 15.803 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.004 (accuracy: 59.942%), validation loss = 1.038 (accuracy: 55.238%)\n",
      "Epoch 83: 15.843 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.017 (accuracy: 58.405%), validation loss = 1.010 (accuracy: 55.238%)\n",
      "Epoch 84: 15.774 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.030 (accuracy: 57.253%), validation loss = 1.005 (accuracy: 55.238%)\n",
      "Epoch 85: 15.750 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.010 (accuracy: 59.174%), validation loss = 1.003 (accuracy: 55.238%)\n",
      "Epoch 86: 15.733 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.027 (accuracy: 56.580%), validation loss = 1.043 (accuracy: 50.476%)\n",
      "Epoch 87: 15.837 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.020 (accuracy: 57.637%), validation loss = 1.023 (accuracy: 55.238%)\n",
      "Epoch 88: 15.653 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.012 (accuracy: 56.868%), validation loss = 1.016 (accuracy: 52.381%)\n",
      "Epoch 89: 15.668 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.006 (accuracy: 60.134%), validation loss = 1.019 (accuracy: 54.286%)\n",
      "Epoch 90: 15.688 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.031 (accuracy: 56.100%), validation loss = 1.023 (accuracy: 54.286%)\n",
      "Epoch 91: 15.835 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.019 (accuracy: 58.982%), validation loss = 1.007 (accuracy: 51.429%)\n",
      "Epoch 92: 15.754 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.018 (accuracy: 57.733%), validation loss = 1.006 (accuracy: 49.524%)\n",
      "Epoch 93: 15.709 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.012 (accuracy: 59.078%), validation loss = 1.011 (accuracy: 51.429%)\n",
      "Epoch 94: 15.741 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.997 (accuracy: 60.615%), validation loss = 1.003 (accuracy: 53.333%)\n",
      "Epoch 95: 15.728 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.001 (accuracy: 58.309%), validation loss = 0.995 (accuracy: 56.190%)\n",
      "Epoch 96: 16.409 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.014 (accuracy: 59.558%), validation loss = 1.004 (accuracy: 53.333%)\n",
      "Epoch 97: 15.762 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.014 (accuracy: 57.541%), validation loss = 1.014 (accuracy: 51.429%)\n",
      "Epoch 98: 15.786 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.025 (accuracy: 56.964%), validation loss = 1.000 (accuracy: 52.381%)\n",
      "Epoch 99: 15.690 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.004 (accuracy: 58.309%), validation loss = 1.011 (accuracy: 54.286%)\n",
      "Epoch 100: 15.660 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.024 (accuracy: 57.061%), validation loss = 1.013 (accuracy: 56.190%)\n",
      "Epoch 101: 15.641 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.006 (accuracy: 58.598%), validation loss = 1.033 (accuracy: 51.429%)\n",
      "Epoch 102: 15.717 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.016 (accuracy: 58.501%), validation loss = 1.034 (accuracy: 50.476%)\n",
      "Epoch 103: 15.732 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.010 (accuracy: 58.598%), validation loss = 1.041 (accuracy: 48.571%)\n",
      "Epoch 104: 15.673 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.009 (accuracy: 58.598%), validation loss = 1.012 (accuracy: 57.143%)\n",
      "Epoch 105: 15.658 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.994 (accuracy: 59.078%), validation loss = 0.995 (accuracy: 57.143%)\n",
      "Epoch 106: 15.975 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.010 (accuracy: 58.309%), validation loss = 0.999 (accuracy: 56.190%)\n",
      "Epoch 107: 15.701 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.010 (accuracy: 60.615%), validation loss = 1.034 (accuracy: 53.333%)\n",
      "Epoch 108: 15.830 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.003 (accuracy: 58.598%), validation loss = 1.016 (accuracy: 54.286%)\n",
      "Epoch 109: 15.658 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.993 (accuracy: 58.790%), validation loss = 0.995 (accuracy: 56.190%)\n",
      "Epoch 110: 16.005 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.012 (accuracy: 57.157%), validation loss = 0.992 (accuracy: 58.095%)\n",
      "Epoch 111: 15.974 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.998 (accuracy: 59.558%), validation loss = 1.022 (accuracy: 51.429%)\n",
      "Epoch 112: 15.698 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.006 (accuracy: 58.694%), validation loss = 0.993 (accuracy: 54.286%)\n",
      "Epoch 113: 15.807 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.007 (accuracy: 58.886%), validation loss = 1.014 (accuracy: 51.429%)\n",
      "Epoch 114: 15.670 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.998 (accuracy: 58.982%), validation loss = 0.998 (accuracy: 55.238%)\n",
      "Epoch 115: 15.771 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.010 (accuracy: 58.886%), validation loss = 0.996 (accuracy: 51.429%)\n",
      "Epoch 116: 16.146 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.016 (accuracy: 56.388%), validation loss = 0.983 (accuracy: 55.238%)\n",
      "Epoch 117: 15.885 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.028 (accuracy: 56.484%), validation loss = 1.011 (accuracy: 50.476%)\n",
      "Epoch 118: 15.771 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.008 (accuracy: 58.790%), validation loss = 1.018 (accuracy: 56.190%)\n",
      "Epoch 119: 15.667 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.030 (accuracy: 58.117%), validation loss = 1.004 (accuracy: 49.524%)\n",
      "Epoch 120: 15.619 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.995 (accuracy: 59.654%), validation loss = 1.001 (accuracy: 55.238%)\n",
      "Epoch 121: 15.776 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.007 (accuracy: 58.501%), validation loss = 1.001 (accuracy: 54.286%)\n",
      "Epoch 122: 15.700 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.000 (accuracy: 60.038%), validation loss = 0.992 (accuracy: 60.000%)\n",
      "Epoch 123: 15.920 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.033 (accuracy: 55.908%), validation loss = 1.000 (accuracy: 54.286%)\n",
      "Epoch 124: 15.730 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.994 (accuracy: 58.886%), validation loss = 1.026 (accuracy: 51.429%)\n",
      "Epoch 125: 15.708 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.983 (accuracy: 60.807%), validation loss = 1.005 (accuracy: 55.238%)\n",
      "Epoch 126: 15.714 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.013 (accuracy: 58.309%), validation loss = 1.008 (accuracy: 54.286%)\n",
      "Epoch 127: 15.671 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.003 (accuracy: 58.598%), validation loss = 1.010 (accuracy: 54.286%)\n",
      "Epoch 128: 15.844 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.007 (accuracy: 58.501%), validation loss = 0.991 (accuracy: 57.143%)\n",
      "Epoch 129: 15.775 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 1.007 (accuracy: 58.694%), validation loss = 1.003 (accuracy: 51.429%)\n",
      "Epoch 130: 15.783 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.998 (accuracy: 58.694%), validation loss = 1.017 (accuracy: 57.143%)\n",
      "Epoch 131: 15.674 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.996 (accuracy: 57.637%), validation loss = 0.991 (accuracy: 55.238%)\n",
      "Epoch 132: 15.771 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 1.002 (accuracy: 58.982%), validation loss = 1.004 (accuracy: 52.381%)\n",
      "Epoch 133: 15.769 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.979 (accuracy: 60.038%), validation loss = 0.997 (accuracy: 51.429%)\n",
      "Epoch 134: 15.651 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 1.007 (accuracy: 57.157%), validation loss = 0.980 (accuracy: 59.048%)\n",
      "Epoch 135: 16.362 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.993 (accuracy: 59.462%), validation loss = 0.996 (accuracy: 58.095%)\n",
      "Epoch 136: 15.933 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 1.013 (accuracy: 57.061%), validation loss = 0.978 (accuracy: 57.143%)\n",
      "Epoch 137: 15.924 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 1.005 (accuracy: 57.541%), validation loss = 0.994 (accuracy: 54.286%)\n",
      "Epoch 138: 15.795 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 1.002 (accuracy: 59.270%), validation loss = 1.004 (accuracy: 56.190%)\n",
      "Epoch 139: 15.675 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.996 (accuracy: 58.694%), validation loss = 1.008 (accuracy: 56.190%)\n",
      "Epoch 140: 15.726 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.998 (accuracy: 60.519%), validation loss = 1.011 (accuracy: 53.333%)\n",
      "Epoch 141: 15.617 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 1.003 (accuracy: 57.541%), validation loss = 1.018 (accuracy: 55.238%)\n",
      "Epoch 142: 15.652 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.997 (accuracy: 58.309%), validation loss = 0.984 (accuracy: 60.000%)\n",
      "Epoch 143: 15.818 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.995 (accuracy: 57.157%), validation loss = 0.986 (accuracy: 56.190%)\n",
      "Epoch 144: 15.784 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 1.011 (accuracy: 57.349%), validation loss = 0.984 (accuracy: 59.048%)\n",
      "Epoch 145: 15.663 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.986 (accuracy: 61.287%), validation loss = 0.991 (accuracy: 56.190%)\n",
      "Epoch 146: 15.699 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 1.011 (accuracy: 58.790%), validation loss = 1.015 (accuracy: 54.286%)\n",
      "Epoch 147: 15.697 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 1.010 (accuracy: 58.213%), validation loss = 0.995 (accuracy: 60.000%)\n",
      "Epoch 148: 15.772 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 1.004 (accuracy: 59.078%), validation loss = 0.987 (accuracy: 56.190%)\n",
      "Epoch 149: 15.781 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.994 (accuracy: 58.309%), validation loss = 1.013 (accuracy: 54.286%)\n",
      "Epoch 150: 15.506 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 1.004 (accuracy: 57.349%), validation loss = 1.016 (accuracy: 50.476%)\n",
      "Epoch 151: 15.463 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.984 (accuracy: 59.270%), validation loss = 1.011 (accuracy: 53.333%)\n",
      "Epoch 152: 15.476 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 1.003 (accuracy: 59.462%), validation loss = 0.996 (accuracy: 56.190%)\n",
      "Epoch 153: 15.513 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.995 (accuracy: 58.982%), validation loss = 0.992 (accuracy: 57.143%)\n",
      "Epoch 154: 15.594 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.992 (accuracy: 58.309%), validation loss = 0.988 (accuracy: 55.238%)\n",
      "Epoch 155: 16.106 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 1.000 (accuracy: 57.733%), validation loss = 1.016 (accuracy: 56.190%)\n",
      "Epoch 156: 15.606 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.995 (accuracy: 58.598%), validation loss = 1.024 (accuracy: 51.429%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 136 with minimum validation error = 0.9777818100793021\n",
      "12147.352 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.2\n",
      "Epoch 1: 15.668 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.296 (accuracy: 39.193%), validation loss = 1.292 (accuracy: 35.238%)\n",
      "Epoch 2: 15.840 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.266 (accuracy: 40.730%), validation loss = 1.300 (accuracy: 34.286%)\n",
      "Epoch 3: 15.618 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.251 (accuracy: 43.228%), validation loss = 1.263 (accuracy: 35.238%)\n",
      "Epoch 4: 15.852 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.226 (accuracy: 43.516%), validation loss = 1.243 (accuracy: 33.333%)\n",
      "Epoch 5: 15.821 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.228 (accuracy: 46.590%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 6: 15.556 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.216 (accuracy: 43.516%), validation loss = 1.236 (accuracy: 37.143%)\n",
      "Epoch 7: 15.796 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.217 (accuracy: 46.013%), validation loss = 1.210 (accuracy: 42.857%)\n",
      "Epoch 8: 15.836 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.201 (accuracy: 45.629%), validation loss = 1.198 (accuracy: 40.000%)\n",
      "Epoch 9: 15.706 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.187 (accuracy: 46.013%), validation loss = 1.197 (accuracy: 41.905%)\n",
      "Epoch 10: 15.738 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.183 (accuracy: 47.550%), validation loss = 1.176 (accuracy: 45.714%)\n",
      "Epoch 11: 15.771 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.179 (accuracy: 47.935%), validation loss = 1.162 (accuracy: 49.524%)\n",
      "Epoch 12: 15.963 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.166 (accuracy: 48.415%), validation loss = 1.181 (accuracy: 41.905%)\n",
      "Epoch 13: 15.605 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.161 (accuracy: 49.568%), validation loss = 1.157 (accuracy: 45.714%)\n",
      "Epoch 14: 15.785 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.151 (accuracy: 50.720%), validation loss = 1.153 (accuracy: 48.571%)\n",
      "Epoch 15: 15.763 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.152 (accuracy: 51.873%), validation loss = 1.173 (accuracy: 41.905%)\n",
      "Epoch 16: 15.553 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.152 (accuracy: 51.009%), validation loss = 1.154 (accuracy: 42.857%)\n",
      "Epoch 17: 15.546 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.148 (accuracy: 51.297%), validation loss = 1.140 (accuracy: 48.571%)\n",
      "Epoch 18: 17.286 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.140 (accuracy: 52.546%), validation loss = 1.121 (accuracy: 53.333%)\n",
      "Epoch 19: 15.995 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.135 (accuracy: 52.546%), validation loss = 1.129 (accuracy: 51.429%)\n",
      "Epoch 20: 15.569 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.147 (accuracy: 52.642%), validation loss = 1.134 (accuracy: 49.524%)\n",
      "Epoch 21: 15.480 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.133 (accuracy: 52.930%), validation loss = 1.139 (accuracy: 45.714%)\n",
      "Epoch 22: 15.523 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.139 (accuracy: 52.450%), validation loss = 1.132 (accuracy: 47.619%)\n",
      "Epoch 23: 15.455 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.138 (accuracy: 52.642%), validation loss = 1.120 (accuracy: 51.429%)\n",
      "Epoch 24: 15.668 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.133 (accuracy: 50.817%), validation loss = 1.133 (accuracy: 45.714%)\n",
      "Epoch 25: 15.402 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.125 (accuracy: 52.065%), validation loss = 1.122 (accuracy: 50.476%)\n",
      "Epoch 26: 15.516 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.136 (accuracy: 52.257%), validation loss = 1.116 (accuracy: 50.476%)\n",
      "Epoch 27: 15.609 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.133 (accuracy: 52.161%), validation loss = 1.122 (accuracy: 48.571%)\n",
      "Epoch 28: 15.531 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.127 (accuracy: 54.083%), validation loss = 1.120 (accuracy: 48.571%)\n",
      "Epoch 29: 15.390 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.121 (accuracy: 52.930%), validation loss = 1.117 (accuracy: 50.476%)\n",
      "Epoch 30: 15.527 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.117 (accuracy: 54.371%), validation loss = 1.124 (accuracy: 49.524%)\n",
      "Epoch 31: 15.447 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.122 (accuracy: 51.777%), validation loss = 1.105 (accuracy: 52.381%)\n",
      "Epoch 32: 15.758 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.124 (accuracy: 53.314%), validation loss = 1.116 (accuracy: 50.476%)\n",
      "Epoch 33: 15.546 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.124 (accuracy: 52.161%), validation loss = 1.102 (accuracy: 54.286%)\n",
      "Epoch 34: 15.654 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.118 (accuracy: 54.467%), validation loss = 1.103 (accuracy: 54.286%)\n",
      "Epoch 35: 15.418 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.117 (accuracy: 54.083%), validation loss = 1.097 (accuracy: 56.190%)\n",
      "Epoch 36: 15.593 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.117 (accuracy: 54.083%), validation loss = 1.096 (accuracy: 54.286%)\n",
      "Epoch 37: 15.652 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.117 (accuracy: 52.642%), validation loss = 1.098 (accuracy: 52.381%)\n",
      "Epoch 38: 15.973 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.118 (accuracy: 51.969%), validation loss = 1.101 (accuracy: 49.524%)\n",
      "Epoch 39: 15.469 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.111 (accuracy: 54.563%), validation loss = 1.092 (accuracy: 53.333%)\n",
      "Epoch 40: 15.722 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.117 (accuracy: 53.026%), validation loss = 1.103 (accuracy: 52.381%)\n",
      "Epoch 41: 15.418 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.128 (accuracy: 53.890%), validation loss = 1.103 (accuracy: 52.381%)\n",
      "Epoch 42: 15.393 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.116 (accuracy: 54.083%), validation loss = 1.104 (accuracy: 51.429%)\n",
      "Epoch 43: 15.500 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.116 (accuracy: 53.026%), validation loss = 1.104 (accuracy: 55.238%)\n",
      "Epoch 44: 15.375 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.129 (accuracy: 52.354%), validation loss = 1.108 (accuracy: 51.429%)\n",
      "Epoch 45: 15.435 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.115 (accuracy: 54.467%), validation loss = 1.110 (accuracy: 50.476%)\n",
      "Epoch 46: 15.419 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.126 (accuracy: 53.410%), validation loss = 1.107 (accuracy: 51.429%)\n",
      "Epoch 47: 15.393 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.117 (accuracy: 53.026%), validation loss = 1.098 (accuracy: 53.333%)\n",
      "Epoch 48: 15.534 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.121 (accuracy: 53.890%), validation loss = 1.112 (accuracy: 50.476%)\n",
      "Epoch 49: 15.422 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.123 (accuracy: 52.450%), validation loss = 1.125 (accuracy: 45.714%)\n",
      "Epoch 50: 15.401 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.113 (accuracy: 54.659%), validation loss = 1.090 (accuracy: 52.381%)\n",
      "Epoch 51: 15.734 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.118 (accuracy: 53.122%), validation loss = 1.098 (accuracy: 53.333%)\n",
      "Epoch 52: 15.396 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.111 (accuracy: 55.139%), validation loss = 1.113 (accuracy: 48.571%)\n",
      "Epoch 53: 15.394 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.113 (accuracy: 55.524%), validation loss = 1.098 (accuracy: 46.667%)\n",
      "Epoch 54: 15.398 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.112 (accuracy: 53.122%), validation loss = 1.089 (accuracy: 54.286%)\n",
      "Epoch 55: 15.535 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.115 (accuracy: 54.659%), validation loss = 1.130 (accuracy: 50.476%)\n",
      "Epoch 56: 15.376 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.121 (accuracy: 51.009%), validation loss = 1.099 (accuracy: 49.524%)\n",
      "Epoch 57: 15.308 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.108 (accuracy: 54.563%), validation loss = 1.099 (accuracy: 50.476%)\n",
      "Epoch 58: 15.711 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.117 (accuracy: 53.410%), validation loss = 1.109 (accuracy: 51.429%)\n",
      "Epoch 59: 15.493 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.120 (accuracy: 53.890%), validation loss = 1.129 (accuracy: 44.762%)\n",
      "Epoch 60: 15.302 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.134 (accuracy: 52.834%), validation loss = 1.109 (accuracy: 51.429%)\n",
      "Epoch 61: 15.369 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.114 (accuracy: 53.218%), validation loss = 1.102 (accuracy: 53.333%)\n",
      "Epoch 62: 15.326 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.115 (accuracy: 55.524%), validation loss = 1.107 (accuracy: 50.476%)\n",
      "Epoch 63: 15.323 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.125 (accuracy: 54.947%), validation loss = 1.142 (accuracy: 44.762%)\n",
      "Epoch 64: 15.493 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.116 (accuracy: 53.410%), validation loss = 1.108 (accuracy: 52.381%)\n",
      "Epoch 65: 15.313 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.109 (accuracy: 54.659%), validation loss = 1.112 (accuracy: 48.571%)\n",
      "Epoch 66: 15.247 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.119 (accuracy: 54.755%), validation loss = 1.137 (accuracy: 42.857%)\n",
      "Epoch 67: 15.286 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.134 (accuracy: 51.009%), validation loss = 1.128 (accuracy: 45.714%)\n",
      "Epoch 68: 15.311 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.122 (accuracy: 53.794%), validation loss = 1.093 (accuracy: 51.429%)\n",
      "Epoch 69: 15.435 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.116 (accuracy: 53.122%), validation loss = 1.094 (accuracy: 51.429%)\n",
      "Epoch 70: 15.254 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.124 (accuracy: 54.275%), validation loss = 1.105 (accuracy: 53.333%)\n",
      "Epoch 71: 15.394 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.120 (accuracy: 52.930%), validation loss = 1.109 (accuracy: 54.286%)\n",
      "Epoch 72: 15.321 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.113 (accuracy: 53.794%), validation loss = 1.100 (accuracy: 52.381%)\n",
      "Epoch 73: 15.222 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.126 (accuracy: 54.083%), validation loss = 1.104 (accuracy: 50.476%)\n",
      "Epoch 74: 15.281 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.122 (accuracy: 53.410%), validation loss = 1.093 (accuracy: 50.476%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 54 with minimum validation error = 1.0894129860968818\n",
      "13307.526 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0\n",
      "Epoch 1: 15.281 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.351 (accuracy: 31.028%), validation loss = 1.325 (accuracy: 34.286%)\n",
      "Epoch 2: 15.418 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.292 (accuracy: 38.136%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 3: 15.401 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.285 (accuracy: 38.905%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 4: 15.736 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.275 (accuracy: 39.385%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 5: 15.591 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.271 (accuracy: 40.634%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 6: 15.462 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.256 (accuracy: 40.730%), validation loss = 1.266 (accuracy: 34.286%)\n",
      "Epoch 7: 15.450 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.266 (accuracy: 40.730%), validation loss = 1.266 (accuracy: 34.286%)\n",
      "Epoch 8: 15.170 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.263 (accuracy: 40.346%), validation loss = 1.263 (accuracy: 34.286%)\n",
      "Epoch 9: 15.458 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.248 (accuracy: 41.499%), validation loss = 1.250 (accuracy: 34.286%)\n",
      "Epoch 10: 15.516 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.242 (accuracy: 41.787%), validation loss = 1.252 (accuracy: 34.286%)\n",
      "Epoch 11: 15.294 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.243 (accuracy: 41.787%), validation loss = 1.242 (accuracy: 35.238%)\n",
      "Epoch 12: 15.438 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.245 (accuracy: 42.075%), validation loss = 1.240 (accuracy: 34.286%)\n",
      "Epoch 13: 15.477 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.235 (accuracy: 43.036%), validation loss = 1.224 (accuracy: 36.190%)\n",
      "Epoch 14: 15.428 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.224 (accuracy: 42.651%), validation loss = 1.227 (accuracy: 35.238%)\n",
      "Epoch 15: 15.277 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.221 (accuracy: 46.206%), validation loss = 1.213 (accuracy: 40.000%)\n",
      "Epoch 16: 15.693 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.215 (accuracy: 45.149%), validation loss = 1.211 (accuracy: 42.857%)\n",
      "Epoch 17: 15.472 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.221 (accuracy: 46.782%), validation loss = 1.212 (accuracy: 39.048%)\n",
      "Epoch 18: 15.144 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.222 (accuracy: 44.092%), validation loss = 1.209 (accuracy: 40.952%)\n",
      "Epoch 19: 15.453 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.205 (accuracy: 46.686%), validation loss = 1.189 (accuracy: 43.810%)\n",
      "Epoch 20: 15.385 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.213 (accuracy: 45.437%), validation loss = 1.189 (accuracy: 44.762%)\n",
      "Epoch 21: 15.609 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.204 (accuracy: 46.398%), validation loss = 1.185 (accuracy: 43.810%)\n",
      "Epoch 22: 15.409 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.193 (accuracy: 47.743%), validation loss = 1.178 (accuracy: 43.810%)\n",
      "Epoch 23: 15.405 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.191 (accuracy: 46.782%), validation loss = 1.176 (accuracy: 41.905%)\n",
      "Epoch 24: 15.927 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.181 (accuracy: 48.127%), validation loss = 1.171 (accuracy: 44.762%)\n",
      "Epoch 25: 15.489 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.184 (accuracy: 46.302%), validation loss = 1.160 (accuracy: 45.714%)\n",
      "Epoch 26: 15.539 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.173 (accuracy: 48.703%), validation loss = 1.158 (accuracy: 45.714%)\n",
      "Epoch 27: 15.418 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.169 (accuracy: 50.432%), validation loss = 1.147 (accuracy: 48.571%)\n",
      "Epoch 28: 15.333 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.184 (accuracy: 48.223%), validation loss = 1.157 (accuracy: 45.714%)\n",
      "Epoch 29: 15.206 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.160 (accuracy: 48.895%), validation loss = 1.147 (accuracy: 46.667%)\n",
      "Epoch 30: 15.370 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.172 (accuracy: 47.262%), validation loss = 1.144 (accuracy: 46.667%)\n",
      "Epoch 31: 15.533 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.154 (accuracy: 50.432%), validation loss = 1.140 (accuracy: 47.619%)\n",
      "Epoch 32: 15.376 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.149 (accuracy: 51.777%), validation loss = 1.129 (accuracy: 49.524%)\n",
      "Epoch 33: 15.390 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.160 (accuracy: 48.991%), validation loss = 1.133 (accuracy: 47.619%)\n",
      "Epoch 34: 15.134 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.145 (accuracy: 51.201%), validation loss = 1.132 (accuracy: 47.619%)\n",
      "Epoch 35: 15.085 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.141 (accuracy: 52.065%), validation loss = 1.119 (accuracy: 52.381%)\n",
      "Epoch 36: 15.673 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.139 (accuracy: 51.009%), validation loss = 1.125 (accuracy: 48.571%)\n",
      "Epoch 37: 15.273 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.147 (accuracy: 51.489%), validation loss = 1.119 (accuracy: 51.429%)\n",
      "Epoch 38: 15.249 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.131 (accuracy: 53.698%), validation loss = 1.111 (accuracy: 52.381%)\n",
      "Epoch 39: 15.455 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.131 (accuracy: 53.026%), validation loss = 1.113 (accuracy: 48.571%)\n",
      "Epoch 40: 15.143 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.135 (accuracy: 51.201%), validation loss = 1.111 (accuracy: 47.619%)\n",
      "Epoch 41: 15.404 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.131 (accuracy: 52.930%), validation loss = 1.102 (accuracy: 51.429%)\n",
      "Epoch 42: 16.250 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.119 (accuracy: 51.489%), validation loss = 1.099 (accuracy: 53.333%)\n",
      "Epoch 43: 16.267 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.104 (accuracy: 54.179%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 44: 16.861 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.106 (accuracy: 54.179%), validation loss = 1.087 (accuracy: 52.381%)\n",
      "Epoch 45: 15.887 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.119 (accuracy: 51.777%), validation loss = 1.087 (accuracy: 53.333%)\n",
      "Epoch 46: 15.694 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.114 (accuracy: 52.738%), validation loss = 1.076 (accuracy: 53.333%)\n",
      "Epoch 47: 15.772 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.104 (accuracy: 53.410%), validation loss = 1.076 (accuracy: 51.429%)\n",
      "Epoch 48: 15.706 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.105 (accuracy: 53.506%), validation loss = 1.077 (accuracy: 51.429%)\n",
      "Epoch 49: 15.524 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.098 (accuracy: 54.659%), validation loss = 1.074 (accuracy: 52.381%)\n",
      "Epoch 50: 15.599 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.109 (accuracy: 53.698%), validation loss = 1.070 (accuracy: 50.476%)\n",
      "Epoch 51: 15.654 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.102 (accuracy: 53.506%), validation loss = 1.062 (accuracy: 51.429%)\n",
      "Epoch 52: 15.677 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.083 (accuracy: 54.563%), validation loss = 1.068 (accuracy: 52.381%)\n",
      "Epoch 53: 15.404 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.100 (accuracy: 54.563%), validation loss = 1.063 (accuracy: 50.476%)\n",
      "Epoch 54: 15.218 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.098 (accuracy: 53.218%), validation loss = 1.062 (accuracy: 50.476%)\n",
      "Epoch 55: 15.498 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.084 (accuracy: 53.602%), validation loss = 1.058 (accuracy: 49.524%)\n",
      "Epoch 56: 15.571 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.086 (accuracy: 54.371%), validation loss = 1.052 (accuracy: 53.333%)\n",
      "Epoch 57: 15.687 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.083 (accuracy: 55.331%), validation loss = 1.057 (accuracy: 49.524%)\n",
      "Epoch 58: 15.300 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.077 (accuracy: 54.467%), validation loss = 1.051 (accuracy: 50.476%)\n",
      "Epoch 59: 15.616 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.083 (accuracy: 54.179%), validation loss = 1.055 (accuracy: 49.524%)\n",
      "Epoch 60: 15.339 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.078 (accuracy: 53.890%), validation loss = 1.041 (accuracy: 54.286%)\n",
      "Epoch 61: 15.679 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.080 (accuracy: 56.196%), validation loss = 1.043 (accuracy: 52.381%)\n",
      "Epoch 62: 15.431 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.074 (accuracy: 55.716%), validation loss = 1.045 (accuracy: 51.429%)\n",
      "Epoch 63: 15.545 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.088 (accuracy: 54.371%), validation loss = 1.048 (accuracy: 52.381%)\n",
      "Epoch 64: 15.623 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.080 (accuracy: 54.275%), validation loss = 1.044 (accuracy: 51.429%)\n",
      "Epoch 65: 15.349 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.079 (accuracy: 55.524%), validation loss = 1.032 (accuracy: 53.333%)\n",
      "Epoch 66: 15.543 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.059 (accuracy: 54.947%), validation loss = 1.033 (accuracy: 52.381%)\n",
      "Epoch 67: 15.472 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.074 (accuracy: 55.235%), validation loss = 1.028 (accuracy: 53.333%)\n",
      "Epoch 68: 15.519 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.073 (accuracy: 52.930%), validation loss = 1.028 (accuracy: 54.286%)\n",
      "Epoch 69: 15.212 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.059 (accuracy: 56.964%), validation loss = 1.029 (accuracy: 51.429%)\n",
      "Epoch 70: 15.215 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.056 (accuracy: 56.388%), validation loss = 1.023 (accuracy: 56.190%)\n",
      "Epoch 71: 15.493 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.039 (accuracy: 57.253%), validation loss = 1.023 (accuracy: 54.286%)\n",
      "Epoch 72: 15.364 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.045 (accuracy: 55.716%), validation loss = 1.028 (accuracy: 52.381%)\n",
      "Epoch 73: 15.253 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.054 (accuracy: 57.829%), validation loss = 1.017 (accuracy: 54.286%)\n",
      "Epoch 74: 15.516 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.045 (accuracy: 55.331%), validation loss = 1.020 (accuracy: 53.333%)\n",
      "Epoch 75: 15.381 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.025 (accuracy: 59.558%), validation loss = 1.022 (accuracy: 52.381%)\n",
      "Epoch 76: 15.200 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.045 (accuracy: 55.620%), validation loss = 1.020 (accuracy: 51.429%)\n",
      "Epoch 77: 15.322 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.043 (accuracy: 56.772%), validation loss = 1.014 (accuracy: 53.333%)\n",
      "Epoch 78: 15.461 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.040 (accuracy: 55.139%), validation loss = 1.016 (accuracy: 54.286%)\n",
      "Epoch 79: 15.348 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.039 (accuracy: 56.292%), validation loss = 1.015 (accuracy: 52.381%)\n",
      "Epoch 80: 15.340 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.035 (accuracy: 57.733%), validation loss = 1.015 (accuracy: 55.238%)\n",
      "Epoch 81: 15.266 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.037 (accuracy: 56.484%), validation loss = 1.015 (accuracy: 54.286%)\n",
      "Epoch 82: 15.241 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.027 (accuracy: 59.174%), validation loss = 1.008 (accuracy: 55.238%)\n",
      "Epoch 83: 15.704 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.027 (accuracy: 57.925%), validation loss = 1.021 (accuracy: 50.476%)\n",
      "Epoch 84: 15.532 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.025 (accuracy: 57.253%), validation loss = 1.009 (accuracy: 55.238%)\n",
      "Epoch 85: 15.145 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.016 (accuracy: 58.694%), validation loss = 1.005 (accuracy: 54.286%)\n",
      "Epoch 86: 15.430 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.021 (accuracy: 59.270%), validation loss = 1.004 (accuracy: 54.286%)\n",
      "Epoch 87: 15.628 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.033 (accuracy: 56.772%), validation loss = 0.997 (accuracy: 55.238%)\n",
      "Epoch 88: 15.618 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.010 (accuracy: 58.309%), validation loss = 1.006 (accuracy: 55.238%)\n",
      "Epoch 89: 15.259 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.014 (accuracy: 55.235%), validation loss = 1.003 (accuracy: 53.333%)\n",
      "Epoch 90: 15.279 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.022 (accuracy: 57.061%), validation loss = 1.000 (accuracy: 54.286%)\n",
      "Epoch 91: 15.244 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.013 (accuracy: 59.174%), validation loss = 1.002 (accuracy: 54.286%)\n",
      "Epoch 92: 15.294 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.033 (accuracy: 55.524%), validation loss = 0.998 (accuracy: 52.381%)\n",
      "Epoch 93: 15.389 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.034 (accuracy: 57.445%), validation loss = 0.997 (accuracy: 54.286%)\n",
      "Epoch 94: 15.432 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.012 (accuracy: 57.541%), validation loss = 1.000 (accuracy: 54.286%)\n",
      "Epoch 95: 15.294 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.017 (accuracy: 57.829%), validation loss = 0.998 (accuracy: 53.333%)\n",
      "Epoch 96: 15.265 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.020 (accuracy: 55.812%), validation loss = 0.995 (accuracy: 53.333%)\n",
      "Epoch 97: 15.533 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.001 (accuracy: 58.886%), validation loss = 0.996 (accuracy: 54.286%)\n",
      "Epoch 98: 15.415 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.994 (accuracy: 58.790%), validation loss = 0.999 (accuracy: 53.333%)\n",
      "Epoch 99: 15.213 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.989 (accuracy: 59.078%), validation loss = 0.992 (accuracy: 54.286%)\n",
      "Epoch 100: 15.493 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.994 (accuracy: 60.519%), validation loss = 0.995 (accuracy: 54.286%)\n",
      "Epoch 101: 15.174 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.998 (accuracy: 59.654%), validation loss = 0.988 (accuracy: 53.333%)\n",
      "Epoch 102: 15.518 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.016 (accuracy: 58.021%), validation loss = 0.993 (accuracy: 53.333%)\n",
      "Epoch 103: 15.550 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.011 (accuracy: 58.886%), validation loss = 0.986 (accuracy: 52.381%)\n",
      "Epoch 104: 15.856 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.996 (accuracy: 57.637%), validation loss = 0.987 (accuracy: 52.381%)\n",
      "Epoch 105: 15.244 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.979 (accuracy: 61.479%), validation loss = 0.991 (accuracy: 55.238%)\n",
      "Epoch 106: 15.252 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.000 (accuracy: 58.501%), validation loss = 0.989 (accuracy: 53.333%)\n",
      "Epoch 107: 15.268 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.005 (accuracy: 57.733%), validation loss = 0.990 (accuracy: 55.238%)\n",
      "Epoch 108: 15.315 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.008 (accuracy: 58.021%), validation loss = 0.982 (accuracy: 54.286%)\n",
      "Epoch 109: 15.551 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.998 (accuracy: 57.925%), validation loss = 0.984 (accuracy: 53.333%)\n",
      "Epoch 110: 15.253 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.002 (accuracy: 58.213%), validation loss = 0.981 (accuracy: 56.190%)\n",
      "Epoch 111: 15.491 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.010 (accuracy: 56.868%), validation loss = 0.973 (accuracy: 56.190%)\n",
      "Epoch 112: 15.509 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.997 (accuracy: 58.982%), validation loss = 0.981 (accuracy: 54.286%)\n",
      "Epoch 113: 15.322 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.995 (accuracy: 60.134%), validation loss = 0.981 (accuracy: 56.190%)\n",
      "Epoch 114: 15.549 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.998 (accuracy: 59.174%), validation loss = 0.974 (accuracy: 57.143%)\n",
      "Epoch 115: 15.288 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.982 (accuracy: 58.694%), validation loss = 0.977 (accuracy: 53.333%)\n",
      "Epoch 116: 15.201 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.975 (accuracy: 58.309%), validation loss = 0.977 (accuracy: 55.238%)\n",
      "Epoch 117: 15.200 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.985 (accuracy: 58.405%), validation loss = 0.974 (accuracy: 54.286%)\n",
      "Epoch 118: 15.292 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 0.991 (accuracy: 58.309%), validation loss = 0.973 (accuracy: 57.143%)\n",
      "Epoch 119: 15.358 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.003 (accuracy: 57.733%), validation loss = 0.969 (accuracy: 56.190%)\n",
      "Epoch 120: 15.499 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.966 (accuracy: 59.750%), validation loss = 0.976 (accuracy: 55.238%)\n",
      "Epoch 121: 15.282 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 0.995 (accuracy: 58.309%), validation loss = 0.968 (accuracy: 57.143%)\n",
      "Epoch 122: 15.486 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.990 (accuracy: 60.999%), validation loss = 0.974 (accuracy: 55.238%)\n",
      "Epoch 123: 15.295 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.987 (accuracy: 59.558%), validation loss = 0.970 (accuracy: 55.238%)\n",
      "Epoch 124: 15.735 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 0.962 (accuracy: 59.942%), validation loss = 0.973 (accuracy: 56.190%)\n",
      "Epoch 125: 15.248 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.983 (accuracy: 58.309%), validation loss = 0.976 (accuracy: 56.190%)\n",
      "Epoch 126: 15.299 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 0.971 (accuracy: 60.711%), validation loss = 0.968 (accuracy: 55.238%)\n",
      "Epoch 127: 15.292 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 0.990 (accuracy: 59.750%), validation loss = 0.970 (accuracy: 56.190%)\n",
      "Epoch 128: 15.259 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 0.986 (accuracy: 58.598%), validation loss = 0.970 (accuracy: 56.190%)\n",
      "Epoch 129: 15.360 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 0.979 (accuracy: 60.807%), validation loss = 0.970 (accuracy: 53.333%)\n",
      "Epoch 130: 15.228 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 0.991 (accuracy: 57.829%), validation loss = 0.968 (accuracy: 57.143%)\n",
      "Epoch 131: 15.445 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 0.978 (accuracy: 59.078%), validation loss = 0.965 (accuracy: 57.143%)\n",
      "Epoch 132: 15.424 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 0.971 (accuracy: 60.038%), validation loss = 0.962 (accuracy: 56.190%)\n",
      "Epoch 133: 15.464 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 0.988 (accuracy: 58.598%), validation loss = 0.970 (accuracy: 56.190%)\n",
      "Epoch 134: 15.587 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 0.973 (accuracy: 60.711%), validation loss = 0.966 (accuracy: 58.095%)\n",
      "Epoch 135: 15.336 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 0.959 (accuracy: 60.999%), validation loss = 0.965 (accuracy: 56.190%)\n",
      "Epoch 136: 15.259 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 0.970 (accuracy: 59.846%), validation loss = 0.970 (accuracy: 56.190%)\n",
      "Epoch 137: 15.375 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 0.960 (accuracy: 60.519%), validation loss = 0.969 (accuracy: 57.143%)\n",
      "Epoch 138: 15.330 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 0.962 (accuracy: 60.711%), validation loss = 0.956 (accuracy: 56.190%)\n",
      "Epoch 139: 15.608 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 0.968 (accuracy: 60.903%), validation loss = 0.955 (accuracy: 58.095%)\n",
      "Epoch 140: 15.592 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 0.955 (accuracy: 58.982%), validation loss = 0.970 (accuracy: 57.143%)\n",
      "Epoch 141: 15.291 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 0.949 (accuracy: 58.886%), validation loss = 0.956 (accuracy: 55.238%)\n",
      "Epoch 142: 15.339 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 0.958 (accuracy: 61.575%), validation loss = 0.965 (accuracy: 57.143%)\n",
      "Epoch 143: 15.288 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 0.967 (accuracy: 60.519%), validation loss = 0.964 (accuracy: 57.143%)\n",
      "Epoch 144: 15.790 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 0.965 (accuracy: 61.287%), validation loss = 0.961 (accuracy: 56.190%)\n",
      "Epoch 145: 15.455 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 0.951 (accuracy: 61.191%), validation loss = 0.962 (accuracy: 57.143%)\n",
      "Epoch 146: 15.311 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 0.965 (accuracy: 59.654%), validation loss = 0.957 (accuracy: 57.143%)\n",
      "Epoch 147: 15.218 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 0.948 (accuracy: 60.903%), validation loss = 0.954 (accuracy: 58.095%)\n",
      "Epoch 148: 15.546 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 0.959 (accuracy: 59.078%), validation loss = 0.962 (accuracy: 56.190%)\n",
      "Epoch 149: 15.362 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 0.965 (accuracy: 60.807%), validation loss = 0.960 (accuracy: 57.143%)\n",
      "Epoch 150: 15.468 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 0.953 (accuracy: 60.807%), validation loss = 0.966 (accuracy: 56.190%)\n",
      "Epoch 151: 15.318 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 0.936 (accuracy: 60.327%), validation loss = 0.954 (accuracy: 58.095%)\n",
      "Epoch 152: 15.303 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 0.966 (accuracy: 59.846%), validation loss = 0.962 (accuracy: 57.143%)\n",
      "Epoch 153: 15.279 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 0.944 (accuracy: 58.598%), validation loss = 0.962 (accuracy: 55.238%)\n",
      "Epoch 154: 15.424 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 0.948 (accuracy: 61.864%), validation loss = 0.951 (accuracy: 59.048%)\n",
      "Epoch 155: 15.745 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 0.939 (accuracy: 60.903%), validation loss = 0.968 (accuracy: 56.190%)\n",
      "Epoch 156: 15.336 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 0.946 (accuracy: 62.344%), validation loss = 0.964 (accuracy: 56.190%)\n",
      "Epoch 157: 15.277 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 0.938 (accuracy: 60.423%), validation loss = 0.964 (accuracy: 55.238%)\n",
      "Epoch 158: 15.270 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 0.942 (accuracy: 60.038%), validation loss = 0.953 (accuracy: 59.048%)\n",
      "Epoch 159: 15.233 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 0.931 (accuracy: 62.632%), validation loss = 0.965 (accuracy: 56.190%)\n",
      "Epoch 160: 15.405 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 0.936 (accuracy: 61.191%), validation loss = 0.953 (accuracy: 57.143%)\n",
      "Epoch 161: 15.361 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 0.949 (accuracy: 60.711%), validation loss = 0.953 (accuracy: 58.095%)\n",
      "Epoch 162: 15.293 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 0.948 (accuracy: 60.038%), validation loss = 0.961 (accuracy: 57.143%)\n",
      "Epoch 163: 15.241 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 0.934 (accuracy: 62.920%), validation loss = 0.955 (accuracy: 56.190%)\n",
      "Epoch 164: 15.793 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 0.932 (accuracy: 62.344%), validation loss = 0.956 (accuracy: 57.143%)\n",
      "Epoch 165: 15.338 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 0.938 (accuracy: 61.287%), validation loss = 0.954 (accuracy: 58.095%)\n",
      "Epoch 166: 15.420 seconds elapsed in epoch.\n",
      "Epoch 166: training loss = 0.941 (accuracy: 62.536%), validation loss = 0.955 (accuracy: 56.190%)\n",
      "Epoch 167: 15.250 seconds elapsed in epoch.\n",
      "Epoch 167: training loss = 0.947 (accuracy: 60.903%), validation loss = 0.952 (accuracy: 56.190%)\n",
      "Epoch 168: 15.286 seconds elapsed in epoch.\n",
      "Epoch 168: training loss = 0.934 (accuracy: 60.423%), validation loss = 0.952 (accuracy: 58.095%)\n",
      "Epoch 169: 15.227 seconds elapsed in epoch.\n",
      "Epoch 169: training loss = 0.927 (accuracy: 61.768%), validation loss = 0.950 (accuracy: 58.095%)\n",
      "Epoch 170: 15.597 seconds elapsed in epoch.\n",
      "Epoch 170: training loss = 0.938 (accuracy: 61.191%), validation loss = 0.952 (accuracy: 57.143%)\n",
      "Epoch 171: 15.447 seconds elapsed in epoch.\n",
      "Epoch 171: training loss = 0.931 (accuracy: 60.327%), validation loss = 0.960 (accuracy: 59.048%)\n",
      "Epoch 172: 15.205 seconds elapsed in epoch.\n",
      "Epoch 172: training loss = 0.939 (accuracy: 61.960%), validation loss = 0.954 (accuracy: 59.048%)\n",
      "Epoch 173: 15.364 seconds elapsed in epoch.\n",
      "Epoch 173: training loss = 0.945 (accuracy: 59.846%), validation loss = 0.947 (accuracy: 57.143%)\n",
      "Epoch 174: 15.609 seconds elapsed in epoch.\n",
      "Epoch 174: training loss = 0.932 (accuracy: 62.248%), validation loss = 0.953 (accuracy: 56.190%)\n",
      "Epoch 175: 15.207 seconds elapsed in epoch.\n",
      "Epoch 175: training loss = 0.947 (accuracy: 57.829%), validation loss = 0.953 (accuracy: 56.190%)\n",
      "Epoch 176: 15.397 seconds elapsed in epoch.\n",
      "Epoch 176: training loss = 0.931 (accuracy: 62.632%), validation loss = 0.948 (accuracy: 57.143%)\n",
      "Epoch 177: 15.261 seconds elapsed in epoch.\n",
      "Epoch 177: training loss = 0.932 (accuracy: 61.287%), validation loss = 0.957 (accuracy: 56.190%)\n",
      "Epoch 178: 15.180 seconds elapsed in epoch.\n",
      "Epoch 178: training loss = 0.954 (accuracy: 60.038%), validation loss = 0.961 (accuracy: 57.143%)\n",
      "Epoch 179: 15.220 seconds elapsed in epoch.\n",
      "Epoch 179: training loss = 0.912 (accuracy: 63.401%), validation loss = 0.951 (accuracy: 56.190%)\n",
      "Epoch 180: 15.177 seconds elapsed in epoch.\n",
      "Epoch 180: training loss = 0.940 (accuracy: 60.038%), validation loss = 0.946 (accuracy: 57.143%)\n",
      "Epoch 181: 15.608 seconds elapsed in epoch.\n",
      "Epoch 181: training loss = 0.934 (accuracy: 62.152%), validation loss = 0.951 (accuracy: 55.238%)\n",
      "Epoch 182: 15.234 seconds elapsed in epoch.\n",
      "Epoch 182: training loss = 0.932 (accuracy: 60.327%), validation loss = 0.951 (accuracy: 58.095%)\n",
      "Epoch 183: 15.321 seconds elapsed in epoch.\n",
      "Epoch 183: training loss = 0.924 (accuracy: 62.632%), validation loss = 0.949 (accuracy: 60.000%)\n",
      "Epoch 184: 15.788 seconds elapsed in epoch.\n",
      "Epoch 184: training loss = 0.924 (accuracy: 62.920%), validation loss = 0.946 (accuracy: 57.143%)\n",
      "Epoch 185: 15.279 seconds elapsed in epoch.\n",
      "Epoch 185: training loss = 0.916 (accuracy: 61.864%), validation loss = 0.947 (accuracy: 60.000%)\n",
      "Epoch 186: 15.372 seconds elapsed in epoch.\n",
      "Epoch 186: training loss = 0.921 (accuracy: 61.671%), validation loss = 0.943 (accuracy: 59.048%)\n",
      "Epoch 187: 15.586 seconds elapsed in epoch.\n",
      "Epoch 187: training loss = 0.944 (accuracy: 61.671%), validation loss = 0.947 (accuracy: 58.095%)\n",
      "Epoch 188: 15.295 seconds elapsed in epoch.\n",
      "Epoch 188: training loss = 0.910 (accuracy: 63.016%), validation loss = 0.943 (accuracy: 59.048%)\n",
      "Epoch 189: 15.268 seconds elapsed in epoch.\n",
      "Epoch 189: training loss = 0.914 (accuracy: 63.593%), validation loss = 0.944 (accuracy: 60.000%)\n",
      "Epoch 190: 15.336 seconds elapsed in epoch.\n",
      "Epoch 190: training loss = 0.921 (accuracy: 62.440%), validation loss = 0.939 (accuracy: 59.048%)\n",
      "Epoch 191: 15.561 seconds elapsed in epoch.\n",
      "Epoch 191: training loss = 0.928 (accuracy: 60.999%), validation loss = 0.947 (accuracy: 57.143%)\n",
      "Epoch 192: 15.393 seconds elapsed in epoch.\n",
      "Epoch 192: training loss = 0.940 (accuracy: 59.942%), validation loss = 0.944 (accuracy: 60.000%)\n",
      "Epoch 193: 15.484 seconds elapsed in epoch.\n",
      "Epoch 193: training loss = 0.919 (accuracy: 62.248%), validation loss = 0.943 (accuracy: 59.048%)\n",
      "Epoch 194: 15.194 seconds elapsed in epoch.\n",
      "Epoch 194: training loss = 0.929 (accuracy: 61.671%), validation loss = 0.955 (accuracy: 57.143%)\n",
      "Epoch 195: 15.217 seconds elapsed in epoch.\n",
      "Epoch 195: training loss = 0.910 (accuracy: 63.881%), validation loss = 0.939 (accuracy: 59.048%)\n",
      "Epoch 196: 15.552 seconds elapsed in epoch.\n",
      "Epoch 196: training loss = 0.930 (accuracy: 61.671%), validation loss = 0.943 (accuracy: 60.952%)\n",
      "Epoch 197: 15.406 seconds elapsed in epoch.\n",
      "Epoch 197: training loss = 0.918 (accuracy: 61.575%), validation loss = 0.950 (accuracy: 58.095%)\n",
      "Epoch 198: 15.152 seconds elapsed in epoch.\n",
      "Epoch 198: training loss = 0.929 (accuracy: 63.497%), validation loss = 0.950 (accuracy: 58.095%)\n",
      "Epoch 199: 15.132 seconds elapsed in epoch.\n",
      "Epoch 199: training loss = 0.912 (accuracy: 62.536%), validation loss = 0.945 (accuracy: 58.095%)\n",
      "Epoch 200: 15.331 seconds elapsed in epoch.\n",
      "Epoch 200: training loss = 0.925 (accuracy: 61.287%), validation loss = 0.941 (accuracy: 59.048%)\n",
      "==================================================result==================================================\n",
      "the best epoch is 195 with minimum validation error = 0.9388837967600141\n",
      "16419.411 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.1\n",
      "Epoch 1: 15.629 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.363 (accuracy: 29.875%), validation loss = 1.325 (accuracy: 33.333%)\n",
      "Epoch 2: 16.250 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.308 (accuracy: 36.984%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 3: 16.529 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.288 (accuracy: 37.848%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 4: 17.016 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.280 (accuracy: 39.289%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 5: 15.924 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.284 (accuracy: 38.425%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 6: 15.940 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.277 (accuracy: 38.905%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 7: 16.081 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.273 (accuracy: 40.922%), validation loss = 1.278 (accuracy: 33.333%)\n",
      "Epoch 8: 16.002 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.269 (accuracy: 39.577%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 9: 16.117 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.252 (accuracy: 42.555%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 10: 15.917 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.263 (accuracy: 40.922%), validation loss = 1.259 (accuracy: 33.333%)\n",
      "Epoch 11: 15.989 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.254 (accuracy: 41.499%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 12: 15.877 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.241 (accuracy: 42.459%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 13: 15.604 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.247 (accuracy: 42.075%), validation loss = 1.248 (accuracy: 33.333%)\n",
      "Epoch 14: 15.676 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.243 (accuracy: 40.826%), validation loss = 1.245 (accuracy: 33.333%)\n",
      "Epoch 15: 15.662 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.230 (accuracy: 43.132%), validation loss = 1.240 (accuracy: 33.333%)\n",
      "Epoch 16: 15.622 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.227 (accuracy: 45.533%), validation loss = 1.236 (accuracy: 34.286%)\n",
      "Epoch 17: 15.592 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.236 (accuracy: 45.341%), validation loss = 1.234 (accuracy: 33.333%)\n",
      "Epoch 18: 15.455 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.224 (accuracy: 43.132%), validation loss = 1.230 (accuracy: 35.238%)\n",
      "Epoch 19: 15.320 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.215 (accuracy: 44.957%), validation loss = 1.224 (accuracy: 36.190%)\n",
      "Epoch 20: 15.386 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.227 (accuracy: 44.573%), validation loss = 1.221 (accuracy: 36.190%)\n",
      "Epoch 21: 15.436 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.219 (accuracy: 45.053%), validation loss = 1.215 (accuracy: 32.381%)\n",
      "Epoch 22: 15.503 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.213 (accuracy: 46.110%), validation loss = 1.215 (accuracy: 38.095%)\n",
      "Epoch 23: 15.606 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.217 (accuracy: 44.284%), validation loss = 1.207 (accuracy: 41.905%)\n",
      "Epoch 24: 15.631 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.208 (accuracy: 46.686%), validation loss = 1.205 (accuracy: 41.905%)\n",
      "Epoch 25: 15.618 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.190 (accuracy: 47.358%), validation loss = 1.205 (accuracy: 39.048%)\n",
      "Epoch 26: 15.342 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.199 (accuracy: 46.878%), validation loss = 1.201 (accuracy: 41.905%)\n",
      "Epoch 27: 15.775 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.190 (accuracy: 48.607%), validation loss = 1.195 (accuracy: 40.952%)\n",
      "Epoch 28: 15.587 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.204 (accuracy: 46.398%), validation loss = 1.193 (accuracy: 40.952%)\n",
      "Epoch 29: 15.642 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.197 (accuracy: 47.839%), validation loss = 1.184 (accuracy: 43.810%)\n",
      "Epoch 30: 15.614 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.183 (accuracy: 49.568%), validation loss = 1.184 (accuracy: 42.857%)\n",
      "Epoch 31: 15.857 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.186 (accuracy: 48.511%), validation loss = 1.185 (accuracy: 40.952%)\n",
      "Epoch 32: 15.569 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.181 (accuracy: 49.472%), validation loss = 1.176 (accuracy: 44.762%)\n",
      "Epoch 33: 15.636 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.182 (accuracy: 48.799%), validation loss = 1.171 (accuracy: 44.762%)\n",
      "Epoch 34: 15.551 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.170 (accuracy: 48.511%), validation loss = 1.171 (accuracy: 44.762%)\n",
      "Epoch 35: 15.311 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.172 (accuracy: 47.743%), validation loss = 1.173 (accuracy: 44.762%)\n",
      "Epoch 36: 15.329 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.164 (accuracy: 49.568%), validation loss = 1.166 (accuracy: 44.762%)\n",
      "Epoch 37: 15.715 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.162 (accuracy: 51.105%), validation loss = 1.160 (accuracy: 46.667%)\n",
      "Epoch 38: 15.656 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.168 (accuracy: 50.144%), validation loss = 1.159 (accuracy: 48.571%)\n",
      "Epoch 39: 15.636 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.160 (accuracy: 49.183%), validation loss = 1.164 (accuracy: 45.714%)\n",
      "Epoch 40: 15.341 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.149 (accuracy: 51.969%), validation loss = 1.153 (accuracy: 50.476%)\n",
      "Epoch 41: 15.642 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.162 (accuracy: 51.009%), validation loss = 1.142 (accuracy: 48.571%)\n",
      "Epoch 42: 15.721 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.157 (accuracy: 49.952%), validation loss = 1.147 (accuracy: 48.571%)\n",
      "Epoch 43: 15.880 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.151 (accuracy: 51.297%), validation loss = 1.146 (accuracy: 52.381%)\n",
      "Epoch 44: 15.330 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.153 (accuracy: 50.817%), validation loss = 1.143 (accuracy: 50.476%)\n",
      "Epoch 45: 15.336 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.138 (accuracy: 53.314%), validation loss = 1.136 (accuracy: 52.381%)\n",
      "Epoch 46: 15.534 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.145 (accuracy: 52.257%), validation loss = 1.136 (accuracy: 50.476%)\n",
      "Epoch 47: 15.312 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.141 (accuracy: 53.314%), validation loss = 1.135 (accuracy: 51.429%)\n",
      "Epoch 48: 15.446 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.142 (accuracy: 52.450%), validation loss = 1.129 (accuracy: 50.476%)\n",
      "Epoch 49: 15.468 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.137 (accuracy: 51.393%), validation loss = 1.131 (accuracy: 53.333%)\n",
      "Epoch 50: 15.223 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.129 (accuracy: 53.602%), validation loss = 1.130 (accuracy: 53.333%)\n",
      "Epoch 51: 15.377 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.138 (accuracy: 53.314%), validation loss = 1.131 (accuracy: 49.524%)\n",
      "Epoch 52: 15.274 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.134 (accuracy: 52.834%), validation loss = 1.124 (accuracy: 51.429%)\n",
      "Epoch 53: 15.417 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.129 (accuracy: 54.563%), validation loss = 1.126 (accuracy: 49.524%)\n",
      "Epoch 54: 15.088 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.119 (accuracy: 54.083%), validation loss = 1.121 (accuracy: 52.381%)\n",
      "Epoch 55: 15.367 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.123 (accuracy: 54.083%), validation loss = 1.116 (accuracy: 51.429%)\n",
      "Epoch 56: 15.409 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.126 (accuracy: 53.506%), validation loss = 1.113 (accuracy: 51.429%)\n",
      "Epoch 57: 15.458 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.127 (accuracy: 52.354%), validation loss = 1.120 (accuracy: 51.429%)\n",
      "Epoch 58: 15.228 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.118 (accuracy: 54.563%), validation loss = 1.112 (accuracy: 51.429%)\n",
      "Epoch 59: 15.317 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.118 (accuracy: 55.043%), validation loss = 1.110 (accuracy: 53.333%)\n",
      "Epoch 60: 15.387 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.110 (accuracy: 53.410%), validation loss = 1.108 (accuracy: 51.429%)\n",
      "Epoch 61: 15.264 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.113 (accuracy: 52.546%), validation loss = 1.104 (accuracy: 49.524%)\n",
      "Epoch 62: 15.287 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.114 (accuracy: 53.987%), validation loss = 1.115 (accuracy: 51.429%)\n",
      "Epoch 63: 15.626 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.112 (accuracy: 53.890%), validation loss = 1.103 (accuracy: 51.429%)\n",
      "Epoch 64: 15.359 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.108 (accuracy: 54.371%), validation loss = 1.104 (accuracy: 51.429%)\n",
      "Epoch 65: 15.048 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.114 (accuracy: 55.139%), validation loss = 1.101 (accuracy: 50.476%)\n",
      "Epoch 66: 15.265 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.104 (accuracy: 55.235%), validation loss = 1.101 (accuracy: 51.429%)\n",
      "Epoch 67: 15.257 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.107 (accuracy: 54.851%), validation loss = 1.097 (accuracy: 50.476%)\n",
      "Epoch 68: 15.428 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.113 (accuracy: 53.698%), validation loss = 1.103 (accuracy: 51.429%)\n",
      "Epoch 69: 15.006 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.100 (accuracy: 54.659%), validation loss = 1.094 (accuracy: 50.476%)\n",
      "Epoch 70: 15.379 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.100 (accuracy: 55.043%), validation loss = 1.101 (accuracy: 51.429%)\n",
      "Epoch 71: 15.050 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.090 (accuracy: 58.309%), validation loss = 1.091 (accuracy: 51.429%)\n",
      "Epoch 72: 15.246 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.095 (accuracy: 58.309%), validation loss = 1.091 (accuracy: 50.476%)\n",
      "Epoch 73: 15.112 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.101 (accuracy: 54.947%), validation loss = 1.089 (accuracy: 51.429%)\n",
      "Epoch 74: 15.223 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.104 (accuracy: 54.275%), validation loss = 1.084 (accuracy: 49.524%)\n",
      "Epoch 75: 15.175 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.076 (accuracy: 56.772%), validation loss = 1.088 (accuracy: 51.429%)\n",
      "Epoch 76: 14.944 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.095 (accuracy: 53.890%), validation loss = 1.083 (accuracy: 51.429%)\n",
      "Epoch 77: 15.208 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.086 (accuracy: 55.524%), validation loss = 1.082 (accuracy: 50.476%)\n",
      "Epoch 78: 15.397 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.088 (accuracy: 54.083%), validation loss = 1.082 (accuracy: 51.429%)\n",
      "Epoch 79: 15.298 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.085 (accuracy: 55.427%), validation loss = 1.077 (accuracy: 52.381%)\n",
      "Epoch 80: 15.214 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.085 (accuracy: 56.004%), validation loss = 1.083 (accuracy: 53.333%)\n",
      "Epoch 81: 15.274 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.087 (accuracy: 55.235%), validation loss = 1.078 (accuracy: 51.429%)\n",
      "Epoch 82: 15.145 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.075 (accuracy: 56.868%), validation loss = 1.084 (accuracy: 54.286%)\n",
      "Epoch 83: 15.591 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.083 (accuracy: 56.676%), validation loss = 1.078 (accuracy: 51.429%)\n",
      "Epoch 84: 15.087 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.077 (accuracy: 55.235%), validation loss = 1.080 (accuracy: 51.429%)\n",
      "Epoch 85: 15.028 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.074 (accuracy: 58.117%), validation loss = 1.070 (accuracy: 51.429%)\n",
      "Epoch 86: 15.207 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.077 (accuracy: 56.868%), validation loss = 1.073 (accuracy: 52.381%)\n",
      "Epoch 87: 15.082 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.073 (accuracy: 55.524%), validation loss = 1.071 (accuracy: 53.333%)\n",
      "Epoch 88: 15.066 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.096 (accuracy: 56.484%), validation loss = 1.070 (accuracy: 52.381%)\n",
      "Epoch 89: 15.423 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.057 (accuracy: 59.654%), validation loss = 1.078 (accuracy: 52.381%)\n",
      "Epoch 90: 15.229 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.074 (accuracy: 56.100%), validation loss = 1.070 (accuracy: 50.476%)\n",
      "Epoch 91: 15.075 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.074 (accuracy: 56.868%), validation loss = 1.071 (accuracy: 48.571%)\n",
      "Epoch 92: 15.066 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.075 (accuracy: 56.100%), validation loss = 1.068 (accuracy: 54.286%)\n",
      "Epoch 93: 15.326 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.067 (accuracy: 58.309%), validation loss = 1.066 (accuracy: 51.429%)\n",
      "Epoch 94: 15.497 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.076 (accuracy: 53.987%), validation loss = 1.075 (accuracy: 54.286%)\n",
      "Epoch 95: 15.092 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.087 (accuracy: 53.987%), validation loss = 1.069 (accuracy: 52.381%)\n",
      "Epoch 96: 15.185 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.081 (accuracy: 53.698%), validation loss = 1.064 (accuracy: 54.286%)\n",
      "Epoch 97: 15.404 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.070 (accuracy: 56.676%), validation loss = 1.064 (accuracy: 53.333%)\n",
      "Epoch 98: 15.355 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.063 (accuracy: 56.196%), validation loss = 1.066 (accuracy: 52.381%)\n",
      "Epoch 99: 15.239 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.063 (accuracy: 56.868%), validation loss = 1.059 (accuracy: 53.333%)\n",
      "Epoch 100: 15.405 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.072 (accuracy: 56.772%), validation loss = 1.059 (accuracy: 51.429%)\n",
      "Epoch 101: 15.110 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.064 (accuracy: 57.061%), validation loss = 1.057 (accuracy: 51.429%)\n",
      "Epoch 102: 15.352 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.073 (accuracy: 56.292%), validation loss = 1.058 (accuracy: 53.333%)\n",
      "Epoch 103: 15.569 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.074 (accuracy: 56.388%), validation loss = 1.053 (accuracy: 54.286%)\n",
      "Epoch 104: 15.345 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.055 (accuracy: 58.213%), validation loss = 1.054 (accuracy: 51.429%)\n",
      "Epoch 105: 15.109 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.059 (accuracy: 55.908%), validation loss = 1.052 (accuracy: 56.190%)\n",
      "Epoch 106: 15.298 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.057 (accuracy: 58.598%), validation loss = 1.052 (accuracy: 53.333%)\n",
      "Epoch 107: 15.058 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.059 (accuracy: 57.349%), validation loss = 1.062 (accuracy: 51.429%)\n",
      "Epoch 108: 15.043 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.053 (accuracy: 57.637%), validation loss = 1.053 (accuracy: 53.333%)\n",
      "Epoch 109: 15.077 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.055 (accuracy: 54.755%), validation loss = 1.051 (accuracy: 54.286%)\n",
      "Epoch 110: 15.617 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.069 (accuracy: 57.445%), validation loss = 1.058 (accuracy: 55.238%)\n",
      "Epoch 111: 15.100 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.054 (accuracy: 57.349%), validation loss = 1.054 (accuracy: 55.238%)\n",
      "Epoch 112: 15.095 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.051 (accuracy: 56.868%), validation loss = 1.053 (accuracy: 54.286%)\n",
      "Epoch 113: 15.009 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.048 (accuracy: 56.292%), validation loss = 1.043 (accuracy: 53.333%)\n",
      "Epoch 114: 15.223 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.059 (accuracy: 56.100%), validation loss = 1.048 (accuracy: 54.286%)\n",
      "Epoch 115: 15.108 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.057 (accuracy: 57.637%), validation loss = 1.055 (accuracy: 54.286%)\n",
      "Epoch 116: 15.011 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.054 (accuracy: 58.501%), validation loss = 1.047 (accuracy: 54.286%)\n",
      "Epoch 117: 15.047 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.053 (accuracy: 56.388%), validation loss = 1.045 (accuracy: 54.286%)\n",
      "Epoch 118: 15.055 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.056 (accuracy: 56.580%), validation loss = 1.046 (accuracy: 55.238%)\n",
      "Epoch 119: 15.006 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.060 (accuracy: 56.196%), validation loss = 1.045 (accuracy: 54.286%)\n",
      "Epoch 120: 15.105 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.050 (accuracy: 58.021%), validation loss = 1.043 (accuracy: 51.429%)\n",
      "Epoch 121: 15.297 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.058 (accuracy: 56.772%), validation loss = 1.047 (accuracy: 55.238%)\n",
      "Epoch 122: 15.023 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.062 (accuracy: 55.235%), validation loss = 1.044 (accuracy: 53.333%)\n",
      "Epoch 123: 15.322 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.052 (accuracy: 56.676%), validation loss = 1.042 (accuracy: 53.333%)\n",
      "Epoch 124: 15.432 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.047 (accuracy: 57.253%), validation loss = 1.036 (accuracy: 56.190%)\n",
      "Epoch 125: 15.258 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 1.056 (accuracy: 56.676%), validation loss = 1.046 (accuracy: 53.333%)\n",
      "Epoch 126: 15.100 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.039 (accuracy: 57.829%), validation loss = 1.042 (accuracy: 55.238%)\n",
      "Epoch 127: 15.027 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.041 (accuracy: 59.270%), validation loss = 1.041 (accuracy: 55.238%)\n",
      "Epoch 128: 14.999 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.049 (accuracy: 56.580%), validation loss = 1.043 (accuracy: 54.286%)\n",
      "Epoch 129: 15.000 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 1.056 (accuracy: 55.331%), validation loss = 1.034 (accuracy: 55.238%)\n",
      "Epoch 130: 15.420 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 1.041 (accuracy: 58.790%), validation loss = 1.042 (accuracy: 54.286%)\n",
      "Epoch 131: 15.136 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 1.049 (accuracy: 58.501%), validation loss = 1.035 (accuracy: 54.286%)\n",
      "Epoch 132: 14.984 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 1.035 (accuracy: 58.598%), validation loss = 1.047 (accuracy: 55.238%)\n",
      "Epoch 133: 15.024 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 1.052 (accuracy: 56.484%), validation loss = 1.042 (accuracy: 52.381%)\n",
      "Epoch 134: 15.015 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 1.044 (accuracy: 56.484%), validation loss = 1.043 (accuracy: 55.238%)\n",
      "Epoch 135: 15.007 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 1.041 (accuracy: 57.637%), validation loss = 1.041 (accuracy: 53.333%)\n",
      "Epoch 136: 15.129 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 1.043 (accuracy: 58.117%), validation loss = 1.039 (accuracy: 52.381%)\n",
      "Epoch 137: 15.018 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 1.036 (accuracy: 57.637%), validation loss = 1.035 (accuracy: 54.286%)\n",
      "Epoch 138: 15.007 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 1.029 (accuracy: 59.558%), validation loss = 1.035 (accuracy: 53.333%)\n",
      "Epoch 139: 14.968 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 1.027 (accuracy: 58.598%), validation loss = 1.044 (accuracy: 55.238%)\n",
      "Epoch 140: 14.975 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 1.064 (accuracy: 56.772%), validation loss = 1.032 (accuracy: 53.333%)\n",
      "Epoch 141: 15.321 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 1.046 (accuracy: 55.812%), validation loss = 1.037 (accuracy: 55.238%)\n",
      "Epoch 142: 15.102 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 1.038 (accuracy: 59.654%), validation loss = 1.035 (accuracy: 53.333%)\n",
      "Epoch 143: 15.011 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 1.051 (accuracy: 55.620%), validation loss = 1.037 (accuracy: 56.190%)\n",
      "Epoch 144: 15.529 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 1.041 (accuracy: 57.349%), validation loss = 1.036 (accuracy: 52.381%)\n",
      "Epoch 145: 14.995 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 1.032 (accuracy: 59.366%), validation loss = 1.031 (accuracy: 55.238%)\n",
      "Epoch 146: 15.258 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 1.054 (accuracy: 57.061%), validation loss = 1.034 (accuracy: 54.286%)\n",
      "Epoch 147: 15.106 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 1.036 (accuracy: 58.598%), validation loss = 1.036 (accuracy: 54.286%)\n",
      "Epoch 148: 15.016 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 1.026 (accuracy: 59.366%), validation loss = 1.030 (accuracy: 52.381%)\n",
      "Epoch 149: 15.188 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 1.030 (accuracy: 57.829%), validation loss = 1.031 (accuracy: 55.238%)\n",
      "Epoch 150: 15.186 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 1.048 (accuracy: 56.004%), validation loss = 1.040 (accuracy: 55.238%)\n",
      "Epoch 151: 15.000 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 1.020 (accuracy: 59.846%), validation loss = 1.032 (accuracy: 53.333%)\n",
      "Epoch 152: 15.174 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 1.039 (accuracy: 56.964%), validation loss = 1.030 (accuracy: 56.190%)\n",
      "Epoch 153: 14.982 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 1.024 (accuracy: 59.174%), validation loss = 1.027 (accuracy: 53.333%)\n",
      "Epoch 154: 15.238 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 1.037 (accuracy: 58.117%), validation loss = 1.027 (accuracy: 54.286%)\n",
      "Epoch 155: 15.200 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 1.035 (accuracy: 57.925%), validation loss = 1.031 (accuracy: 54.286%)\n",
      "Epoch 156: 14.960 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 1.041 (accuracy: 58.213%), validation loss = 1.027 (accuracy: 55.238%)\n",
      "Epoch 157: 15.055 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 1.033 (accuracy: 57.733%), validation loss = 1.026 (accuracy: 55.238%)\n",
      "Epoch 158: 15.263 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 1.023 (accuracy: 57.061%), validation loss = 1.025 (accuracy: 54.286%)\n",
      "Epoch 159: 15.254 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 1.030 (accuracy: 58.213%), validation loss = 1.024 (accuracy: 55.238%)\n",
      "Epoch 160: 15.196 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 1.021 (accuracy: 59.654%), validation loss = 1.032 (accuracy: 55.238%)\n",
      "Epoch 161: 14.959 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 1.039 (accuracy: 59.174%), validation loss = 1.025 (accuracy: 55.238%)\n",
      "Epoch 162: 15.024 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 1.024 (accuracy: 59.750%), validation loss = 1.030 (accuracy: 55.238%)\n",
      "Epoch 163: 15.039 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 1.034 (accuracy: 57.157%), validation loss = 1.024 (accuracy: 53.333%)\n",
      "Epoch 164: 15.319 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 1.044 (accuracy: 58.405%), validation loss = 1.028 (accuracy: 53.333%)\n",
      "Epoch 165: 15.074 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 1.037 (accuracy: 54.851%), validation loss = 1.018 (accuracy: 55.238%)\n",
      "Epoch 166: 15.197 seconds elapsed in epoch.\n",
      "Epoch 166: training loss = 1.041 (accuracy: 56.772%), validation loss = 1.023 (accuracy: 52.381%)\n",
      "Epoch 167: 14.953 seconds elapsed in epoch.\n",
      "Epoch 167: training loss = 1.026 (accuracy: 57.925%), validation loss = 1.027 (accuracy: 55.238%)\n",
      "Epoch 168: 15.102 seconds elapsed in epoch.\n",
      "Epoch 168: training loss = 1.028 (accuracy: 59.174%), validation loss = 1.026 (accuracy: 53.333%)\n",
      "Epoch 169: 14.967 seconds elapsed in epoch.\n",
      "Epoch 169: training loss = 1.030 (accuracy: 58.213%), validation loss = 1.020 (accuracy: 55.238%)\n",
      "Epoch 170: 15.115 seconds elapsed in epoch.\n",
      "Epoch 170: training loss = 1.008 (accuracy: 59.174%), validation loss = 1.021 (accuracy: 53.333%)\n",
      "Epoch 171: 14.970 seconds elapsed in epoch.\n",
      "Epoch 171: training loss = 1.019 (accuracy: 59.366%), validation loss = 1.023 (accuracy: 54.286%)\n",
      "Epoch 172: 14.969 seconds elapsed in epoch.\n",
      "Epoch 172: training loss = 1.022 (accuracy: 57.733%), validation loss = 1.023 (accuracy: 53.333%)\n",
      "Epoch 173: 15.048 seconds elapsed in epoch.\n",
      "Epoch 173: training loss = 1.036 (accuracy: 58.021%), validation loss = 1.023 (accuracy: 54.286%)\n",
      "Epoch 174: 15.005 seconds elapsed in epoch.\n",
      "Epoch 174: training loss = 1.027 (accuracy: 58.117%), validation loss = 1.021 (accuracy: 53.333%)\n",
      "Epoch 175: 14.935 seconds elapsed in epoch.\n",
      "Epoch 175: training loss = 1.040 (accuracy: 57.637%), validation loss = 1.015 (accuracy: 55.238%)\n",
      "Epoch 176: 15.174 seconds elapsed in epoch.\n",
      "Epoch 176: training loss = 1.018 (accuracy: 59.654%), validation loss = 1.022 (accuracy: 53.333%)\n",
      "Epoch 177: 14.957 seconds elapsed in epoch.\n",
      "Epoch 177: training loss = 1.039 (accuracy: 57.637%), validation loss = 1.020 (accuracy: 55.238%)\n",
      "Epoch 178: 15.005 seconds elapsed in epoch.\n",
      "Epoch 178: training loss = 1.023 (accuracy: 57.829%), validation loss = 1.024 (accuracy: 53.333%)\n",
      "Epoch 179: 15.018 seconds elapsed in epoch.\n",
      "Epoch 179: training loss = 1.029 (accuracy: 58.309%), validation loss = 1.022 (accuracy: 53.333%)\n",
      "Epoch 180: 14.941 seconds elapsed in epoch.\n",
      "Epoch 180: training loss = 1.027 (accuracy: 58.021%), validation loss = 1.019 (accuracy: 54.286%)\n",
      "Epoch 181: 15.004 seconds elapsed in epoch.\n",
      "Epoch 181: training loss = 1.018 (accuracy: 57.541%), validation loss = 1.018 (accuracy: 54.286%)\n",
      "Epoch 182: 14.968 seconds elapsed in epoch.\n",
      "Epoch 182: training loss = 1.023 (accuracy: 59.558%), validation loss = 1.022 (accuracy: 55.238%)\n",
      "Epoch 183: 15.013 seconds elapsed in epoch.\n",
      "Epoch 183: training loss = 1.026 (accuracy: 59.558%), validation loss = 1.020 (accuracy: 54.286%)\n",
      "Epoch 184: 15.087 seconds elapsed in epoch.\n",
      "Epoch 184: training loss = 1.021 (accuracy: 59.654%), validation loss = 1.016 (accuracy: 55.238%)\n",
      "Epoch 185: 15.523 seconds elapsed in epoch.\n",
      "Epoch 185: training loss = 1.013 (accuracy: 59.558%), validation loss = 1.023 (accuracy: 55.238%)\n",
      "Epoch 186: 15.020 seconds elapsed in epoch.\n",
      "Epoch 186: training loss = 1.016 (accuracy: 60.231%), validation loss = 1.017 (accuracy: 55.238%)\n",
      "Epoch 187: 14.990 seconds elapsed in epoch.\n",
      "Epoch 187: training loss = 1.032 (accuracy: 57.253%), validation loss = 1.025 (accuracy: 56.190%)\n",
      "Epoch 188: 14.978 seconds elapsed in epoch.\n",
      "Epoch 188: training loss = 1.023 (accuracy: 60.134%), validation loss = 1.020 (accuracy: 54.286%)\n",
      "Epoch 189: 15.090 seconds elapsed in epoch.\n",
      "Epoch 189: training loss = 1.040 (accuracy: 57.637%), validation loss = 1.022 (accuracy: 53.333%)\n",
      "Epoch 190: 15.136 seconds elapsed in epoch.\n",
      "Epoch 190: training loss = 1.020 (accuracy: 58.694%), validation loss = 1.017 (accuracy: 52.381%)\n",
      "Epoch 191: 15.022 seconds elapsed in epoch.\n",
      "Epoch 191: training loss = 1.015 (accuracy: 58.501%), validation loss = 1.029 (accuracy: 53.333%)\n",
      "Epoch 192: 14.986 seconds elapsed in epoch.\n",
      "Epoch 192: training loss = 1.024 (accuracy: 58.694%), validation loss = 1.014 (accuracy: 54.286%)\n",
      "Epoch 193: 15.214 seconds elapsed in epoch.\n",
      "Epoch 193: training loss = 1.016 (accuracy: 59.654%), validation loss = 1.019 (accuracy: 52.381%)\n",
      "Epoch 194: 15.003 seconds elapsed in epoch.\n",
      "Epoch 194: training loss = 1.014 (accuracy: 60.519%), validation loss = 1.020 (accuracy: 55.238%)\n",
      "Epoch 195: 15.094 seconds elapsed in epoch.\n",
      "Epoch 195: training loss = 1.015 (accuracy: 61.383%), validation loss = 1.017 (accuracy: 55.238%)\n",
      "Epoch 196: 14.952 seconds elapsed in epoch.\n",
      "Epoch 196: training loss = 1.023 (accuracy: 57.829%), validation loss = 1.025 (accuracy: 54.286%)\n",
      "Epoch 197: 14.957 seconds elapsed in epoch.\n",
      "Epoch 197: training loss = 1.006 (accuracy: 58.405%), validation loss = 1.012 (accuracy: 54.286%)\n",
      "Epoch 198: 15.183 seconds elapsed in epoch.\n",
      "Epoch 198: training loss = 1.000 (accuracy: 60.423%), validation loss = 1.017 (accuracy: 53.333%)\n",
      "Epoch 199: 14.953 seconds elapsed in epoch.\n",
      "Epoch 199: training loss = 1.009 (accuracy: 59.462%), validation loss = 1.012 (accuracy: 53.333%)\n",
      "Epoch 200: 15.132 seconds elapsed in epoch.\n",
      "Epoch 200: training loss = 1.025 (accuracy: 58.213%), validation loss = 1.020 (accuracy: 55.238%)\n",
      "==================================================result==================================================\n",
      "the best epoch is 197 with minimum validation error = 1.0117178814751762\n",
      "19509.082 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.2\n",
      "Epoch 1: 15.050 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.349 (accuracy: 34.294%), validation loss = 1.326 (accuracy: 33.333%)\n",
      "Epoch 2: 15.181 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.306 (accuracy: 39.962%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 3: 15.141 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.292 (accuracy: 38.521%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 4: 15.200 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.287 (accuracy: 39.769%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 5: 15.706 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.282 (accuracy: 39.097%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 6: 15.266 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.279 (accuracy: 38.617%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 7: 15.144 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.274 (accuracy: 38.809%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 8: 14.951 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.264 (accuracy: 40.730%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 9: 15.184 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.270 (accuracy: 40.250%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 10: 15.394 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.265 (accuracy: 38.809%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 11: 15.193 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.259 (accuracy: 40.058%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 12: 15.162 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.265 (accuracy: 41.691%), validation loss = 1.262 (accuracy: 33.333%)\n",
      "Epoch 13: 15.007 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.250 (accuracy: 40.346%), validation loss = 1.258 (accuracy: 33.333%)\n",
      "Epoch 14: 15.230 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.253 (accuracy: 43.228%), validation loss = 1.249 (accuracy: 33.333%)\n",
      "Epoch 15: 15.252 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.243 (accuracy: 42.267%), validation loss = 1.247 (accuracy: 34.286%)\n",
      "Epoch 16: 15.286 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.242 (accuracy: 43.612%), validation loss = 1.244 (accuracy: 34.286%)\n",
      "Epoch 17: 15.204 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.245 (accuracy: 42.843%), validation loss = 1.244 (accuracy: 34.286%)\n",
      "Epoch 18: 15.220 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.242 (accuracy: 42.747%), validation loss = 1.240 (accuracy: 34.286%)\n",
      "Epoch 19: 15.217 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.233 (accuracy: 42.555%), validation loss = 1.236 (accuracy: 34.286%)\n",
      "Epoch 20: 15.299 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.232 (accuracy: 42.747%), validation loss = 1.235 (accuracy: 34.286%)\n",
      "Epoch 21: 15.303 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.232 (accuracy: 43.996%), validation loss = 1.228 (accuracy: 36.190%)\n",
      "Epoch 22: 15.228 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.236 (accuracy: 42.747%), validation loss = 1.229 (accuracy: 34.286%)\n",
      "Epoch 23: 15.013 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.231 (accuracy: 43.612%), validation loss = 1.222 (accuracy: 36.190%)\n",
      "Epoch 24: 15.224 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.225 (accuracy: 43.324%), validation loss = 1.224 (accuracy: 36.190%)\n",
      "Epoch 25: 15.483 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.224 (accuracy: 44.476%), validation loss = 1.217 (accuracy: 38.095%)\n",
      "Epoch 26: 15.593 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.227 (accuracy: 43.420%), validation loss = 1.216 (accuracy: 36.190%)\n",
      "Epoch 27: 15.294 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.217 (accuracy: 44.284%), validation loss = 1.214 (accuracy: 36.190%)\n",
      "Epoch 28: 15.343 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.215 (accuracy: 43.516%), validation loss = 1.211 (accuracy: 35.238%)\n",
      "Epoch 29: 15.461 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.213 (accuracy: 44.861%), validation loss = 1.205 (accuracy: 40.000%)\n",
      "Epoch 30: 15.572 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.212 (accuracy: 45.341%), validation loss = 1.206 (accuracy: 40.000%)\n",
      "Epoch 31: 15.323 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.206 (accuracy: 44.861%), validation loss = 1.209 (accuracy: 39.048%)\n",
      "Epoch 32: 15.168 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.211 (accuracy: 46.013%), validation loss = 1.194 (accuracy: 41.905%)\n",
      "Epoch 33: 15.424 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.194 (accuracy: 47.550%), validation loss = 1.191 (accuracy: 42.857%)\n",
      "Epoch 34: 15.470 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.200 (accuracy: 46.110%), validation loss = 1.192 (accuracy: 40.000%)\n",
      "Epoch 35: 15.101 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.192 (accuracy: 47.550%), validation loss = 1.193 (accuracy: 41.905%)\n",
      "Epoch 36: 15.566 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.200 (accuracy: 46.686%), validation loss = 1.193 (accuracy: 41.905%)\n",
      "Epoch 37: 15.147 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.196 (accuracy: 48.127%), validation loss = 1.186 (accuracy: 42.857%)\n",
      "Epoch 38: 15.452 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.190 (accuracy: 47.646%), validation loss = 1.183 (accuracy: 44.762%)\n",
      "Epoch 39: 15.411 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.197 (accuracy: 47.935%), validation loss = 1.182 (accuracy: 40.952%)\n",
      "Epoch 40: 15.300 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.184 (accuracy: 48.031%), validation loss = 1.181 (accuracy: 42.857%)\n",
      "Epoch 41: 15.713 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.190 (accuracy: 48.031%), validation loss = 1.184 (accuracy: 41.905%)\n",
      "Epoch 42: 15.104 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.195 (accuracy: 47.262%), validation loss = 1.177 (accuracy: 43.810%)\n",
      "Epoch 43: 15.273 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.183 (accuracy: 50.432%), validation loss = 1.177 (accuracy: 46.667%)\n",
      "Epoch 44: 15.338 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.185 (accuracy: 49.856%), validation loss = 1.172 (accuracy: 46.667%)\n",
      "Epoch 45: 15.891 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.186 (accuracy: 49.183%), validation loss = 1.174 (accuracy: 44.762%)\n",
      "Epoch 46: 15.285 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.175 (accuracy: 49.183%), validation loss = 1.171 (accuracy: 47.619%)\n",
      "Epoch 47: 15.489 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.174 (accuracy: 51.105%), validation loss = 1.165 (accuracy: 46.667%)\n",
      "Epoch 48: 15.494 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.176 (accuracy: 50.913%), validation loss = 1.167 (accuracy: 47.619%)\n",
      "Epoch 49: 15.238 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.175 (accuracy: 48.415%), validation loss = 1.163 (accuracy: 47.619%)\n",
      "Epoch 50: 15.523 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.174 (accuracy: 49.856%), validation loss = 1.163 (accuracy: 45.714%)\n",
      "Epoch 51: 15.458 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.167 (accuracy: 50.048%), validation loss = 1.157 (accuracy: 45.714%)\n",
      "Epoch 52: 15.446 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.168 (accuracy: 48.031%), validation loss = 1.162 (accuracy: 46.667%)\n",
      "Epoch 53: 15.085 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.164 (accuracy: 49.952%), validation loss = 1.154 (accuracy: 51.429%)\n",
      "Epoch 54: 15.394 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.160 (accuracy: 52.065%), validation loss = 1.156 (accuracy: 49.524%)\n",
      "Epoch 55: 15.111 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.170 (accuracy: 50.144%), validation loss = 1.153 (accuracy: 50.476%)\n",
      "Epoch 56: 15.430 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.165 (accuracy: 51.777%), validation loss = 1.152 (accuracy: 49.524%)\n",
      "Epoch 57: 15.495 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.157 (accuracy: 50.432%), validation loss = 1.148 (accuracy: 50.476%)\n",
      "Epoch 58: 15.465 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.148 (accuracy: 51.777%), validation loss = 1.147 (accuracy: 49.524%)\n",
      "Epoch 59: 15.412 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.151 (accuracy: 51.201%), validation loss = 1.147 (accuracy: 51.429%)\n",
      "Epoch 60: 15.173 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.156 (accuracy: 51.873%), validation loss = 1.149 (accuracy: 49.524%)\n",
      "Epoch 61: 15.166 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.153 (accuracy: 51.585%), validation loss = 1.147 (accuracy: 48.571%)\n",
      "Epoch 62: 15.346 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.160 (accuracy: 49.472%), validation loss = 1.143 (accuracy: 51.429%)\n",
      "Epoch 63: 15.395 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.154 (accuracy: 51.297%), validation loss = 1.143 (accuracy: 50.476%)\n",
      "Epoch 64: 15.276 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.161 (accuracy: 50.720%), validation loss = 1.142 (accuracy: 50.476%)\n",
      "Epoch 65: 16.066 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.154 (accuracy: 51.969%), validation loss = 1.144 (accuracy: 50.476%)\n",
      "Epoch 66: 15.287 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.163 (accuracy: 50.528%), validation loss = 1.143 (accuracy: 50.476%)\n",
      "Epoch 67: 15.297 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.150 (accuracy: 53.218%), validation loss = 1.134 (accuracy: 50.476%)\n",
      "Epoch 68: 15.358 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.146 (accuracy: 52.642%), validation loss = 1.135 (accuracy: 50.476%)\n",
      "Epoch 69: 15.268 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.141 (accuracy: 55.139%), validation loss = 1.132 (accuracy: 50.476%)\n",
      "Epoch 70: 15.437 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.151 (accuracy: 53.410%), validation loss = 1.136 (accuracy: 51.429%)\n",
      "Epoch 71: 15.022 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.144 (accuracy: 53.122%), validation loss = 1.133 (accuracy: 50.476%)\n",
      "Epoch 72: 15.132 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.151 (accuracy: 52.834%), validation loss = 1.131 (accuracy: 51.429%)\n",
      "Epoch 73: 15.319 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.146 (accuracy: 50.913%), validation loss = 1.136 (accuracy: 51.429%)\n",
      "Epoch 74: 15.135 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.133 (accuracy: 55.043%), validation loss = 1.127 (accuracy: 53.333%)\n",
      "Epoch 75: 15.391 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.132 (accuracy: 53.987%), validation loss = 1.130 (accuracy: 50.476%)\n",
      "Epoch 76: 15.086 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.131 (accuracy: 52.834%), validation loss = 1.129 (accuracy: 50.476%)\n",
      "Epoch 77: 15.034 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.132 (accuracy: 53.602%), validation loss = 1.129 (accuracy: 50.476%)\n",
      "Epoch 78: 15.053 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.140 (accuracy: 52.354%), validation loss = 1.129 (accuracy: 51.429%)\n",
      "Epoch 79: 14.989 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.140 (accuracy: 52.930%), validation loss = 1.125 (accuracy: 53.333%)\n",
      "Epoch 80: 15.254 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.132 (accuracy: 53.506%), validation loss = 1.124 (accuracy: 50.476%)\n",
      "Epoch 81: 15.250 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.132 (accuracy: 53.602%), validation loss = 1.120 (accuracy: 53.333%)\n",
      "Epoch 82: 15.216 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.126 (accuracy: 53.506%), validation loss = 1.121 (accuracy: 52.381%)\n",
      "Epoch 83: 15.132 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.137 (accuracy: 53.122%), validation loss = 1.121 (accuracy: 53.333%)\n",
      "Epoch 84: 14.976 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.139 (accuracy: 53.218%), validation loss = 1.120 (accuracy: 53.333%)\n",
      "Epoch 85: 15.652 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.138 (accuracy: 52.354%), validation loss = 1.122 (accuracy: 51.429%)\n",
      "Epoch 86: 15.088 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.143 (accuracy: 53.890%), validation loss = 1.126 (accuracy: 51.429%)\n",
      "Epoch 87: 14.993 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.129 (accuracy: 52.354%), validation loss = 1.121 (accuracy: 50.476%)\n",
      "Epoch 88: 15.063 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.138 (accuracy: 53.794%), validation loss = 1.113 (accuracy: 53.333%)\n",
      "Epoch 89: 15.398 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.129 (accuracy: 53.026%), validation loss = 1.120 (accuracy: 51.429%)\n",
      "Epoch 90: 14.988 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.130 (accuracy: 52.930%), validation loss = 1.116 (accuracy: 53.333%)\n",
      "Epoch 91: 14.946 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.129 (accuracy: 54.179%), validation loss = 1.120 (accuracy: 50.476%)\n",
      "Epoch 92: 14.986 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.119 (accuracy: 56.004%), validation loss = 1.109 (accuracy: 53.333%)\n",
      "Epoch 93: 15.280 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.136 (accuracy: 53.122%), validation loss = 1.115 (accuracy: 51.429%)\n",
      "Epoch 94: 14.944 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.118 (accuracy: 53.506%), validation loss = 1.110 (accuracy: 52.381%)\n",
      "Epoch 95: 14.929 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.130 (accuracy: 54.083%), validation loss = 1.112 (accuracy: 52.381%)\n",
      "Epoch 96: 14.954 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.121 (accuracy: 54.851%), validation loss = 1.111 (accuracy: 53.333%)\n",
      "Epoch 97: 14.987 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.122 (accuracy: 53.890%), validation loss = 1.115 (accuracy: 50.476%)\n",
      "Epoch 98: 14.960 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.123 (accuracy: 54.083%), validation loss = 1.109 (accuracy: 53.333%)\n",
      "Epoch 99: 14.969 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.123 (accuracy: 53.122%), validation loss = 1.114 (accuracy: 50.476%)\n",
      "Epoch 100: 14.877 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.124 (accuracy: 55.812%), validation loss = 1.110 (accuracy: 52.381%)\n",
      "Epoch 101: 14.895 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.134 (accuracy: 51.489%), validation loss = 1.117 (accuracy: 50.476%)\n",
      "Epoch 102: 14.930 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.124 (accuracy: 54.083%), validation loss = 1.113 (accuracy: 52.381%)\n",
      "Epoch 103: 14.944 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.124 (accuracy: 54.851%), validation loss = 1.109 (accuracy: 53.333%)\n",
      "Epoch 104: 15.332 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.124 (accuracy: 51.201%), validation loss = 1.110 (accuracy: 51.429%)\n",
      "Epoch 105: 14.994 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.124 (accuracy: 54.467%), validation loss = 1.112 (accuracy: 51.429%)\n",
      "Epoch 106: 15.419 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.119 (accuracy: 55.331%), validation loss = 1.106 (accuracy: 54.286%)\n",
      "Epoch 107: 15.148 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.110 (accuracy: 54.371%), validation loss = 1.108 (accuracy: 53.333%)\n",
      "Epoch 108: 14.932 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.131 (accuracy: 53.794%), validation loss = 1.110 (accuracy: 52.381%)\n",
      "Epoch 109: 15.174 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.125 (accuracy: 54.467%), validation loss = 1.105 (accuracy: 54.286%)\n",
      "Epoch 110: 15.194 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.127 (accuracy: 53.026%), validation loss = 1.109 (accuracy: 50.476%)\n",
      "Epoch 111: 14.924 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.126 (accuracy: 54.179%), validation loss = 1.114 (accuracy: 50.476%)\n",
      "Epoch 112: 14.916 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.117 (accuracy: 55.139%), validation loss = 1.109 (accuracy: 51.429%)\n",
      "Epoch 113: 14.897 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.118 (accuracy: 54.371%), validation loss = 1.104 (accuracy: 52.381%)\n",
      "Epoch 114: 15.166 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.112 (accuracy: 57.157%), validation loss = 1.105 (accuracy: 53.333%)\n",
      "Epoch 115: 15.054 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.111 (accuracy: 54.371%), validation loss = 1.108 (accuracy: 50.476%)\n",
      "Epoch 116: 14.965 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.118 (accuracy: 55.716%), validation loss = 1.108 (accuracy: 51.429%)\n",
      "Epoch 117: 14.873 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.111 (accuracy: 56.676%), validation loss = 1.108 (accuracy: 51.429%)\n",
      "Epoch 118: 14.860 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.120 (accuracy: 54.947%), validation loss = 1.103 (accuracy: 54.286%)\n",
      "Epoch 119: 15.091 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.108 (accuracy: 55.043%), validation loss = 1.104 (accuracy: 52.381%)\n",
      "Epoch 120: 14.987 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.122 (accuracy: 54.851%), validation loss = 1.105 (accuracy: 51.429%)\n",
      "Epoch 121: 14.846 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.116 (accuracy: 54.659%), validation loss = 1.106 (accuracy: 52.381%)\n",
      "Epoch 122: 14.866 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.116 (accuracy: 55.043%), validation loss = 1.104 (accuracy: 51.429%)\n",
      "Epoch 123: 14.868 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.108 (accuracy: 56.100%), validation loss = 1.105 (accuracy: 52.381%)\n",
      "Epoch 124: 14.864 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.114 (accuracy: 55.812%), validation loss = 1.104 (accuracy: 49.524%)\n",
      "Epoch 125: 14.924 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 1.111 (accuracy: 53.890%), validation loss = 1.099 (accuracy: 52.381%)\n",
      "Epoch 126: 15.393 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.104 (accuracy: 56.772%), validation loss = 1.103 (accuracy: 53.333%)\n",
      "Epoch 127: 15.073 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.114 (accuracy: 53.890%), validation loss = 1.101 (accuracy: 53.333%)\n",
      "Epoch 128: 14.816 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.107 (accuracy: 55.235%), validation loss = 1.109 (accuracy: 51.429%)\n",
      "Epoch 129: 14.860 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 1.113 (accuracy: 53.506%), validation loss = 1.101 (accuracy: 51.429%)\n",
      "Epoch 130: 14.926 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 1.114 (accuracy: 56.772%), validation loss = 1.098 (accuracy: 54.286%)\n",
      "Epoch 131: 15.147 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 1.115 (accuracy: 52.834%), validation loss = 1.105 (accuracy: 49.524%)\n",
      "Epoch 132: 14.835 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 1.115 (accuracy: 53.410%), validation loss = 1.096 (accuracy: 54.286%)\n",
      "Epoch 133: 15.056 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 1.112 (accuracy: 54.083%), validation loss = 1.102 (accuracy: 53.333%)\n",
      "Epoch 134: 14.840 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 1.115 (accuracy: 55.427%), validation loss = 1.096 (accuracy: 53.333%)\n",
      "Epoch 135: 14.895 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 1.106 (accuracy: 57.061%), validation loss = 1.097 (accuracy: 52.381%)\n",
      "Epoch 136: 15.013 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 1.100 (accuracy: 54.659%), validation loss = 1.105 (accuracy: 49.524%)\n",
      "Epoch 137: 14.900 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 1.102 (accuracy: 57.157%), validation loss = 1.099 (accuracy: 54.286%)\n",
      "Epoch 138: 14.851 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 1.111 (accuracy: 54.371%), validation loss = 1.101 (accuracy: 51.429%)\n",
      "Epoch 139: 14.836 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 1.106 (accuracy: 56.004%), validation loss = 1.100 (accuracy: 51.429%)\n",
      "Epoch 140: 14.830 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 1.106 (accuracy: 55.235%), validation loss = 1.100 (accuracy: 52.381%)\n",
      "Epoch 141: 14.923 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 1.097 (accuracy: 56.388%), validation loss = 1.106 (accuracy: 48.571%)\n",
      "Epoch 142: 14.921 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 1.115 (accuracy: 56.868%), validation loss = 1.095 (accuracy: 52.381%)\n",
      "Epoch 143: 15.111 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 1.109 (accuracy: 54.947%), validation loss = 1.096 (accuracy: 51.429%)\n",
      "Epoch 144: 14.887 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 1.093 (accuracy: 57.349%), validation loss = 1.105 (accuracy: 51.429%)\n",
      "Epoch 145: 14.909 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 1.112 (accuracy: 53.602%), validation loss = 1.098 (accuracy: 52.381%)\n",
      "Epoch 146: 14.975 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 1.110 (accuracy: 56.196%), validation loss = 1.099 (accuracy: 51.429%)\n",
      "Epoch 147: 15.438 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 1.106 (accuracy: 56.100%), validation loss = 1.098 (accuracy: 54.286%)\n",
      "Epoch 148: 14.916 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 1.106 (accuracy: 54.755%), validation loss = 1.095 (accuracy: 53.333%)\n",
      "Epoch 149: 15.174 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 1.101 (accuracy: 56.772%), validation loss = 1.090 (accuracy: 53.333%)\n",
      "Epoch 150: 15.228 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 1.108 (accuracy: 54.371%), validation loss = 1.102 (accuracy: 49.524%)\n",
      "Epoch 151: 14.870 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 1.099 (accuracy: 56.196%), validation loss = 1.092 (accuracy: 53.333%)\n",
      "Epoch 152: 15.040 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 1.103 (accuracy: 56.772%), validation loss = 1.105 (accuracy: 48.571%)\n",
      "Epoch 153: 14.914 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 1.115 (accuracy: 54.851%), validation loss = 1.098 (accuracy: 51.429%)\n",
      "Epoch 154: 14.890 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 1.103 (accuracy: 55.524%), validation loss = 1.103 (accuracy: 51.429%)\n",
      "Epoch 155: 14.880 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 1.111 (accuracy: 54.371%), validation loss = 1.101 (accuracy: 52.381%)\n",
      "Epoch 156: 14.905 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 1.107 (accuracy: 55.235%), validation loss = 1.095 (accuracy: 52.381%)\n",
      "Epoch 157: 14.989 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 1.107 (accuracy: 56.388%), validation loss = 1.099 (accuracy: 51.429%)\n",
      "Epoch 158: 14.948 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 1.109 (accuracy: 54.947%), validation loss = 1.099 (accuracy: 50.476%)\n",
      "Epoch 159: 14.837 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 1.106 (accuracy: 55.908%), validation loss = 1.102 (accuracy: 48.571%)\n",
      "Epoch 160: 14.871 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 1.101 (accuracy: 56.196%), validation loss = 1.094 (accuracy: 53.333%)\n",
      "Epoch 161: 14.880 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 1.099 (accuracy: 56.484%), validation loss = 1.100 (accuracy: 51.429%)\n",
      "Epoch 162: 14.868 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 1.099 (accuracy: 54.851%), validation loss = 1.107 (accuracy: 48.571%)\n",
      "Epoch 163: 14.986 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 1.102 (accuracy: 56.964%), validation loss = 1.096 (accuracy: 53.333%)\n",
      "Epoch 164: 14.862 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 1.104 (accuracy: 54.371%), validation loss = 1.090 (accuracy: 53.333%)\n",
      "Epoch 165: 15.125 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 1.110 (accuracy: 56.004%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 166: 14.856 seconds elapsed in epoch.\n",
      "Epoch 166: training loss = 1.106 (accuracy: 54.755%), validation loss = 1.111 (accuracy: 49.524%)\n",
      "Epoch 167: 14.837 seconds elapsed in epoch.\n",
      "Epoch 167: training loss = 1.090 (accuracy: 56.772%), validation loss = 1.097 (accuracy: 50.476%)\n",
      "Epoch 168: 15.510 seconds elapsed in epoch.\n",
      "Epoch 168: training loss = 1.101 (accuracy: 55.716%), validation loss = 1.092 (accuracy: 53.333%)\n",
      "Epoch 169: 14.892 seconds elapsed in epoch.\n",
      "Epoch 169: training loss = 1.110 (accuracy: 54.467%), validation loss = 1.096 (accuracy: 52.381%)\n",
      "Epoch 170: 15.054 seconds elapsed in epoch.\n",
      "Epoch 170: training loss = 1.092 (accuracy: 56.388%), validation loss = 1.099 (accuracy: 50.476%)\n",
      "Epoch 171: 14.927 seconds elapsed in epoch.\n",
      "Epoch 171: training loss = 1.113 (accuracy: 54.275%), validation loss = 1.100 (accuracy: 50.476%)\n",
      "Epoch 172: 14.911 seconds elapsed in epoch.\n",
      "Epoch 172: training loss = 1.104 (accuracy: 56.292%), validation loss = 1.101 (accuracy: 49.524%)\n",
      "Epoch 173: 14.993 seconds elapsed in epoch.\n",
      "Epoch 173: training loss = 1.110 (accuracy: 54.179%), validation loss = 1.101 (accuracy: 52.381%)\n",
      "Epoch 174: 14.970 seconds elapsed in epoch.\n",
      "Epoch 174: training loss = 1.105 (accuracy: 53.506%), validation loss = 1.097 (accuracy: 51.429%)\n",
      "Epoch 175: 14.908 seconds elapsed in epoch.\n",
      "Epoch 175: training loss = 1.107 (accuracy: 56.196%), validation loss = 1.102 (accuracy: 49.524%)\n",
      "Epoch 176: 14.873 seconds elapsed in epoch.\n",
      "Epoch 176: training loss = 1.100 (accuracy: 56.100%), validation loss = 1.104 (accuracy: 49.524%)\n",
      "Epoch 177: 14.908 seconds elapsed in epoch.\n",
      "Epoch 177: training loss = 1.113 (accuracy: 56.196%), validation loss = 1.096 (accuracy: 54.286%)\n",
      "Epoch 178: 14.885 seconds elapsed in epoch.\n",
      "Epoch 178: training loss = 1.108 (accuracy: 54.659%), validation loss = 1.102 (accuracy: 50.476%)\n",
      "Epoch 179: 15.027 seconds elapsed in epoch.\n",
      "Epoch 179: training loss = 1.101 (accuracy: 57.349%), validation loss = 1.097 (accuracy: 53.333%)\n",
      "Epoch 180: 14.924 seconds elapsed in epoch.\n",
      "Epoch 180: training loss = 1.106 (accuracy: 53.794%), validation loss = 1.098 (accuracy: 51.429%)\n",
      "Epoch 181: 14.916 seconds elapsed in epoch.\n",
      "Epoch 181: training loss = 1.105 (accuracy: 57.349%), validation loss = 1.095 (accuracy: 53.333%)\n",
      "Epoch 182: 14.851 seconds elapsed in epoch.\n",
      "Epoch 182: training loss = 1.106 (accuracy: 55.908%), validation loss = 1.092 (accuracy: 51.429%)\n",
      "Epoch 183: 14.833 seconds elapsed in epoch.\n",
      "Epoch 183: training loss = 1.101 (accuracy: 56.676%), validation loss = 1.091 (accuracy: 54.286%)\n",
      "Epoch 184: 14.906 seconds elapsed in epoch.\n",
      "Epoch 184: training loss = 1.098 (accuracy: 56.580%), validation loss = 1.089 (accuracy: 53.333%)\n",
      "Epoch 185: 15.145 seconds elapsed in epoch.\n",
      "Epoch 185: training loss = 1.112 (accuracy: 53.410%), validation loss = 1.085 (accuracy: 52.381%)\n",
      "Epoch 186: 15.090 seconds elapsed in epoch.\n",
      "Epoch 186: training loss = 1.098 (accuracy: 55.043%), validation loss = 1.092 (accuracy: 52.381%)\n",
      "Epoch 187: 14.861 seconds elapsed in epoch.\n",
      "Epoch 187: training loss = 1.096 (accuracy: 56.388%), validation loss = 1.091 (accuracy: 54.286%)\n",
      "Epoch 188: 15.009 seconds elapsed in epoch.\n",
      "Epoch 188: training loss = 1.099 (accuracy: 57.061%), validation loss = 1.101 (accuracy: 49.524%)\n",
      "Epoch 189: 15.170 seconds elapsed in epoch.\n",
      "Epoch 189: training loss = 1.104 (accuracy: 55.043%), validation loss = 1.089 (accuracy: 53.333%)\n",
      "Epoch 190: 14.974 seconds elapsed in epoch.\n",
      "Epoch 190: training loss = 1.104 (accuracy: 55.716%), validation loss = 1.088 (accuracy: 53.333%)\n",
      "Epoch 191: 14.958 seconds elapsed in epoch.\n",
      "Epoch 191: training loss = 1.105 (accuracy: 54.755%), validation loss = 1.094 (accuracy: 52.381%)\n",
      "Epoch 192: 14.846 seconds elapsed in epoch.\n",
      "Epoch 192: training loss = 1.111 (accuracy: 54.467%), validation loss = 1.091 (accuracy: 53.333%)\n",
      "Epoch 193: 14.842 seconds elapsed in epoch.\n",
      "Epoch 193: training loss = 1.102 (accuracy: 55.139%), validation loss = 1.096 (accuracy: 53.333%)\n",
      "Epoch 194: 14.843 seconds elapsed in epoch.\n",
      "Epoch 194: training loss = 1.099 (accuracy: 56.676%), validation loss = 1.093 (accuracy: 54.286%)\n",
      "Epoch 195: 14.992 seconds elapsed in epoch.\n",
      "Epoch 195: training loss = 1.106 (accuracy: 54.083%), validation loss = 1.090 (accuracy: 53.333%)\n",
      "Epoch 196: 14.817 seconds elapsed in epoch.\n",
      "Epoch 196: training loss = 1.099 (accuracy: 54.947%), validation loss = 1.089 (accuracy: 51.429%)\n",
      "Epoch 197: 14.860 seconds elapsed in epoch.\n",
      "Epoch 197: training loss = 1.098 (accuracy: 55.716%), validation loss = 1.090 (accuracy: 52.381%)\n",
      "Epoch 198: 14.884 seconds elapsed in epoch.\n",
      "Epoch 198: training loss = 1.089 (accuracy: 57.349%), validation loss = 1.098 (accuracy: 49.524%)\n",
      "Epoch 199: 14.936 seconds elapsed in epoch.\n",
      "Epoch 199: training loss = 1.097 (accuracy: 56.964%), validation loss = 1.092 (accuracy: 51.429%)\n",
      "Epoch 200: 14.962 seconds elapsed in epoch.\n",
      "Epoch 200: training loss = 1.107 (accuracy: 55.235%), validation loss = 1.093 (accuracy: 52.381%)\n",
      "==================================================result==================================================\n",
      "the best epoch is 185 with minimum validation error = 1.0851464578083583\n",
      "22558.505 total second elapsed\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.0005, 0.0001, 0.00005, 0.00001]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "min_valid_loss_list_Q3_Adam = []\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "for lr in lr_list:\n",
    "    for weight in weight_list:\n",
    "        save_file_name = \"/content/gdrive/My Drive/SLDL/hw5/Q3/Adam/resnet50_lr_\" + str(lr) + \"_weight_\" + str(weight) + \".pt\"\n",
    "        model = reset_model(isFreeze = True)\n",
    "        if train_on_gpu:\n",
    "            model = model.to('cuda')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight)\n",
    "        nepoch = 200\n",
    "        Q3_tune_model = Resnet50()\n",
    "        print(\"Start training model: learning rate = {}, weight decay = {}\".format(lr, weight))\n",
    "        model_finish = Q3_tune_model.train(train_on_gpu, model, nepoch, optimizer, save_file_name, dataloaders['train'], dataloaders['val'], verbose = True)\n",
    "        min_valid_loss_list_Q3_Adam.append(Q3_tune_model.best_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1610378043326,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "WI7xBWkPSfWi",
    "outputId": "c39fbc77-53fe-45dd-e1e1-dfbc51953537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-axis: learning rate\n",
      "y-axis: weight decay\n",
      "Best hyperparameters with Adam optimizer : learning rate = 0.0001, weight decay = 0\n",
      "      0.00050   0.00010   0.00005   0.00001\n",
      "0.0  0.942281  0.919803  0.954571  0.938884\n",
      "0.1  1.093395  1.001242  0.977782  1.011718\n",
      "0.2  1.202506  1.104850  1.089413  1.085146\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.0005, 0.0001, 0.00005, 0.00001]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "df = pd.DataFrame(index = weight_list)\n",
    "count = 0\n",
    "for lr in lr_list:\n",
    "    temp = []\n",
    "    for weight in weight_list:\n",
    "        temp.append(min_valid_loss_list_Q3_Adam[count])\n",
    "        count +=1 \n",
    "    df[lr] = temp\n",
    "index = np.unravel_index(np.argmin(df, axis=None), df.shape)\n",
    "row_index = index[0]\n",
    "column_index = index[1]\n",
    "print(\"x-axis: learning rate\")\n",
    "print(\"y-axis: weight decay\")\n",
    "print(\"Best hyperparameters with Adam optimizer : learning rate = {}, weight decay = {}\".format(lr_list[column_index], weight_list[row_index]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQXuBzllA2LY"
   },
   "source": [
    "### Tuning, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "2_buoxS9A4kf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5f19a086-7f86-41ed-a4bc-59653d6fa55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: learning rate = 0.01, weight decay = 0\n",
      "Epoch 1: 593.686 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.300 (accuracy: 37.176%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 2: 22.351 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.275 (accuracy: 40.346%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 3: 22.346 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.237 (accuracy: 42.459%), validation loss = 1.258 (accuracy: 33.333%)\n",
      "Epoch 4: 22.328 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.228 (accuracy: 43.132%), validation loss = 1.206 (accuracy: 38.095%)\n",
      "Epoch 5: 22.449 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.219 (accuracy: 45.629%), validation loss = 1.189 (accuracy: 41.905%)\n",
      "Epoch 6: 22.691 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.183 (accuracy: 45.821%), validation loss = 1.163 (accuracy: 44.762%)\n",
      "Epoch 7: 22.413 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.182 (accuracy: 47.743%), validation loss = 1.151 (accuracy: 46.667%)\n",
      "Epoch 8: 22.450 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.164 (accuracy: 49.183%), validation loss = 1.121 (accuracy: 49.524%)\n",
      "Epoch 9: 22.309 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.137 (accuracy: 50.048%), validation loss = 1.101 (accuracy: 46.667%)\n",
      "Epoch 10: 22.372 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.135 (accuracy: 50.817%), validation loss = 1.113 (accuracy: 50.476%)\n",
      "Epoch 11: 22.791 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.106 (accuracy: 52.738%), validation loss = 1.066 (accuracy: 49.524%)\n",
      "Epoch 12: 22.397 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.105 (accuracy: 52.450%), validation loss = 1.071 (accuracy: 52.381%)\n",
      "Epoch 13: 21.994 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.084 (accuracy: 55.331%), validation loss = 1.052 (accuracy: 50.476%)\n",
      "Epoch 14: 22.227 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.080 (accuracy: 55.812%), validation loss = 1.036 (accuracy: 52.381%)\n",
      "Epoch 15: 22.309 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.074 (accuracy: 51.297%), validation loss = 1.081 (accuracy: 48.571%)\n",
      "Epoch 16: 21.637 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.076 (accuracy: 52.642%), validation loss = 1.046 (accuracy: 52.381%)\n",
      "Epoch 17: 21.818 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.057 (accuracy: 54.179%), validation loss = 1.044 (accuracy: 48.571%)\n",
      "Epoch 18: 21.828 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.044 (accuracy: 55.139%), validation loss = 1.036 (accuracy: 57.143%)\n",
      "Epoch 19: 22.339 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.058 (accuracy: 53.890%), validation loss = 1.042 (accuracy: 48.571%)\n",
      "Epoch 20: 22.035 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.043 (accuracy: 56.484%), validation loss = 1.048 (accuracy: 53.333%)\n",
      "Epoch 21: 21.985 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.010 (accuracy: 56.100%), validation loss = 1.162 (accuracy: 43.810%)\n",
      "Epoch 22: 22.054 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.006 (accuracy: 56.004%), validation loss = 1.053 (accuracy: 53.333%)\n",
      "Epoch 23: 22.034 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.001 (accuracy: 57.445%), validation loss = 1.014 (accuracy: 54.286%)\n",
      "Epoch 24: 22.423 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.017 (accuracy: 56.100%), validation loss = 0.997 (accuracy: 56.190%)\n",
      "Epoch 25: 23.107 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.002 (accuracy: 56.868%), validation loss = 1.028 (accuracy: 55.238%)\n",
      "Epoch 26: 21.923 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 0.985 (accuracy: 58.405%), validation loss = 0.976 (accuracy: 55.238%)\n",
      "Epoch 27: 22.290 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.002 (accuracy: 57.253%), validation loss = 0.975 (accuracy: 59.048%)\n",
      "Epoch 28: 22.231 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 0.997 (accuracy: 58.790%), validation loss = 0.971 (accuracy: 63.810%)\n",
      "Epoch 29: 22.072 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 0.982 (accuracy: 59.366%), validation loss = 0.977 (accuracy: 59.048%)\n",
      "Epoch 30: 21.933 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 0.988 (accuracy: 57.637%), validation loss = 1.014 (accuracy: 52.381%)\n",
      "Epoch 31: 21.912 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 0.976 (accuracy: 57.349%), validation loss = 1.088 (accuracy: 49.524%)\n",
      "Epoch 32: 22.028 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 0.974 (accuracy: 57.061%), validation loss = 0.991 (accuracy: 56.190%)\n",
      "Epoch 33: 22.300 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 0.979 (accuracy: 58.501%), validation loss = 0.981 (accuracy: 59.048%)\n",
      "Epoch 34: 21.982 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 0.998 (accuracy: 58.309%), validation loss = 1.072 (accuracy: 51.429%)\n",
      "Epoch 35: 21.978 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.952 (accuracy: 59.462%), validation loss = 0.957 (accuracy: 58.095%)\n",
      "Epoch 36: 22.192 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 0.918 (accuracy: 62.248%), validation loss = 0.960 (accuracy: 60.952%)\n",
      "Epoch 37: 21.961 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 0.986 (accuracy: 56.772%), validation loss = 0.959 (accuracy: 56.190%)\n",
      "Epoch 38: 22.008 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 0.920 (accuracy: 63.305%), validation loss = 1.004 (accuracy: 54.286%)\n",
      "Epoch 39: 22.822 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 0.949 (accuracy: 59.750%), validation loss = 0.982 (accuracy: 58.095%)\n",
      "Epoch 40: 21.950 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.927 (accuracy: 61.383%), validation loss = 0.954 (accuracy: 58.095%)\n",
      "Epoch 41: 22.109 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 0.940 (accuracy: 60.999%), validation loss = 0.966 (accuracy: 58.095%)\n",
      "Epoch 42: 21.792 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.906 (accuracy: 60.999%), validation loss = 1.021 (accuracy: 55.238%)\n",
      "Epoch 43: 21.672 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.907 (accuracy: 62.632%), validation loss = 0.955 (accuracy: 60.952%)\n",
      "Epoch 44: 21.646 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.968 (accuracy: 58.790%), validation loss = 0.966 (accuracy: 60.952%)\n",
      "Epoch 45: 21.588 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.929 (accuracy: 61.191%), validation loss = 0.965 (accuracy: 57.143%)\n",
      "Epoch 46: 21.485 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.922 (accuracy: 61.864%), validation loss = 0.981 (accuracy: 62.857%)\n",
      "Epoch 47: 22.025 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.944 (accuracy: 60.999%), validation loss = 0.969 (accuracy: 64.762%)\n",
      "Epoch 48: 21.640 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 0.919 (accuracy: 60.711%), validation loss = 1.014 (accuracy: 51.429%)\n",
      "Epoch 49: 21.857 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.900 (accuracy: 61.575%), validation loss = 0.982 (accuracy: 56.190%)\n",
      "Epoch 50: 21.662 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.919 (accuracy: 60.038%), validation loss = 0.956 (accuracy: 57.143%)\n",
      "Epoch 51: 21.616 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.902 (accuracy: 61.575%), validation loss = 0.972 (accuracy: 60.952%)\n",
      "Epoch 52: 21.516 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.896 (accuracy: 62.248%), validation loss = 0.974 (accuracy: 57.143%)\n",
      "Epoch 53: 22.238 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.920 (accuracy: 62.248%), validation loss = 0.963 (accuracy: 58.095%)\n",
      "Epoch 54: 21.568 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.887 (accuracy: 64.073%), validation loss = 0.957 (accuracy: 60.952%)\n",
      "Epoch 55: 21.593 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.906 (accuracy: 62.728%), validation loss = 0.982 (accuracy: 58.095%)\n",
      "Epoch 56: 21.360 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.896 (accuracy: 64.457%), validation loss = 0.954 (accuracy: 60.952%)\n",
      "Epoch 57: 21.479 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.897 (accuracy: 61.768%), validation loss = 0.954 (accuracy: 60.000%)\n",
      "Epoch 58: 21.487 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.895 (accuracy: 63.689%), validation loss = 1.018 (accuracy: 54.286%)\n",
      "Epoch 59: 21.539 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.891 (accuracy: 61.671%), validation loss = 0.955 (accuracy: 60.000%)\n",
      "Epoch 60: 21.554 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.881 (accuracy: 63.785%), validation loss = 1.010 (accuracy: 53.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 40 with minimum validation error = 0.9537031037466867\n",
      "2066.010 total second elapsed\n",
      "Start training model: learning rate = 0.01, weight decay = 0.1\n",
      "Epoch 1: 21.789 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.296 (accuracy: 37.752%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 2: 21.512 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.278 (accuracy: 39.866%), validation loss = 1.259 (accuracy: 33.333%)\n",
      "Epoch 3: 21.622 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.253 (accuracy: 42.075%), validation loss = 1.249 (accuracy: 33.333%)\n",
      "Epoch 4: 21.526 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.243 (accuracy: 42.459%), validation loss = 1.239 (accuracy: 33.333%)\n",
      "Epoch 5: 21.514 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.226 (accuracy: 45.149%), validation loss = 1.217 (accuracy: 38.095%)\n",
      "Epoch 6: 21.520 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.215 (accuracy: 44.380%), validation loss = 1.239 (accuracy: 33.333%)\n",
      "Epoch 7: 21.809 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.199 (accuracy: 45.341%), validation loss = 1.175 (accuracy: 44.762%)\n",
      "Epoch 8: 21.877 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.198 (accuracy: 46.686%), validation loss = 1.162 (accuracy: 47.619%)\n",
      "Epoch 9: 21.799 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.169 (accuracy: 50.048%), validation loss = 1.156 (accuracy: 50.476%)\n",
      "Epoch 10: 21.986 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.174 (accuracy: 49.183%), validation loss = 1.190 (accuracy: 40.952%)\n",
      "Epoch 11: 21.726 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.162 (accuracy: 50.913%), validation loss = 1.152 (accuracy: 48.571%)\n",
      "Epoch 12: 21.736 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.150 (accuracy: 50.528%), validation loss = 1.141 (accuracy: 47.619%)\n",
      "Epoch 13: 21.665 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.152 (accuracy: 50.240%), validation loss = 1.151 (accuracy: 42.857%)\n",
      "Epoch 14: 21.493 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.130 (accuracy: 51.873%), validation loss = 1.124 (accuracy: 48.571%)\n",
      "Epoch 15: 22.042 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.127 (accuracy: 51.009%), validation loss = 1.148 (accuracy: 42.857%)\n",
      "Epoch 16: 21.462 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.123 (accuracy: 50.336%), validation loss = 1.093 (accuracy: 50.476%)\n",
      "Epoch 17: 21.892 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.116 (accuracy: 54.371%), validation loss = 1.102 (accuracy: 48.571%)\n",
      "Epoch 18: 21.706 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.103 (accuracy: 53.698%), validation loss = 1.089 (accuracy: 57.143%)\n",
      "Epoch 19: 21.944 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.097 (accuracy: 53.218%), validation loss = 1.096 (accuracy: 53.333%)\n",
      "Epoch 20: 21.753 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.101 (accuracy: 53.506%), validation loss = 1.094 (accuracy: 49.524%)\n",
      "Epoch 21: 21.988 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.088 (accuracy: 53.410%), validation loss = 1.063 (accuracy: 50.476%)\n",
      "Epoch 22: 22.216 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.080 (accuracy: 54.947%), validation loss = 1.057 (accuracy: 49.524%)\n",
      "Epoch 23: 21.768 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.099 (accuracy: 52.065%), validation loss = 1.046 (accuracy: 60.000%)\n",
      "Epoch 24: 21.639 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.091 (accuracy: 53.314%), validation loss = 1.073 (accuracy: 54.286%)\n",
      "Epoch 25: 21.412 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.078 (accuracy: 55.331%), validation loss = 1.067 (accuracy: 52.381%)\n",
      "Epoch 26: 21.454 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.074 (accuracy: 56.484%), validation loss = 1.055 (accuracy: 52.381%)\n",
      "Epoch 27: 21.611 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.058 (accuracy: 55.427%), validation loss = 1.055 (accuracy: 49.524%)\n",
      "Epoch 28: 21.702 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.062 (accuracy: 57.349%), validation loss = 1.058 (accuracy: 53.333%)\n",
      "Epoch 29: 22.018 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.073 (accuracy: 54.275%), validation loss = 1.034 (accuracy: 55.238%)\n",
      "Epoch 30: 21.994 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.051 (accuracy: 55.620%), validation loss = 1.036 (accuracy: 51.429%)\n",
      "Epoch 31: 21.733 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.051 (accuracy: 56.196%), validation loss = 1.053 (accuracy: 55.238%)\n",
      "Epoch 32: 21.757 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.061 (accuracy: 55.812%), validation loss = 1.024 (accuracy: 56.190%)\n",
      "Epoch 33: 21.995 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.050 (accuracy: 55.331%), validation loss = 1.043 (accuracy: 54.286%)\n",
      "Epoch 34: 21.757 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.046 (accuracy: 57.541%), validation loss = 1.038 (accuracy: 59.048%)\n",
      "Epoch 35: 21.802 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.054 (accuracy: 53.794%), validation loss = 1.017 (accuracy: 51.429%)\n",
      "Epoch 37: 21.918 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.045 (accuracy: 55.524%), validation loss = 1.022 (accuracy: 50.476%)\n",
      "Epoch 38: 21.448 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.015 (accuracy: 58.694%), validation loss = 1.061 (accuracy: 51.429%)\n",
      "Epoch 39: 21.472 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.023 (accuracy: 57.733%), validation loss = 1.005 (accuracy: 61.905%)\n",
      "Epoch 40: 21.649 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.026 (accuracy: 55.427%), validation loss = 1.034 (accuracy: 52.381%)\n",
      "Epoch 41: 21.362 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.035 (accuracy: 56.772%), validation loss = 1.004 (accuracy: 58.095%)\n",
      "Epoch 42: 21.523 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.057 (accuracy: 56.100%), validation loss = 1.013 (accuracy: 57.143%)\n",
      "Epoch 43: 21.645 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.025 (accuracy: 57.349%), validation loss = 1.042 (accuracy: 49.524%)\n",
      "Epoch 44: 21.247 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.030 (accuracy: 56.292%), validation loss = 1.072 (accuracy: 50.476%)\n",
      "Epoch 45: 21.348 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.040 (accuracy: 55.427%), validation loss = 1.037 (accuracy: 51.429%)\n",
      "Epoch 46: 21.333 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.022 (accuracy: 56.292%), validation loss = 1.011 (accuracy: 53.333%)\n",
      "Epoch 47: 21.125 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.035 (accuracy: 57.061%), validation loss = 1.008 (accuracy: 56.190%)\n",
      "Epoch 48: 20.776 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.012 (accuracy: 57.925%), validation loss = 0.996 (accuracy: 58.095%)\n",
      "Epoch 49: 21.711 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.037 (accuracy: 56.676%), validation loss = 1.065 (accuracy: 50.476%)\n",
      "Epoch 50: 22.523 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.024 (accuracy: 58.021%), validation loss = 1.013 (accuracy: 55.238%)\n",
      "Epoch 51: 21.818 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.019 (accuracy: 57.637%), validation loss = 1.045 (accuracy: 49.524%)\n",
      "Epoch 52: 21.882 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.021 (accuracy: 55.908%), validation loss = 0.996 (accuracy: 59.048%)\n",
      "Epoch 53: 21.814 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.012 (accuracy: 56.964%), validation loss = 1.027 (accuracy: 58.095%)\n",
      "Epoch 54: 21.931 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.020 (accuracy: 56.772%), validation loss = 1.014 (accuracy: 51.429%)\n",
      "Epoch 55: 22.050 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.005 (accuracy: 59.654%), validation loss = 1.013 (accuracy: 54.286%)\n",
      "Epoch 56: 21.913 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.031 (accuracy: 57.829%), validation loss = 1.013 (accuracy: 54.286%)\n",
      "Epoch 57: 22.244 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.030 (accuracy: 57.829%), validation loss = 1.002 (accuracy: 52.381%)\n",
      "Epoch 58: 21.923 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.021 (accuracy: 58.598%), validation loss = 1.061 (accuracy: 53.333%)\n",
      "Epoch 59: 21.940 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.040 (accuracy: 55.043%), validation loss = 1.005 (accuracy: 52.381%)\n",
      "Epoch 60: 21.996 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.014 (accuracy: 58.982%), validation loss = 1.008 (accuracy: 53.333%)\n",
      "Epoch 61: 22.059 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.013 (accuracy: 57.541%), validation loss = 1.027 (accuracy: 53.333%)\n",
      "Epoch 62: 22.129 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.993 (accuracy: 58.405%), validation loss = 1.026 (accuracy: 52.381%)\n",
      "Epoch 63: 21.836 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.999 (accuracy: 58.694%), validation loss = 1.076 (accuracy: 48.571%)\n",
      "Epoch 64: 22.435 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.036 (accuracy: 55.043%), validation loss = 1.004 (accuracy: 59.048%)\n",
      "Epoch 65: 21.876 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.022 (accuracy: 57.349%), validation loss = 0.992 (accuracy: 55.238%)\n",
      "Epoch 66: 21.820 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.011 (accuracy: 56.388%), validation loss = 1.024 (accuracy: 51.429%)\n",
      "Epoch 67: 21.835 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.033 (accuracy: 55.427%), validation loss = 1.012 (accuracy: 57.143%)\n",
      "Epoch 68: 21.863 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.024 (accuracy: 57.157%), validation loss = 1.034 (accuracy: 48.571%)\n",
      "Epoch 69: 21.951 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.019 (accuracy: 59.078%), validation loss = 0.991 (accuracy: 55.238%)\n",
      "Epoch 70: 22.017 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.021 (accuracy: 57.925%), validation loss = 1.019 (accuracy: 55.238%)\n",
      "Epoch 71: 22.338 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.016 (accuracy: 56.964%), validation loss = 1.008 (accuracy: 52.381%)\n",
      "Epoch 72: 22.056 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.006 (accuracy: 57.157%), validation loss = 1.015 (accuracy: 51.429%)\n",
      "Epoch 73: 21.964 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.004 (accuracy: 59.846%), validation loss = 1.002 (accuracy: 56.190%)\n",
      "Epoch 74: 22.088 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.021 (accuracy: 56.484%), validation loss = 1.048 (accuracy: 51.429%)\n",
      "Epoch 75: 21.977 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.010 (accuracy: 57.157%), validation loss = 1.009 (accuracy: 51.429%)\n",
      "Epoch 76: 21.809 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.031 (accuracy: 57.445%), validation loss = 1.030 (accuracy: 51.429%)\n",
      "Epoch 77: 21.725 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.020 (accuracy: 56.964%), validation loss = 1.008 (accuracy: 51.429%)\n",
      "Epoch 78: 22.469 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.006 (accuracy: 58.213%), validation loss = 1.052 (accuracy: 50.476%)\n",
      "Epoch 79: 21.809 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.002 (accuracy: 56.964%), validation loss = 1.027 (accuracy: 52.381%)\n",
      "Epoch 80: 21.810 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.998 (accuracy: 57.061%), validation loss = 0.999 (accuracy: 54.286%)\n",
      "Epoch 81: 21.738 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.995 (accuracy: 58.405%), validation loss = 0.996 (accuracy: 52.381%)\n",
      "Epoch 82: 21.807 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.020 (accuracy: 54.851%), validation loss = 1.029 (accuracy: 51.429%)\n",
      "Epoch 83: 21.821 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.000 (accuracy: 57.253%), validation loss = 0.993 (accuracy: 52.381%)\n",
      "Epoch 84: 21.775 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.008 (accuracy: 57.349%), validation loss = 1.023 (accuracy: 53.333%)\n",
      "Epoch 85: 22.108 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.014 (accuracy: 56.868%), validation loss = 1.044 (accuracy: 52.381%)\n",
      "Epoch 86: 21.747 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.991 (accuracy: 59.462%), validation loss = 0.990 (accuracy: 56.190%)\n",
      "Epoch 87: 21.970 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.995 (accuracy: 60.134%), validation loss = 0.998 (accuracy: 54.286%)\n",
      "Epoch 88: 21.585 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.992 (accuracy: 59.270%), validation loss = 0.987 (accuracy: 57.143%)\n",
      "Epoch 89: 21.997 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.016 (accuracy: 57.061%), validation loss = 1.050 (accuracy: 50.476%)\n",
      "Epoch 90: 21.652 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.010 (accuracy: 57.925%), validation loss = 1.009 (accuracy: 51.429%)\n",
      "Epoch 91: 21.674 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.999 (accuracy: 56.004%), validation loss = 0.996 (accuracy: 55.238%)\n",
      "Epoch 92: 22.071 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.013 (accuracy: 55.812%), validation loss = 1.024 (accuracy: 51.429%)\n",
      "Epoch 93: 21.686 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.001 (accuracy: 56.676%), validation loss = 1.098 (accuracy: 50.476%)\n",
      "Epoch 94: 21.411 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.019 (accuracy: 57.829%), validation loss = 1.020 (accuracy: 52.381%)\n",
      "Epoch 95: 21.561 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.999 (accuracy: 59.078%), validation loss = 1.018 (accuracy: 51.429%)\n",
      "Epoch 96: 21.628 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.016 (accuracy: 58.117%), validation loss = 0.982 (accuracy: 58.095%)\n",
      "Epoch 97: 21.871 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.022 (accuracy: 57.541%), validation loss = 1.065 (accuracy: 49.524%)\n",
      "Epoch 98: 21.588 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.023 (accuracy: 56.580%), validation loss = 1.008 (accuracy: 57.143%)\n",
      "Epoch 99: 21.892 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.004 (accuracy: 60.711%), validation loss = 1.010 (accuracy: 57.143%)\n",
      "Epoch 100: 21.673 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.002 (accuracy: 59.078%), validation loss = 1.005 (accuracy: 60.000%)\n",
      "Epoch 101: 21.597 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.991 (accuracy: 58.694%), validation loss = 1.001 (accuracy: 59.048%)\n",
      "Epoch 102: 21.698 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.993 (accuracy: 59.654%), validation loss = 0.996 (accuracy: 55.238%)\n",
      "Epoch 103: 21.630 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.014 (accuracy: 58.598%), validation loss = 1.000 (accuracy: 60.000%)\n",
      "Epoch 104: 21.449 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.989 (accuracy: 59.366%), validation loss = 1.021 (accuracy: 55.238%)\n",
      "Epoch 105: 21.560 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.005 (accuracy: 57.733%), validation loss = 1.016 (accuracy: 50.476%)\n",
      "Epoch 106: 21.513 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.009 (accuracy: 59.366%), validation loss = 0.983 (accuracy: 57.143%)\n",
      "Epoch 107: 22.202 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.005 (accuracy: 59.174%), validation loss = 1.080 (accuracy: 48.571%)\n",
      "Epoch 108: 21.384 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.995 (accuracy: 57.733%), validation loss = 1.015 (accuracy: 50.476%)\n",
      "Epoch 109: 21.483 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.000 (accuracy: 57.925%), validation loss = 0.991 (accuracy: 59.048%)\n",
      "Epoch 110: 21.408 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.017 (accuracy: 58.790%), validation loss = 1.019 (accuracy: 50.476%)\n",
      "Epoch 111: 21.415 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.005 (accuracy: 56.964%), validation loss = 0.995 (accuracy: 56.190%)\n",
      "Epoch 112: 21.526 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.986 (accuracy: 59.078%), validation loss = 1.023 (accuracy: 57.143%)\n",
      "Epoch 113: 21.975 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.007 (accuracy: 58.501%), validation loss = 0.985 (accuracy: 55.238%)\n",
      "Epoch 114: 21.793 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.995 (accuracy: 59.174%), validation loss = 0.988 (accuracy: 61.905%)\n",
      "Epoch 115: 21.739 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.019 (accuracy: 56.580%), validation loss = 1.012 (accuracy: 53.333%)\n",
      "Epoch 116: 21.840 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.015 (accuracy: 58.790%), validation loss = 1.053 (accuracy: 51.429%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 96 with minimum validation error = 0.9817825578507923\n",
      "4606.557 total second elapsed\n",
      "Start training model: learning rate = 0.01, weight decay = 0.2\n",
      "Epoch 1: 21.911 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.307 (accuracy: 36.215%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 2: 22.359 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.268 (accuracy: 39.289%), validation loss = 1.251 (accuracy: 36.190%)\n",
      "Epoch 3: 22.168 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.257 (accuracy: 40.730%), validation loss = 1.247 (accuracy: 42.857%)\n",
      "Epoch 4: 22.154 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.253 (accuracy: 41.210%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 5: 22.605 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.242 (accuracy: 43.996%), validation loss = 1.250 (accuracy: 34.286%)\n",
      "Epoch 6: 21.890 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.226 (accuracy: 43.996%), validation loss = 1.232 (accuracy: 34.286%)\n",
      "Epoch 7: 22.205 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.222 (accuracy: 44.284%), validation loss = 1.215 (accuracy: 43.810%)\n",
      "Epoch 8: 22.194 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.218 (accuracy: 45.341%), validation loss = 1.192 (accuracy: 40.952%)\n",
      "Epoch 9: 22.195 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.211 (accuracy: 45.917%), validation loss = 1.229 (accuracy: 35.238%)\n",
      "Epoch 10: 22.177 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.200 (accuracy: 47.839%), validation loss = 1.182 (accuracy: 42.857%)\n",
      "Epoch 11: 22.235 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.194 (accuracy: 47.839%), validation loss = 1.200 (accuracy: 42.857%)\n",
      "Epoch 12: 21.864 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.198 (accuracy: 45.245%), validation loss = 1.171 (accuracy: 51.429%)\n",
      "Epoch 13: 22.221 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.195 (accuracy: 46.878%), validation loss = 1.204 (accuracy: 41.905%)\n",
      "Epoch 14: 21.752 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.183 (accuracy: 48.703%), validation loss = 1.203 (accuracy: 38.095%)\n",
      "Epoch 15: 21.683 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.182 (accuracy: 46.878%), validation loss = 1.163 (accuracy: 47.619%)\n",
      "Epoch 16: 22.204 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.171 (accuracy: 51.009%), validation loss = 1.192 (accuracy: 40.952%)\n",
      "Epoch 17: 21.827 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.191 (accuracy: 48.031%), validation loss = 1.176 (accuracy: 48.571%)\n",
      "Epoch 18: 21.932 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.168 (accuracy: 50.144%), validation loss = 1.213 (accuracy: 41.905%)\n",
      "Epoch 19: 22.596 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.168 (accuracy: 48.607%), validation loss = 1.190 (accuracy: 42.857%)\n",
      "Epoch 20: 21.838 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.158 (accuracy: 50.240%), validation loss = 1.146 (accuracy: 46.667%)\n",
      "Epoch 21: 22.162 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.171 (accuracy: 50.624%), validation loss = 1.138 (accuracy: 48.571%)\n",
      "Epoch 22: 22.082 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.157 (accuracy: 49.664%), validation loss = 1.154 (accuracy: 48.571%)\n",
      "Epoch 23: 21.791 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.152 (accuracy: 52.257%), validation loss = 1.178 (accuracy: 41.905%)\n",
      "Epoch 24: 22.144 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.157 (accuracy: 50.048%), validation loss = 1.182 (accuracy: 44.762%)\n",
      "Epoch 25: 21.763 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.157 (accuracy: 49.087%), validation loss = 1.163 (accuracy: 43.810%)\n",
      "Epoch 26: 21.756 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.151 (accuracy: 50.240%), validation loss = 1.138 (accuracy: 50.476%)\n",
      "Epoch 27: 22.091 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.158 (accuracy: 50.048%), validation loss = 1.140 (accuracy: 51.429%)\n",
      "Epoch 28: 21.673 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.143 (accuracy: 50.336%), validation loss = 1.123 (accuracy: 54.286%)\n",
      "Epoch 29: 21.965 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.130 (accuracy: 54.179%), validation loss = 1.156 (accuracy: 45.714%)\n",
      "Epoch 30: 21.946 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.140 (accuracy: 51.201%), validation loss = 1.157 (accuracy: 43.810%)\n",
      "Epoch 31: 21.887 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.143 (accuracy: 51.777%), validation loss = 1.151 (accuracy: 43.810%)\n",
      "Epoch 32: 21.967 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.148 (accuracy: 51.393%), validation loss = 1.117 (accuracy: 47.619%)\n",
      "Epoch 33: 23.097 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.145 (accuracy: 52.354%), validation loss = 1.121 (accuracy: 51.429%)\n",
      "Epoch 34: 21.870 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.136 (accuracy: 53.506%), validation loss = 1.121 (accuracy: 51.429%)\n",
      "Epoch 35: 21.929 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.134 (accuracy: 54.467%), validation loss = 1.161 (accuracy: 45.714%)\n",
      "Epoch 36: 21.921 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.128 (accuracy: 53.987%), validation loss = 1.124 (accuracy: 52.381%)\n",
      "Epoch 37: 21.987 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.140 (accuracy: 53.506%), validation loss = 1.103 (accuracy: 54.286%)\n",
      "Epoch 38: 22.743 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.125 (accuracy: 54.179%), validation loss = 1.140 (accuracy: 44.762%)\n",
      "Epoch 39: 21.992 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.131 (accuracy: 53.218%), validation loss = 1.112 (accuracy: 53.333%)\n",
      "Epoch 40: 21.905 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.126 (accuracy: 53.410%), validation loss = 1.146 (accuracy: 47.619%)\n",
      "Epoch 41: 21.975 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.135 (accuracy: 52.546%), validation loss = 1.135 (accuracy: 52.381%)\n",
      "Epoch 42: 21.932 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.131 (accuracy: 53.698%), validation loss = 1.108 (accuracy: 53.333%)\n",
      "Epoch 43: 21.976 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.126 (accuracy: 53.314%), validation loss = 1.106 (accuracy: 52.381%)\n",
      "Epoch 44: 22.012 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.139 (accuracy: 52.834%), validation loss = 1.118 (accuracy: 51.429%)\n",
      "Epoch 45: 22.073 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.134 (accuracy: 52.738%), validation loss = 1.106 (accuracy: 52.381%)\n",
      "Epoch 46: 22.042 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.125 (accuracy: 54.275%), validation loss = 1.127 (accuracy: 52.381%)\n",
      "Epoch 47: 22.716 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.120 (accuracy: 55.331%), validation loss = 1.105 (accuracy: 54.286%)\n",
      "Epoch 48: 22.025 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.129 (accuracy: 54.179%), validation loss = 1.126 (accuracy: 49.524%)\n",
      "Epoch 49: 22.030 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.121 (accuracy: 53.410%), validation loss = 1.141 (accuracy: 45.714%)\n",
      "Epoch 50: 22.028 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.136 (accuracy: 52.450%), validation loss = 1.101 (accuracy: 56.190%)\n",
      "Epoch 51: 22.376 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.134 (accuracy: 55.524%), validation loss = 1.126 (accuracy: 45.714%)\n",
      "Epoch 52: 22.435 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.118 (accuracy: 54.755%), validation loss = 1.107 (accuracy: 52.381%)\n",
      "Epoch 53: 22.108 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.120 (accuracy: 54.659%), validation loss = 1.121 (accuracy: 49.524%)\n",
      "Epoch 54: 22.037 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.129 (accuracy: 52.450%), validation loss = 1.128 (accuracy: 47.619%)\n",
      "Epoch 55: 22.028 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.124 (accuracy: 54.179%), validation loss = 1.128 (accuracy: 46.667%)\n",
      "Epoch 56: 22.012 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.124 (accuracy: 53.026%), validation loss = 1.122 (accuracy: 49.524%)\n",
      "Epoch 57: 22.052 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.114 (accuracy: 52.065%), validation loss = 1.106 (accuracy: 51.429%)\n",
      "Epoch 58: 22.091 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.119 (accuracy: 54.755%), validation loss = 1.107 (accuracy: 52.381%)\n",
      "Epoch 59: 22.100 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.109 (accuracy: 55.427%), validation loss = 1.127 (accuracy: 44.762%)\n",
      "Epoch 60: 22.147 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.122 (accuracy: 54.275%), validation loss = 1.106 (accuracy: 55.238%)\n",
      "Epoch 61: 22.771 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.118 (accuracy: 53.410%), validation loss = 1.139 (accuracy: 46.667%)\n",
      "Epoch 62: 21.959 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.126 (accuracy: 51.393%), validation loss = 1.116 (accuracy: 58.095%)\n",
      "Epoch 63: 22.051 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.109 (accuracy: 55.043%), validation loss = 1.114 (accuracy: 51.429%)\n",
      "Epoch 64: 21.982 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.130 (accuracy: 53.506%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 65: 22.479 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.123 (accuracy: 51.777%), validation loss = 1.093 (accuracy: 59.048%)\n",
      "Epoch 66: 22.441 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.135 (accuracy: 54.179%), validation loss = 1.147 (accuracy: 42.857%)\n",
      "Epoch 67: 21.993 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.111 (accuracy: 55.524%), validation loss = 1.098 (accuracy: 54.286%)\n",
      "Epoch 68: 21.963 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.116 (accuracy: 54.659%), validation loss = 1.092 (accuracy: 56.190%)\n",
      "Epoch 69: 22.246 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.121 (accuracy: 52.642%), validation loss = 1.102 (accuracy: 50.476%)\n",
      "Epoch 70: 21.963 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.120 (accuracy: 52.354%), validation loss = 1.112 (accuracy: 50.476%)\n",
      "Epoch 71: 22.099 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.109 (accuracy: 53.987%), validation loss = 1.140 (accuracy: 42.857%)\n",
      "Epoch 72: 22.001 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.126 (accuracy: 53.218%), validation loss = 1.093 (accuracy: 51.429%)\n",
      "Epoch 73: 22.089 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.121 (accuracy: 55.524%), validation loss = 1.108 (accuracy: 52.381%)\n",
      "Epoch 74: 22.071 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.125 (accuracy: 52.546%), validation loss = 1.096 (accuracy: 48.571%)\n",
      "Epoch 75: 22.729 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.119 (accuracy: 53.890%), validation loss = 1.116 (accuracy: 50.476%)\n",
      "Epoch 76: 21.824 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.119 (accuracy: 53.410%), validation loss = 1.106 (accuracy: 55.238%)\n",
      "Epoch 77: 21.876 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.119 (accuracy: 55.139%), validation loss = 1.087 (accuracy: 52.381%)\n",
      "Epoch 78: 22.318 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.114 (accuracy: 53.794%), validation loss = 1.138 (accuracy: 46.667%)\n",
      "Epoch 79: 22.297 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.099 (accuracy: 53.890%), validation loss = 1.133 (accuracy: 45.714%)\n",
      "Epoch 80: 21.998 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.123 (accuracy: 52.738%), validation loss = 1.096 (accuracy: 48.571%)\n",
      "Epoch 81: 22.130 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.116 (accuracy: 54.275%), validation loss = 1.091 (accuracy: 50.476%)\n",
      "Epoch 82: 22.257 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.114 (accuracy: 54.851%), validation loss = 1.112 (accuracy: 49.524%)\n",
      "Epoch 83: 22.041 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.121 (accuracy: 51.873%), validation loss = 1.089 (accuracy: 50.476%)\n",
      "Epoch 84: 22.067 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.116 (accuracy: 54.851%), validation loss = 1.092 (accuracy: 52.381%)\n",
      "Epoch 85: 22.055 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.099 (accuracy: 55.235%), validation loss = 1.106 (accuracy: 49.524%)\n",
      "Epoch 86: 22.108 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.104 (accuracy: 55.812%), validation loss = 1.093 (accuracy: 53.333%)\n",
      "Epoch 87: 22.189 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.125 (accuracy: 52.738%), validation loss = 1.098 (accuracy: 56.190%)\n",
      "Epoch 88: 22.117 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.112 (accuracy: 55.620%), validation loss = 1.086 (accuracy: 57.143%)\n",
      "Epoch 89: 23.253 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.123 (accuracy: 54.179%), validation loss = 1.090 (accuracy: 47.619%)\n",
      "Epoch 90: 22.194 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.119 (accuracy: 54.467%), validation loss = 1.169 (accuracy: 40.952%)\n",
      "Epoch 91: 22.039 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.120 (accuracy: 53.122%), validation loss = 1.092 (accuracy: 49.524%)\n",
      "Epoch 92: 22.075 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.109 (accuracy: 53.987%), validation loss = 1.093 (accuracy: 49.524%)\n",
      "Epoch 93: 22.435 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.125 (accuracy: 52.930%), validation loss = 1.108 (accuracy: 49.524%)\n",
      "Epoch 94: 22.195 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.115 (accuracy: 53.794%), validation loss = 1.134 (accuracy: 45.714%)\n",
      "Epoch 95: 22.243 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.115 (accuracy: 54.563%), validation loss = 1.088 (accuracy: 60.952%)\n",
      "Epoch 96: 22.187 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.114 (accuracy: 55.908%), validation loss = 1.103 (accuracy: 54.286%)\n",
      "Epoch 97: 22.159 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.103 (accuracy: 53.890%), validation loss = 1.089 (accuracy: 55.238%)\n",
      "Epoch 98: 22.089 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.130 (accuracy: 53.314%), validation loss = 1.119 (accuracy: 49.524%)\n",
      "Epoch 99: 22.153 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.106 (accuracy: 57.349%), validation loss = 1.102 (accuracy: 52.381%)\n",
      "Epoch 100: 22.134 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.116 (accuracy: 52.546%), validation loss = 1.088 (accuracy: 52.381%)\n",
      "Epoch 101: 22.082 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.117 (accuracy: 54.563%), validation loss = 1.102 (accuracy: 55.238%)\n",
      "Epoch 102: 22.155 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.112 (accuracy: 54.467%), validation loss = 1.117 (accuracy: 48.571%)\n",
      "Epoch 103: 22.925 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.112 (accuracy: 55.235%), validation loss = 1.110 (accuracy: 50.476%)\n",
      "Epoch 104: 22.091 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.112 (accuracy: 55.427%), validation loss = 1.097 (accuracy: 51.429%)\n",
      "Epoch 105: 22.091 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.108 (accuracy: 54.083%), validation loss = 1.093 (accuracy: 54.286%)\n",
      "Epoch 106: 22.037 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.110 (accuracy: 55.043%), validation loss = 1.087 (accuracy: 50.476%)\n",
      "Epoch 107: 22.436 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.106 (accuracy: 55.139%), validation loss = 1.096 (accuracy: 59.048%)\n",
      "Epoch 108: 22.182 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.102 (accuracy: 54.659%), validation loss = 1.095 (accuracy: 50.476%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 88 with minimum validation error = 1.0859042621794202\n",
      "7010.840 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0\n",
      "Epoch 1: 22.446 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.314 (accuracy: 34.582%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 2: 22.993 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.271 (accuracy: 39.962%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 3: 22.796 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.266 (accuracy: 40.250%), validation loss = 1.265 (accuracy: 33.333%)\n",
      "Epoch 4: 22.682 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.252 (accuracy: 42.171%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 5: 22.653 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.244 (accuracy: 42.267%), validation loss = 1.237 (accuracy: 35.238%)\n",
      "Epoch 6: 22.838 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.233 (accuracy: 44.380%), validation loss = 1.236 (accuracy: 35.238%)\n",
      "Epoch 7: 22.639 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.219 (accuracy: 43.708%), validation loss = 1.221 (accuracy: 36.190%)\n",
      "Epoch 8: 23.384 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.220 (accuracy: 44.476%), validation loss = 1.199 (accuracy: 45.714%)\n",
      "Epoch 9: 22.816 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.205 (accuracy: 46.013%), validation loss = 1.197 (accuracy: 42.857%)\n",
      "Epoch 10: 22.899 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.200 (accuracy: 46.686%), validation loss = 1.167 (accuracy: 51.429%)\n",
      "Epoch 11: 22.736 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.176 (accuracy: 49.087%), validation loss = 1.166 (accuracy: 46.667%)\n",
      "Epoch 12: 22.993 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.179 (accuracy: 49.183%), validation loss = 1.149 (accuracy: 53.333%)\n",
      "Epoch 13: 22.799 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.166 (accuracy: 49.856%), validation loss = 1.156 (accuracy: 46.667%)\n",
      "Epoch 14: 22.454 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.157 (accuracy: 49.472%), validation loss = 1.149 (accuracy: 46.667%)\n",
      "Epoch 15: 22.567 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.151 (accuracy: 52.354%), validation loss = 1.137 (accuracy: 49.524%)\n",
      "Epoch 16: 22.731 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.143 (accuracy: 51.873%), validation loss = 1.126 (accuracy: 49.524%)\n",
      "Epoch 17: 22.772 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.136 (accuracy: 52.257%), validation loss = 1.152 (accuracy: 44.762%)\n",
      "Epoch 18: 22.388 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.129 (accuracy: 50.432%), validation loss = 1.101 (accuracy: 52.381%)\n",
      "Epoch 19: 22.742 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.115 (accuracy: 51.681%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 20: 22.772 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.109 (accuracy: 53.218%), validation loss = 1.088 (accuracy: 53.333%)\n",
      "Epoch 21: 22.723 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.100 (accuracy: 54.755%), validation loss = 1.086 (accuracy: 51.429%)\n",
      "Epoch 22: 23.327 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.088 (accuracy: 56.196%), validation loss = 1.075 (accuracy: 51.429%)\n",
      "Epoch 23: 22.718 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.083 (accuracy: 55.139%), validation loss = 1.094 (accuracy: 49.524%)\n",
      "Epoch 24: 22.566 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.069 (accuracy: 54.275%), validation loss = 1.056 (accuracy: 50.476%)\n",
      "Epoch 25: 23.074 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.080 (accuracy: 53.506%), validation loss = 1.065 (accuracy: 50.476%)\n",
      "Epoch 26: 22.443 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.056 (accuracy: 57.637%), validation loss = 1.056 (accuracy: 52.381%)\n",
      "Epoch 27: 22.567 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.057 (accuracy: 56.676%), validation loss = 1.085 (accuracy: 48.571%)\n",
      "Epoch 28: 22.563 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.064 (accuracy: 54.947%), validation loss = 1.075 (accuracy: 50.476%)\n",
      "Epoch 29: 22.525 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.029 (accuracy: 56.676%), validation loss = 1.026 (accuracy: 55.238%)\n",
      "Epoch 30: 22.875 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.044 (accuracy: 56.964%), validation loss = 1.057 (accuracy: 50.476%)\n",
      "Epoch 31: 22.611 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.023 (accuracy: 56.868%), validation loss = 1.023 (accuracy: 56.190%)\n",
      "Epoch 32: 22.781 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.026 (accuracy: 57.253%), validation loss = 1.013 (accuracy: 55.238%)\n",
      "Epoch 33: 22.659 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.015 (accuracy: 57.925%), validation loss = 1.036 (accuracy: 49.524%)\n",
      "Epoch 34: 22.554 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.035 (accuracy: 56.292%), validation loss = 1.038 (accuracy: 51.429%)\n",
      "Epoch 35: 23.104 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 0.995 (accuracy: 57.733%), validation loss = 1.035 (accuracy: 51.429%)\n",
      "Epoch 36: 22.542 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.020 (accuracy: 57.061%), validation loss = 1.023 (accuracy: 53.333%)\n",
      "Epoch 37: 22.467 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.018 (accuracy: 57.253%), validation loss = 0.995 (accuracy: 53.333%)\n",
      "Epoch 38: 23.071 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.006 (accuracy: 57.541%), validation loss = 1.025 (accuracy: 53.333%)\n",
      "Epoch 39: 22.797 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.011 (accuracy: 57.445%), validation loss = 1.061 (accuracy: 49.524%)\n",
      "Epoch 40: 22.458 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 0.998 (accuracy: 59.462%), validation loss = 1.061 (accuracy: 51.429%)\n",
      "Epoch 41: 22.390 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.002 (accuracy: 57.829%), validation loss = 1.009 (accuracy: 56.190%)\n",
      "Epoch 42: 22.351 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 0.986 (accuracy: 59.270%), validation loss = 1.011 (accuracy: 54.286%)\n",
      "Epoch 43: 22.472 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 0.969 (accuracy: 60.423%), validation loss = 0.989 (accuracy: 57.143%)\n",
      "Epoch 44: 22.834 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 0.995 (accuracy: 57.157%), validation loss = 0.972 (accuracy: 60.952%)\n",
      "Epoch 45: 22.656 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 0.981 (accuracy: 58.309%), validation loss = 0.993 (accuracy: 55.238%)\n",
      "Epoch 46: 22.395 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 0.983 (accuracy: 59.846%), validation loss = 0.997 (accuracy: 54.286%)\n",
      "Epoch 47: 22.424 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 0.953 (accuracy: 60.231%), validation loss = 1.054 (accuracy: 52.381%)\n",
      "Epoch 48: 22.511 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.013 (accuracy: 58.501%), validation loss = 1.004 (accuracy: 55.238%)\n",
      "Epoch 49: 23.116 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 0.944 (accuracy: 60.807%), validation loss = 0.965 (accuracy: 59.048%)\n",
      "Epoch 50: 22.690 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 0.988 (accuracy: 57.925%), validation loss = 0.995 (accuracy: 54.286%)\n",
      "Epoch 51: 22.399 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 0.972 (accuracy: 59.174%), validation loss = 0.968 (accuracy: 59.048%)\n",
      "Epoch 52: 22.928 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 0.969 (accuracy: 60.903%), validation loss = 0.958 (accuracy: 60.000%)\n",
      "Epoch 53: 22.810 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.935 (accuracy: 61.864%), validation loss = 1.016 (accuracy: 51.429%)\n",
      "Epoch 54: 22.520 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.924 (accuracy: 63.401%), validation loss = 0.976 (accuracy: 59.048%)\n",
      "Epoch 55: 22.560 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.951 (accuracy: 59.654%), validation loss = 0.966 (accuracy: 59.048%)\n",
      "Epoch 56: 22.492 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.945 (accuracy: 60.423%), validation loss = 0.981 (accuracy: 58.095%)\n",
      "Epoch 57: 22.627 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.954 (accuracy: 59.654%), validation loss = 0.978 (accuracy: 60.000%)\n",
      "Epoch 58: 22.409 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.939 (accuracy: 59.174%), validation loss = 0.980 (accuracy: 60.000%)\n",
      "Epoch 59: 22.429 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 0.932 (accuracy: 61.768%), validation loss = 0.975 (accuracy: 52.381%)\n",
      "Epoch 60: 22.562 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 0.939 (accuracy: 61.095%), validation loss = 0.979 (accuracy: 57.143%)\n",
      "Epoch 61: 22.518 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 0.945 (accuracy: 60.903%), validation loss = 0.961 (accuracy: 58.095%)\n",
      "Epoch 62: 22.656 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 0.939 (accuracy: 60.711%), validation loss = 1.039 (accuracy: 52.381%)\n",
      "Epoch 63: 22.834 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 0.928 (accuracy: 61.287%), validation loss = 0.978 (accuracy: 61.905%)\n",
      "Epoch 64: 21.905 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 0.908 (accuracy: 62.824%), validation loss = 0.983 (accuracy: 55.238%)\n",
      "Epoch 65: 22.058 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 0.928 (accuracy: 61.575%), validation loss = 0.966 (accuracy: 59.048%)\n",
      "Epoch 66: 22.119 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 0.925 (accuracy: 62.728%), validation loss = 0.970 (accuracy: 56.190%)\n",
      "Epoch 67: 22.010 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 0.924 (accuracy: 60.231%), validation loss = 0.974 (accuracy: 60.000%)\n",
      "Epoch 68: 21.802 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 0.918 (accuracy: 62.056%), validation loss = 0.965 (accuracy: 58.095%)\n",
      "Epoch 69: 21.949 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 0.912 (accuracy: 60.615%), validation loss = 0.950 (accuracy: 59.048%)\n",
      "Epoch 70: 22.129 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 0.894 (accuracy: 63.208%), validation loss = 0.967 (accuracy: 57.143%)\n",
      "Epoch 71: 21.913 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 0.915 (accuracy: 62.056%), validation loss = 0.957 (accuracy: 58.095%)\n",
      "Epoch 72: 21.809 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 0.923 (accuracy: 62.344%), validation loss = 1.010 (accuracy: 54.286%)\n",
      "Epoch 73: 21.847 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 0.899 (accuracy: 62.920%), validation loss = 0.982 (accuracy: 54.286%)\n",
      "Epoch 74: 21.765 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 0.908 (accuracy: 62.440%), validation loss = 0.991 (accuracy: 54.286%)\n",
      "Epoch 75: 21.914 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 0.905 (accuracy: 61.575%), validation loss = 0.996 (accuracy: 60.000%)\n",
      "Epoch 76: 22.018 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 0.927 (accuracy: 60.423%), validation loss = 1.007 (accuracy: 53.333%)\n",
      "Epoch 77: 22.735 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 0.926 (accuracy: 62.344%), validation loss = 0.972 (accuracy: 56.190%)\n",
      "Epoch 78: 22.754 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 0.888 (accuracy: 63.016%), validation loss = 0.979 (accuracy: 58.095%)\n",
      "Epoch 79: 22.762 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 0.910 (accuracy: 62.632%), validation loss = 0.969 (accuracy: 55.238%)\n",
      "Epoch 80: 22.528 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 0.892 (accuracy: 63.208%), validation loss = 0.934 (accuracy: 62.857%)\n",
      "Epoch 81: 22.785 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 0.898 (accuracy: 62.248%), validation loss = 0.954 (accuracy: 58.095%)\n",
      "Epoch 82: 22.624 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 0.897 (accuracy: 63.208%), validation loss = 0.934 (accuracy: 63.810%)\n",
      "Epoch 83: 22.429 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 0.890 (accuracy: 62.632%), validation loss = 0.977 (accuracy: 55.238%)\n",
      "Epoch 84: 22.464 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 0.888 (accuracy: 61.960%), validation loss = 0.947 (accuracy: 60.000%)\n",
      "Epoch 85: 22.411 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 0.914 (accuracy: 63.112%), validation loss = 0.961 (accuracy: 56.190%)\n",
      "Epoch 86: 22.500 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 0.885 (accuracy: 64.265%), validation loss = 0.927 (accuracy: 61.905%)\n",
      "Epoch 87: 22.785 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 0.880 (accuracy: 63.593%), validation loss = 0.940 (accuracy: 60.000%)\n",
      "Epoch 88: 22.373 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 0.887 (accuracy: 61.768%), validation loss = 0.946 (accuracy: 60.952%)\n",
      "Epoch 89: 22.559 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 0.880 (accuracy: 63.401%), validation loss = 0.933 (accuracy: 60.000%)\n",
      "Epoch 90: 22.886 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 0.893 (accuracy: 63.497%), validation loss = 0.997 (accuracy: 54.286%)\n",
      "Epoch 91: 22.839 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 0.887 (accuracy: 63.785%), validation loss = 0.945 (accuracy: 58.095%)\n",
      "Epoch 92: 22.253 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 0.884 (accuracy: 62.824%), validation loss = 0.975 (accuracy: 59.048%)\n",
      "Epoch 93: 22.790 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.881 (accuracy: 62.248%), validation loss = 0.938 (accuracy: 58.095%)\n",
      "Epoch 94: 22.454 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 0.893 (accuracy: 63.689%), validation loss = 0.939 (accuracy: 59.048%)\n",
      "Epoch 95: 22.475 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 0.876 (accuracy: 64.553%), validation loss = 0.963 (accuracy: 58.095%)\n",
      "Epoch 96: 22.587 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 0.851 (accuracy: 64.745%), validation loss = 0.955 (accuracy: 62.857%)\n",
      "Epoch 97: 22.507 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 0.894 (accuracy: 63.881%), validation loss = 0.929 (accuracy: 59.048%)\n",
      "Epoch 98: 22.407 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 0.865 (accuracy: 65.610%), validation loss = 0.953 (accuracy: 60.000%)\n",
      "Epoch 99: 22.199 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.864 (accuracy: 63.785%), validation loss = 0.951 (accuracy: 62.857%)\n",
      "Epoch 100: 22.503 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 0.863 (accuracy: 64.265%), validation loss = 0.955 (accuracy: 58.095%)\n",
      "Epoch 101: 22.455 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 0.857 (accuracy: 65.130%), validation loss = 0.967 (accuracy: 60.952%)\n",
      "Epoch 102: 22.575 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 0.864 (accuracy: 64.265%), validation loss = 0.937 (accuracy: 59.048%)\n",
      "Epoch 103: 22.462 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 0.856 (accuracy: 64.361%), validation loss = 0.987 (accuracy: 54.286%)\n",
      "Epoch 104: 23.327 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.848 (accuracy: 64.745%), validation loss = 0.945 (accuracy: 60.000%)\n",
      "Epoch 105: 22.359 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 0.843 (accuracy: 64.649%), validation loss = 0.946 (accuracy: 58.095%)\n",
      "Epoch 106: 22.472 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 0.861 (accuracy: 65.994%), validation loss = 0.932 (accuracy: 60.000%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 86 with minimum validation error = 0.9273719401586623\n",
      "9421.639 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0.1\n",
      "Epoch 1: 21.751 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.313 (accuracy: 37.464%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 2: 22.125 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.278 (accuracy: 39.962%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 3: 22.000 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.261 (accuracy: 41.595%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 4: 21.896 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.251 (accuracy: 40.826%), validation loss = 1.248 (accuracy: 33.333%)\n",
      "Epoch 5: 21.931 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.252 (accuracy: 41.402%), validation loss = 1.238 (accuracy: 38.095%)\n",
      "Epoch 6: 22.147 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.240 (accuracy: 43.036%), validation loss = 1.239 (accuracy: 33.333%)\n",
      "Epoch 7: 21.818 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.232 (accuracy: 41.787%), validation loss = 1.236 (accuracy: 33.333%)\n",
      "Epoch 8: 22.113 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.229 (accuracy: 43.036%), validation loss = 1.210 (accuracy: 43.810%)\n",
      "Epoch 9: 22.118 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.225 (accuracy: 45.245%), validation loss = 1.222 (accuracy: 38.095%)\n",
      "Epoch 10: 21.792 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.210 (accuracy: 44.573%), validation loss = 1.224 (accuracy: 37.143%)\n",
      "Epoch 11: 21.896 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.204 (accuracy: 46.110%), validation loss = 1.199 (accuracy: 40.952%)\n",
      "Epoch 12: 22.752 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.200 (accuracy: 46.206%), validation loss = 1.200 (accuracy: 40.000%)\n",
      "Epoch 13: 21.790 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.193 (accuracy: 45.437%), validation loss = 1.173 (accuracy: 48.571%)\n",
      "Epoch 14: 22.406 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.194 (accuracy: 46.302%), validation loss = 1.171 (accuracy: 47.619%)\n",
      "Epoch 15: 22.041 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.184 (accuracy: 49.664%), validation loss = 1.171 (accuracy: 45.714%)\n",
      "Epoch 16: 22.090 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.168 (accuracy: 51.489%), validation loss = 1.162 (accuracy: 47.619%)\n",
      "Epoch 17: 22.081 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.166 (accuracy: 50.048%), validation loss = 1.156 (accuracy: 44.762%)\n",
      "Epoch 18: 22.021 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.163 (accuracy: 51.489%), validation loss = 1.153 (accuracy: 48.571%)\n",
      "Epoch 19: 22.112 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.161 (accuracy: 50.336%), validation loss = 1.149 (accuracy: 47.619%)\n",
      "Epoch 20: 22.096 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.149 (accuracy: 50.817%), validation loss = 1.138 (accuracy: 48.571%)\n",
      "Epoch 21: 22.103 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.166 (accuracy: 50.144%), validation loss = 1.133 (accuracy: 48.571%)\n",
      "Epoch 22: 22.129 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.153 (accuracy: 50.240%), validation loss = 1.119 (accuracy: 52.381%)\n",
      "Epoch 23: 22.085 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.141 (accuracy: 51.969%), validation loss = 1.121 (accuracy: 52.381%)\n",
      "Epoch 24: 21.908 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.140 (accuracy: 51.777%), validation loss = 1.113 (accuracy: 54.286%)\n",
      "Epoch 25: 21.964 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.125 (accuracy: 54.179%), validation loss = 1.123 (accuracy: 48.571%)\n",
      "Epoch 26: 22.594 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.128 (accuracy: 52.930%), validation loss = 1.109 (accuracy: 49.524%)\n",
      "Epoch 27: 22.278 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.130 (accuracy: 52.354%), validation loss = 1.094 (accuracy: 51.429%)\n",
      "Epoch 28: 22.092 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.122 (accuracy: 54.179%), validation loss = 1.104 (accuracy: 52.381%)\n",
      "Epoch 29: 21.784 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.117 (accuracy: 53.410%), validation loss = 1.104 (accuracy: 52.381%)\n",
      "Epoch 30: 21.831 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.110 (accuracy: 53.602%), validation loss = 1.102 (accuracy: 54.286%)\n",
      "Epoch 31: 21.680 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.109 (accuracy: 53.410%), validation loss = 1.082 (accuracy: 50.476%)\n",
      "Epoch 32: 22.131 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.124 (accuracy: 52.546%), validation loss = 1.088 (accuracy: 53.333%)\n",
      "Epoch 33: 21.871 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.116 (accuracy: 53.794%), validation loss = 1.078 (accuracy: 50.476%)\n",
      "Epoch 34: 22.062 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.092 (accuracy: 55.139%), validation loss = 1.093 (accuracy: 52.381%)\n",
      "Epoch 35: 21.864 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.094 (accuracy: 53.410%), validation loss = 1.072 (accuracy: 50.476%)\n",
      "Epoch 36: 22.109 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.088 (accuracy: 56.196%), validation loss = 1.080 (accuracy: 53.333%)\n",
      "Epoch 37: 21.756 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.090 (accuracy: 54.947%), validation loss = 1.076 (accuracy: 50.476%)\n",
      "Epoch 38: 21.713 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.081 (accuracy: 56.580%), validation loss = 1.069 (accuracy: 49.524%)\n",
      "Epoch 39: 22.132 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.083 (accuracy: 55.620%), validation loss = 1.054 (accuracy: 54.286%)\n",
      "Epoch 40: 22.835 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.085 (accuracy: 53.506%), validation loss = 1.059 (accuracy: 52.381%)\n",
      "Epoch 41: 22.048 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.085 (accuracy: 56.196%), validation loss = 1.053 (accuracy: 50.476%)\n",
      "Epoch 42: 21.998 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.072 (accuracy: 56.292%), validation loss = 1.069 (accuracy: 53.333%)\n",
      "Epoch 43: 21.738 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.081 (accuracy: 55.139%), validation loss = 1.057 (accuracy: 53.333%)\n",
      "Epoch 44: 21.723 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.066 (accuracy: 55.620%), validation loss = 1.044 (accuracy: 53.333%)\n",
      "Epoch 45: 21.911 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.066 (accuracy: 56.772%), validation loss = 1.042 (accuracy: 56.190%)\n",
      "Epoch 46: 22.067 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.074 (accuracy: 55.331%), validation loss = 1.049 (accuracy: 54.286%)\n",
      "Epoch 47: 21.714 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.052 (accuracy: 57.637%), validation loss = 1.054 (accuracy: 52.381%)\n",
      "Epoch 48: 21.734 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.061 (accuracy: 54.371%), validation loss = 1.035 (accuracy: 52.381%)\n",
      "Epoch 49: 22.013 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.058 (accuracy: 57.253%), validation loss = 1.030 (accuracy: 60.000%)\n",
      "Epoch 50: 22.064 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.051 (accuracy: 57.253%), validation loss = 1.032 (accuracy: 56.190%)\n",
      "Epoch 51: 21.786 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.059 (accuracy: 54.947%), validation loss = 1.031 (accuracy: 57.143%)\n",
      "Epoch 52: 21.705 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.055 (accuracy: 56.964%), validation loss = 1.036 (accuracy: 55.238%)\n",
      "Epoch 53: 21.668 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.041 (accuracy: 58.117%), validation loss = 1.054 (accuracy: 55.238%)\n",
      "Epoch 54: 22.396 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.060 (accuracy: 56.484%), validation loss = 1.037 (accuracy: 55.238%)\n",
      "Epoch 55: 21.943 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.045 (accuracy: 57.349%), validation loss = 1.030 (accuracy: 55.238%)\n",
      "Epoch 56: 21.734 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.055 (accuracy: 56.580%), validation loss = 1.033 (accuracy: 52.381%)\n",
      "Epoch 57: 21.651 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.064 (accuracy: 55.524%), validation loss = 1.038 (accuracy: 54.286%)\n",
      "Epoch 58: 21.667 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.040 (accuracy: 57.061%), validation loss = 1.038 (accuracy: 53.333%)\n",
      "Epoch 59: 21.772 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.049 (accuracy: 57.925%), validation loss = 1.015 (accuracy: 57.143%)\n",
      "Epoch 60: 22.046 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.032 (accuracy: 57.637%), validation loss = 1.024 (accuracy: 53.333%)\n",
      "Epoch 61: 21.723 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.031 (accuracy: 56.868%), validation loss = 1.050 (accuracy: 51.429%)\n",
      "Epoch 62: 21.637 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.020 (accuracy: 56.196%), validation loss = 1.022 (accuracy: 52.381%)\n",
      "Epoch 63: 21.773 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.026 (accuracy: 58.309%), validation loss = 1.044 (accuracy: 53.333%)\n",
      "Epoch 64: 21.729 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.049 (accuracy: 57.253%), validation loss = 1.027 (accuracy: 56.190%)\n",
      "Epoch 65: 21.810 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.026 (accuracy: 58.598%), validation loss = 1.012 (accuracy: 57.143%)\n",
      "Epoch 66: 22.013 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.020 (accuracy: 59.942%), validation loss = 1.024 (accuracy: 56.190%)\n",
      "Epoch 67: 21.714 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.022 (accuracy: 58.694%), validation loss = 1.032 (accuracy: 53.333%)\n",
      "Epoch 68: 22.360 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.034 (accuracy: 56.292%), validation loss = 1.026 (accuracy: 54.286%)\n",
      "Epoch 69: 21.984 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.034 (accuracy: 56.580%), validation loss = 1.029 (accuracy: 56.190%)\n",
      "Epoch 70: 21.704 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.025 (accuracy: 59.270%), validation loss = 1.016 (accuracy: 53.333%)\n",
      "Epoch 71: 21.665 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.027 (accuracy: 56.580%), validation loss = 1.001 (accuracy: 57.143%)\n",
      "Epoch 72: 22.038 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.011 (accuracy: 58.405%), validation loss = 1.013 (accuracy: 57.143%)\n",
      "Epoch 73: 21.756 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.008 (accuracy: 59.558%), validation loss = 1.013 (accuracy: 57.143%)\n",
      "Epoch 74: 21.716 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.007 (accuracy: 59.654%), validation loss = 1.003 (accuracy: 58.095%)\n",
      "Epoch 75: 21.634 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.021 (accuracy: 58.982%), validation loss = 1.014 (accuracy: 52.381%)\n",
      "Epoch 76: 21.756 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.020 (accuracy: 56.964%), validation loss = 1.013 (accuracy: 56.190%)\n",
      "Epoch 77: 21.794 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.011 (accuracy: 58.213%), validation loss = 0.997 (accuracy: 58.095%)\n",
      "Epoch 78: 21.985 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.005 (accuracy: 58.694%), validation loss = 1.010 (accuracy: 56.190%)\n",
      "Epoch 79: 21.660 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.024 (accuracy: 56.964%), validation loss = 1.003 (accuracy: 57.143%)\n",
      "Epoch 80: 21.665 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.015 (accuracy: 57.349%), validation loss = 1.000 (accuracy: 58.095%)\n",
      "Epoch 81: 21.641 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.012 (accuracy: 57.541%), validation loss = 1.032 (accuracy: 53.333%)\n",
      "Epoch 82: 22.213 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.025 (accuracy: 57.349%), validation loss = 1.006 (accuracy: 55.238%)\n",
      "Epoch 83: 22.163 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.018 (accuracy: 58.117%), validation loss = 1.004 (accuracy: 54.286%)\n",
      "Epoch 84: 21.655 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.014 (accuracy: 58.501%), validation loss = 1.002 (accuracy: 56.190%)\n",
      "Epoch 85: 21.629 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.016 (accuracy: 57.445%), validation loss = 0.996 (accuracy: 58.095%)\n",
      "Epoch 86: 22.033 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.003 (accuracy: 59.270%), validation loss = 1.004 (accuracy: 55.238%)\n",
      "Epoch 87: 21.782 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.011 (accuracy: 59.174%), validation loss = 0.990 (accuracy: 59.048%)\n",
      "Epoch 88: 21.998 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.004 (accuracy: 59.174%), validation loss = 1.023 (accuracy: 53.333%)\n",
      "Epoch 89: 21.735 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.008 (accuracy: 57.445%), validation loss = 0.996 (accuracy: 58.095%)\n",
      "Epoch 90: 21.811 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.028 (accuracy: 56.964%), validation loss = 1.011 (accuracy: 55.238%)\n",
      "Epoch 91: 21.556 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.017 (accuracy: 56.772%), validation loss = 1.001 (accuracy: 55.238%)\n",
      "Epoch 92: 21.607 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.013 (accuracy: 58.117%), validation loss = 1.014 (accuracy: 56.190%)\n",
      "Epoch 93: 21.650 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 0.994 (accuracy: 61.287%), validation loss = 1.008 (accuracy: 51.429%)\n",
      "Epoch 94: 21.604 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.000 (accuracy: 59.078%), validation loss = 1.014 (accuracy: 54.286%)\n",
      "Epoch 95: 21.604 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.011 (accuracy: 58.213%), validation loss = 1.010 (accuracy: 54.286%)\n",
      "Epoch 96: 21.842 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.005 (accuracy: 58.309%), validation loss = 0.993 (accuracy: 55.238%)\n",
      "Epoch 97: 22.469 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.019 (accuracy: 57.253%), validation loss = 0.996 (accuracy: 55.238%)\n",
      "Epoch 98: 21.571 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.002 (accuracy: 57.061%), validation loss = 1.020 (accuracy: 55.238%)\n",
      "Epoch 99: 21.579 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 0.990 (accuracy: 60.423%), validation loss = 0.986 (accuracy: 59.048%)\n",
      "Epoch 100: 21.877 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.000 (accuracy: 59.174%), validation loss = 0.997 (accuracy: 56.190%)\n",
      "Epoch 101: 21.691 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.015 (accuracy: 58.501%), validation loss = 1.003 (accuracy: 56.190%)\n",
      "Epoch 102: 21.563 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.009 (accuracy: 57.445%), validation loss = 1.012 (accuracy: 55.238%)\n",
      "Epoch 103: 21.661 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.010 (accuracy: 58.790%), validation loss = 1.018 (accuracy: 55.238%)\n",
      "Epoch 104: 21.832 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 0.976 (accuracy: 61.191%), validation loss = 0.987 (accuracy: 57.143%)\n",
      "Epoch 105: 21.590 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.009 (accuracy: 57.349%), validation loss = 1.003 (accuracy: 56.190%)\n",
      "Epoch 106: 21.559 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.009 (accuracy: 58.501%), validation loss = 0.985 (accuracy: 57.143%)\n",
      "Epoch 107: 21.979 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.017 (accuracy: 58.405%), validation loss = 1.019 (accuracy: 52.381%)\n",
      "Epoch 108: 21.551 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 0.986 (accuracy: 59.366%), validation loss = 0.988 (accuracy: 57.143%)\n",
      "Epoch 109: 21.516 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 0.995 (accuracy: 60.327%), validation loss = 1.009 (accuracy: 57.143%)\n",
      "Epoch 110: 21.552 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 0.999 (accuracy: 58.694%), validation loss = 1.000 (accuracy: 55.238%)\n",
      "Epoch 111: 22.507 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 0.991 (accuracy: 59.558%), validation loss = 1.030 (accuracy: 52.381%)\n",
      "Epoch 112: 21.519 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 0.993 (accuracy: 56.676%), validation loss = 1.000 (accuracy: 55.238%)\n",
      "Epoch 113: 21.534 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 0.992 (accuracy: 60.327%), validation loss = 0.986 (accuracy: 56.190%)\n",
      "Epoch 114: 21.533 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 0.988 (accuracy: 58.886%), validation loss = 0.998 (accuracy: 55.238%)\n",
      "Epoch 115: 21.582 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 0.982 (accuracy: 60.519%), validation loss = 0.987 (accuracy: 57.143%)\n",
      "Epoch 116: 21.469 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 0.975 (accuracy: 60.711%), validation loss = 0.994 (accuracy: 55.238%)\n",
      "Epoch 117: 21.523 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 0.984 (accuracy: 60.231%), validation loss = 1.010 (accuracy: 55.238%)\n",
      "Epoch 118: 21.574 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.000 (accuracy: 58.886%), validation loss = 0.989 (accuracy: 57.143%)\n",
      "Epoch 119: 21.597 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.006 (accuracy: 58.598%), validation loss = 0.994 (accuracy: 54.286%)\n",
      "Epoch 120: 21.564 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 0.986 (accuracy: 59.174%), validation loss = 0.988 (accuracy: 54.286%)\n",
      "Epoch 121: 21.533 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.001 (accuracy: 58.021%), validation loss = 0.985 (accuracy: 58.095%)\n",
      "Epoch 122: 21.513 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 0.991 (accuracy: 58.213%), validation loss = 0.990 (accuracy: 55.238%)\n",
      "Epoch 123: 21.569 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 0.989 (accuracy: 61.191%), validation loss = 1.010 (accuracy: 55.238%)\n",
      "Epoch 124: 21.441 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.008 (accuracy: 59.942%), validation loss = 0.998 (accuracy: 56.190%)\n",
      "Epoch 125: 22.480 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 0.970 (accuracy: 60.615%), validation loss = 0.995 (accuracy: 55.238%)\n",
      "Epoch 126: 21.504 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.000 (accuracy: 59.654%), validation loss = 1.009 (accuracy: 55.238%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 106 with minimum validation error = 0.9845978430339268\n",
      "12197.337 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0.2\n",
      "Epoch 1: 21.269 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.316 (accuracy: 36.503%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 2: 21.595 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.280 (accuracy: 40.154%), validation loss = 1.276 (accuracy: 36.190%)\n",
      "Epoch 3: 21.528 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.263 (accuracy: 40.730%), validation loss = 1.261 (accuracy: 33.333%)\n",
      "Epoch 4: 21.405 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.253 (accuracy: 41.499%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 5: 21.455 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.258 (accuracy: 40.154%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 6: 21.230 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.250 (accuracy: 41.595%), validation loss = 1.239 (accuracy: 38.095%)\n",
      "Epoch 7: 21.738 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.234 (accuracy: 43.132%), validation loss = 1.224 (accuracy: 37.143%)\n",
      "Epoch 8: 21.782 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.242 (accuracy: 42.459%), validation loss = 1.226 (accuracy: 39.048%)\n",
      "Epoch 9: 21.292 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.227 (accuracy: 43.804%), validation loss = 1.233 (accuracy: 37.143%)\n",
      "Epoch 10: 21.185 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.221 (accuracy: 46.494%), validation loss = 1.233 (accuracy: 34.286%)\n",
      "Epoch 11: 21.222 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.224 (accuracy: 43.996%), validation loss = 1.209 (accuracy: 40.000%)\n",
      "Epoch 12: 21.394 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.210 (accuracy: 45.629%), validation loss = 1.213 (accuracy: 39.048%)\n",
      "Epoch 13: 21.130 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.208 (accuracy: 46.013%), validation loss = 1.200 (accuracy: 41.905%)\n",
      "Epoch 14: 21.439 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.201 (accuracy: 46.302%), validation loss = 1.208 (accuracy: 40.952%)\n",
      "Epoch 15: 21.090 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.210 (accuracy: 46.782%), validation loss = 1.198 (accuracy: 42.857%)\n",
      "Epoch 16: 21.417 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.204 (accuracy: 46.110%), validation loss = 1.197 (accuracy: 42.857%)\n",
      "Epoch 17: 21.281 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.191 (accuracy: 48.511%), validation loss = 1.179 (accuracy: 42.857%)\n",
      "Epoch 18: 21.503 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.187 (accuracy: 49.087%), validation loss = 1.191 (accuracy: 41.905%)\n",
      "Epoch 19: 21.155 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.198 (accuracy: 47.358%), validation loss = 1.174 (accuracy: 46.667%)\n",
      "Epoch 20: 21.197 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.187 (accuracy: 48.607%), validation loss = 1.168 (accuracy: 54.286%)\n",
      "Epoch 21: 20.616 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.184 (accuracy: 50.720%), validation loss = 1.175 (accuracy: 42.857%)\n",
      "Epoch 22: 21.250 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.179 (accuracy: 49.760%), validation loss = 1.174 (accuracy: 44.762%)\n",
      "Epoch 23: 20.453 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.181 (accuracy: 49.183%), validation loss = 1.172 (accuracy: 46.667%)\n",
      "Epoch 24: 20.479 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.179 (accuracy: 50.144%), validation loss = 1.174 (accuracy: 42.857%)\n",
      "Epoch 25: 20.388 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.166 (accuracy: 50.144%), validation loss = 1.186 (accuracy: 41.905%)\n",
      "Epoch 26: 20.476 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.175 (accuracy: 48.607%), validation loss = 1.174 (accuracy: 43.810%)\n",
      "Epoch 27: 20.394 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.173 (accuracy: 49.664%), validation loss = 1.166 (accuracy: 45.714%)\n",
      "Epoch 28: 20.503 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.174 (accuracy: 50.817%), validation loss = 1.159 (accuracy: 47.619%)\n",
      "Epoch 29: 20.412 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.163 (accuracy: 51.201%), validation loss = 1.152 (accuracy: 51.429%)\n",
      "Epoch 30: 20.564 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.166 (accuracy: 49.183%), validation loss = 1.162 (accuracy: 46.667%)\n",
      "Epoch 31: 20.458 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.164 (accuracy: 49.472%), validation loss = 1.157 (accuracy: 46.667%)\n",
      "Epoch 32: 20.311 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.165 (accuracy: 48.127%), validation loss = 1.161 (accuracy: 44.762%)\n",
      "Epoch 33: 20.376 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.156 (accuracy: 51.009%), validation loss = 1.154 (accuracy: 48.571%)\n",
      "Epoch 34: 20.351 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.156 (accuracy: 51.201%), validation loss = 1.155 (accuracy: 45.714%)\n",
      "Epoch 35: 20.224 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.162 (accuracy: 51.873%), validation loss = 1.155 (accuracy: 46.667%)\n",
      "Epoch 36: 20.343 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.151 (accuracy: 51.969%), validation loss = 1.150 (accuracy: 47.619%)\n",
      "Epoch 37: 21.415 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.154 (accuracy: 51.681%), validation loss = 1.143 (accuracy: 50.476%)\n",
      "Epoch 38: 20.819 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.147 (accuracy: 52.834%), validation loss = 1.152 (accuracy: 46.667%)\n",
      "Epoch 39: 20.729 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.151 (accuracy: 52.546%), validation loss = 1.129 (accuracy: 50.476%)\n",
      "Epoch 40: 21.196 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.150 (accuracy: 51.681%), validation loss = 1.132 (accuracy: 50.476%)\n",
      "Epoch 41: 20.622 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.148 (accuracy: 52.930%), validation loss = 1.131 (accuracy: 53.333%)\n",
      "Epoch 42: 20.543 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.145 (accuracy: 51.105%), validation loss = 1.133 (accuracy: 51.429%)\n",
      "Epoch 43: 20.439 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.148 (accuracy: 51.393%), validation loss = 1.130 (accuracy: 50.476%)\n",
      "Epoch 44: 20.450 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.142 (accuracy: 53.218%), validation loss = 1.121 (accuracy: 53.333%)\n",
      "Epoch 45: 20.541 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.154 (accuracy: 52.642%), validation loss = 1.126 (accuracy: 49.524%)\n",
      "Epoch 46: 20.471 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.149 (accuracy: 51.009%), validation loss = 1.124 (accuracy: 53.333%)\n",
      "Epoch 47: 20.449 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.131 (accuracy: 54.467%), validation loss = 1.126 (accuracy: 50.476%)\n",
      "Epoch 48: 20.459 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.140 (accuracy: 51.585%), validation loss = 1.116 (accuracy: 54.286%)\n",
      "Epoch 49: 20.640 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.151 (accuracy: 52.161%), validation loss = 1.120 (accuracy: 52.381%)\n",
      "Epoch 50: 20.351 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.134 (accuracy: 52.546%), validation loss = 1.127 (accuracy: 48.571%)\n",
      "Epoch 51: 20.436 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.131 (accuracy: 54.563%), validation loss = 1.131 (accuracy: 48.571%)\n",
      "Epoch 52: 21.118 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.131 (accuracy: 54.275%), validation loss = 1.116 (accuracy: 51.429%)\n",
      "Epoch 53: 20.636 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.141 (accuracy: 52.257%), validation loss = 1.134 (accuracy: 48.571%)\n",
      "Epoch 54: 20.505 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.132 (accuracy: 55.043%), validation loss = 1.123 (accuracy: 50.476%)\n",
      "Epoch 55: 20.463 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.116 (accuracy: 54.563%), validation loss = 1.110 (accuracy: 52.381%)\n",
      "Epoch 56: 20.793 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.138 (accuracy: 53.410%), validation loss = 1.112 (accuracy: 51.429%)\n",
      "Epoch 57: 20.593 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.135 (accuracy: 53.410%), validation loss = 1.122 (accuracy: 49.524%)\n",
      "Epoch 58: 20.730 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.121 (accuracy: 56.004%), validation loss = 1.115 (accuracy: 49.524%)\n",
      "Epoch 59: 20.783 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.133 (accuracy: 52.834%), validation loss = 1.120 (accuracy: 49.524%)\n",
      "Epoch 60: 20.815 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.123 (accuracy: 54.371%), validation loss = 1.133 (accuracy: 49.524%)\n",
      "Epoch 61: 20.791 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.118 (accuracy: 54.275%), validation loss = 1.129 (accuracy: 47.619%)\n",
      "Epoch 62: 20.663 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.124 (accuracy: 53.122%), validation loss = 1.137 (accuracy: 46.667%)\n",
      "Epoch 63: 20.669 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.122 (accuracy: 53.987%), validation loss = 1.118 (accuracy: 51.429%)\n",
      "Epoch 64: 20.558 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.123 (accuracy: 53.410%), validation loss = 1.117 (accuracy: 49.524%)\n",
      "Epoch 65: 20.524 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.129 (accuracy: 53.602%), validation loss = 1.126 (accuracy: 49.524%)\n",
      "Epoch 66: 20.879 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.129 (accuracy: 53.602%), validation loss = 1.121 (accuracy: 49.524%)\n",
      "Epoch 67: 21.077 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.126 (accuracy: 53.890%), validation loss = 1.114 (accuracy: 52.381%)\n",
      "Epoch 68: 20.783 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.112 (accuracy: 55.620%), validation loss = 1.107 (accuracy: 53.333%)\n",
      "Epoch 69: 20.825 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.126 (accuracy: 54.755%), validation loss = 1.104 (accuracy: 52.381%)\n",
      "Epoch 70: 20.675 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.115 (accuracy: 53.794%), validation loss = 1.099 (accuracy: 51.429%)\n",
      "Epoch 71: 20.834 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.121 (accuracy: 54.947%), validation loss = 1.106 (accuracy: 52.381%)\n",
      "Epoch 72: 20.516 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.122 (accuracy: 53.218%), validation loss = 1.111 (accuracy: 52.381%)\n",
      "Epoch 73: 20.451 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.122 (accuracy: 54.467%), validation loss = 1.111 (accuracy: 51.429%)\n",
      "Epoch 74: 20.542 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.116 (accuracy: 55.812%), validation loss = 1.111 (accuracy: 50.476%)\n",
      "Epoch 75: 20.468 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.106 (accuracy: 55.427%), validation loss = 1.111 (accuracy: 52.381%)\n",
      "Epoch 76: 20.506 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.104 (accuracy: 56.388%), validation loss = 1.112 (accuracy: 54.286%)\n",
      "Epoch 77: 20.554 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.113 (accuracy: 55.331%), validation loss = 1.111 (accuracy: 52.381%)\n",
      "Epoch 78: 20.658 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.127 (accuracy: 53.218%), validation loss = 1.102 (accuracy: 54.286%)\n",
      "Epoch 79: 20.668 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.110 (accuracy: 55.043%), validation loss = 1.124 (accuracy: 49.524%)\n",
      "Epoch 80: 20.790 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.111 (accuracy: 53.987%), validation loss = 1.104 (accuracy: 53.333%)\n",
      "Epoch 81: 21.003 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.112 (accuracy: 57.061%), validation loss = 1.099 (accuracy: 51.429%)\n",
      "Epoch 82: 21.539 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.112 (accuracy: 55.427%), validation loss = 1.100 (accuracy: 54.286%)\n",
      "Epoch 83: 20.697 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.111 (accuracy: 57.253%), validation loss = 1.097 (accuracy: 53.333%)\n",
      "Epoch 84: 20.900 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.109 (accuracy: 55.331%), validation loss = 1.120 (accuracy: 49.524%)\n",
      "Epoch 85: 20.478 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.113 (accuracy: 54.563%), validation loss = 1.103 (accuracy: 49.524%)\n",
      "Epoch 86: 20.555 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.094 (accuracy: 56.964%), validation loss = 1.092 (accuracy: 50.476%)\n",
      "Epoch 87: 20.708 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.105 (accuracy: 55.716%), validation loss = 1.113 (accuracy: 49.524%)\n",
      "Epoch 88: 20.521 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.109 (accuracy: 54.275%), validation loss = 1.102 (accuracy: 52.381%)\n",
      "Epoch 89: 20.520 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.110 (accuracy: 55.427%), validation loss = 1.100 (accuracy: 51.429%)\n",
      "Epoch 90: 20.440 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.107 (accuracy: 55.620%), validation loss = 1.113 (accuracy: 50.476%)\n",
      "Epoch 91: 20.421 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.114 (accuracy: 54.851%), validation loss = 1.098 (accuracy: 53.333%)\n",
      "Epoch 92: 20.426 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.116 (accuracy: 54.467%), validation loss = 1.097 (accuracy: 52.381%)\n",
      "Epoch 93: 20.413 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.115 (accuracy: 55.043%), validation loss = 1.109 (accuracy: 51.429%)\n",
      "Epoch 94: 20.446 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.109 (accuracy: 53.122%), validation loss = 1.088 (accuracy: 56.190%)\n",
      "Epoch 95: 20.727 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.109 (accuracy: 55.524%), validation loss = 1.092 (accuracy: 50.476%)\n",
      "Epoch 96: 20.710 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.110 (accuracy: 54.467%), validation loss = 1.091 (accuracy: 55.238%)\n",
      "Epoch 97: 20.964 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.112 (accuracy: 54.563%), validation loss = 1.103 (accuracy: 51.429%)\n",
      "Epoch 98: 20.427 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.112 (accuracy: 53.890%), validation loss = 1.117 (accuracy: 47.619%)\n",
      "Epoch 99: 20.390 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.106 (accuracy: 54.851%), validation loss = 1.093 (accuracy: 53.333%)\n",
      "Epoch 100: 20.399 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.122 (accuracy: 52.930%), validation loss = 1.089 (accuracy: 53.333%)\n",
      "Epoch 101: 20.289 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.103 (accuracy: 55.427%), validation loss = 1.089 (accuracy: 52.381%)\n",
      "Epoch 102: 20.400 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.102 (accuracy: 56.676%), validation loss = 1.122 (accuracy: 49.524%)\n",
      "Epoch 103: 20.315 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.108 (accuracy: 54.467%), validation loss = 1.094 (accuracy: 53.333%)\n",
      "Epoch 104: 20.246 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.115 (accuracy: 55.620%), validation loss = 1.106 (accuracy: 50.476%)\n",
      "Epoch 105: 20.270 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.109 (accuracy: 54.659%), validation loss = 1.096 (accuracy: 53.333%)\n",
      "Epoch 106: 20.152 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.102 (accuracy: 55.139%), validation loss = 1.100 (accuracy: 53.333%)\n",
      "Epoch 107: 20.151 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.115 (accuracy: 53.698%), validation loss = 1.086 (accuracy: 50.476%)\n",
      "Epoch 108: 20.433 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.107 (accuracy: 55.908%), validation loss = 1.120 (accuracy: 49.524%)\n",
      "Epoch 109: 20.354 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.111 (accuracy: 55.427%), validation loss = 1.101 (accuracy: 53.333%)\n",
      "Epoch 110: 20.364 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.106 (accuracy: 54.467%), validation loss = 1.087 (accuracy: 58.095%)\n",
      "Epoch 111: 20.583 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.105 (accuracy: 55.235%), validation loss = 1.097 (accuracy: 51.429%)\n",
      "Epoch 112: 20.489 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.107 (accuracy: 54.275%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 113: 20.649 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.103 (accuracy: 56.484%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 114: 20.326 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.119 (accuracy: 54.947%), validation loss = 1.109 (accuracy: 50.476%)\n",
      "Epoch 115: 20.314 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.110 (accuracy: 55.908%), validation loss = 1.098 (accuracy: 52.381%)\n",
      "Epoch 116: 20.374 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.101 (accuracy: 57.253%), validation loss = 1.119 (accuracy: 49.524%)\n",
      "Epoch 117: 20.357 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.103 (accuracy: 54.755%), validation loss = 1.091 (accuracy: 55.238%)\n",
      "Epoch 118: 20.304 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.119 (accuracy: 54.947%), validation loss = 1.097 (accuracy: 52.381%)\n",
      "Epoch 119: 20.355 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.096 (accuracy: 56.292%), validation loss = 1.083 (accuracy: 53.333%)\n",
      "Epoch 120: 20.599 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.105 (accuracy: 55.908%), validation loss = 1.093 (accuracy: 53.333%)\n",
      "Epoch 121: 20.334 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.103 (accuracy: 57.061%), validation loss = 1.086 (accuracy: 49.524%)\n",
      "Epoch 122: 20.442 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.112 (accuracy: 54.563%), validation loss = 1.087 (accuracy: 55.238%)\n",
      "Epoch 123: 20.513 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.095 (accuracy: 57.061%), validation loss = 1.116 (accuracy: 49.524%)\n",
      "Epoch 124: 20.544 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.103 (accuracy: 54.371%), validation loss = 1.086 (accuracy: 50.476%)\n",
      "Epoch 125: 20.522 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 1.104 (accuracy: 54.851%), validation loss = 1.087 (accuracy: 51.429%)\n",
      "Epoch 126: 20.861 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.107 (accuracy: 54.179%), validation loss = 1.099 (accuracy: 54.286%)\n",
      "Epoch 127: 20.824 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.104 (accuracy: 56.004%), validation loss = 1.112 (accuracy: 50.476%)\n",
      "Epoch 128: 21.311 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.099 (accuracy: 55.716%), validation loss = 1.094 (accuracy: 50.476%)\n",
      "Epoch 129: 20.745 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 1.109 (accuracy: 55.139%), validation loss = 1.088 (accuracy: 54.286%)\n",
      "Epoch 130: 20.830 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 1.111 (accuracy: 56.004%), validation loss = 1.096 (accuracy: 54.286%)\n",
      "Epoch 131: 20.872 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 1.088 (accuracy: 56.580%), validation loss = 1.095 (accuracy: 52.381%)\n",
      "Epoch 132: 20.891 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 1.099 (accuracy: 56.004%), validation loss = 1.094 (accuracy: 51.429%)\n",
      "Epoch 133: 20.896 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 1.104 (accuracy: 55.331%), validation loss = 1.080 (accuracy: 54.286%)\n",
      "Epoch 134: 21.194 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 1.103 (accuracy: 55.043%), validation loss = 1.090 (accuracy: 52.381%)\n",
      "Epoch 135: 21.034 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 1.093 (accuracy: 55.331%), validation loss = 1.086 (accuracy: 48.571%)\n",
      "Epoch 136: 21.040 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 1.101 (accuracy: 56.484%), validation loss = 1.086 (accuracy: 53.333%)\n",
      "Epoch 137: 21.025 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 1.114 (accuracy: 54.371%), validation loss = 1.081 (accuracy: 57.143%)\n",
      "Epoch 138: 21.024 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 1.111 (accuracy: 55.139%), validation loss = 1.109 (accuracy: 49.524%)\n",
      "Epoch 139: 20.990 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 1.111 (accuracy: 55.235%), validation loss = 1.089 (accuracy: 51.429%)\n",
      "Epoch 140: 21.223 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 1.100 (accuracy: 54.467%), validation loss = 1.089 (accuracy: 51.429%)\n",
      "Epoch 141: 20.970 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 1.108 (accuracy: 54.563%), validation loss = 1.085 (accuracy: 54.286%)\n",
      "Epoch 142: 21.242 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 1.115 (accuracy: 54.563%), validation loss = 1.094 (accuracy: 51.429%)\n",
      "Epoch 143: 21.283 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 1.106 (accuracy: 56.676%), validation loss = 1.102 (accuracy: 50.476%)\n",
      "Epoch 144: 21.014 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 1.104 (accuracy: 55.716%), validation loss = 1.091 (accuracy: 52.381%)\n",
      "Epoch 145: 20.925 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 1.104 (accuracy: 57.541%), validation loss = 1.133 (accuracy: 46.667%)\n",
      "Epoch 146: 21.127 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 1.112 (accuracy: 55.139%), validation loss = 1.101 (accuracy: 53.333%)\n",
      "Epoch 147: 21.090 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 1.113 (accuracy: 55.043%), validation loss = 1.118 (accuracy: 47.619%)\n",
      "Epoch 148: 20.992 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 1.101 (accuracy: 55.235%), validation loss = 1.085 (accuracy: 54.286%)\n",
      "Epoch 149: 21.121 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 1.105 (accuracy: 55.235%), validation loss = 1.104 (accuracy: 49.524%)\n",
      "Epoch 150: 21.036 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 1.101 (accuracy: 56.292%), validation loss = 1.082 (accuracy: 54.286%)\n",
      "Epoch 151: 21.059 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 1.109 (accuracy: 56.004%), validation loss = 1.087 (accuracy: 51.429%)\n",
      "Epoch 152: 21.131 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 1.110 (accuracy: 54.179%), validation loss = 1.091 (accuracy: 52.381%)\n",
      "Epoch 153: 21.177 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 1.112 (accuracy: 55.908%), validation loss = 1.097 (accuracy: 51.429%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 133 with minimum validation error = 1.0798317318870907\n",
      "15391.777 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0\n",
      "Epoch 1: 21.266 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.376 (accuracy: 28.626%), validation loss = 1.353 (accuracy: 31.429%)\n",
      "Epoch 2: 21.981 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.319 (accuracy: 38.136%), validation loss = 1.331 (accuracy: 33.333%)\n",
      "Epoch 3: 21.564 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.299 (accuracy: 38.713%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 4: 22.167 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.289 (accuracy: 38.232%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 5: 21.608 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.282 (accuracy: 39.289%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 6: 21.648 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.276 (accuracy: 39.962%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 7: 21.552 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.275 (accuracy: 39.481%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 8: 21.607 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.277 (accuracy: 39.769%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 9: 21.369 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.269 (accuracy: 39.769%), validation loss = 1.283 (accuracy: 33.333%)\n",
      "Epoch 10: 21.624 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.272 (accuracy: 40.346%), validation loss = 1.283 (accuracy: 33.333%)\n",
      "Epoch 11: 21.622 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.266 (accuracy: 39.673%), validation loss = 1.280 (accuracy: 33.333%)\n",
      "Epoch 12: 21.487 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.260 (accuracy: 40.730%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 13: 21.566 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.255 (accuracy: 40.826%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 14: 21.535 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.263 (accuracy: 40.250%), validation loss = 1.272 (accuracy: 33.333%)\n",
      "Epoch 15: 21.480 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.262 (accuracy: 41.499%), validation loss = 1.269 (accuracy: 33.333%)\n",
      "Epoch 16: 21.654 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.248 (accuracy: 40.826%), validation loss = 1.268 (accuracy: 33.333%)\n",
      "Epoch 17: 21.630 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.253 (accuracy: 41.306%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 18: 22.023 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.252 (accuracy: 41.979%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 19: 21.610 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.250 (accuracy: 42.267%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 20: 21.535 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.253 (accuracy: 41.499%), validation loss = 1.258 (accuracy: 35.238%)\n",
      "Epoch 21: 21.625 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.235 (accuracy: 42.843%), validation loss = 1.253 (accuracy: 35.238%)\n",
      "Epoch 22: 21.458 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.237 (accuracy: 42.075%), validation loss = 1.253 (accuracy: 34.286%)\n",
      "Epoch 23: 21.676 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.241 (accuracy: 41.979%), validation loss = 1.252 (accuracy: 35.238%)\n",
      "Epoch 24: 21.737 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.233 (accuracy: 44.284%), validation loss = 1.246 (accuracy: 36.190%)\n",
      "Epoch 25: 21.653 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.238 (accuracy: 42.171%), validation loss = 1.242 (accuracy: 36.190%)\n",
      "Epoch 26: 21.690 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.231 (accuracy: 43.900%), validation loss = 1.243 (accuracy: 36.190%)\n",
      "Epoch 27: 21.277 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.234 (accuracy: 42.459%), validation loss = 1.241 (accuracy: 36.190%)\n",
      "Epoch 28: 21.656 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.228 (accuracy: 43.420%), validation loss = 1.239 (accuracy: 36.190%)\n",
      "Epoch 29: 21.929 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.228 (accuracy: 41.883%), validation loss = 1.235 (accuracy: 36.190%)\n",
      "Epoch 30: 21.581 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.226 (accuracy: 44.573%), validation loss = 1.236 (accuracy: 36.190%)\n",
      "Epoch 31: 21.422 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.224 (accuracy: 44.765%), validation loss = 1.234 (accuracy: 36.190%)\n",
      "Epoch 32: 22.129 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.223 (accuracy: 44.284%), validation loss = 1.230 (accuracy: 36.190%)\n",
      "Epoch 33: 21.694 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.224 (accuracy: 42.843%), validation loss = 1.226 (accuracy: 36.190%)\n",
      "Epoch 34: 21.601 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.223 (accuracy: 43.612%), validation loss = 1.219 (accuracy: 36.190%)\n",
      "Epoch 35: 21.542 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.214 (accuracy: 44.380%), validation loss = 1.220 (accuracy: 35.238%)\n",
      "Epoch 36: 21.214 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.214 (accuracy: 46.110%), validation loss = 1.217 (accuracy: 35.238%)\n",
      "Epoch 37: 21.515 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.210 (accuracy: 46.398%), validation loss = 1.216 (accuracy: 36.190%)\n",
      "Epoch 38: 21.476 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.207 (accuracy: 45.533%), validation loss = 1.216 (accuracy: 35.238%)\n",
      "Epoch 39: 21.224 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.205 (accuracy: 45.053%), validation loss = 1.211 (accuracy: 37.143%)\n",
      "Epoch 40: 21.560 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.202 (accuracy: 46.110%), validation loss = 1.206 (accuracy: 40.000%)\n",
      "Epoch 41: 21.529 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.198 (accuracy: 46.590%), validation loss = 1.205 (accuracy: 38.095%)\n",
      "Epoch 42: 21.506 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.201 (accuracy: 45.821%), validation loss = 1.203 (accuracy: 40.952%)\n",
      "Epoch 43: 21.730 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.194 (accuracy: 47.935%), validation loss = 1.202 (accuracy: 40.000%)\n",
      "Epoch 44: 21.514 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.191 (accuracy: 47.839%), validation loss = 1.201 (accuracy: 40.000%)\n",
      "Epoch 45: 21.542 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.189 (accuracy: 48.031%), validation loss = 1.198 (accuracy: 40.000%)\n",
      "Epoch 46: 22.051 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.203 (accuracy: 46.302%), validation loss = 1.195 (accuracy: 39.048%)\n",
      "Epoch 47: 21.517 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.183 (accuracy: 50.336%), validation loss = 1.192 (accuracy: 40.000%)\n",
      "Epoch 48: 21.494 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.185 (accuracy: 48.127%), validation loss = 1.190 (accuracy: 40.000%)\n",
      "Epoch 49: 21.514 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.180 (accuracy: 48.511%), validation loss = 1.194 (accuracy: 38.095%)\n",
      "Epoch 50: 21.268 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.181 (accuracy: 48.031%), validation loss = 1.191 (accuracy: 40.000%)\n",
      "Epoch 51: 21.201 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.181 (accuracy: 47.839%), validation loss = 1.184 (accuracy: 39.048%)\n",
      "Epoch 52: 21.560 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.195 (accuracy: 47.358%), validation loss = 1.183 (accuracy: 43.810%)\n",
      "Epoch 53: 21.506 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.188 (accuracy: 49.472%), validation loss = 1.181 (accuracy: 41.905%)\n",
      "Epoch 54: 21.530 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.167 (accuracy: 47.743%), validation loss = 1.173 (accuracy: 47.619%)\n",
      "Epoch 55: 21.533 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.176 (accuracy: 50.240%), validation loss = 1.175 (accuracy: 45.714%)\n",
      "Epoch 56: 21.279 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.171 (accuracy: 48.799%), validation loss = 1.171 (accuracy: 47.619%)\n",
      "Epoch 57: 21.741 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.168 (accuracy: 50.817%), validation loss = 1.167 (accuracy: 49.524%)\n",
      "Epoch 58: 21.533 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.169 (accuracy: 50.624%), validation loss = 1.170 (accuracy: 45.714%)\n",
      "Epoch 59: 21.392 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.170 (accuracy: 49.568%), validation loss = 1.162 (accuracy: 48.571%)\n",
      "Epoch 60: 21.783 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.178 (accuracy: 47.646%), validation loss = 1.163 (accuracy: 48.571%)\n",
      "Epoch 61: 21.573 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.171 (accuracy: 49.280%), validation loss = 1.158 (accuracy: 49.524%)\n",
      "Epoch 62: 21.582 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.156 (accuracy: 52.546%), validation loss = 1.161 (accuracy: 47.619%)\n",
      "Epoch 63: 21.358 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.166 (accuracy: 49.760%), validation loss = 1.155 (accuracy: 46.667%)\n",
      "Epoch 64: 21.455 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.155 (accuracy: 51.009%), validation loss = 1.154 (accuracy: 49.524%)\n",
      "Epoch 65: 21.449 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.156 (accuracy: 49.376%), validation loss = 1.153 (accuracy: 50.476%)\n",
      "Epoch 66: 21.524 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.153 (accuracy: 51.009%), validation loss = 1.144 (accuracy: 53.333%)\n",
      "Epoch 67: 21.506 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.157 (accuracy: 50.336%), validation loss = 1.148 (accuracy: 51.429%)\n",
      "Epoch 68: 21.363 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.143 (accuracy: 50.432%), validation loss = 1.143 (accuracy: 49.524%)\n",
      "Epoch 69: 21.569 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.151 (accuracy: 50.240%), validation loss = 1.146 (accuracy: 51.429%)\n",
      "Epoch 70: 21.254 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.147 (accuracy: 51.777%), validation loss = 1.139 (accuracy: 51.429%)\n",
      "Epoch 71: 21.772 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.147 (accuracy: 52.065%), validation loss = 1.141 (accuracy: 52.381%)\n",
      "Epoch 72: 21.343 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.134 (accuracy: 52.354%), validation loss = 1.141 (accuracy: 52.381%)\n",
      "Epoch 73: 21.385 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.147 (accuracy: 53.506%), validation loss = 1.138 (accuracy: 51.429%)\n",
      "Epoch 74: 21.638 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.141 (accuracy: 51.297%), validation loss = 1.130 (accuracy: 52.381%)\n",
      "Epoch 75: 22.053 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.146 (accuracy: 52.354%), validation loss = 1.132 (accuracy: 51.429%)\n",
      "Epoch 76: 21.340 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.133 (accuracy: 52.257%), validation loss = 1.125 (accuracy: 54.286%)\n",
      "Epoch 77: 21.447 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.138 (accuracy: 53.314%), validation loss = 1.130 (accuracy: 51.429%)\n",
      "Epoch 78: 21.192 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.118 (accuracy: 51.393%), validation loss = 1.128 (accuracy: 51.429%)\n",
      "Epoch 79: 21.275 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.127 (accuracy: 52.065%), validation loss = 1.121 (accuracy: 54.286%)\n",
      "Epoch 80: 21.560 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.131 (accuracy: 52.450%), validation loss = 1.125 (accuracy: 52.381%)\n",
      "Epoch 81: 21.210 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.137 (accuracy: 52.834%), validation loss = 1.127 (accuracy: 52.381%)\n",
      "Epoch 82: 21.233 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.124 (accuracy: 51.585%), validation loss = 1.107 (accuracy: 54.286%)\n",
      "Epoch 83: 21.471 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.122 (accuracy: 54.179%), validation loss = 1.112 (accuracy: 52.381%)\n",
      "Epoch 84: 21.370 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.117 (accuracy: 54.851%), validation loss = 1.111 (accuracy: 54.286%)\n",
      "Epoch 85: 21.546 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.118 (accuracy: 52.930%), validation loss = 1.117 (accuracy: 52.381%)\n",
      "Epoch 86: 21.428 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.106 (accuracy: 52.930%), validation loss = 1.108 (accuracy: 54.286%)\n",
      "Epoch 87: 21.332 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.123 (accuracy: 52.834%), validation loss = 1.108 (accuracy: 52.381%)\n",
      "Epoch 88: 21.351 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.105 (accuracy: 53.698%), validation loss = 1.115 (accuracy: 51.429%)\n",
      "Epoch 89: 21.826 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.121 (accuracy: 53.410%), validation loss = 1.105 (accuracy: 52.381%)\n",
      "Epoch 90: 21.515 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.102 (accuracy: 55.427%), validation loss = 1.102 (accuracy: 52.381%)\n",
      "Epoch 91: 21.573 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.118 (accuracy: 51.201%), validation loss = 1.104 (accuracy: 53.333%)\n",
      "Epoch 92: 21.214 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.105 (accuracy: 54.659%), validation loss = 1.097 (accuracy: 52.381%)\n",
      "Epoch 93: 21.428 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.116 (accuracy: 52.257%), validation loss = 1.099 (accuracy: 52.381%)\n",
      "Epoch 94: 21.325 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.109 (accuracy: 53.602%), validation loss = 1.095 (accuracy: 51.429%)\n",
      "Epoch 95: 21.503 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.120 (accuracy: 52.354%), validation loss = 1.095 (accuracy: 54.286%)\n",
      "Epoch 96: 21.524 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.113 (accuracy: 52.642%), validation loss = 1.093 (accuracy: 53.333%)\n",
      "Epoch 97: 21.457 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.100 (accuracy: 54.179%), validation loss = 1.087 (accuracy: 53.333%)\n",
      "Epoch 98: 21.476 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.110 (accuracy: 52.257%), validation loss = 1.086 (accuracy: 53.333%)\n",
      "Epoch 99: 21.791 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.096 (accuracy: 57.157%), validation loss = 1.088 (accuracy: 50.476%)\n",
      "Epoch 100: 21.375 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.099 (accuracy: 55.427%), validation loss = 1.085 (accuracy: 52.381%)\n",
      "Epoch 101: 21.454 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.084 (accuracy: 55.139%), validation loss = 1.088 (accuracy: 52.381%)\n",
      "Epoch 102: 21.215 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.101 (accuracy: 55.139%), validation loss = 1.085 (accuracy: 52.381%)\n",
      "Epoch 103: 21.735 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.081 (accuracy: 55.235%), validation loss = 1.074 (accuracy: 53.333%)\n",
      "Epoch 104: 21.711 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.087 (accuracy: 56.388%), validation loss = 1.075 (accuracy: 53.333%)\n",
      "Epoch 105: 21.230 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.079 (accuracy: 54.467%), validation loss = 1.078 (accuracy: 53.333%)\n",
      "Epoch 106: 21.284 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.084 (accuracy: 54.179%), validation loss = 1.076 (accuracy: 52.381%)\n",
      "Epoch 107: 21.252 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.088 (accuracy: 55.524%), validation loss = 1.076 (accuracy: 54.286%)\n",
      "Epoch 108: 21.234 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.067 (accuracy: 54.467%), validation loss = 1.072 (accuracy: 54.286%)\n",
      "Epoch 109: 21.568 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.089 (accuracy: 54.371%), validation loss = 1.064 (accuracy: 53.333%)\n",
      "Epoch 110: 21.399 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.090 (accuracy: 53.890%), validation loss = 1.064 (accuracy: 53.333%)\n",
      "Epoch 111: 21.503 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.074 (accuracy: 53.410%), validation loss = 1.063 (accuracy: 52.381%)\n",
      "Epoch 112: 21.519 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.087 (accuracy: 54.371%), validation loss = 1.067 (accuracy: 50.476%)\n",
      "Epoch 113: 21.229 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.076 (accuracy: 55.139%), validation loss = 1.068 (accuracy: 54.286%)\n",
      "Epoch 114: 21.474 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.079 (accuracy: 54.851%), validation loss = 1.065 (accuracy: 52.381%)\n",
      "Epoch 115: 21.149 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.085 (accuracy: 54.467%), validation loss = 1.058 (accuracy: 55.238%)\n",
      "Epoch 116: 21.496 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.076 (accuracy: 55.139%), validation loss = 1.057 (accuracy: 53.333%)\n",
      "Epoch 117: 21.449 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.055 (accuracy: 56.580%), validation loss = 1.059 (accuracy: 54.286%)\n",
      "Epoch 118: 21.805 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.083 (accuracy: 54.275%), validation loss = 1.050 (accuracy: 56.190%)\n",
      "Epoch 119: 21.589 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.081 (accuracy: 53.314%), validation loss = 1.053 (accuracy: 53.333%)\n",
      "Epoch 120: 21.402 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.060 (accuracy: 58.117%), validation loss = 1.060 (accuracy: 51.429%)\n",
      "Epoch 121: 21.258 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.062 (accuracy: 55.235%), validation loss = 1.050 (accuracy: 51.429%)\n",
      "Epoch 122: 21.285 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.062 (accuracy: 56.100%), validation loss = 1.053 (accuracy: 53.333%)\n",
      "Epoch 123: 21.355 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.068 (accuracy: 54.563%), validation loss = 1.052 (accuracy: 54.286%)\n",
      "Epoch 124: 21.161 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.053 (accuracy: 57.157%), validation loss = 1.048 (accuracy: 55.238%)\n",
      "Epoch 125: 23.202 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 1.069 (accuracy: 56.580%), validation loss = 1.047 (accuracy: 54.286%)\n",
      "Epoch 126: 21.466 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.079 (accuracy: 53.026%), validation loss = 1.055 (accuracy: 53.333%)\n",
      "Epoch 127: 21.281 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.057 (accuracy: 55.139%), validation loss = 1.043 (accuracy: 55.238%)\n",
      "Epoch 128: 21.741 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.072 (accuracy: 55.620%), validation loss = 1.044 (accuracy: 57.143%)\n",
      "Epoch 129: 21.231 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 1.057 (accuracy: 55.427%), validation loss = 1.042 (accuracy: 56.190%)\n",
      "Epoch 130: 21.438 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 1.044 (accuracy: 56.484%), validation loss = 1.038 (accuracy: 57.143%)\n",
      "Epoch 131: 21.439 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 1.055 (accuracy: 56.004%), validation loss = 1.039 (accuracy: 53.333%)\n",
      "Epoch 132: 21.795 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 1.056 (accuracy: 56.292%), validation loss = 1.040 (accuracy: 55.238%)\n",
      "Epoch 133: 21.296 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 1.053 (accuracy: 56.676%), validation loss = 1.043 (accuracy: 53.333%)\n",
      "Epoch 134: 21.250 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 1.053 (accuracy: 56.772%), validation loss = 1.038 (accuracy: 56.190%)\n",
      "Epoch 135: 21.119 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 1.045 (accuracy: 57.157%), validation loss = 1.032 (accuracy: 56.190%)\n",
      "Epoch 136: 21.517 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 1.023 (accuracy: 57.349%), validation loss = 1.032 (accuracy: 55.238%)\n",
      "Epoch 137: 21.315 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 1.046 (accuracy: 57.061%), validation loss = 1.037 (accuracy: 55.238%)\n",
      "Epoch 138: 21.156 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 1.071 (accuracy: 53.410%), validation loss = 1.040 (accuracy: 56.190%)\n",
      "Epoch 139: 21.148 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 1.056 (accuracy: 56.292%), validation loss = 1.028 (accuracy: 56.190%)\n",
      "Epoch 140: 21.536 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 1.028 (accuracy: 57.733%), validation loss = 1.035 (accuracy: 55.238%)\n",
      "Epoch 141: 21.233 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 1.025 (accuracy: 58.501%), validation loss = 1.033 (accuracy: 55.238%)\n",
      "Epoch 142: 21.426 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 1.049 (accuracy: 55.716%), validation loss = 1.036 (accuracy: 56.190%)\n",
      "Epoch 143: 21.102 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 1.039 (accuracy: 56.580%), validation loss = 1.024 (accuracy: 56.190%)\n",
      "Epoch 144: 21.372 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 1.040 (accuracy: 57.349%), validation loss = 1.023 (accuracy: 58.095%)\n",
      "Epoch 145: 21.481 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 1.039 (accuracy: 57.349%), validation loss = 1.021 (accuracy: 58.095%)\n",
      "Epoch 146: 21.569 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 1.038 (accuracy: 56.388%), validation loss = 1.026 (accuracy: 56.190%)\n",
      "Epoch 147: 21.598 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 1.021 (accuracy: 56.580%), validation loss = 1.025 (accuracy: 56.190%)\n",
      "Epoch 148: 21.321 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 1.023 (accuracy: 58.213%), validation loss = 1.023 (accuracy: 58.095%)\n",
      "Epoch 149: 21.165 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 1.052 (accuracy: 56.772%), validation loss = 1.020 (accuracy: 56.190%)\n",
      "Epoch 150: 21.403 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 1.037 (accuracy: 56.004%), validation loss = 1.028 (accuracy: 56.190%)\n",
      "Epoch 151: 21.151 seconds elapsed in epoch.\n",
      "Epoch 151: training loss = 1.020 (accuracy: 57.733%), validation loss = 1.025 (accuracy: 56.190%)\n",
      "Epoch 152: 21.277 seconds elapsed in epoch.\n",
      "Epoch 152: training loss = 1.034 (accuracy: 57.253%), validation loss = 1.017 (accuracy: 55.238%)\n",
      "Epoch 153: 21.399 seconds elapsed in epoch.\n",
      "Epoch 153: training loss = 1.036 (accuracy: 56.196%), validation loss = 1.014 (accuracy: 60.000%)\n",
      "Epoch 154: 21.549 seconds elapsed in epoch.\n",
      "Epoch 154: training loss = 1.043 (accuracy: 56.868%), validation loss = 1.010 (accuracy: 59.048%)\n",
      "Epoch 155: 21.481 seconds elapsed in epoch.\n",
      "Epoch 155: training loss = 1.029 (accuracy: 56.772%), validation loss = 1.016 (accuracy: 57.143%)\n",
      "Epoch 156: 21.394 seconds elapsed in epoch.\n",
      "Epoch 156: training loss = 1.022 (accuracy: 56.676%), validation loss = 1.016 (accuracy: 57.143%)\n",
      "Epoch 157: 21.223 seconds elapsed in epoch.\n",
      "Epoch 157: training loss = 1.027 (accuracy: 56.196%), validation loss = 1.012 (accuracy: 58.095%)\n",
      "Epoch 158: 21.186 seconds elapsed in epoch.\n",
      "Epoch 158: training loss = 1.016 (accuracy: 55.235%), validation loss = 1.014 (accuracy: 58.095%)\n",
      "Epoch 159: 21.289 seconds elapsed in epoch.\n",
      "Epoch 159: training loss = 1.034 (accuracy: 57.157%), validation loss = 1.017 (accuracy: 57.143%)\n",
      "Epoch 160: 21.287 seconds elapsed in epoch.\n",
      "Epoch 160: training loss = 1.029 (accuracy: 56.196%), validation loss = 1.012 (accuracy: 57.143%)\n",
      "Epoch 161: 21.797 seconds elapsed in epoch.\n",
      "Epoch 161: training loss = 1.018 (accuracy: 57.733%), validation loss = 1.013 (accuracy: 56.190%)\n",
      "Epoch 162: 21.288 seconds elapsed in epoch.\n",
      "Epoch 162: training loss = 1.022 (accuracy: 56.004%), validation loss = 1.007 (accuracy: 59.048%)\n",
      "Epoch 163: 21.583 seconds elapsed in epoch.\n",
      "Epoch 163: training loss = 1.026 (accuracy: 57.733%), validation loss = 1.004 (accuracy: 58.095%)\n",
      "Epoch 164: 21.696 seconds elapsed in epoch.\n",
      "Epoch 164: training loss = 1.024 (accuracy: 58.886%), validation loss = 1.007 (accuracy: 60.000%)\n",
      "Epoch 165: 21.344 seconds elapsed in epoch.\n",
      "Epoch 165: training loss = 1.016 (accuracy: 57.349%), validation loss = 1.007 (accuracy: 59.048%)\n",
      "Epoch 166: 21.365 seconds elapsed in epoch.\n",
      "Epoch 166: training loss = 1.011 (accuracy: 59.270%), validation loss = 1.015 (accuracy: 58.095%)\n",
      "Epoch 167: 21.404 seconds elapsed in epoch.\n",
      "Epoch 167: training loss = 1.016 (accuracy: 57.637%), validation loss = 1.005 (accuracy: 57.143%)\n",
      "Epoch 168: 21.380 seconds elapsed in epoch.\n",
      "Epoch 168: training loss = 1.021 (accuracy: 58.021%), validation loss = 1.004 (accuracy: 58.095%)\n",
      "Epoch 169: 21.297 seconds elapsed in epoch.\n",
      "Epoch 169: training loss = 1.002 (accuracy: 59.270%), validation loss = 1.000 (accuracy: 60.000%)\n",
      "Epoch 170: 21.809 seconds elapsed in epoch.\n",
      "Epoch 170: training loss = 1.007 (accuracy: 60.327%), validation loss = 1.005 (accuracy: 57.143%)\n",
      "Epoch 171: 21.344 seconds elapsed in epoch.\n",
      "Epoch 171: training loss = 0.990 (accuracy: 60.231%), validation loss = 1.000 (accuracy: 58.095%)\n",
      "Epoch 172: 21.451 seconds elapsed in epoch.\n",
      "Epoch 172: training loss = 0.999 (accuracy: 56.964%), validation loss = 1.005 (accuracy: 58.095%)\n",
      "Epoch 173: 21.250 seconds elapsed in epoch.\n",
      "Epoch 173: training loss = 1.025 (accuracy: 56.388%), validation loss = 1.004 (accuracy: 57.143%)\n",
      "Epoch 174: 21.145 seconds elapsed in epoch.\n",
      "Epoch 174: training loss = 0.992 (accuracy: 58.405%), validation loss = 1.007 (accuracy: 59.048%)\n",
      "Epoch 175: 21.489 seconds elapsed in epoch.\n",
      "Epoch 175: training loss = 1.009 (accuracy: 57.733%), validation loss = 1.003 (accuracy: 59.048%)\n",
      "Epoch 176: 21.480 seconds elapsed in epoch.\n",
      "Epoch 176: training loss = 1.003 (accuracy: 59.174%), validation loss = 1.008 (accuracy: 58.095%)\n",
      "Epoch 177: 21.283 seconds elapsed in epoch.\n",
      "Epoch 177: training loss = 1.009 (accuracy: 57.253%), validation loss = 1.011 (accuracy: 57.143%)\n",
      "Epoch 178: 21.222 seconds elapsed in epoch.\n",
      "Epoch 178: training loss = 0.989 (accuracy: 59.558%), validation loss = 1.005 (accuracy: 57.143%)\n",
      "Epoch 179: 21.202 seconds elapsed in epoch.\n",
      "Epoch 179: training loss = 0.992 (accuracy: 58.405%), validation loss = 0.989 (accuracy: 60.952%)\n",
      "Epoch 180: 21.533 seconds elapsed in epoch.\n",
      "Epoch 180: training loss = 0.990 (accuracy: 59.462%), validation loss = 0.995 (accuracy: 59.048%)\n",
      "Epoch 181: 21.289 seconds elapsed in epoch.\n",
      "Epoch 181: training loss = 1.012 (accuracy: 57.349%), validation loss = 0.999 (accuracy: 58.095%)\n",
      "Epoch 182: 21.255 seconds elapsed in epoch.\n",
      "Epoch 182: training loss = 1.002 (accuracy: 58.213%), validation loss = 0.998 (accuracy: 58.095%)\n",
      "Epoch 183: 21.172 seconds elapsed in epoch.\n",
      "Epoch 183: training loss = 1.013 (accuracy: 58.021%), validation loss = 0.995 (accuracy: 60.000%)\n",
      "Epoch 184: 21.356 seconds elapsed in epoch.\n",
      "Epoch 184: training loss = 0.998 (accuracy: 58.598%), validation loss = 0.999 (accuracy: 59.048%)\n",
      "Epoch 185: 21.403 seconds elapsed in epoch.\n",
      "Epoch 185: training loss = 0.989 (accuracy: 59.750%), validation loss = 0.993 (accuracy: 60.000%)\n",
      "Epoch 186: 21.255 seconds elapsed in epoch.\n",
      "Epoch 186: training loss = 1.002 (accuracy: 58.213%), validation loss = 0.988 (accuracy: 60.000%)\n",
      "Epoch 187: 21.708 seconds elapsed in epoch.\n",
      "Epoch 187: training loss = 1.025 (accuracy: 56.580%), validation loss = 0.994 (accuracy: 57.143%)\n",
      "Epoch 188: 21.452 seconds elapsed in epoch.\n",
      "Epoch 188: training loss = 0.992 (accuracy: 58.309%), validation loss = 0.996 (accuracy: 60.000%)\n",
      "Epoch 189: 21.303 seconds elapsed in epoch.\n",
      "Epoch 189: training loss = 0.988 (accuracy: 57.829%), validation loss = 0.987 (accuracy: 59.048%)\n",
      "Epoch 190: 22.182 seconds elapsed in epoch.\n",
      "Epoch 190: training loss = 0.997 (accuracy: 59.174%), validation loss = 0.991 (accuracy: 58.095%)\n",
      "Epoch 191: 21.307 seconds elapsed in epoch.\n",
      "Epoch 191: training loss = 0.977 (accuracy: 59.366%), validation loss = 0.992 (accuracy: 59.048%)\n",
      "Epoch 192: 21.288 seconds elapsed in epoch.\n",
      "Epoch 192: training loss = 0.975 (accuracy: 58.982%), validation loss = 0.990 (accuracy: 60.952%)\n",
      "Epoch 193: 21.391 seconds elapsed in epoch.\n",
      "Epoch 193: training loss = 0.996 (accuracy: 57.829%), validation loss = 0.992 (accuracy: 58.095%)\n",
      "Epoch 194: 21.311 seconds elapsed in epoch.\n",
      "Epoch 194: training loss = 0.985 (accuracy: 60.615%), validation loss = 0.990 (accuracy: 58.095%)\n",
      "Epoch 195: 21.318 seconds elapsed in epoch.\n",
      "Epoch 195: training loss = 0.983 (accuracy: 59.174%), validation loss = 0.985 (accuracy: 57.143%)\n",
      "Epoch 196: 21.730 seconds elapsed in epoch.\n",
      "Epoch 196: training loss = 0.981 (accuracy: 58.213%), validation loss = 0.989 (accuracy: 59.048%)\n",
      "Epoch 197: 21.330 seconds elapsed in epoch.\n",
      "Epoch 197: training loss = 0.992 (accuracy: 57.445%), validation loss = 0.974 (accuracy: 60.000%)\n",
      "Epoch 198: 21.661 seconds elapsed in epoch.\n",
      "Epoch 198: training loss = 0.987 (accuracy: 60.327%), validation loss = 0.979 (accuracy: 61.905%)\n",
      "Epoch 199: 21.594 seconds elapsed in epoch.\n",
      "Epoch 199: training loss = 0.974 (accuracy: 60.903%), validation loss = 0.989 (accuracy: 60.000%)\n",
      "Epoch 200: 21.357 seconds elapsed in epoch.\n",
      "Epoch 200: training loss = 0.982 (accuracy: 58.886%), validation loss = 0.994 (accuracy: 58.095%)\n",
      "==================================================result==================================================\n",
      "the best epoch is 197 with minimum validation error = 0.9738557395480928\n",
      "19737.627 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0.1\n",
      "Epoch 1: 21.279 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.331 (accuracy: 35.255%), validation loss = 1.329 (accuracy: 32.381%)\n",
      "Epoch 2: 21.708 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.304 (accuracy: 39.385%), validation loss = 1.312 (accuracy: 32.381%)\n",
      "Epoch 3: 21.553 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.295 (accuracy: 39.289%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 4: 22.154 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.284 (accuracy: 39.673%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 5: 21.529 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.280 (accuracy: 39.962%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 6: 21.576 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.276 (accuracy: 39.962%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 7: 21.522 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.274 (accuracy: 39.866%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 8: 21.562 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.275 (accuracy: 39.577%), validation loss = 1.283 (accuracy: 33.333%)\n",
      "Epoch 9: 21.510 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.269 (accuracy: 38.809%), validation loss = 1.279 (accuracy: 33.333%)\n",
      "Epoch 10: 21.583 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.272 (accuracy: 39.769%), validation loss = 1.276 (accuracy: 33.333%)\n",
      "Epoch 11: 21.473 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.269 (accuracy: 41.787%), validation loss = 1.274 (accuracy: 33.333%)\n",
      "Epoch 12: 21.757 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.266 (accuracy: 39.673%), validation loss = 1.271 (accuracy: 33.333%)\n",
      "Epoch 13: 21.563 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.265 (accuracy: 40.730%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 14: 21.554 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.259 (accuracy: 40.538%), validation loss = 1.267 (accuracy: 33.333%)\n",
      "Epoch 15: 21.590 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.258 (accuracy: 40.826%), validation loss = 1.264 (accuracy: 33.333%)\n",
      "Epoch 16: 21.552 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.262 (accuracy: 40.634%), validation loss = 1.263 (accuracy: 33.333%)\n",
      "Epoch 17: 21.371 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.257 (accuracy: 41.691%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 18: 21.839 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.250 (accuracy: 41.499%), validation loss = 1.260 (accuracy: 33.333%)\n",
      "Epoch 19: 21.322 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.249 (accuracy: 40.826%), validation loss = 1.257 (accuracy: 33.333%)\n",
      "Epoch 20: 21.445 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.252 (accuracy: 40.826%), validation loss = 1.255 (accuracy: 33.333%)\n",
      "Epoch 21: 21.331 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.243 (accuracy: 41.018%), validation loss = 1.254 (accuracy: 33.333%)\n",
      "Epoch 22: 21.345 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.240 (accuracy: 41.499%), validation loss = 1.252 (accuracy: 33.333%)\n",
      "Epoch 23: 21.394 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.237 (accuracy: 42.267%), validation loss = 1.251 (accuracy: 33.333%)\n",
      "Epoch 24: 21.358 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.236 (accuracy: 41.787%), validation loss = 1.250 (accuracy: 33.333%)\n",
      "Epoch 25: 21.301 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.243 (accuracy: 42.651%), validation loss = 1.247 (accuracy: 33.333%)\n",
      "Epoch 26: 21.561 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.244 (accuracy: 41.787%), validation loss = 1.247 (accuracy: 33.333%)\n",
      "Epoch 27: 21.009 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.237 (accuracy: 41.306%), validation loss = 1.243 (accuracy: 34.286%)\n",
      "Epoch 28: 21.356 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.230 (accuracy: 41.883%), validation loss = 1.242 (accuracy: 34.286%)\n",
      "Epoch 29: 21.328 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.230 (accuracy: 43.420%), validation loss = 1.240 (accuracy: 35.238%)\n",
      "Epoch 30: 21.329 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.233 (accuracy: 42.459%), validation loss = 1.238 (accuracy: 35.238%)\n",
      "Epoch 31: 21.382 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.231 (accuracy: 43.132%), validation loss = 1.234 (accuracy: 36.190%)\n",
      "Epoch 32: 21.544 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.227 (accuracy: 43.516%), validation loss = 1.234 (accuracy: 36.190%)\n",
      "Epoch 33: 21.541 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.225 (accuracy: 44.380%), validation loss = 1.233 (accuracy: 36.190%)\n",
      "Epoch 34: 21.385 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.226 (accuracy: 42.555%), validation loss = 1.234 (accuracy: 36.190%)\n",
      "Epoch 35: 21.032 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.218 (accuracy: 44.669%), validation loss = 1.232 (accuracy: 36.190%)\n",
      "Epoch 36: 21.424 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.218 (accuracy: 43.324%), validation loss = 1.232 (accuracy: 36.190%)\n",
      "Epoch 37: 21.317 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.219 (accuracy: 44.669%), validation loss = 1.229 (accuracy: 37.143%)\n",
      "Epoch 38: 21.354 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.218 (accuracy: 44.284%), validation loss = 1.226 (accuracy: 38.095%)\n",
      "Epoch 39: 21.336 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.221 (accuracy: 44.765%), validation loss = 1.223 (accuracy: 39.048%)\n",
      "Epoch 40: 21.626 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.213 (accuracy: 44.092%), validation loss = 1.223 (accuracy: 37.143%)\n",
      "Epoch 41: 21.001 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.222 (accuracy: 45.533%), validation loss = 1.219 (accuracy: 40.000%)\n",
      "Epoch 42: 21.396 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.220 (accuracy: 44.765%), validation loss = 1.217 (accuracy: 41.905%)\n",
      "Epoch 43: 21.347 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.214 (accuracy: 43.228%), validation loss = 1.218 (accuracy: 40.000%)\n",
      "Epoch 44: 21.044 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.206 (accuracy: 45.245%), validation loss = 1.216 (accuracy: 39.048%)\n",
      "Epoch 45: 21.328 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.204 (accuracy: 43.324%), validation loss = 1.215 (accuracy: 41.905%)\n",
      "Epoch 46: 21.308 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.212 (accuracy: 45.341%), validation loss = 1.213 (accuracy: 40.952%)\n",
      "Epoch 47: 21.856 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.200 (accuracy: 46.590%), validation loss = 1.211 (accuracy: 40.952%)\n",
      "Epoch 48: 21.299 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.204 (accuracy: 45.533%), validation loss = 1.209 (accuracy: 40.952%)\n",
      "Epoch 49: 21.307 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.201 (accuracy: 47.839%), validation loss = 1.204 (accuracy: 41.905%)\n",
      "Epoch 50: 21.395 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.206 (accuracy: 45.437%), validation loss = 1.203 (accuracy: 40.952%)\n",
      "Epoch 51: 21.347 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.199 (accuracy: 48.223%), validation loss = 1.202 (accuracy: 41.905%)\n",
      "Epoch 52: 21.392 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.204 (accuracy: 46.686%), validation loss = 1.202 (accuracy: 41.905%)\n",
      "Epoch 53: 21.024 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.194 (accuracy: 47.262%), validation loss = 1.195 (accuracy: 41.905%)\n",
      "Epoch 54: 21.438 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.200 (accuracy: 48.511%), validation loss = 1.201 (accuracy: 42.857%)\n",
      "Epoch 55: 21.082 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.197 (accuracy: 47.262%), validation loss = 1.198 (accuracy: 42.857%)\n",
      "Epoch 56: 20.991 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.190 (accuracy: 47.743%), validation loss = 1.195 (accuracy: 40.952%)\n",
      "Epoch 57: 21.014 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.187 (accuracy: 46.590%), validation loss = 1.193 (accuracy: 41.905%)\n",
      "Epoch 58: 21.299 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.192 (accuracy: 47.070%), validation loss = 1.192 (accuracy: 41.905%)\n",
      "Epoch 59: 21.403 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.188 (accuracy: 47.646%), validation loss = 1.192 (accuracy: 41.905%)\n",
      "Epoch 60: 21.310 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.190 (accuracy: 47.262%), validation loss = 1.188 (accuracy: 42.857%)\n",
      "Epoch 61: 21.913 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.183 (accuracy: 47.743%), validation loss = 1.185 (accuracy: 42.857%)\n",
      "Epoch 62: 21.395 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.178 (accuracy: 47.935%), validation loss = 1.185 (accuracy: 42.857%)\n",
      "Epoch 63: 21.331 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.173 (accuracy: 50.528%), validation loss = 1.185 (accuracy: 42.857%)\n",
      "Epoch 64: 21.070 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.180 (accuracy: 47.550%), validation loss = 1.186 (accuracy: 40.952%)\n",
      "Epoch 65: 21.058 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.179 (accuracy: 49.087%), validation loss = 1.182 (accuracy: 41.905%)\n",
      "Epoch 66: 21.283 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.181 (accuracy: 47.935%), validation loss = 1.181 (accuracy: 43.810%)\n",
      "Epoch 67: 21.398 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.179 (accuracy: 48.895%), validation loss = 1.183 (accuracy: 43.810%)\n",
      "Epoch 68: 21.085 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.178 (accuracy: 49.087%), validation loss = 1.176 (accuracy: 44.762%)\n",
      "Epoch 69: 21.459 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.164 (accuracy: 51.297%), validation loss = 1.178 (accuracy: 45.714%)\n",
      "Epoch 70: 21.012 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.168 (accuracy: 49.760%), validation loss = 1.176 (accuracy: 45.714%)\n",
      "Epoch 71: 21.088 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.176 (accuracy: 48.223%), validation loss = 1.174 (accuracy: 46.667%)\n",
      "Epoch 72: 21.366 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.167 (accuracy: 51.201%), validation loss = 1.171 (accuracy: 47.619%)\n",
      "Epoch 73: 21.294 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.167 (accuracy: 49.183%), validation loss = 1.167 (accuracy: 49.524%)\n",
      "Epoch 74: 21.414 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.174 (accuracy: 48.799%), validation loss = 1.166 (accuracy: 48.571%)\n",
      "Epoch 75: 21.530 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.161 (accuracy: 51.585%), validation loss = 1.166 (accuracy: 47.619%)\n",
      "Epoch 76: 21.715 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.169 (accuracy: 48.511%), validation loss = 1.166 (accuracy: 48.571%)\n",
      "Epoch 77: 21.303 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.167 (accuracy: 50.048%), validation loss = 1.165 (accuracy: 48.571%)\n",
      "Epoch 78: 21.415 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.163 (accuracy: 50.720%), validation loss = 1.161 (accuracy: 49.524%)\n",
      "Epoch 79: 21.342 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.160 (accuracy: 51.585%), validation loss = 1.163 (accuracy: 47.619%)\n",
      "Epoch 80: 20.981 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.161 (accuracy: 50.624%), validation loss = 1.160 (accuracy: 50.476%)\n",
      "Epoch 81: 21.349 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.167 (accuracy: 49.183%), validation loss = 1.161 (accuracy: 49.524%)\n",
      "Epoch 82: 20.998 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.157 (accuracy: 50.336%), validation loss = 1.160 (accuracy: 49.524%)\n",
      "Epoch 83: 21.221 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.156 (accuracy: 52.642%), validation loss = 1.155 (accuracy: 50.476%)\n",
      "Epoch 84: 21.456 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.157 (accuracy: 51.201%), validation loss = 1.157 (accuracy: 47.619%)\n",
      "Epoch 85: 20.993 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.158 (accuracy: 52.161%), validation loss = 1.155 (accuracy: 49.524%)\n",
      "Epoch 86: 21.427 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.150 (accuracy: 53.314%), validation loss = 1.151 (accuracy: 48.571%)\n",
      "Epoch 87: 21.234 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.151 (accuracy: 51.297%), validation loss = 1.149 (accuracy: 48.571%)\n",
      "Epoch 88: 21.357 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.149 (accuracy: 50.817%), validation loss = 1.152 (accuracy: 49.524%)\n",
      "Epoch 89: 21.017 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.155 (accuracy: 50.720%), validation loss = 1.151 (accuracy: 49.524%)\n",
      "Epoch 90: 21.557 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.151 (accuracy: 50.048%), validation loss = 1.150 (accuracy: 49.524%)\n",
      "Epoch 91: 21.086 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.151 (accuracy: 50.528%), validation loss = 1.144 (accuracy: 50.476%)\n",
      "Epoch 92: 21.361 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.155 (accuracy: 51.585%), validation loss = 1.149 (accuracy: 48.571%)\n",
      "Epoch 93: 21.037 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.145 (accuracy: 50.817%), validation loss = 1.144 (accuracy: 49.524%)\n",
      "Epoch 94: 21.647 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.144 (accuracy: 51.009%), validation loss = 1.145 (accuracy: 48.571%)\n",
      "Epoch 95: 21.011 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.148 (accuracy: 50.720%), validation loss = 1.140 (accuracy: 52.381%)\n",
      "Epoch 96: 21.395 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.137 (accuracy: 52.546%), validation loss = 1.139 (accuracy: 50.476%)\n",
      "Epoch 97: 21.548 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.138 (accuracy: 51.681%), validation loss = 1.137 (accuracy: 49.524%)\n",
      "Epoch 98: 21.370 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.140 (accuracy: 50.720%), validation loss = 1.135 (accuracy: 52.381%)\n",
      "Epoch 99: 21.366 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.134 (accuracy: 53.506%), validation loss = 1.136 (accuracy: 51.429%)\n",
      "Epoch 100: 21.088 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.134 (accuracy: 54.371%), validation loss = 1.134 (accuracy: 49.524%)\n",
      "Epoch 101: 21.340 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.130 (accuracy: 52.738%), validation loss = 1.131 (accuracy: 53.333%)\n",
      "Epoch 102: 21.389 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.127 (accuracy: 53.218%), validation loss = 1.130 (accuracy: 54.286%)\n",
      "Epoch 103: 21.375 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.144 (accuracy: 51.105%), validation loss = 1.130 (accuracy: 53.333%)\n",
      "Epoch 104: 21.777 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.116 (accuracy: 55.331%), validation loss = 1.131 (accuracy: 52.381%)\n",
      "Epoch 105: 21.109 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.128 (accuracy: 52.642%), validation loss = 1.128 (accuracy: 52.381%)\n",
      "Epoch 106: 21.443 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.126 (accuracy: 52.354%), validation loss = 1.125 (accuracy: 52.381%)\n",
      "Epoch 107: 21.262 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.132 (accuracy: 52.642%), validation loss = 1.127 (accuracy: 51.429%)\n",
      "Epoch 108: 21.014 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.126 (accuracy: 52.546%), validation loss = 1.128 (accuracy: 53.333%)\n",
      "Epoch 109: 20.991 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.134 (accuracy: 50.432%), validation loss = 1.128 (accuracy: 50.476%)\n",
      "Epoch 110: 21.008 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.129 (accuracy: 51.585%), validation loss = 1.119 (accuracy: 53.333%)\n",
      "Epoch 111: 21.615 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.125 (accuracy: 53.410%), validation loss = 1.119 (accuracy: 52.381%)\n",
      "Epoch 112: 21.358 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.127 (accuracy: 51.681%), validation loss = 1.121 (accuracy: 52.381%)\n",
      "Epoch 113: 21.071 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.111 (accuracy: 55.043%), validation loss = 1.122 (accuracy: 52.381%)\n",
      "Epoch 114: 21.075 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.128 (accuracy: 51.585%), validation loss = 1.121 (accuracy: 52.381%)\n",
      "Epoch 115: 21.043 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.122 (accuracy: 53.794%), validation loss = 1.117 (accuracy: 52.381%)\n",
      "Epoch 116: 21.326 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.113 (accuracy: 53.122%), validation loss = 1.112 (accuracy: 52.381%)\n",
      "Epoch 117: 21.496 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.121 (accuracy: 54.083%), validation loss = 1.112 (accuracy: 52.381%)\n",
      "Epoch 118: 21.428 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.130 (accuracy: 52.642%), validation loss = 1.114 (accuracy: 52.381%)\n",
      "Epoch 119: 21.515 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.116 (accuracy: 53.218%), validation loss = 1.116 (accuracy: 53.333%)\n",
      "Epoch 120: 21.032 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.121 (accuracy: 53.218%), validation loss = 1.111 (accuracy: 53.333%)\n",
      "Epoch 121: 21.449 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.116 (accuracy: 53.987%), validation loss = 1.111 (accuracy: 52.381%)\n",
      "Epoch 122: 21.380 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.109 (accuracy: 54.275%), validation loss = 1.111 (accuracy: 51.429%)\n",
      "Epoch 123: 21.104 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.117 (accuracy: 53.314%), validation loss = 1.111 (accuracy: 52.381%)\n",
      "Epoch 124: 21.445 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.124 (accuracy: 52.930%), validation loss = 1.111 (accuracy: 52.381%)\n",
      "Epoch 125: 21.272 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 1.112 (accuracy: 53.698%), validation loss = 1.112 (accuracy: 53.333%)\n",
      "Epoch 126: 20.999 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.111 (accuracy: 53.410%), validation loss = 1.107 (accuracy: 52.381%)\n",
      "Epoch 127: 21.390 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.113 (accuracy: 54.083%), validation loss = 1.110 (accuracy: 53.333%)\n",
      "Epoch 128: 21.068 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.106 (accuracy: 54.467%), validation loss = 1.108 (accuracy: 52.381%)\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.005, 0.001, 0.0005]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "min_valid_loss_list_Q3_SGD = []\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "for lr in lr_list:\n",
    "    for weight in weight_list:\n",
    "        save_file_name = \"/content/gdrive/My Drive/SLDL/hw5/Q3/SGD/resnet50_lr_\" + str(lr) + \"_weight_\" + str(weight) + \".pt\"\n",
    "        model = reset_model(isFreeze = True)\n",
    "        if train_on_gpu:\n",
    "            model = model.to('cuda')\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay = weight)\n",
    "        nepoch = 200\n",
    "        Q3_tune_model = Resnet50()\n",
    "        print(\"Start training model: learning rate = {}, weight decay = {}\".format(lr, weight))\n",
    "        model_finish = Q3_tune_model.train(train_on_gpu, model, nepoch, optimizer, save_file_name, dataloaders['train'], dataloaders['val'], verbose = True)\n",
    "        min_valid_loss_list_Q3_SGD.append(Q3_tune_model.best_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1610589002245,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "Rzjw1Zk2BnTs",
    "outputId": "f80a4060-7c84-42c7-a4fe-685fbc0ec56f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-axis: learning rate\n",
      "y-axis: weight decay\n",
      "Best hyperparameters with SGD optimizer : learning rate = 0.005, weight decay = 0\n",
      "       0.0100    0.0050    0.0010    0.0005\n",
      "0.0  0.953703  0.927372  0.973856  1.100165\n",
      "0.1  0.981783  0.984598  0.977782  1.121718\n",
      "0.2  1.085904  1.079832  1.089413  1.145146\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.005, 0.001, 0.0005]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "df = pd.DataFrame(index = weight_list)\n",
    "count = 0\n",
    "for lr in lr_list:\n",
    "    temp = []\n",
    "    for weight in weight_list:\n",
    "        temp.append(min_valid_loss_list_Q3_SGD[count])\n",
    "        count +=1 \n",
    "    df[lr] = temp\n",
    "index = np.unravel_index(np.argmin(df, axis=None), df.shape)\n",
    "row_index = index[0]\n",
    "column_index = index[1]\n",
    "print(\"x-axis: learning rate\")\n",
    "print(\"y-axis: weight decay\")\n",
    "print(\"Best hyperparameters with SGD optimizer : learning rate = {}, weight decay = {}\".format(lr_list[column_index], weight_list[row_index]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ur8XUjXU-fFb"
   },
   "source": [
    "## Q3 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 186290,
     "status": "ok",
     "timestamp": 1610589296181,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "Lwx1K07t-qgS",
    "outputId": "e117dea5-0e5c-4955-a45f-e04b10896afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q3 result==================================================\n",
      "when optimizer = Adam, learning rate = 0.0001, weight decay = 0, overall testing accuracy = 0.596\n",
      "label = blazer, per class accuracy = 0.4444444444444444\n",
      "label = cardigan, per class accuracy = 0.6666666666666666\n",
      "label = coat, per class accuracy = 0.5116279069767442\n",
      "label = jacket, per class accuracy = 0.6346153846153846\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q3 result==================================================\n",
      "when optimizer = Adam, learning rate = 1e-05, weight decay = 0, overall testing accuracy = 0.596\n",
      "label = blazer, per class accuracy = 0.3333333333333333\n",
      "label = cardigan, per class accuracy = 0.5238095238095238\n",
      "label = coat, per class accuracy = 0.5581395348837209\n",
      "label = jacket, per class accuracy = 0.7307692307692307\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q3 result==================================================\n",
      "when optimizer = SGD, learning rate = 0.01, weight decay = 0.1, overall testing accuracy = 0.610\n",
      "label = blazer, per class accuracy = 0.0\n",
      "label = cardigan, per class accuracy = 0.7142857142857143\n",
      "label = coat, per class accuracy = 0.5581395348837209\n",
      "label = jacket, per class accuracy = 0.6730769230769231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q3 result==================================================\n",
      "when optimizer = SGD, learning rate = 0.005, weight decay = 0, overall testing accuracy = 0.651\n",
      "label = blazer, per class accuracy = 0.3333333333333333\n",
      "label = cardigan, per class accuracy = 0.7142857142857143\n",
      "label = coat, per class accuracy = 0.5581395348837209\n",
      "label = jacket, per class accuracy = 0.7307692307692307\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q3 Adam\n",
    "#lr = 0.0001, w = 0.0, lr = 0.00001, w = 0.0\n",
    "print_result(\"Q3\", \"Adam\", 0.0001, 0)\n",
    "print_result(\"Q3\", \"Adam\", 0.00001, 0)\n",
    "#Q3 SGD\n",
    "#lr = 0.01, w = 0.1, lr = 0.005, w = 0\n",
    "print_result(\"Q3\", \"SGD\", 0.01, 0.1)\n",
    "print_result(\"Q3\", \"SGD\", 0.005, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyygBzsr_HBy"
   },
   "source": [
    "### Tuning, Optimizer = Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 12085182,
     "status": "ok",
     "timestamp": 1610441721539,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "Oknd_ucC_Fff",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "26c31f77-fa8b-4fab-fbb3-ed84853f0ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: learning rate = 0.0005, weight decay = 0\n",
      "Epoch 1: 600.380 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.388 (accuracy: 35.639%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 2: 17.387 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.311 (accuracy: 37.272%), validation loss = 1.493 (accuracy: 30.476%)\n",
      "Epoch 3: 17.035 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.297 (accuracy: 39.385%), validation loss = 1.291 (accuracy: 32.381%)\n",
      "Epoch 4: 17.099 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.274 (accuracy: 39.962%), validation loss = 1.289 (accuracy: 36.190%)\n",
      "Epoch 5: 17.228 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.276 (accuracy: 36.503%), validation loss = 1.296 (accuracy: 43.810%)\n",
      "Epoch 6: 17.072 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.265 (accuracy: 39.097%), validation loss = 1.236 (accuracy: 40.000%)\n",
      "Epoch 7: 17.136 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.267 (accuracy: 40.250%), validation loss = 1.277 (accuracy: 40.952%)\n",
      "Epoch 8: 16.958 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.263 (accuracy: 40.154%), validation loss = 1.254 (accuracy: 37.143%)\n",
      "Epoch 9: 16.987 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.246 (accuracy: 40.922%), validation loss = 1.309 (accuracy: 40.000%)\n",
      "Epoch 10: 16.991 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.243 (accuracy: 42.555%), validation loss = 1.271 (accuracy: 42.857%)\n",
      "Epoch 11: 16.915 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.255 (accuracy: 40.922%), validation loss = 1.301 (accuracy: 36.190%)\n",
      "Epoch 12: 16.992 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.244 (accuracy: 41.499%), validation loss = 1.290 (accuracy: 40.952%)\n",
      "Epoch 13: 16.928 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.235 (accuracy: 43.036%), validation loss = 1.334 (accuracy: 38.095%)\n",
      "Epoch 14: 16.954 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.245 (accuracy: 41.979%), validation loss = 1.257 (accuracy: 42.857%)\n",
      "Epoch 15: 16.916 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.239 (accuracy: 42.075%), validation loss = 1.346 (accuracy: 40.952%)\n",
      "Epoch 16: 16.889 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.238 (accuracy: 42.171%), validation loss = 1.256 (accuracy: 40.952%)\n",
      "Epoch 17: 16.870 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.235 (accuracy: 42.939%), validation loss = 1.264 (accuracy: 45.714%)\n",
      "Epoch 18: 16.881 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.233 (accuracy: 41.691%), validation loss = 1.258 (accuracy: 43.810%)\n",
      "Epoch 19: 16.906 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.231 (accuracy: 43.324%), validation loss = 1.241 (accuracy: 42.857%)\n",
      "Epoch 20: 17.157 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.232 (accuracy: 39.577%), validation loss = 1.265 (accuracy: 40.952%)\n",
      "Epoch 21: 16.946 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.219 (accuracy: 44.957%), validation loss = 1.233 (accuracy: 40.000%)\n",
      "Epoch 22: 17.082 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.218 (accuracy: 44.092%), validation loss = 1.258 (accuracy: 42.857%)\n",
      "Epoch 23: 16.883 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.243 (accuracy: 43.900%), validation loss = 1.345 (accuracy: 39.048%)\n",
      "Epoch 24: 16.939 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.228 (accuracy: 41.595%), validation loss = 1.243 (accuracy: 43.810%)\n",
      "Epoch 25: 16.902 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.233 (accuracy: 41.402%), validation loss = 1.244 (accuracy: 43.810%)\n",
      "Epoch 26: 16.880 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.223 (accuracy: 42.939%), validation loss = 1.335 (accuracy: 39.048%)\n",
      "Epoch 27: 16.905 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.217 (accuracy: 43.612%), validation loss = 1.302 (accuracy: 40.000%)\n",
      "Epoch 28: 16.937 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.220 (accuracy: 42.267%), validation loss = 1.284 (accuracy: 42.857%)\n",
      "Epoch 29: 16.986 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.223 (accuracy: 44.092%), validation loss = 1.238 (accuracy: 46.667%)\n",
      "Epoch 30: 16.915 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.236 (accuracy: 43.900%), validation loss = 1.302 (accuracy: 40.000%)\n",
      "Epoch 31: 16.939 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.226 (accuracy: 41.979%), validation loss = 1.247 (accuracy: 45.714%)\n",
      "Epoch 32: 16.877 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.223 (accuracy: 44.476%), validation loss = 1.317 (accuracy: 44.762%)\n",
      "Epoch 33: 16.884 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.213 (accuracy: 44.476%), validation loss = 1.262 (accuracy: 40.952%)\n",
      "Epoch 34: 16.987 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.216 (accuracy: 44.669%), validation loss = 1.244 (accuracy: 41.905%)\n",
      "Epoch 35: 16.835 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.235 (accuracy: 43.036%), validation loss = 1.223 (accuracy: 40.952%)\n",
      "Epoch 36: 17.073 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.222 (accuracy: 43.900%), validation loss = 1.217 (accuracy: 41.905%)\n",
      "Epoch 37: 17.048 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.223 (accuracy: 43.516%), validation loss = 1.269 (accuracy: 40.000%)\n",
      "Epoch 38: 17.202 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.229 (accuracy: 44.188%), validation loss = 1.291 (accuracy: 39.048%)\n",
      "Epoch 39: 17.028 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.209 (accuracy: 43.324%), validation loss = 1.267 (accuracy: 42.857%)\n",
      "Epoch 40: 16.925 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.219 (accuracy: 44.188%), validation loss = 1.227 (accuracy: 42.857%)\n",
      "Epoch 41: 16.943 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.213 (accuracy: 42.075%), validation loss = 1.329 (accuracy: 40.000%)\n",
      "Epoch 42: 16.935 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.211 (accuracy: 43.516%), validation loss = 1.228 (accuracy: 47.619%)\n",
      "Epoch 43: 16.959 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.217 (accuracy: 44.092%), validation loss = 1.396 (accuracy: 38.095%)\n",
      "Epoch 44: 16.938 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.223 (accuracy: 42.363%), validation loss = 1.258 (accuracy: 40.000%)\n",
      "Epoch 45: 16.995 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.199 (accuracy: 44.669%), validation loss = 1.230 (accuracy: 40.952%)\n",
      "Epoch 46: 16.911 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.216 (accuracy: 43.612%), validation loss = 1.278 (accuracy: 43.810%)\n",
      "Epoch 47: 16.949 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.205 (accuracy: 44.861%), validation loss = 1.234 (accuracy: 40.952%)\n",
      "Epoch 48: 16.986 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.166 (accuracy: 46.398%), validation loss = 1.257 (accuracy: 45.714%)\n",
      "Epoch 49: 16.913 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.200 (accuracy: 45.053%), validation loss = 1.319 (accuracy: 39.048%)\n",
      "Epoch 50: 16.807 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.199 (accuracy: 46.494%), validation loss = 1.229 (accuracy: 41.905%)\n",
      "Epoch 51: 16.898 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.180 (accuracy: 46.206%), validation loss = 1.281 (accuracy: 43.810%)\n",
      "Epoch 52: 16.920 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.187 (accuracy: 46.206%), validation loss = 1.265 (accuracy: 42.857%)\n",
      "Epoch 53: 16.929 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.196 (accuracy: 45.437%), validation loss = 1.256 (accuracy: 41.905%)\n",
      "Epoch 54: 16.834 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.184 (accuracy: 44.669%), validation loss = 1.273 (accuracy: 47.619%)\n",
      "Epoch 55: 16.896 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.188 (accuracy: 45.341%), validation loss = 1.270 (accuracy: 44.762%)\n",
      "Epoch 56: 17.055 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.186 (accuracy: 43.804%), validation loss = 1.268 (accuracy: 40.000%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 36 with minimum validation error = 1.216842686562311\n",
      "1654.134 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.1\n",
      "Epoch 1: 17.124 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.389 (accuracy: 34.774%), validation loss = 1.321 (accuracy: 33.333%)\n",
      "Epoch 2: 17.107 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.348 (accuracy: 35.735%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 3: 17.082 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.310 (accuracy: 36.311%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 4: 16.884 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.303 (accuracy: 38.713%), validation loss = 1.321 (accuracy: 23.810%)\n",
      "Epoch 5: 16.870 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.298 (accuracy: 38.329%), validation loss = 1.267 (accuracy: 40.000%)\n",
      "Epoch 6: 17.134 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.308 (accuracy: 36.888%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 7: 16.889 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.295 (accuracy: 39.289%), validation loss = 1.312 (accuracy: 34.286%)\n",
      "Epoch 8: 16.906 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 30.476%)\n",
      "Epoch 9: 16.857 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.310 (accuracy: 35.927%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 10: 16.948 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.317 (accuracy: 37.272%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 11: 16.932 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.298 (accuracy: 38.521%), validation loss = 1.448 (accuracy: 33.333%)\n",
      "Epoch 12: 16.934 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.313 (accuracy: 38.136%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 13: 16.893 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.306 (accuracy: 39.673%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 14: 16.912 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.303 (accuracy: 38.040%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 15: 16.904 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.307 (accuracy: 38.136%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 16: 16.943 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.297 (accuracy: 38.713%), validation loss = 1.283 (accuracy: 33.333%)\n",
      "Epoch 17: 16.900 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.302 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 18: 16.957 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.307 (accuracy: 39.193%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 19: 17.137 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.301 (accuracy: 38.329%), validation loss = 1.785 (accuracy: 33.333%)\n",
      "Epoch 20: 16.912 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.304 (accuracy: 39.962%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 21: 16.943 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.301 (accuracy: 38.713%), validation loss = 1.325 (accuracy: 33.333%)\n",
      "Epoch 22: 16.850 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.305 (accuracy: 38.617%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 23: 16.893 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.293 (accuracy: 38.905%), validation loss = 5.767 (accuracy: 33.333%)\n",
      "Epoch 24: 16.895 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.293 (accuracy: 38.905%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 25: 16.924 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.301 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 5 with minimum validation error = 1.2665573528834753\n",
      "2079.372 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.2\n",
      "Epoch 1: 16.940 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.387 (accuracy: 35.543%), validation loss = 1.306 (accuracy: 25.714%)\n",
      "Epoch 2: 17.032 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.322 (accuracy: 34.870%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 3: 17.138 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.311 (accuracy: 36.792%), validation loss = 1.289 (accuracy: 28.571%)\n",
      "Epoch 4: 17.099 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.302 (accuracy: 37.368%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 5: 16.951 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.305 (accuracy: 34.966%), validation loss = 1.484 (accuracy: 33.333%)\n",
      "Epoch 6: 16.930 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.302 (accuracy: 37.752%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 7: 16.908 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.299 (accuracy: 39.097%), validation loss = 1.334 (accuracy: 33.333%)\n",
      "Epoch 8: 16.852 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.302 (accuracy: 39.193%), validation loss = 1.339 (accuracy: 33.333%)\n",
      "Epoch 9: 16.911 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.309 (accuracy: 37.656%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 10: 16.929 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.297 (accuracy: 38.809%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 11: 16.897 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.304 (accuracy: 39.481%), validation loss = 2.774 (accuracy: 33.333%)\n",
      "Epoch 12: 17.181 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.292 (accuracy: 39.193%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 13: 16.957 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.303 (accuracy: 39.385%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 14: 16.914 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.306 (accuracy: 39.385%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 15: 16.901 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.309 (accuracy: 38.425%), validation loss = 1.365 (accuracy: 33.333%)\n",
      "Epoch 16: 16.886 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.306 (accuracy: 38.809%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 17: 16.894 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.303 (accuracy: 38.521%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 18: 16.912 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.300 (accuracy: 39.385%), validation loss = 1.495 (accuracy: 33.333%)\n",
      "Epoch 19: 16.912 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.298 (accuracy: 39.289%), validation loss = 1.322 (accuracy: 33.333%)\n",
      "Epoch 20: 16.975 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.303 (accuracy: 39.481%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 21: 16.889 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.294 (accuracy: 39.481%), validation loss = 1.702 (accuracy: 33.333%)\n",
      "Epoch 22: 16.896 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.307 (accuracy: 39.385%), validation loss = 1.777 (accuracy: 33.333%)\n",
      "Epoch 23: 16.912 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.297 (accuracy: 39.385%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 3 with minimum validation error = 1.2892168158576602\n",
      "2470.716 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0\n",
      "Epoch 1: 16.968 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.341 (accuracy: 36.984%), validation loss = 1.294 (accuracy: 35.238%)\n",
      "Epoch 2: 17.018 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.303 (accuracy: 38.329%), validation loss = 1.304 (accuracy: 36.190%)\n",
      "Epoch 3: 16.841 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.285 (accuracy: 39.289%), validation loss = 1.347 (accuracy: 34.286%)\n",
      "Epoch 4: 16.932 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.284 (accuracy: 39.673%), validation loss = 1.267 (accuracy: 40.000%)\n",
      "Epoch 5: 17.071 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.257 (accuracy: 41.018%), validation loss = 1.324 (accuracy: 41.905%)\n",
      "Epoch 6: 16.985 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.273 (accuracy: 38.713%), validation loss = 1.264 (accuracy: 41.905%)\n",
      "Epoch 7: 17.324 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.258 (accuracy: 39.769%), validation loss = 1.230 (accuracy: 40.000%)\n",
      "Epoch 8: 17.035 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.267 (accuracy: 37.080%), validation loss = 1.236 (accuracy: 40.952%)\n",
      "Epoch 9: 16.862 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.254 (accuracy: 41.691%), validation loss = 1.245 (accuracy: 40.000%)\n",
      "Epoch 10: 16.915 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.241 (accuracy: 41.691%), validation loss = 1.234 (accuracy: 40.000%)\n",
      "Epoch 11: 16.937 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.235 (accuracy: 42.267%), validation loss = 1.237 (accuracy: 43.810%)\n",
      "Epoch 12: 16.865 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.232 (accuracy: 42.171%), validation loss = 1.224 (accuracy: 50.476%)\n",
      "Epoch 13: 17.009 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.244 (accuracy: 43.036%), validation loss = 1.214 (accuracy: 48.571%)\n",
      "Epoch 14: 17.092 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.234 (accuracy: 40.538%), validation loss = 1.214 (accuracy: 46.667%)\n",
      "Epoch 15: 17.108 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.208 (accuracy: 44.092%), validation loss = 1.444 (accuracy: 37.143%)\n",
      "Epoch 16: 16.895 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.221 (accuracy: 44.092%), validation loss = 1.201 (accuracy: 44.762%)\n",
      "Epoch 17: 17.091 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.220 (accuracy: 45.245%), validation loss = 1.206 (accuracy: 48.571%)\n",
      "Epoch 18: 16.876 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.220 (accuracy: 44.284%), validation loss = 1.589 (accuracy: 40.000%)\n",
      "Epoch 19: 16.906 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.230 (accuracy: 42.459%), validation loss = 1.264 (accuracy: 40.952%)\n",
      "Epoch 20: 16.906 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.221 (accuracy: 44.188%), validation loss = 1.266 (accuracy: 43.810%)\n",
      "Epoch 21: 16.874 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.196 (accuracy: 45.629%), validation loss = 1.261 (accuracy: 43.810%)\n",
      "Epoch 22: 16.848 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.196 (accuracy: 44.957%), validation loss = 1.233 (accuracy: 43.810%)\n",
      "Epoch 23: 16.880 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.197 (accuracy: 44.669%), validation loss = 1.288 (accuracy: 36.190%)\n",
      "Epoch 24: 16.936 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.179 (accuracy: 45.245%), validation loss = 1.189 (accuracy: 45.714%)\n",
      "Epoch 25: 17.344 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.182 (accuracy: 45.629%), validation loss = 1.162 (accuracy: 48.571%)\n",
      "Epoch 26: 17.134 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.157 (accuracy: 44.957%), validation loss = 1.250 (accuracy: 42.857%)\n",
      "Epoch 27: 16.838 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.169 (accuracy: 48.031%), validation loss = 1.359 (accuracy: 35.238%)\n",
      "Epoch 28: 16.863 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.174 (accuracy: 46.302%), validation loss = 1.242 (accuracy: 39.048%)\n",
      "Epoch 29: 16.941 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.155 (accuracy: 46.686%), validation loss = 1.156 (accuracy: 50.476%)\n",
      "Epoch 30: 17.143 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.146 (accuracy: 49.087%), validation loss = 1.232 (accuracy: 43.810%)\n",
      "Epoch 31: 16.838 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.124 (accuracy: 48.799%), validation loss = 1.243 (accuracy: 42.857%)\n",
      "Epoch 32: 16.865 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.145 (accuracy: 48.415%), validation loss = 1.213 (accuracy: 42.857%)\n",
      "Epoch 33: 16.910 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.157 (accuracy: 47.454%), validation loss = 1.327 (accuracy: 40.000%)\n",
      "Epoch 34: 16.941 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.129 (accuracy: 50.240%), validation loss = 1.240 (accuracy: 44.762%)\n",
      "Epoch 35: 16.842 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.119 (accuracy: 48.319%), validation loss = 1.265 (accuracy: 38.095%)\n",
      "Epoch 36: 16.937 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.103 (accuracy: 50.720%), validation loss = 1.217 (accuracy: 44.762%)\n",
      "Epoch 37: 16.817 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.124 (accuracy: 49.183%), validation loss = 1.318 (accuracy: 42.857%)\n",
      "Epoch 38: 16.889 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.111 (accuracy: 49.760%), validation loss = 1.133 (accuracy: 48.571%)\n",
      "Epoch 39: 17.118 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.113 (accuracy: 51.009%), validation loss = 1.276 (accuracy: 37.143%)\n",
      "Epoch 40: 16.883 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.086 (accuracy: 52.257%), validation loss = 1.167 (accuracy: 45.714%)\n",
      "Epoch 41: 16.861 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.085 (accuracy: 53.506%), validation loss = 1.380 (accuracy: 41.905%)\n",
      "Epoch 42: 16.907 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.061 (accuracy: 51.489%), validation loss = 1.187 (accuracy: 48.571%)\n",
      "Epoch 43: 16.999 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.082 (accuracy: 53.410%), validation loss = 1.282 (accuracy: 41.905%)\n",
      "Epoch 44: 17.071 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.037 (accuracy: 54.083%), validation loss = 1.314 (accuracy: 47.619%)\n",
      "Epoch 45: 16.848 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.042 (accuracy: 53.506%), validation loss = 1.378 (accuracy: 47.619%)\n",
      "Epoch 46: 16.851 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.066 (accuracy: 53.218%), validation loss = 1.337 (accuracy: 42.857%)\n",
      "Epoch 47: 16.913 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.046 (accuracy: 54.275%), validation loss = 1.249 (accuracy: 40.952%)\n",
      "Epoch 48: 16.938 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.029 (accuracy: 52.930%), validation loss = 1.143 (accuracy: 55.238%)\n",
      "Epoch 49: 16.903 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.048 (accuracy: 56.004%), validation loss = 1.267 (accuracy: 46.667%)\n",
      "Epoch 50: 16.855 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.005 (accuracy: 56.964%), validation loss = 1.335 (accuracy: 48.571%)\n",
      "Epoch 51: 16.879 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.023 (accuracy: 56.868%), validation loss = 1.194 (accuracy: 53.333%)\n",
      "Epoch 52: 16.891 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.001 (accuracy: 57.445%), validation loss = 1.250 (accuracy: 44.762%)\n",
      "Epoch 53: 16.928 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 0.972 (accuracy: 56.388%), validation loss = 1.197 (accuracy: 56.190%)\n",
      "Epoch 54: 16.915 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 0.984 (accuracy: 59.174%), validation loss = 1.270 (accuracy: 49.524%)\n",
      "Epoch 55: 16.848 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 0.957 (accuracy: 58.982%), validation loss = 1.322 (accuracy: 47.619%)\n",
      "Epoch 56: 16.878 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 0.971 (accuracy: 59.078%), validation loss = 1.315 (accuracy: 47.619%)\n",
      "Epoch 57: 16.881 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 0.936 (accuracy: 59.462%), validation loss = 1.176 (accuracy: 56.190%)\n",
      "Epoch 58: 16.895 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 0.941 (accuracy: 61.671%), validation loss = 1.332 (accuracy: 45.714%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 38 with minimum validation error = 1.1327596948260352\n",
      "3458.227 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.1\n",
      "Epoch 1: 16.873 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.326 (accuracy: 36.984%), validation loss = 1.303 (accuracy: 27.619%)\n",
      "Epoch 2: 17.157 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.309 (accuracy: 35.255%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 3: 17.119 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.314 (accuracy: 35.927%), validation loss = 1.316 (accuracy: 33.333%)\n",
      "Epoch 4: 17.184 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.303 (accuracy: 36.599%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 5: 16.910 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.297 (accuracy: 38.232%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 6: 16.944 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.296 (accuracy: 37.464%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 7: 16.850 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.295 (accuracy: 39.385%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 8: 16.903 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.294 (accuracy: 27.619%)\n",
      "Epoch 9: 17.160 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.284 (accuracy: 39.577%), validation loss = 1.295 (accuracy: 26.667%)\n",
      "Epoch 10: 16.903 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.277 (accuracy: 40.154%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 11: 16.892 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.279 (accuracy: 38.232%), validation loss = 1.303 (accuracy: 39.048%)\n",
      "Epoch 12: 16.866 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.257 (accuracy: 41.595%), validation loss = 1.268 (accuracy: 41.905%)\n",
      "Epoch 13: 17.374 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.273 (accuracy: 38.136%), validation loss = 1.284 (accuracy: 40.000%)\n",
      "Epoch 14: 16.928 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.258 (accuracy: 41.306%), validation loss = 1.265 (accuracy: 42.857%)\n",
      "Epoch 15: 17.051 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.260 (accuracy: 40.730%), validation loss = 1.250 (accuracy: 39.048%)\n",
      "Epoch 16: 17.090 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.264 (accuracy: 40.922%), validation loss = 1.357 (accuracy: 35.238%)\n",
      "Epoch 17: 16.892 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.259 (accuracy: 40.538%), validation loss = 1.240 (accuracy: 40.952%)\n",
      "Epoch 18: 17.051 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.260 (accuracy: 41.402%), validation loss = 1.221 (accuracy: 38.095%)\n",
      "Epoch 19: 17.084 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.250 (accuracy: 42.555%), validation loss = 1.244 (accuracy: 40.000%)\n",
      "Epoch 20: 17.088 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.247 (accuracy: 42.171%), validation loss = 1.295 (accuracy: 40.000%)\n",
      "Epoch 21: 16.844 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.247 (accuracy: 40.538%), validation loss = 1.249 (accuracy: 38.095%)\n",
      "Epoch 22: 17.116 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.226 (accuracy: 41.499%), validation loss = 1.610 (accuracy: 36.190%)\n",
      "Epoch 23: 16.906 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.241 (accuracy: 42.555%), validation loss = 1.247 (accuracy: 38.095%)\n",
      "Epoch 24: 16.966 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.240 (accuracy: 42.939%), validation loss = 1.280 (accuracy: 38.095%)\n",
      "Epoch 25: 16.871 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.246 (accuracy: 42.171%), validation loss = 1.259 (accuracy: 41.905%)\n",
      "Epoch 26: 16.858 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.237 (accuracy: 42.555%), validation loss = 1.245 (accuracy: 41.905%)\n",
      "Epoch 27: 16.981 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.235 (accuracy: 43.900%), validation loss = 1.276 (accuracy: 39.048%)\n",
      "Epoch 28: 16.951 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.227 (accuracy: 42.747%), validation loss = 1.297 (accuracy: 39.048%)\n",
      "Epoch 29: 16.860 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.250 (accuracy: 41.499%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 30: 16.943 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.224 (accuracy: 43.708%), validation loss = 1.565 (accuracy: 35.238%)\n",
      "Epoch 31: 16.918 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.222 (accuracy: 42.939%), validation loss = 1.229 (accuracy: 41.905%)\n",
      "Epoch 32: 16.911 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.221 (accuracy: 42.651%), validation loss = 1.585 (accuracy: 37.143%)\n",
      "Epoch 33: 16.993 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.217 (accuracy: 44.380%), validation loss = 1.228 (accuracy: 43.810%)\n",
      "Epoch 34: 16.873 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.230 (accuracy: 44.476%), validation loss = 1.244 (accuracy: 39.048%)\n",
      "Epoch 35: 16.964 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.218 (accuracy: 44.669%), validation loss = 1.258 (accuracy: 43.810%)\n",
      "Epoch 36: 16.839 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.222 (accuracy: 43.228%), validation loss = 1.233 (accuracy: 40.000%)\n",
      "Epoch 37: 16.970 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.224 (accuracy: 43.708%), validation loss = 1.311 (accuracy: 37.143%)\n",
      "Epoch 38: 17.053 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.217 (accuracy: 44.669%), validation loss = 1.335 (accuracy: 48.571%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 18 with minimum validation error = 1.2208784546170917\n",
      "4106.662 total second elapsed\n",
      "Start training model: learning rate = 0.0001, weight decay = 0.2\n",
      "Epoch 1: 16.920 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.326 (accuracy: 33.910%), validation loss = 1.319 (accuracy: 33.333%)\n",
      "Epoch 2: 17.194 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.293 (accuracy: 39.481%), validation loss = 1.328 (accuracy: 33.333%)\n",
      "Epoch 3: 17.008 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.299 (accuracy: 37.080%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 4: 17.140 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.304 (accuracy: 37.848%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 5: 16.912 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.296 (accuracy: 37.560%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 6: 16.943 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.290 (accuracy: 37.560%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 7: 16.924 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.303 (accuracy: 39.097%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 8: 16.864 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.294 (accuracy: 37.944%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 9: 16.942 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.297 (accuracy: 38.521%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 10: 16.913 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.297 (accuracy: 39.673%), validation loss = 1.321 (accuracy: 33.333%)\n",
      "Epoch 11: 16.913 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.290 (accuracy: 38.521%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 12: 16.899 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.290 (accuracy: 39.097%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 13: 16.893 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 14: 16.956 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.288 (accuracy: 39.289%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 15: 16.889 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.282 (accuracy: 39.289%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 16: 16.861 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.284 (accuracy: 39.001%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 17: 17.047 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.273 (accuracy: 39.385%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 18: 17.062 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.267 (accuracy: 39.001%), validation loss = 1.272 (accuracy: 30.476%)\n",
      "Epoch 19: 17.123 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.251 (accuracy: 40.922%), validation loss = 1.261 (accuracy: 40.000%)\n",
      "Epoch 20: 17.183 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.258 (accuracy: 42.555%), validation loss = 1.233 (accuracy: 40.952%)\n",
      "Epoch 21: 17.272 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.247 (accuracy: 41.018%), validation loss = 1.376 (accuracy: 33.333%)\n",
      "Epoch 22: 16.913 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.261 (accuracy: 41.210%), validation loss = 1.269 (accuracy: 40.952%)\n",
      "Epoch 23: 16.930 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.254 (accuracy: 40.634%), validation loss = 1.400 (accuracy: 42.857%)\n",
      "Epoch 24: 16.901 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.254 (accuracy: 39.769%), validation loss = 1.288 (accuracy: 40.952%)\n",
      "Epoch 25: 16.993 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.246 (accuracy: 42.459%), validation loss = 1.255 (accuracy: 34.286%)\n",
      "Epoch 26: 16.885 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.258 (accuracy: 39.769%), validation loss = 1.424 (accuracy: 40.952%)\n",
      "Epoch 27: 16.946 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.242 (accuracy: 41.595%), validation loss = 1.341 (accuracy: 40.000%)\n",
      "Epoch 28: 16.963 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.274 (accuracy: 39.673%), validation loss = 1.279 (accuracy: 38.095%)\n",
      "Epoch 29: 16.857 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.242 (accuracy: 40.250%), validation loss = 1.255 (accuracy: 32.381%)\n",
      "Epoch 30: 16.837 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.255 (accuracy: 39.866%), validation loss = 1.251 (accuracy: 37.143%)\n",
      "Epoch 31: 16.911 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.251 (accuracy: 39.866%), validation loss = 1.268 (accuracy: 40.000%)\n",
      "Epoch 32: 16.960 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.251 (accuracy: 40.826%), validation loss = 1.266 (accuracy: 40.000%)\n",
      "Epoch 33: 16.946 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.250 (accuracy: 40.634%), validation loss = 1.251 (accuracy: 40.000%)\n",
      "Epoch 34: 16.894 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.243 (accuracy: 41.499%), validation loss = 1.291 (accuracy: 40.952%)\n",
      "Epoch 35: 16.933 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.237 (accuracy: 42.459%), validation loss = 1.310 (accuracy: 34.286%)\n",
      "Epoch 36: 17.005 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.251 (accuracy: 41.114%), validation loss = 1.305 (accuracy: 37.143%)\n",
      "Epoch 37: 16.886 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.246 (accuracy: 41.595%), validation loss = 1.608 (accuracy: 41.905%)\n",
      "Epoch 38: 16.944 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.245 (accuracy: 41.402%), validation loss = 1.260 (accuracy: 40.000%)\n",
      "Epoch 39: 17.156 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.242 (accuracy: 41.018%), validation loss = 1.293 (accuracy: 39.048%)\n",
      "Epoch 40: 16.915 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.243 (accuracy: 42.747%), validation loss = 1.404 (accuracy: 39.048%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 20 with minimum validation error = 1.2334053732099988\n",
      "4787.897 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0\n",
      "Epoch 1: 16.850 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.321 (accuracy: 36.792%), validation loss = 1.331 (accuracy: 27.619%)\n",
      "Epoch 2: 17.102 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.306 (accuracy: 36.503%), validation loss = 1.335 (accuracy: 33.333%)\n",
      "Epoch 3: 16.905 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.300 (accuracy: 36.695%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 4: 17.030 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.279 (accuracy: 38.136%), validation loss = 1.320 (accuracy: 31.429%)\n",
      "Epoch 5: 16.853 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.280 (accuracy: 38.425%), validation loss = 1.292 (accuracy: 37.143%)\n",
      "Epoch 6: 17.087 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.272 (accuracy: 39.769%), validation loss = 1.289 (accuracy: 31.429%)\n",
      "Epoch 7: 17.088 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.250 (accuracy: 40.250%), validation loss = 1.346 (accuracy: 36.190%)\n",
      "Epoch 8: 16.845 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.264 (accuracy: 40.826%), validation loss = 1.304 (accuracy: 41.905%)\n",
      "Epoch 9: 16.912 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.262 (accuracy: 38.425%), validation loss = 1.314 (accuracy: 36.190%)\n",
      "Epoch 10: 16.825 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.256 (accuracy: 41.210%), validation loss = 1.278 (accuracy: 39.048%)\n",
      "Epoch 11: 17.072 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.248 (accuracy: 40.250%), validation loss = 1.257 (accuracy: 40.952%)\n",
      "Epoch 12: 17.062 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.257 (accuracy: 40.154%), validation loss = 1.259 (accuracy: 42.857%)\n",
      "Epoch 13: 16.912 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.232 (accuracy: 42.459%), validation loss = 1.292 (accuracy: 39.048%)\n",
      "Epoch 14: 16.931 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.230 (accuracy: 42.843%), validation loss = 1.245 (accuracy: 40.000%)\n",
      "Epoch 15: 17.018 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.226 (accuracy: 41.787%), validation loss = 1.253 (accuracy: 40.952%)\n",
      "Epoch 16: 16.951 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.219 (accuracy: 43.420%), validation loss = 1.290 (accuracy: 41.905%)\n",
      "Epoch 17: 17.139 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.211 (accuracy: 44.092%), validation loss = 1.262 (accuracy: 40.952%)\n",
      "Epoch 18: 16.847 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.220 (accuracy: 42.651%), validation loss = 1.268 (accuracy: 47.619%)\n",
      "Epoch 19: 16.852 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.222 (accuracy: 43.996%), validation loss = 1.330 (accuracy: 40.952%)\n",
      "Epoch 20: 16.941 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.221 (accuracy: 43.420%), validation loss = 1.286 (accuracy: 44.762%)\n",
      "Epoch 21: 16.878 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.216 (accuracy: 42.267%), validation loss = 1.282 (accuracy: 46.667%)\n",
      "Epoch 22: 16.857 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.202 (accuracy: 43.228%), validation loss = 1.188 (accuracy: 48.571%)\n",
      "Epoch 23: 17.053 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.212 (accuracy: 44.092%), validation loss = 1.236 (accuracy: 45.714%)\n",
      "Epoch 24: 16.872 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.202 (accuracy: 43.036%), validation loss = 1.253 (accuracy: 45.714%)\n",
      "Epoch 25: 16.858 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.193 (accuracy: 44.669%), validation loss = 1.376 (accuracy: 41.905%)\n",
      "Epoch 26: 16.897 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.194 (accuracy: 46.302%), validation loss = 1.281 (accuracy: 42.857%)\n",
      "Epoch 27: 16.874 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.192 (accuracy: 44.861%), validation loss = 1.337 (accuracy: 43.810%)\n",
      "Epoch 28: 16.859 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.166 (accuracy: 47.454%), validation loss = 1.261 (accuracy: 40.000%)\n",
      "Epoch 29: 16.855 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.163 (accuracy: 47.454%), validation loss = 1.439 (accuracy: 40.000%)\n",
      "Epoch 30: 16.889 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.168 (accuracy: 45.245%), validation loss = 1.497 (accuracy: 40.952%)\n",
      "Epoch 31: 16.927 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.179 (accuracy: 44.380%), validation loss = 1.382 (accuracy: 40.000%)\n",
      "Epoch 32: 16.947 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.171 (accuracy: 45.533%), validation loss = 1.358 (accuracy: 48.571%)\n",
      "Epoch 33: 16.860 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.159 (accuracy: 44.476%), validation loss = 1.550 (accuracy: 39.048%)\n",
      "Epoch 34: 16.811 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.164 (accuracy: 47.454%), validation loss = 1.293 (accuracy: 40.952%)\n",
      "Epoch 35: 17.125 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.142 (accuracy: 47.454%), validation loss = 1.270 (accuracy: 49.524%)\n",
      "Epoch 36: 16.949 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.156 (accuracy: 47.262%), validation loss = 1.428 (accuracy: 41.905%)\n",
      "Epoch 37: 16.876 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.140 (accuracy: 47.262%), validation loss = 1.302 (accuracy: 45.714%)\n",
      "Epoch 38: 16.919 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.115 (accuracy: 49.280%), validation loss = 1.540 (accuracy: 40.952%)\n",
      "Epoch 39: 16.864 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.119 (accuracy: 48.031%), validation loss = 1.504 (accuracy: 34.286%)\n",
      "Epoch 40: 16.862 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.136 (accuracy: 50.144%), validation loss = 1.863 (accuracy: 40.000%)\n",
      "Epoch 41: 16.922 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.146 (accuracy: 47.839%), validation loss = 1.386 (accuracy: 43.810%)\n",
      "Epoch 42: 16.832 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.118 (accuracy: 48.415%), validation loss = 1.383 (accuracy: 44.762%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 22 with minimum validation error = 1.1879492135274978\n",
      "5502.178 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.1\n",
      "Epoch 1: 16.857 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.322 (accuracy: 33.622%), validation loss = 1.323 (accuracy: 25.714%)\n",
      "Epoch 2: 17.114 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.307 (accuracy: 36.215%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 3: 17.073 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.310 (accuracy: 35.927%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 4: 17.099 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.292 (accuracy: 37.752%), validation loss = 1.309 (accuracy: 36.190%)\n",
      "Epoch 5: 16.885 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.294 (accuracy: 39.385%), validation loss = 1.297 (accuracy: 36.190%)\n",
      "Epoch 6: 17.178 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.291 (accuracy: 39.001%), validation loss = 1.303 (accuracy: 34.286%)\n",
      "Epoch 7: 16.881 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.288 (accuracy: 38.329%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 8: 17.041 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.296 (accuracy: 36.888%), validation loss = 1.313 (accuracy: 32.381%)\n",
      "Epoch 9: 16.874 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.285 (accuracy: 38.617%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 10: 16.983 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.302 (accuracy: 37.272%), validation loss = 1.319 (accuracy: 34.286%)\n",
      "Epoch 11: 17.030 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.290 (accuracy: 38.521%), validation loss = 1.309 (accuracy: 31.429%)\n",
      "Epoch 12: 17.118 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.281 (accuracy: 39.481%), validation loss = 1.293 (accuracy: 36.190%)\n",
      "Epoch 13: 17.261 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.280 (accuracy: 38.713%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 14: 16.872 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.272 (accuracy: 39.481%), validation loss = 1.273 (accuracy: 37.143%)\n",
      "Epoch 15: 17.082 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.281 (accuracy: 38.905%), validation loss = 1.290 (accuracy: 40.952%)\n",
      "Epoch 16: 16.880 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.264 (accuracy: 38.809%), validation loss = 1.274 (accuracy: 42.857%)\n",
      "Epoch 17: 16.997 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.264 (accuracy: 40.826%), validation loss = 1.291 (accuracy: 39.048%)\n",
      "Epoch 18: 16.858 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.264 (accuracy: 40.250%), validation loss = 1.281 (accuracy: 43.810%)\n",
      "Epoch 19: 16.878 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.256 (accuracy: 40.346%), validation loss = 1.261 (accuracy: 38.095%)\n",
      "Epoch 20: 17.058 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.256 (accuracy: 41.306%), validation loss = 1.274 (accuracy: 39.048%)\n",
      "Epoch 21: 16.904 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.253 (accuracy: 41.114%), validation loss = 1.340 (accuracy: 44.762%)\n",
      "Epoch 22: 16.927 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.240 (accuracy: 40.826%), validation loss = 1.249 (accuracy: 39.048%)\n",
      "Epoch 23: 17.078 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.253 (accuracy: 40.346%), validation loss = 1.283 (accuracy: 39.048%)\n",
      "Epoch 24: 16.941 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.242 (accuracy: 43.036%), validation loss = 1.305 (accuracy: 43.810%)\n",
      "Epoch 25: 16.869 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.223 (accuracy: 43.228%), validation loss = 1.305 (accuracy: 40.000%)\n",
      "Epoch 26: 17.070 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.229 (accuracy: 43.420%), validation loss = 1.254 (accuracy: 46.667%)\n",
      "Epoch 27: 16.938 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.225 (accuracy: 42.747%), validation loss = 1.249 (accuracy: 45.714%)\n",
      "Epoch 28: 17.143 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.227 (accuracy: 43.228%), validation loss = 1.251 (accuracy: 41.905%)\n",
      "Epoch 29: 16.842 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.214 (accuracy: 45.149%), validation loss = 1.223 (accuracy: 44.762%)\n",
      "Epoch 30: 17.316 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.214 (accuracy: 43.324%), validation loss = 1.240 (accuracy: 40.952%)\n",
      "Epoch 31: 16.993 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.230 (accuracy: 43.036%), validation loss = 1.359 (accuracy: 34.286%)\n",
      "Epoch 32: 16.888 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.204 (accuracy: 44.188%), validation loss = 1.275 (accuracy: 36.190%)\n",
      "Epoch 33: 16.862 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.214 (accuracy: 43.420%), validation loss = 1.203 (accuracy: 43.810%)\n",
      "Epoch 34: 17.175 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.215 (accuracy: 42.747%), validation loss = 1.260 (accuracy: 43.810%)\n",
      "Epoch 35: 16.893 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.209 (accuracy: 45.437%), validation loss = 1.268 (accuracy: 48.571%)\n",
      "Epoch 36: 16.941 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.211 (accuracy: 45.917%), validation loss = 1.277 (accuracy: 41.905%)\n",
      "Epoch 37: 16.897 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.197 (accuracy: 45.341%), validation loss = 1.271 (accuracy: 39.048%)\n",
      "Epoch 38: 16.902 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.201 (accuracy: 44.284%), validation loss = 1.228 (accuracy: 40.952%)\n",
      "Epoch 39: 16.908 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.174 (accuracy: 45.053%), validation loss = 1.247 (accuracy: 36.190%)\n",
      "Epoch 40: 16.943 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.180 (accuracy: 45.341%), validation loss = 1.378 (accuracy: 38.095%)\n",
      "Epoch 41: 16.974 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.181 (accuracy: 46.110%), validation loss = 1.179 (accuracy: 42.857%)\n",
      "Epoch 42: 17.034 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.169 (accuracy: 48.127%), validation loss = 1.342 (accuracy: 40.952%)\n",
      "Epoch 43: 16.956 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.190 (accuracy: 45.821%), validation loss = 1.226 (accuracy: 45.714%)\n",
      "Epoch 44: 16.945 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.155 (accuracy: 47.839%), validation loss = 1.687 (accuracy: 44.762%)\n",
      "Epoch 45: 17.003 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.187 (accuracy: 44.573%), validation loss = 1.220 (accuracy: 41.905%)\n",
      "Epoch 46: 16.925 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.155 (accuracy: 49.087%), validation loss = 1.242 (accuracy: 43.810%)\n",
      "Epoch 47: 16.888 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.170 (accuracy: 47.743%), validation loss = 1.305 (accuracy: 40.000%)\n",
      "Epoch 48: 17.155 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.161 (accuracy: 48.127%), validation loss = 1.207 (accuracy: 40.000%)\n",
      "Epoch 49: 16.938 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.153 (accuracy: 48.799%), validation loss = 1.259 (accuracy: 44.762%)\n",
      "Epoch 50: 16.926 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.149 (accuracy: 48.127%), validation loss = 1.305 (accuracy: 39.048%)\n",
      "Epoch 51: 16.880 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.156 (accuracy: 47.262%), validation loss = 1.231 (accuracy: 41.905%)\n",
      "Epoch 52: 16.978 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.139 (accuracy: 49.280%), validation loss = 1.208 (accuracy: 47.619%)\n",
      "Epoch 53: 16.858 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.180 (accuracy: 45.149%), validation loss = 1.287 (accuracy: 44.762%)\n",
      "Epoch 54: 16.924 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.139 (accuracy: 47.358%), validation loss = 1.330 (accuracy: 35.238%)\n",
      "Epoch 55: 16.903 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.154 (accuracy: 45.437%), validation loss = 1.493 (accuracy: 40.000%)\n",
      "Epoch 56: 16.965 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.166 (accuracy: 46.013%), validation loss = 1.232 (accuracy: 40.952%)\n",
      "Epoch 57: 16.874 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.143 (accuracy: 46.782%), validation loss = 1.237 (accuracy: 44.762%)\n",
      "Epoch 58: 16.885 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.148 (accuracy: 48.607%), validation loss = 1.283 (accuracy: 42.857%)\n",
      "Epoch 59: 16.956 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.125 (accuracy: 49.664%), validation loss = 1.250 (accuracy: 42.857%)\n",
      "Epoch 60: 16.943 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.125 (accuracy: 47.358%), validation loss = 1.163 (accuracy: 46.667%)\n",
      "Epoch 61: 17.132 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.151 (accuracy: 47.646%), validation loss = 1.287 (accuracy: 43.810%)\n",
      "Epoch 62: 16.954 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.121 (accuracy: 49.183%), validation loss = 1.250 (accuracy: 37.143%)\n",
      "Epoch 63: 16.953 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.101 (accuracy: 50.048%), validation loss = 1.267 (accuracy: 35.238%)\n",
      "Epoch 64: 16.969 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.134 (accuracy: 48.415%), validation loss = 1.250 (accuracy: 40.000%)\n",
      "Epoch 65: 16.938 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.145 (accuracy: 49.280%), validation loss = 1.332 (accuracy: 35.238%)\n",
      "Epoch 66: 17.105 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.119 (accuracy: 50.336%), validation loss = 1.245 (accuracy: 40.000%)\n",
      "Epoch 67: 16.998 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.120 (accuracy: 48.511%), validation loss = 1.248 (accuracy: 40.952%)\n",
      "Epoch 68: 16.884 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.115 (accuracy: 52.065%), validation loss = 1.549 (accuracy: 40.000%)\n",
      "Epoch 69: 16.964 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.157 (accuracy: 49.856%), validation loss = 1.254 (accuracy: 40.952%)\n",
      "Epoch 70: 16.958 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.100 (accuracy: 50.913%), validation loss = 1.384 (accuracy: 40.000%)\n",
      "Epoch 71: 16.869 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.120 (accuracy: 51.105%), validation loss = 1.261 (accuracy: 41.905%)\n",
      "Epoch 72: 16.895 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.097 (accuracy: 53.602%), validation loss = 1.254 (accuracy: 39.048%)\n",
      "Epoch 73: 16.926 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.106 (accuracy: 51.297%), validation loss = 1.225 (accuracy: 44.762%)\n",
      "Epoch 74: 17.013 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.100 (accuracy: 51.393%), validation loss = 1.412 (accuracy: 39.048%)\n",
      "Epoch 75: 16.869 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.104 (accuracy: 51.201%), validation loss = 1.245 (accuracy: 36.190%)\n",
      "Epoch 76: 16.919 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.105 (accuracy: 50.336%), validation loss = 1.327 (accuracy: 40.952%)\n",
      "Epoch 77: 16.909 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.094 (accuracy: 51.969%), validation loss = 1.340 (accuracy: 41.905%)\n",
      "Epoch 78: 16.925 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.094 (accuracy: 51.297%), validation loss = 1.448 (accuracy: 43.810%)\n",
      "Epoch 79: 17.009 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.105 (accuracy: 50.624%), validation loss = 1.294 (accuracy: 41.905%)\n",
      "Epoch 80: 17.071 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.081 (accuracy: 55.043%), validation loss = 1.424 (accuracy: 41.905%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 60 with minimum validation error = 1.163302417028518\n",
      "6864.937 total second elapsed\n",
      "Start training model: learning rate = 5e-05, weight decay = 0.2\n",
      "Epoch 1: 16.995 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.336 (accuracy: 35.543%), validation loss = 1.334 (accuracy: 31.429%)\n",
      "Epoch 2: 17.160 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.301 (accuracy: 36.984%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 3: 17.129 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.298 (accuracy: 37.080%), validation loss = 1.324 (accuracy: 32.381%)\n",
      "Epoch 4: 17.285 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.316 (accuracy: 36.503%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 5: 17.209 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.292 (accuracy: 39.001%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 6: 17.044 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.293 (accuracy: 39.289%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 7: 16.972 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.298 (accuracy: 37.176%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 8: 16.938 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.299 (accuracy: 38.521%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 9: 17.116 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.295 (accuracy: 38.329%), validation loss = 1.292 (accuracy: 32.381%)\n",
      "Epoch 10: 16.871 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.287 (accuracy: 38.329%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 11: 16.951 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.291 (accuracy: 39.385%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 12: 16.885 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.289 (accuracy: 39.193%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 13: 16.975 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.289 (accuracy: 39.385%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 14: 16.901 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.287 (accuracy: 38.713%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 15: 16.912 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.288 (accuracy: 38.329%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 16: 16.838 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.288 (accuracy: 39.289%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 17: 17.047 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.285 (accuracy: 39.769%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 18: 16.958 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.288 (accuracy: 39.673%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 19: 16.937 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.288 (accuracy: 39.577%), validation loss = 1.295 (accuracy: 30.476%)\n",
      "Epoch 20: 16.919 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.290 (accuracy: 38.425%), validation loss = 1.292 (accuracy: 31.429%)\n",
      "Epoch 21: 16.898 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.285 (accuracy: 38.713%), validation loss = 1.286 (accuracy: 31.429%)\n",
      "Epoch 22: 17.027 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.267 (accuracy: 40.058%), validation loss = 1.283 (accuracy: 36.190%)\n",
      "Epoch 23: 17.278 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.265 (accuracy: 41.499%), validation loss = 1.276 (accuracy: 42.857%)\n",
      "Epoch 24: 17.083 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.280 (accuracy: 40.826%), validation loss = 1.259 (accuracy: 40.952%)\n",
      "Epoch 25: 17.117 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.260 (accuracy: 40.826%), validation loss = 1.244 (accuracy: 41.905%)\n",
      "Epoch 26: 17.104 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.244 (accuracy: 40.730%), validation loss = 1.240 (accuracy: 44.762%)\n",
      "Epoch 27: 17.140 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.247 (accuracy: 42.075%), validation loss = 1.260 (accuracy: 43.810%)\n",
      "Epoch 28: 16.892 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.242 (accuracy: 43.420%), validation loss = 1.226 (accuracy: 43.810%)\n",
      "Epoch 29: 17.121 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.239 (accuracy: 42.459%), validation loss = 1.270 (accuracy: 40.000%)\n",
      "Epoch 30: 16.872 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.234 (accuracy: 42.075%), validation loss = 1.225 (accuracy: 41.905%)\n",
      "Epoch 31: 17.144 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.236 (accuracy: 43.324%), validation loss = 1.218 (accuracy: 43.810%)\n",
      "Epoch 32: 17.104 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.221 (accuracy: 42.171%), validation loss = 1.225 (accuracy: 40.952%)\n",
      "Epoch 33: 16.901 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.221 (accuracy: 45.437%), validation loss = 1.241 (accuracy: 43.810%)\n",
      "Epoch 34: 16.884 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.230 (accuracy: 41.018%), validation loss = 1.227 (accuracy: 48.571%)\n",
      "Epoch 35: 17.063 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.232 (accuracy: 42.171%), validation loss = 1.268 (accuracy: 44.762%)\n",
      "Epoch 36: 16.996 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.216 (accuracy: 43.612%), validation loss = 1.228 (accuracy: 46.667%)\n",
      "Epoch 37: 16.897 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.217 (accuracy: 43.708%), validation loss = 1.281 (accuracy: 44.762%)\n",
      "Epoch 38: 16.893 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.219 (accuracy: 44.188%), validation loss = 1.220 (accuracy: 40.000%)\n",
      "Epoch 39: 16.950 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.227 (accuracy: 42.939%), validation loss = 1.266 (accuracy: 42.857%)\n",
      "Epoch 40: 16.905 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.216 (accuracy: 43.324%), validation loss = 1.361 (accuracy: 39.048%)\n",
      "Epoch 41: 17.243 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.228 (accuracy: 42.171%), validation loss = 1.286 (accuracy: 43.810%)\n",
      "Epoch 42: 16.974 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.205 (accuracy: 44.476%), validation loss = 1.233 (accuracy: 41.905%)\n",
      "Epoch 43: 16.890 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.221 (accuracy: 44.765%), validation loss = 1.241 (accuracy: 43.810%)\n",
      "Epoch 44: 16.884 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.192 (accuracy: 45.533%), validation loss = 1.220 (accuracy: 45.714%)\n",
      "Epoch 45: 16.929 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.216 (accuracy: 43.708%), validation loss = 1.292 (accuracy: 39.048%)\n",
      "Epoch 46: 16.941 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.199 (accuracy: 44.573%), validation loss = 1.386 (accuracy: 34.286%)\n",
      "Epoch 47: 16.906 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.214 (accuracy: 45.053%), validation loss = 1.230 (accuracy: 42.857%)\n",
      "Epoch 48: 16.896 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.189 (accuracy: 45.821%), validation loss = 1.219 (accuracy: 44.762%)\n",
      "Epoch 49: 16.900 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.207 (accuracy: 44.284%), validation loss = 1.259 (accuracy: 42.857%)\n",
      "Epoch 50: 17.007 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.206 (accuracy: 45.437%), validation loss = 1.313 (accuracy: 41.905%)\n",
      "Epoch 51: 16.932 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.188 (accuracy: 46.494%), validation loss = 1.321 (accuracy: 40.000%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 31 with minimum validation error = 1.2177429925827754\n",
      "7737.248 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0\n",
      "Epoch 1: 16.919 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.325 (accuracy: 33.237%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 2: 17.241 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.310 (accuracy: 36.023%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 3: 17.070 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.298 (accuracy: 38.040%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 4: 17.110 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.293 (accuracy: 37.848%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 5: 16.841 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.287 (accuracy: 39.673%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 6: 17.109 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.300 (accuracy: 38.040%), validation loss = 1.298 (accuracy: 34.286%)\n",
      "Epoch 7: 16.834 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.297 (accuracy: 39.001%), validation loss = 1.297 (accuracy: 31.429%)\n",
      "Epoch 8: 17.159 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.287 (accuracy: 38.617%), validation loss = 1.294 (accuracy: 32.381%)\n",
      "Epoch 9: 16.929 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.286 (accuracy: 39.289%), validation loss = 1.298 (accuracy: 30.476%)\n",
      "Epoch 10: 16.895 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.285 (accuracy: 38.713%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 11: 16.840 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.278 (accuracy: 39.673%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 12: 16.879 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.272 (accuracy: 40.442%), validation loss = 1.302 (accuracy: 34.286%)\n",
      "Epoch 13: 16.917 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.271 (accuracy: 38.425%), validation loss = 1.290 (accuracy: 29.524%)\n",
      "Epoch 14: 17.065 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.266 (accuracy: 41.499%), validation loss = 1.284 (accuracy: 32.381%)\n",
      "Epoch 15: 17.092 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.281 (accuracy: 38.809%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 16: 16.839 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.268 (accuracy: 40.250%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 17: 16.907 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.266 (accuracy: 42.171%), validation loss = 1.281 (accuracy: 36.190%)\n",
      "Epoch 18: 17.091 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.261 (accuracy: 41.691%), validation loss = 1.298 (accuracy: 34.286%)\n",
      "Epoch 19: 16.899 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.267 (accuracy: 40.538%), validation loss = 1.288 (accuracy: 35.238%)\n",
      "Epoch 20: 17.031 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.255 (accuracy: 41.499%), validation loss = 1.284 (accuracy: 34.286%)\n",
      "Epoch 21: 16.865 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.266 (accuracy: 40.154%), validation loss = 1.273 (accuracy: 37.143%)\n",
      "Epoch 22: 17.085 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.268 (accuracy: 40.730%), validation loss = 1.286 (accuracy: 39.048%)\n",
      "Epoch 23: 16.954 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.249 (accuracy: 43.228%), validation loss = 1.279 (accuracy: 40.952%)\n",
      "Epoch 24: 16.882 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.261 (accuracy: 39.866%), validation loss = 1.282 (accuracy: 32.381%)\n",
      "Epoch 25: 16.864 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.254 (accuracy: 41.114%), validation loss = 1.273 (accuracy: 40.952%)\n",
      "Epoch 26: 17.355 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.258 (accuracy: 40.442%), validation loss = 1.266 (accuracy: 43.810%)\n",
      "Epoch 27: 17.132 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.253 (accuracy: 39.577%), validation loss = 1.284 (accuracy: 39.048%)\n",
      "Epoch 28: 16.917 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.263 (accuracy: 39.097%), validation loss = 1.268 (accuracy: 39.048%)\n",
      "Epoch 29: 16.845 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.248 (accuracy: 41.306%), validation loss = 1.255 (accuracy: 43.810%)\n",
      "Epoch 30: 17.116 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.243 (accuracy: 41.595%), validation loss = 1.265 (accuracy: 37.143%)\n",
      "Epoch 31: 16.854 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.246 (accuracy: 40.730%), validation loss = 1.265 (accuracy: 40.952%)\n",
      "Epoch 32: 16.958 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.236 (accuracy: 42.363%), validation loss = 1.258 (accuracy: 40.000%)\n",
      "Epoch 33: 16.885 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.243 (accuracy: 41.114%), validation loss = 1.255 (accuracy: 40.000%)\n",
      "Epoch 34: 17.096 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.235 (accuracy: 43.612%), validation loss = 1.247 (accuracy: 41.905%)\n",
      "Epoch 35: 17.036 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.232 (accuracy: 41.883%), validation loss = 1.237 (accuracy: 42.857%)\n",
      "Epoch 36: 17.101 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.233 (accuracy: 43.036%), validation loss = 1.238 (accuracy: 42.857%)\n",
      "Epoch 37: 16.931 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.234 (accuracy: 42.555%), validation loss = 1.243 (accuracy: 40.952%)\n",
      "Epoch 38: 16.972 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.238 (accuracy: 42.171%), validation loss = 1.233 (accuracy: 40.952%)\n",
      "Epoch 39: 17.074 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.221 (accuracy: 43.708%), validation loss = 1.237 (accuracy: 42.857%)\n",
      "Epoch 40: 16.892 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.232 (accuracy: 43.804%), validation loss = 1.236 (accuracy: 41.905%)\n",
      "Epoch 41: 16.947 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.222 (accuracy: 43.420%), validation loss = 1.221 (accuracy: 45.714%)\n",
      "Epoch 42: 17.084 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.222 (accuracy: 42.363%), validation loss = 1.239 (accuracy: 39.048%)\n",
      "Epoch 43: 16.895 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.228 (accuracy: 43.228%), validation loss = 1.241 (accuracy: 40.952%)\n",
      "Epoch 44: 17.027 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.216 (accuracy: 43.708%), validation loss = 1.233 (accuracy: 41.905%)\n",
      "Epoch 45: 16.958 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.218 (accuracy: 44.188%), validation loss = 1.229 (accuracy: 41.905%)\n",
      "Epoch 46: 16.879 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.201 (accuracy: 44.476%), validation loss = 1.219 (accuracy: 40.952%)\n",
      "Epoch 47: 17.106 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.220 (accuracy: 43.132%), validation loss = 1.220 (accuracy: 41.905%)\n",
      "Epoch 48: 16.879 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.218 (accuracy: 44.092%), validation loss = 1.252 (accuracy: 43.810%)\n",
      "Epoch 49: 16.906 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.213 (accuracy: 44.092%), validation loss = 1.236 (accuracy: 44.762%)\n",
      "Epoch 50: 16.890 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.222 (accuracy: 44.669%), validation loss = 1.226 (accuracy: 39.048%)\n",
      "Epoch 51: 16.902 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.219 (accuracy: 43.804%), validation loss = 1.233 (accuracy: 43.810%)\n",
      "Epoch 52: 16.937 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.207 (accuracy: 43.420%), validation loss = 1.224 (accuracy: 41.905%)\n",
      "Epoch 53: 16.834 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.202 (accuracy: 43.324%), validation loss = 1.203 (accuracy: 43.810%)\n",
      "Epoch 54: 17.086 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.209 (accuracy: 42.843%), validation loss = 1.200 (accuracy: 42.857%)\n",
      "Epoch 55: 17.107 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.207 (accuracy: 44.284%), validation loss = 1.214 (accuracy: 43.810%)\n",
      "Epoch 56: 17.031 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.200 (accuracy: 44.380%), validation loss = 1.237 (accuracy: 43.810%)\n",
      "Epoch 57: 16.852 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.198 (accuracy: 44.476%), validation loss = 1.206 (accuracy: 43.810%)\n",
      "Epoch 58: 16.883 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.193 (accuracy: 44.380%), validation loss = 1.196 (accuracy: 48.571%)\n",
      "Epoch 59: 17.048 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.193 (accuracy: 46.110%), validation loss = 1.219 (accuracy: 40.000%)\n",
      "Epoch 60: 16.912 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.199 (accuracy: 46.013%), validation loss = 1.220 (accuracy: 43.810%)\n",
      "Epoch 61: 16.972 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.189 (accuracy: 45.917%), validation loss = 1.201 (accuracy: 44.762%)\n",
      "Epoch 62: 16.977 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.192 (accuracy: 45.341%), validation loss = 1.200 (accuracy: 45.714%)\n",
      "Epoch 63: 17.031 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.188 (accuracy: 45.245%), validation loss = 1.216 (accuracy: 43.810%)\n",
      "Epoch 64: 16.826 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.194 (accuracy: 47.166%), validation loss = 1.217 (accuracy: 41.905%)\n",
      "Epoch 65: 16.950 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.210 (accuracy: 43.900%), validation loss = 1.235 (accuracy: 43.810%)\n",
      "Epoch 66: 16.878 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.184 (accuracy: 46.686%), validation loss = 1.194 (accuracy: 42.857%)\n",
      "Epoch 67: 17.037 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.187 (accuracy: 43.516%), validation loss = 1.235 (accuracy: 40.952%)\n",
      "Epoch 68: 16.865 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.198 (accuracy: 44.573%), validation loss = 1.170 (accuracy: 44.762%)\n",
      "Epoch 69: 17.052 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.189 (accuracy: 47.070%), validation loss = 1.194 (accuracy: 43.810%)\n",
      "Epoch 70: 16.902 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.184 (accuracy: 46.686%), validation loss = 1.210 (accuracy: 41.905%)\n",
      "Epoch 71: 16.883 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.186 (accuracy: 43.612%), validation loss = 1.216 (accuracy: 42.857%)\n",
      "Epoch 72: 16.871 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.186 (accuracy: 46.013%), validation loss = 1.240 (accuracy: 40.952%)\n",
      "Epoch 73: 16.950 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.179 (accuracy: 47.358%), validation loss = 1.215 (accuracy: 41.905%)\n",
      "Epoch 74: 16.967 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.180 (accuracy: 46.782%), validation loss = 1.203 (accuracy: 41.905%)\n",
      "Epoch 75: 16.959 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.164 (accuracy: 47.839%), validation loss = 1.202 (accuracy: 41.905%)\n",
      "Epoch 76: 16.916 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.174 (accuracy: 45.917%), validation loss = 1.205 (accuracy: 44.762%)\n",
      "Epoch 77: 16.851 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.195 (accuracy: 44.957%), validation loss = 1.214 (accuracy: 42.857%)\n",
      "Epoch 78: 16.860 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.172 (accuracy: 46.782%), validation loss = 1.194 (accuracy: 43.810%)\n",
      "Epoch 79: 16.861 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.160 (accuracy: 46.878%), validation loss = 1.181 (accuracy: 43.810%)\n",
      "Epoch 80: 16.961 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.173 (accuracy: 46.013%), validation loss = 1.234 (accuracy: 44.762%)\n",
      "Epoch 81: 17.069 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.160 (accuracy: 48.799%), validation loss = 1.193 (accuracy: 44.762%)\n",
      "Epoch 82: 16.880 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.164 (accuracy: 47.839%), validation loss = 1.203 (accuracy: 41.905%)\n",
      "Epoch 83: 16.849 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.154 (accuracy: 47.935%), validation loss = 1.187 (accuracy: 42.857%)\n",
      "Epoch 84: 16.916 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.174 (accuracy: 46.782%), validation loss = 1.181 (accuracy: 43.810%)\n",
      "Epoch 85: 16.877 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.181 (accuracy: 46.878%), validation loss = 1.190 (accuracy: 45.714%)\n",
      "Epoch 86: 16.823 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.145 (accuracy: 48.031%), validation loss = 1.175 (accuracy: 48.571%)\n",
      "Epoch 87: 16.867 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.164 (accuracy: 47.646%), validation loss = 1.188 (accuracy: 45.714%)\n",
      "Epoch 88: 16.915 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.156 (accuracy: 47.454%), validation loss = 1.178 (accuracy: 44.762%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 68 with minimum validation error = 1.1700145897411165\n",
      "9238.092 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.1\n",
      "Epoch 1: 16.942 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.387 (accuracy: 29.299%), validation loss = 1.344 (accuracy: 33.333%)\n",
      "Epoch 2: 17.077 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.290 (accuracy: 37.464%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 3: 17.141 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.299 (accuracy: 37.464%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 4: 17.137 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.288 (accuracy: 38.329%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 5: 17.104 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.293 (accuracy: 38.136%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 6: 16.946 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.300 (accuracy: 37.464%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 7: 16.887 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.297 (accuracy: 38.425%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 8: 17.070 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.293 (accuracy: 38.040%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 9: 16.943 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.283 (accuracy: 38.713%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 10: 16.934 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.291 (accuracy: 38.136%), validation loss = 1.298 (accuracy: 32.381%)\n",
      "Epoch 11: 17.173 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.293 (accuracy: 37.560%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 12: 16.904 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.291 (accuracy: 39.481%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 13: 16.905 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.288 (accuracy: 39.385%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 14: 16.937 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.288 (accuracy: 38.905%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 15: 16.926 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.285 (accuracy: 38.713%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 16: 16.941 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.285 (accuracy: 38.713%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 17: 16.867 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.283 (accuracy: 39.577%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 18: 17.098 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.285 (accuracy: 39.289%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 19: 16.898 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.288 (accuracy: 39.193%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 20: 17.067 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.281 (accuracy: 39.193%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 21: 16.906 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.285 (accuracy: 39.097%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 22: 16.965 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.282 (accuracy: 39.577%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 23: 16.953 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.286 (accuracy: 39.577%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 24: 16.958 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.279 (accuracy: 39.577%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 25: 16.945 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.289 (accuracy: 39.673%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 26: 16.901 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.285 (accuracy: 40.346%), validation loss = 1.299 (accuracy: 32.381%)\n",
      "Epoch 27: 16.935 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.285 (accuracy: 39.097%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 28: 17.108 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.278 (accuracy: 38.329%), validation loss = 1.300 (accuracy: 32.381%)\n",
      "Epoch 29: 17.107 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.279 (accuracy: 39.289%), validation loss = 1.294 (accuracy: 32.381%)\n",
      "Epoch 30: 17.036 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.283 (accuracy: 39.673%), validation loss = 1.297 (accuracy: 31.429%)\n",
      "Epoch 31: 16.902 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.280 (accuracy: 39.577%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 32: 17.070 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.275 (accuracy: 40.346%), validation loss = 1.298 (accuracy: 31.429%)\n",
      "Epoch 33: 16.880 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.282 (accuracy: 39.673%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 34: 17.136 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.279 (accuracy: 39.193%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 35: 16.881 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.279 (accuracy: 39.673%), validation loss = 1.295 (accuracy: 34.286%)\n",
      "Epoch 36: 16.877 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.281 (accuracy: 39.385%), validation loss = 1.296 (accuracy: 32.381%)\n",
      "Epoch 37: 16.933 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.280 (accuracy: 39.289%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 38: 16.951 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.278 (accuracy: 39.769%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 39: 17.020 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.279 (accuracy: 39.769%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 40: 16.921 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.278 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 41: 16.932 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.280 (accuracy: 38.425%), validation loss = 1.298 (accuracy: 32.381%)\n",
      "Epoch 42: 16.894 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.281 (accuracy: 39.962%), validation loss = 1.288 (accuracy: 31.429%)\n",
      "Epoch 43: 17.112 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.269 (accuracy: 39.577%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 44: 16.957 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.279 (accuracy: 39.481%), validation loss = 1.297 (accuracy: 31.429%)\n",
      "Epoch 45: 16.870 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.275 (accuracy: 39.385%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 46: 16.904 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.270 (accuracy: 39.962%), validation loss = 1.287 (accuracy: 33.333%)\n",
      "Epoch 47: 17.212 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.272 (accuracy: 40.538%), validation loss = 1.289 (accuracy: 32.381%)\n",
      "Epoch 48: 17.111 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.278 (accuracy: 39.577%), validation loss = 1.291 (accuracy: 33.333%)\n",
      "Epoch 49: 16.939 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.269 (accuracy: 39.481%), validation loss = 1.287 (accuracy: 32.381%)\n",
      "Epoch 50: 16.863 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.265 (accuracy: 39.673%), validation loss = 1.282 (accuracy: 30.476%)\n",
      "Epoch 51: 17.134 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.265 (accuracy: 39.962%), validation loss = 1.285 (accuracy: 30.476%)\n",
      "Epoch 52: 16.895 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.270 (accuracy: 39.289%), validation loss = 1.290 (accuracy: 32.381%)\n",
      "Epoch 53: 16.970 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.271 (accuracy: 40.826%), validation loss = 1.291 (accuracy: 30.476%)\n",
      "Epoch 54: 16.852 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.261 (accuracy: 39.962%), validation loss = 1.290 (accuracy: 29.524%)\n",
      "Epoch 55: 16.906 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.269 (accuracy: 40.538%), validation loss = 1.281 (accuracy: 32.381%)\n",
      "Epoch 56: 17.072 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.262 (accuracy: 39.481%), validation loss = 1.292 (accuracy: 28.571%)\n",
      "Epoch 57: 17.066 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.264 (accuracy: 39.866%), validation loss = 1.282 (accuracy: 36.190%)\n",
      "Epoch 58: 17.014 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.261 (accuracy: 40.250%), validation loss = 1.280 (accuracy: 36.190%)\n",
      "Epoch 59: 17.090 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.257 (accuracy: 40.826%), validation loss = 1.282 (accuracy: 33.333%)\n",
      "Epoch 60: 16.921 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.260 (accuracy: 40.826%), validation loss = 1.280 (accuracy: 31.429%)\n",
      "Epoch 61: 16.882 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.256 (accuracy: 40.730%), validation loss = 1.276 (accuracy: 39.048%)\n",
      "Epoch 62: 17.137 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.259 (accuracy: 40.250%), validation loss = 1.278 (accuracy: 36.190%)\n",
      "Epoch 63: 16.935 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.258 (accuracy: 41.883%), validation loss = 1.278 (accuracy: 37.143%)\n",
      "Epoch 64: 16.895 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.250 (accuracy: 40.634%), validation loss = 1.278 (accuracy: 42.857%)\n",
      "Epoch 65: 16.963 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.263 (accuracy: 39.962%), validation loss = 1.269 (accuracy: 42.857%)\n",
      "Epoch 66: 17.351 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.252 (accuracy: 42.267%), validation loss = 1.272 (accuracy: 40.000%)\n",
      "Epoch 67: 16.936 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.243 (accuracy: 41.595%), validation loss = 1.270 (accuracy: 36.190%)\n",
      "Epoch 68: 16.925 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.252 (accuracy: 41.018%), validation loss = 1.268 (accuracy: 42.857%)\n",
      "Epoch 69: 17.097 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.249 (accuracy: 41.402%), validation loss = 1.275 (accuracy: 37.143%)\n",
      "Epoch 70: 16.916 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.253 (accuracy: 39.673%), validation loss = 1.267 (accuracy: 40.952%)\n",
      "Epoch 71: 17.117 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.246 (accuracy: 41.979%), validation loss = 1.267 (accuracy: 41.905%)\n",
      "Epoch 72: 17.167 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.246 (accuracy: 40.634%), validation loss = 1.264 (accuracy: 43.810%)\n",
      "Epoch 73: 17.076 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.242 (accuracy: 40.442%), validation loss = 1.262 (accuracy: 40.952%)\n",
      "Epoch 74: 17.089 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.237 (accuracy: 41.787%), validation loss = 1.255 (accuracy: 42.857%)\n",
      "Epoch 75: 17.209 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.246 (accuracy: 40.442%), validation loss = 1.267 (accuracy: 43.810%)\n",
      "Epoch 76: 16.983 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.240 (accuracy: 42.747%), validation loss = 1.278 (accuracy: 38.095%)\n",
      "Epoch 77: 16.920 seconds elapsed in epoch.\n",
      "Epoch 77: training loss = 1.239 (accuracy: 42.075%), validation loss = 1.254 (accuracy: 39.048%)\n",
      "Epoch 78: 17.091 seconds elapsed in epoch.\n",
      "Epoch 78: training loss = 1.237 (accuracy: 41.883%), validation loss = 1.249 (accuracy: 40.952%)\n",
      "Epoch 79: 17.083 seconds elapsed in epoch.\n",
      "Epoch 79: training loss = 1.225 (accuracy: 43.516%), validation loss = 1.247 (accuracy: 40.952%)\n",
      "Epoch 80: 17.103 seconds elapsed in epoch.\n",
      "Epoch 80: training loss = 1.227 (accuracy: 42.939%), validation loss = 1.253 (accuracy: 43.810%)\n",
      "Epoch 81: 16.968 seconds elapsed in epoch.\n",
      "Epoch 81: training loss = 1.235 (accuracy: 43.900%), validation loss = 1.227 (accuracy: 43.810%)\n",
      "Epoch 82: 17.123 seconds elapsed in epoch.\n",
      "Epoch 82: training loss = 1.233 (accuracy: 42.363%), validation loss = 1.226 (accuracy: 42.857%)\n",
      "Epoch 83: 17.175 seconds elapsed in epoch.\n",
      "Epoch 83: training loss = 1.227 (accuracy: 43.324%), validation loss = 1.228 (accuracy: 44.762%)\n",
      "Epoch 84: 17.085 seconds elapsed in epoch.\n",
      "Epoch 84: training loss = 1.226 (accuracy: 43.420%), validation loss = 1.224 (accuracy: 44.762%)\n",
      "Epoch 85: 17.105 seconds elapsed in epoch.\n",
      "Epoch 85: training loss = 1.224 (accuracy: 43.420%), validation loss = 1.216 (accuracy: 45.714%)\n",
      "Epoch 86: 17.158 seconds elapsed in epoch.\n",
      "Epoch 86: training loss = 1.214 (accuracy: 42.555%), validation loss = 1.222 (accuracy: 45.714%)\n",
      "Epoch 87: 16.882 seconds elapsed in epoch.\n",
      "Epoch 87: training loss = 1.224 (accuracy: 42.843%), validation loss = 1.226 (accuracy: 44.762%)\n",
      "Epoch 88: 16.951 seconds elapsed in epoch.\n",
      "Epoch 88: training loss = 1.215 (accuracy: 43.420%), validation loss = 1.226 (accuracy: 43.810%)\n",
      "Epoch 89: 16.906 seconds elapsed in epoch.\n",
      "Epoch 89: training loss = 1.215 (accuracy: 43.612%), validation loss = 1.218 (accuracy: 45.714%)\n",
      "Epoch 90: 16.944 seconds elapsed in epoch.\n",
      "Epoch 90: training loss = 1.209 (accuracy: 45.533%), validation loss = 1.242 (accuracy: 43.810%)\n",
      "Epoch 91: 16.926 seconds elapsed in epoch.\n",
      "Epoch 91: training loss = 1.212 (accuracy: 43.228%), validation loss = 1.207 (accuracy: 47.619%)\n",
      "Epoch 92: 17.112 seconds elapsed in epoch.\n",
      "Epoch 92: training loss = 1.214 (accuracy: 44.573%), validation loss = 1.209 (accuracy: 44.762%)\n",
      "Epoch 93: 17.028 seconds elapsed in epoch.\n",
      "Epoch 93: training loss = 1.216 (accuracy: 45.821%), validation loss = 1.225 (accuracy: 41.905%)\n",
      "Epoch 94: 16.908 seconds elapsed in epoch.\n",
      "Epoch 94: training loss = 1.213 (accuracy: 44.669%), validation loss = 1.207 (accuracy: 45.714%)\n",
      "Epoch 95: 17.142 seconds elapsed in epoch.\n",
      "Epoch 95: training loss = 1.212 (accuracy: 43.516%), validation loss = 1.224 (accuracy: 44.762%)\n",
      "Epoch 96: 16.923 seconds elapsed in epoch.\n",
      "Epoch 96: training loss = 1.202 (accuracy: 44.380%), validation loss = 1.196 (accuracy: 44.762%)\n",
      "Epoch 97: 17.331 seconds elapsed in epoch.\n",
      "Epoch 97: training loss = 1.208 (accuracy: 44.284%), validation loss = 1.230 (accuracy: 42.857%)\n",
      "Epoch 98: 16.881 seconds elapsed in epoch.\n",
      "Epoch 98: training loss = 1.190 (accuracy: 46.302%), validation loss = 1.203 (accuracy: 42.857%)\n",
      "Epoch 99: 16.927 seconds elapsed in epoch.\n",
      "Epoch 99: training loss = 1.204 (accuracy: 43.612%), validation loss = 1.219 (accuracy: 47.619%)\n",
      "Epoch 100: 16.949 seconds elapsed in epoch.\n",
      "Epoch 100: training loss = 1.199 (accuracy: 43.996%), validation loss = 1.211 (accuracy: 43.810%)\n",
      "Epoch 101: 16.903 seconds elapsed in epoch.\n",
      "Epoch 101: training loss = 1.204 (accuracy: 44.573%), validation loss = 1.214 (accuracy: 43.810%)\n",
      "Epoch 102: 17.137 seconds elapsed in epoch.\n",
      "Epoch 102: training loss = 1.203 (accuracy: 45.533%), validation loss = 1.242 (accuracy: 43.810%)\n",
      "Epoch 103: 16.929 seconds elapsed in epoch.\n",
      "Epoch 103: training loss = 1.192 (accuracy: 44.765%), validation loss = 1.211 (accuracy: 43.810%)\n",
      "Epoch 104: 16.906 seconds elapsed in epoch.\n",
      "Epoch 104: training loss = 1.176 (accuracy: 47.358%), validation loss = 1.208 (accuracy: 43.810%)\n",
      "Epoch 105: 16.935 seconds elapsed in epoch.\n",
      "Epoch 105: training loss = 1.191 (accuracy: 44.957%), validation loss = 1.251 (accuracy: 42.857%)\n",
      "Epoch 106: 16.893 seconds elapsed in epoch.\n",
      "Epoch 106: training loss = 1.174 (accuracy: 46.974%), validation loss = 1.250 (accuracy: 47.619%)\n",
      "Epoch 107: 16.888 seconds elapsed in epoch.\n",
      "Epoch 107: training loss = 1.187 (accuracy: 45.533%), validation loss = 1.186 (accuracy: 45.714%)\n",
      "Epoch 108: 17.164 seconds elapsed in epoch.\n",
      "Epoch 108: training loss = 1.165 (accuracy: 46.110%), validation loss = 1.220 (accuracy: 40.952%)\n",
      "Epoch 109: 16.936 seconds elapsed in epoch.\n",
      "Epoch 109: training loss = 1.184 (accuracy: 45.725%), validation loss = 1.221 (accuracy: 37.143%)\n",
      "Epoch 110: 16.944 seconds elapsed in epoch.\n",
      "Epoch 110: training loss = 1.169 (accuracy: 46.590%), validation loss = 1.205 (accuracy: 41.905%)\n",
      "Epoch 111: 17.033 seconds elapsed in epoch.\n",
      "Epoch 111: training loss = 1.171 (accuracy: 47.454%), validation loss = 1.191 (accuracy: 47.619%)\n",
      "Epoch 112: 16.896 seconds elapsed in epoch.\n",
      "Epoch 112: training loss = 1.182 (accuracy: 45.149%), validation loss = 1.203 (accuracy: 44.762%)\n",
      "Epoch 113: 16.904 seconds elapsed in epoch.\n",
      "Epoch 113: training loss = 1.160 (accuracy: 46.686%), validation loss = 1.295 (accuracy: 40.952%)\n",
      "Epoch 114: 16.979 seconds elapsed in epoch.\n",
      "Epoch 114: training loss = 1.166 (accuracy: 48.031%), validation loss = 1.195 (accuracy: 43.810%)\n",
      "Epoch 115: 16.902 seconds elapsed in epoch.\n",
      "Epoch 115: training loss = 1.177 (accuracy: 45.341%), validation loss = 1.316 (accuracy: 43.810%)\n",
      "Epoch 116: 16.929 seconds elapsed in epoch.\n",
      "Epoch 116: training loss = 1.162 (accuracy: 46.206%), validation loss = 1.205 (accuracy: 39.048%)\n",
      "Epoch 117: 16.895 seconds elapsed in epoch.\n",
      "Epoch 117: training loss = 1.177 (accuracy: 45.437%), validation loss = 1.183 (accuracy: 42.857%)\n",
      "Epoch 118: 17.075 seconds elapsed in epoch.\n",
      "Epoch 118: training loss = 1.159 (accuracy: 47.454%), validation loss = 1.196 (accuracy: 42.857%)\n",
      "Epoch 119: 16.969 seconds elapsed in epoch.\n",
      "Epoch 119: training loss = 1.154 (accuracy: 46.302%), validation loss = 1.197 (accuracy: 42.857%)\n",
      "Epoch 120: 17.133 seconds elapsed in epoch.\n",
      "Epoch 120: training loss = 1.149 (accuracy: 47.743%), validation loss = 1.235 (accuracy: 41.905%)\n",
      "Epoch 121: 16.926 seconds elapsed in epoch.\n",
      "Epoch 121: training loss = 1.143 (accuracy: 47.646%), validation loss = 1.301 (accuracy: 40.952%)\n",
      "Epoch 122: 16.906 seconds elapsed in epoch.\n",
      "Epoch 122: training loss = 1.143 (accuracy: 45.341%), validation loss = 1.263 (accuracy: 40.000%)\n",
      "Epoch 123: 16.918 seconds elapsed in epoch.\n",
      "Epoch 123: training loss = 1.144 (accuracy: 48.607%), validation loss = 1.165 (accuracy: 44.762%)\n",
      "Epoch 124: 17.119 seconds elapsed in epoch.\n",
      "Epoch 124: training loss = 1.137 (accuracy: 47.935%), validation loss = 1.350 (accuracy: 40.952%)\n",
      "Epoch 125: 16.898 seconds elapsed in epoch.\n",
      "Epoch 125: training loss = 1.146 (accuracy: 47.070%), validation loss = 1.206 (accuracy: 42.857%)\n",
      "Epoch 126: 16.894 seconds elapsed in epoch.\n",
      "Epoch 126: training loss = 1.144 (accuracy: 47.839%), validation loss = 1.198 (accuracy: 42.857%)\n",
      "Epoch 127: 16.945 seconds elapsed in epoch.\n",
      "Epoch 127: training loss = 1.136 (accuracy: 47.262%), validation loss = 1.238 (accuracy: 35.238%)\n",
      "Epoch 128: 16.935 seconds elapsed in epoch.\n",
      "Epoch 128: training loss = 1.125 (accuracy: 49.760%), validation loss = 1.176 (accuracy: 44.762%)\n",
      "Epoch 129: 17.003 seconds elapsed in epoch.\n",
      "Epoch 129: training loss = 1.154 (accuracy: 47.550%), validation loss = 1.253 (accuracy: 44.762%)\n",
      "Epoch 130: 16.894 seconds elapsed in epoch.\n",
      "Epoch 130: training loss = 1.130 (accuracy: 48.511%), validation loss = 1.165 (accuracy: 44.762%)\n",
      "Epoch 131: 17.092 seconds elapsed in epoch.\n",
      "Epoch 131: training loss = 1.100 (accuracy: 50.624%), validation loss = 1.251 (accuracy: 42.857%)\n",
      "Epoch 132: 17.006 seconds elapsed in epoch.\n",
      "Epoch 132: training loss = 1.148 (accuracy: 46.686%), validation loss = 1.219 (accuracy: 40.000%)\n",
      "Epoch 133: 16.918 seconds elapsed in epoch.\n",
      "Epoch 133: training loss = 1.133 (accuracy: 49.183%), validation loss = 1.238 (accuracy: 37.143%)\n",
      "Epoch 134: 16.923 seconds elapsed in epoch.\n",
      "Epoch 134: training loss = 1.115 (accuracy: 49.856%), validation loss = 1.293 (accuracy: 35.238%)\n",
      "Epoch 135: 16.855 seconds elapsed in epoch.\n",
      "Epoch 135: training loss = 1.124 (accuracy: 49.280%), validation loss = 1.261 (accuracy: 43.810%)\n",
      "Epoch 136: 16.943 seconds elapsed in epoch.\n",
      "Epoch 136: training loss = 1.130 (accuracy: 48.991%), validation loss = 1.256 (accuracy: 37.143%)\n",
      "Epoch 137: 16.891 seconds elapsed in epoch.\n",
      "Epoch 137: training loss = 1.105 (accuracy: 51.489%), validation loss = 1.350 (accuracy: 39.048%)\n",
      "Epoch 138: 17.088 seconds elapsed in epoch.\n",
      "Epoch 138: training loss = 1.112 (accuracy: 48.319%), validation loss = 1.185 (accuracy: 41.905%)\n",
      "Epoch 139: 17.005 seconds elapsed in epoch.\n",
      "Epoch 139: training loss = 1.096 (accuracy: 50.432%), validation loss = 1.220 (accuracy: 44.762%)\n",
      "Epoch 140: 16.881 seconds elapsed in epoch.\n",
      "Epoch 140: training loss = 1.094 (accuracy: 49.856%), validation loss = 1.296 (accuracy: 38.095%)\n",
      "Epoch 141: 16.895 seconds elapsed in epoch.\n",
      "Epoch 141: training loss = 1.122 (accuracy: 49.760%), validation loss = 1.207 (accuracy: 41.905%)\n",
      "Epoch 142: 16.897 seconds elapsed in epoch.\n",
      "Epoch 142: training loss = 1.087 (accuracy: 50.817%), validation loss = 1.218 (accuracy: 44.762%)\n",
      "Epoch 143: 16.966 seconds elapsed in epoch.\n",
      "Epoch 143: training loss = 1.110 (accuracy: 49.952%), validation loss = 1.191 (accuracy: 42.857%)\n",
      "Epoch 144: 16.891 seconds elapsed in epoch.\n",
      "Epoch 144: training loss = 1.092 (accuracy: 52.834%), validation loss = 1.271 (accuracy: 41.905%)\n",
      "Epoch 145: 16.894 seconds elapsed in epoch.\n",
      "Epoch 145: training loss = 1.092 (accuracy: 52.354%), validation loss = 1.238 (accuracy: 40.000%)\n",
      "Epoch 146: 16.946 seconds elapsed in epoch.\n",
      "Epoch 146: training loss = 1.111 (accuracy: 50.913%), validation loss = 1.220 (accuracy: 40.952%)\n",
      "Epoch 147: 17.054 seconds elapsed in epoch.\n",
      "Epoch 147: training loss = 1.072 (accuracy: 51.681%), validation loss = 1.226 (accuracy: 47.619%)\n",
      "Epoch 148: 16.932 seconds elapsed in epoch.\n",
      "Epoch 148: training loss = 1.092 (accuracy: 51.777%), validation loss = 1.296 (accuracy: 36.190%)\n",
      "Epoch 149: 16.909 seconds elapsed in epoch.\n",
      "Epoch 149: training loss = 1.089 (accuracy: 49.760%), validation loss = 1.219 (accuracy: 44.762%)\n",
      "Epoch 150: 16.928 seconds elapsed in epoch.\n",
      "Epoch 150: training loss = 1.078 (accuracy: 53.314%), validation loss = 1.237 (accuracy: 42.857%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 130 with minimum validation error = 1.1650665725980487\n",
      "11799.635 total second elapsed\n",
      "Start training model: learning rate = 1e-05, weight decay = 0.2\n",
      "Epoch 1: 16.953 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.332 (accuracy: 35.159%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 2: 17.236 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.297 (accuracy: 38.136%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 3: 17.118 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.307 (accuracy: 36.984%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 4: 17.076 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.300 (accuracy: 38.329%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 5: 16.920 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.295 (accuracy: 37.656%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 6: 17.047 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.301 (accuracy: 35.447%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 7: 17.122 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.293 (accuracy: 38.040%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 8: 16.884 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.301 (accuracy: 36.407%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 9: 16.911 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.288 (accuracy: 39.866%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 10: 16.949 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.292 (accuracy: 39.097%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 11: 16.972 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.284 (accuracy: 38.329%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 12: 16.948 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.292 (accuracy: 38.425%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 13: 16.941 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 14: 17.030 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.292 (accuracy: 38.617%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 15: 16.956 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.290 (accuracy: 39.577%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 16: 16.986 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.284 (accuracy: 39.385%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 17: 16.919 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.280 (accuracy: 39.769%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 18: 16.935 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.286 (accuracy: 39.577%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 19: 16.903 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.294 (accuracy: 38.425%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 20: 16.933 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.291 (accuracy: 38.617%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 21: 17.016 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.284 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 22: 16.910 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.290 (accuracy: 39.289%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 23: 16.926 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.285 (accuracy: 39.769%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 3 with minimum validation error = 1.2941297621954055\n",
      "12191.769 total second elapsed\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.0005, 0.0001, 0.00005, 0.00001]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "min_valid_loss_list_Q4_Adam = []\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "for lr in lr_list:\n",
    "    for weight in weight_list:\n",
    "        save_file_name = \"/content/gdrive/My Drive/SLDL/hw5/Q4/Adam/resnet50_lr_\" + str(lr) + \"_weight_\" + str(weight) + \".pt\"\n",
    "        model = reset_model(isFreeze = False, isPretrained = False)\n",
    "        if train_on_gpu:\n",
    "            model = model.to('cuda')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = weight)\n",
    "        nepoch = 200\n",
    "        Q4_tune_model = Resnet50()\n",
    "        print(\"Start training model: learning rate = {}, weight decay = {}\".format(lr, weight))\n",
    "        model_finish = Q4_tune_model.train(train_on_gpu, model, nepoch, optimizer, save_file_name, dataloaders['train'], dataloaders['val'], verbose = True)\n",
    "        min_valid_loss_list_Q4_Adam.append(Q4_tune_model.best_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1180,
     "status": "ok",
     "timestamp": 1610441722733,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "6L5E-xUsAyCV",
    "outputId": "d2faf035-e29c-4dbc-ef38-f61820ebdaac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-axis: learning rate\n",
      "y-axis: weight decay\n",
      "Best hyperparameters with Adam optimizer : learning rate = 0.0001, weight decay = 0\n",
      "      0.00050   0.00010   0.00005   0.00001\n",
      "0.0  1.216843  1.132760  1.187949  1.170015\n",
      "0.1  1.266557  1.220878  1.163302  1.165067\n",
      "0.2  1.289217  1.233405  1.217743  1.294130\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.0005, 0.0001, 0.00005, 0.00001]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "df = pd.DataFrame(index = weight_list)\n",
    "count = 0\n",
    "for lr in lr_list:\n",
    "    temp = []\n",
    "    for weight in weight_list:\n",
    "        temp.append(min_valid_loss_list_Q4_Adam[count])\n",
    "        count +=1 \n",
    "    df[lr] = temp\n",
    "index = np.unravel_index(np.argmin(df, axis=None), df.shape)\n",
    "row_index = index[0]\n",
    "column_index = index[1]\n",
    "print(\"x-axis: learning rate\")\n",
    "print(\"y-axis: weight decay\")\n",
    "print(\"Best hyperparameters with Adam optimizer : learning rate = {}, weight decay = {}\".format(lr_list[column_index], weight_list[row_index]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBRxWgmY1QaW"
   },
   "source": [
    "### Tuning, Optimizer =  SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 6714448,
     "status": "ok",
     "timestamp": 1610451694089,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "Yabw8M1P1J7p",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1b30e11a-d5c5-4c26-bbdd-c6d6e2aedb2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: learning rate = 0.01, weight decay = 0\n",
      "Epoch 1: 16.895 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.325 (accuracy: 35.447%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 2: 16.983 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.301 (accuracy: 36.023%), validation loss = 1.334 (accuracy: 33.333%)\n",
      "Epoch 3: 16.938 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.286 (accuracy: 39.001%), validation loss = 1.336 (accuracy: 35.238%)\n",
      "Epoch 4: 17.106 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.291 (accuracy: 38.329%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 5: 17.146 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.291 (accuracy: 39.097%), validation loss = 1.323 (accuracy: 33.333%)\n",
      "Epoch 6: 16.959 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.288 (accuracy: 38.713%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 7: 17.057 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.284 (accuracy: 39.001%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 8: 16.911 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.294 (accuracy: 39.577%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 9: 16.958 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.289 (accuracy: 39.577%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 10: 16.964 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.284 (accuracy: 39.866%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 11: 17.268 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.283 (accuracy: 40.538%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 12: 16.814 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.276 (accuracy: 39.673%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 13: 16.802 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.288 (accuracy: 39.289%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 14: 16.844 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.278 (accuracy: 39.289%), validation loss = 1.316 (accuracy: 33.333%)\n",
      "Epoch 15: 16.888 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.285 (accuracy: 39.577%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 16: 16.742 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.285 (accuracy: 39.577%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 17: 16.878 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 18: 16.852 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.283 (accuracy: 39.289%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 19: 17.065 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.278 (accuracy: 39.385%), validation loss = 1.318 (accuracy: 32.381%)\n",
      "Epoch 20: 16.916 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.268 (accuracy: 38.809%), validation loss = 1.326 (accuracy: 32.381%)\n",
      "Epoch 21: 16.831 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.269 (accuracy: 39.673%), validation loss = 1.281 (accuracy: 37.143%)\n",
      "Epoch 22: 17.114 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.269 (accuracy: 40.538%), validation loss = 1.277 (accuracy: 41.905%)\n",
      "Epoch 23: 17.053 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.266 (accuracy: 39.769%), validation loss = 1.268 (accuracy: 37.143%)\n",
      "Epoch 24: 17.104 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.272 (accuracy: 38.809%), validation loss = 1.272 (accuracy: 37.143%)\n",
      "Epoch 25: 16.906 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.256 (accuracy: 41.018%), validation loss = 1.266 (accuracy: 36.190%)\n",
      "Epoch 26: 17.084 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.254 (accuracy: 41.210%), validation loss = 1.287 (accuracy: 36.190%)\n",
      "Epoch 27: 16.766 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.259 (accuracy: 38.905%), validation loss = 1.285 (accuracy: 37.143%)\n",
      "Epoch 28: 16.828 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.249 (accuracy: 41.114%), validation loss = 1.322 (accuracy: 41.905%)\n",
      "Epoch 29: 16.978 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.257 (accuracy: 41.787%), validation loss = 1.309 (accuracy: 40.000%)\n",
      "Epoch 30: 16.834 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.252 (accuracy: 41.210%), validation loss = 1.260 (accuracy: 40.000%)\n",
      "Epoch 31: 16.978 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.258 (accuracy: 40.538%), validation loss = 1.267 (accuracy: 39.048%)\n",
      "Epoch 32: 16.787 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.251 (accuracy: 42.363%), validation loss = 1.293 (accuracy: 39.048%)\n",
      "Epoch 33: 16.884 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.261 (accuracy: 41.306%), validation loss = 1.340 (accuracy: 40.952%)\n",
      "Epoch 34: 16.836 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.247 (accuracy: 40.730%), validation loss = 1.274 (accuracy: 41.905%)\n",
      "Epoch 35: 16.756 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.252 (accuracy: 40.634%), validation loss = 1.255 (accuracy: 41.905%)\n",
      "Epoch 36: 16.929 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.236 (accuracy: 42.651%), validation loss = 1.291 (accuracy: 39.048%)\n",
      "Epoch 37: 16.770 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.247 (accuracy: 41.499%), validation loss = 1.279 (accuracy: 37.143%)\n",
      "Epoch 38: 16.778 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.253 (accuracy: 41.018%), validation loss = 1.306 (accuracy: 37.143%)\n",
      "Epoch 39: 16.777 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.248 (accuracy: 41.595%), validation loss = 1.271 (accuracy: 37.143%)\n",
      "Epoch 40: 16.744 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.255 (accuracy: 40.442%), validation loss = 1.261 (accuracy: 37.143%)\n",
      "Epoch 41: 16.743 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.240 (accuracy: 41.210%), validation loss = 1.299 (accuracy: 39.048%)\n",
      "Epoch 42: 16.751 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.236 (accuracy: 41.595%), validation loss = 1.261 (accuracy: 39.048%)\n",
      "Epoch 43: 16.820 seconds elapsed in epoch.\n",
      "Epoch 43: training loss = 1.243 (accuracy: 41.787%), validation loss = 1.317 (accuracy: 40.952%)\n",
      "Epoch 44: 16.838 seconds elapsed in epoch.\n",
      "Epoch 44: training loss = 1.244 (accuracy: 40.442%), validation loss = 1.439 (accuracy: 36.190%)\n",
      "Epoch 45: 16.757 seconds elapsed in epoch.\n",
      "Epoch 45: training loss = 1.248 (accuracy: 41.787%), validation loss = 1.297 (accuracy: 36.190%)\n",
      "Epoch 46: 16.784 seconds elapsed in epoch.\n",
      "Epoch 46: training loss = 1.242 (accuracy: 40.922%), validation loss = 1.285 (accuracy: 40.952%)\n",
      "Epoch 47: 16.766 seconds elapsed in epoch.\n",
      "Epoch 47: training loss = 1.247 (accuracy: 41.979%), validation loss = 1.256 (accuracy: 40.000%)\n",
      "Epoch 48: 17.088 seconds elapsed in epoch.\n",
      "Epoch 48: training loss = 1.244 (accuracy: 41.979%), validation loss = 1.255 (accuracy: 43.810%)\n",
      "Epoch 49: 16.932 seconds elapsed in epoch.\n",
      "Epoch 49: training loss = 1.242 (accuracy: 42.747%), validation loss = 1.281 (accuracy: 37.143%)\n",
      "Epoch 50: 16.878 seconds elapsed in epoch.\n",
      "Epoch 50: training loss = 1.238 (accuracy: 42.267%), validation loss = 1.281 (accuracy: 40.952%)\n",
      "Epoch 51: 16.832 seconds elapsed in epoch.\n",
      "Epoch 51: training loss = 1.250 (accuracy: 42.843%), validation loss = 1.262 (accuracy: 41.905%)\n",
      "Epoch 52: 16.787 seconds elapsed in epoch.\n",
      "Epoch 52: training loss = 1.236 (accuracy: 43.324%), validation loss = 1.277 (accuracy: 44.762%)\n",
      "Epoch 53: 16.825 seconds elapsed in epoch.\n",
      "Epoch 53: training loss = 1.246 (accuracy: 42.843%), validation loss = 1.277 (accuracy: 40.952%)\n",
      "Epoch 54: 16.764 seconds elapsed in epoch.\n",
      "Epoch 54: training loss = 1.236 (accuracy: 41.691%), validation loss = 1.297 (accuracy: 40.952%)\n",
      "Epoch 55: 16.759 seconds elapsed in epoch.\n",
      "Epoch 55: training loss = 1.237 (accuracy: 42.363%), validation loss = 1.254 (accuracy: 40.000%)\n",
      "Epoch 56: 16.893 seconds elapsed in epoch.\n",
      "Epoch 56: training loss = 1.243 (accuracy: 41.979%), validation loss = 1.244 (accuracy: 37.143%)\n",
      "Epoch 57: 17.041 seconds elapsed in epoch.\n",
      "Epoch 57: training loss = 1.214 (accuracy: 41.883%), validation loss = 1.303 (accuracy: 41.905%)\n",
      "Epoch 58: 16.788 seconds elapsed in epoch.\n",
      "Epoch 58: training loss = 1.243 (accuracy: 41.114%), validation loss = 1.359 (accuracy: 40.952%)\n",
      "Epoch 59: 16.772 seconds elapsed in epoch.\n",
      "Epoch 59: training loss = 1.228 (accuracy: 42.843%), validation loss = 1.298 (accuracy: 42.857%)\n",
      "Epoch 60: 16.728 seconds elapsed in epoch.\n",
      "Epoch 60: training loss = 1.226 (accuracy: 41.595%), validation loss = 1.279 (accuracy: 43.810%)\n",
      "Epoch 61: 16.831 seconds elapsed in epoch.\n",
      "Epoch 61: training loss = 1.228 (accuracy: 42.651%), validation loss = 1.339 (accuracy: 43.810%)\n",
      "Epoch 62: 16.773 seconds elapsed in epoch.\n",
      "Epoch 62: training loss = 1.231 (accuracy: 43.516%), validation loss = 1.403 (accuracy: 41.905%)\n",
      "Epoch 63: 16.805 seconds elapsed in epoch.\n",
      "Epoch 63: training loss = 1.230 (accuracy: 43.132%), validation loss = 1.304 (accuracy: 44.762%)\n",
      "Epoch 64: 16.802 seconds elapsed in epoch.\n",
      "Epoch 64: training loss = 1.233 (accuracy: 42.459%), validation loss = 1.366 (accuracy: 42.857%)\n",
      "Epoch 65: 16.729 seconds elapsed in epoch.\n",
      "Epoch 65: training loss = 1.227 (accuracy: 41.883%), validation loss = 1.377 (accuracy: 42.857%)\n",
      "Epoch 66: 16.953 seconds elapsed in epoch.\n",
      "Epoch 66: training loss = 1.222 (accuracy: 43.516%), validation loss = 1.411 (accuracy: 42.857%)\n",
      "Epoch 67: 16.854 seconds elapsed in epoch.\n",
      "Epoch 67: training loss = 1.222 (accuracy: 43.324%), validation loss = 1.328 (accuracy: 42.857%)\n",
      "Epoch 68: 16.854 seconds elapsed in epoch.\n",
      "Epoch 68: training loss = 1.233 (accuracy: 43.612%), validation loss = 1.340 (accuracy: 41.905%)\n",
      "Epoch 69: 16.777 seconds elapsed in epoch.\n",
      "Epoch 69: training loss = 1.225 (accuracy: 41.883%), validation loss = 1.374 (accuracy: 40.000%)\n",
      "Epoch 70: 16.866 seconds elapsed in epoch.\n",
      "Epoch 70: training loss = 1.224 (accuracy: 42.555%), validation loss = 1.338 (accuracy: 44.762%)\n",
      "Epoch 71: 16.770 seconds elapsed in epoch.\n",
      "Epoch 71: training loss = 1.228 (accuracy: 43.420%), validation loss = 1.308 (accuracy: 41.905%)\n",
      "Epoch 72: 16.839 seconds elapsed in epoch.\n",
      "Epoch 72: training loss = 1.221 (accuracy: 43.708%), validation loss = 1.388 (accuracy: 40.952%)\n",
      "Epoch 73: 16.754 seconds elapsed in epoch.\n",
      "Epoch 73: training loss = 1.224 (accuracy: 42.843%), validation loss = 1.458 (accuracy: 40.000%)\n",
      "Epoch 74: 16.755 seconds elapsed in epoch.\n",
      "Epoch 74: training loss = 1.210 (accuracy: 43.804%), validation loss = 1.390 (accuracy: 40.952%)\n",
      "Epoch 75: 16.780 seconds elapsed in epoch.\n",
      "Epoch 75: training loss = 1.227 (accuracy: 43.996%), validation loss = 1.406 (accuracy: 42.857%)\n",
      "Epoch 76: 16.783 seconds elapsed in epoch.\n",
      "Epoch 76: training loss = 1.222 (accuracy: 43.708%), validation loss = 1.409 (accuracy: 40.952%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 56 with minimum validation error = 1.244183981986273\n",
      "16737.894 total second elapsed\n",
      "Start training model: learning rate = 0.01, weight decay = 0.1\n",
      "Epoch 1: 16.839 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.323 (accuracy: 35.639%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 2: 16.999 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.307 (accuracy: 38.521%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 3: 16.879 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.284 (accuracy: 38.809%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 4: 16.740 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.301 (accuracy: 39.097%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 5: 16.872 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.291 (accuracy: 39.097%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 6: 16.837 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.287 (accuracy: 38.905%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 7: 16.782 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.285 (accuracy: 39.481%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 8: 16.870 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.285 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 9: 17.049 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.279 (accuracy: 39.289%), validation loss = 1.318 (accuracy: 33.333%)\n",
      "Epoch 10: 16.914 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.285 (accuracy: 39.481%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 11: 16.945 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.280 (accuracy: 39.289%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 12: 16.844 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.278 (accuracy: 39.385%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 13: 16.826 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.284 (accuracy: 39.289%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 14: 16.730 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.276 (accuracy: 39.577%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 15: 16.840 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.280 (accuracy: 39.193%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 16: 16.792 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.280 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 17: 16.785 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.276 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 18: 16.753 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.281 (accuracy: 39.577%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 19: 16.754 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.276 (accuracy: 39.481%), validation loss = 1.316 (accuracy: 33.333%)\n",
      "Epoch 20: 16.811 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.279 (accuracy: 39.097%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 21: 16.838 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.280 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 1 with minimum validation error = 1.289611089797247\n",
      "17092.407 total second elapsed\n",
      "Start training model: learning rate = 0.01, weight decay = 0.2\n",
      "Epoch 1: 16.796 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.304 (accuracy: 36.792%), validation loss = 1.327 (accuracy: 25.714%)\n",
      "Epoch 2: 16.992 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.305 (accuracy: 37.656%), validation loss = 1.319 (accuracy: 25.714%)\n",
      "Epoch 3: 17.054 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.293 (accuracy: 37.080%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 4: 17.015 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.290 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 25.714%)\n",
      "Epoch 5: 16.756 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.289 (accuracy: 38.713%), validation loss = 1.303 (accuracy: 23.810%)\n",
      "Epoch 6: 17.060 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.286 (accuracy: 39.001%), validation loss = 1.302 (accuracy: 25.714%)\n",
      "Epoch 7: 16.830 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.281 (accuracy: 40.058%), validation loss = 1.301 (accuracy: 26.667%)\n",
      "Epoch 8: 16.830 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.284 (accuracy: 39.001%), validation loss = 1.302 (accuracy: 32.381%)\n",
      "Epoch 9: 16.830 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.285 (accuracy: 39.577%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 10: 17.000 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.283 (accuracy: 39.097%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 11: 16.713 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 12: 16.803 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.281 (accuracy: 39.577%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 13: 16.843 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.277 (accuracy: 39.481%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 14: 16.862 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.281 (accuracy: 39.481%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 15: 17.014 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.278 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 16: 16.813 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.273 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 17: 16.735 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.273 (accuracy: 39.577%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 18: 16.850 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.269 (accuracy: 39.481%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 19: 16.755 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.271 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 20: 16.764 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.272 (accuracy: 39.481%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 21: 16.774 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.272 (accuracy: 39.481%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 22: 16.781 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.266 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 23: 16.847 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.272 (accuracy: 39.481%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 24: 16.895 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.272 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 25: 16.894 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.271 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 26: 16.748 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.266 (accuracy: 39.481%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 27: 16.894 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.266 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 28: 16.763 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.271 (accuracy: 39.481%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 29: 16.795 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.277 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 30: 16.727 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.271 (accuracy: 39.481%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 31: 16.786 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.274 (accuracy: 39.481%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 32: 16.818 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.276 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 33: 16.752 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.268 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 34: 16.731 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.274 (accuracy: 39.481%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 14 with minimum validation error = 1.299241324833461\n",
      "17667.208 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0\n",
      "Epoch 1: 16.792 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.325 (accuracy: 33.910%), validation loss = 1.403 (accuracy: 34.286%)\n",
      "Epoch 2: 16.910 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.307 (accuracy: 37.176%), validation loss = 1.318 (accuracy: 33.333%)\n",
      "Epoch 3: 17.039 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.294 (accuracy: 38.232%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 4: 17.105 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.299 (accuracy: 37.752%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 5: 16.740 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.294 (accuracy: 39.193%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 6: 16.908 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.292 (accuracy: 38.713%), validation loss = 1.328 (accuracy: 33.333%)\n",
      "Epoch 7: 16.784 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.290 (accuracy: 39.673%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 8: 16.842 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.293 (accuracy: 39.289%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 9: 16.959 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.287 (accuracy: 39.001%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 10: 16.749 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.287 (accuracy: 38.713%), validation loss = 1.319 (accuracy: 33.333%)\n",
      "Epoch 11: 16.865 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.289 (accuracy: 38.521%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 12: 16.796 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.292 (accuracy: 39.866%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 13: 16.792 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.290 (accuracy: 38.809%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 14: 16.754 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.287 (accuracy: 38.905%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 15: 16.729 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.288 (accuracy: 39.385%), validation loss = 1.333 (accuracy: 33.333%)\n",
      "Epoch 16: 16.730 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.287 (accuracy: 39.097%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 17: 16.763 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.331 (accuracy: 33.333%)\n",
      "Epoch 18: 16.744 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.290 (accuracy: 39.385%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 19: 16.865 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.292 (accuracy: 39.289%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 20: 16.675 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.286 (accuracy: 39.481%), validation loss = 1.326 (accuracy: 33.333%)\n",
      "Epoch 21: 16.763 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.286 (accuracy: 39.481%), validation loss = 1.318 (accuracy: 33.333%)\n",
      "Epoch 22: 16.806 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.285 (accuracy: 39.385%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 23: 16.827 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.288 (accuracy: 39.385%), validation loss = 1.331 (accuracy: 33.333%)\n",
      "Epoch 24: 16.716 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.283 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 25: 16.733 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.292 (accuracy: 39.385%), validation loss = 1.322 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 5 with minimum validation error = 1.2902671337127685\n",
      "18089.527 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0.1\n",
      "Epoch 1: 16.845 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.313 (accuracy: 35.543%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 2: 17.210 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.296 (accuracy: 37.656%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 3: 16.971 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.293 (accuracy: 37.272%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 4: 17.093 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.294 (accuracy: 38.329%), validation loss = 1.296 (accuracy: 28.571%)\n",
      "Epoch 5: 16.783 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.290 (accuracy: 39.289%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 6: 16.717 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.289 (accuracy: 39.001%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 7: 16.824 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.287 (accuracy: 38.136%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 8: 17.016 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.289 (accuracy: 38.617%), validation loss = 1.277 (accuracy: 33.333%)\n",
      "Epoch 9: 16.921 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.288 (accuracy: 38.905%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 10: 16.729 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.291 (accuracy: 39.193%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 11: 16.878 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.288 (accuracy: 40.250%), validation loss = 1.288 (accuracy: 33.333%)\n",
      "Epoch 12: 16.809 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.288 (accuracy: 39.577%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 13: 16.796 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.290 (accuracy: 39.577%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 14: 16.814 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.279 (accuracy: 39.481%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 15: 16.899 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.284 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 16: 16.792 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.284 (accuracy: 39.577%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 17: 16.818 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.287 (accuracy: 39.385%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 18: 16.769 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.280 (accuracy: 39.289%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 19: 16.840 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.283 (accuracy: 39.385%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 20: 16.860 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.285 (accuracy: 39.289%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 21: 16.981 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.280 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 22: 16.940 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.283 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 23: 16.711 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.285 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 24: 16.796 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.277 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 25: 16.734 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.277 (accuracy: 39.577%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 26: 16.820 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.279 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 27: 16.698 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.285 (accuracy: 39.577%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 28: 16.776 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.284 (accuracy: 39.577%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 8 with minimum validation error = 1.2769315299533663\n",
      "18563.684 total second elapsed\n",
      "Start training model: learning rate = 0.005, weight decay = 0.2\n",
      "Epoch 1: 16.779 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.322 (accuracy: 33.814%), validation loss = 1.316 (accuracy: 30.476%)\n",
      "Epoch 2: 16.947 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.302 (accuracy: 35.639%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 3: 16.950 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.295 (accuracy: 37.368%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 4: 17.043 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.292 (accuracy: 38.136%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 5: 16.816 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.294 (accuracy: 39.289%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 6: 16.752 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.291 (accuracy: 39.385%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 7: 16.810 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.285 (accuracy: 39.385%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 8: 16.816 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.279 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 9: 16.817 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.279 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 10: 16.717 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.285 (accuracy: 39.385%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 11: 17.261 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.278 (accuracy: 39.769%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 12: 17.028 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.283 (accuracy: 39.577%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 13: 17.004 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.282 (accuracy: 39.481%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 14: 17.046 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.281 (accuracy: 39.577%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 15: 16.971 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.278 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 16: 16.760 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.275 (accuracy: 39.289%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 17: 16.869 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.278 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 18: 16.785 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.282 (accuracy: 39.673%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 19: 16.781 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.281 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 20: 16.763 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.278 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 21: 16.822 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.274 (accuracy: 39.577%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 22: 16.842 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.276 (accuracy: 39.385%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 23: 16.773 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.274 (accuracy: 39.481%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 24: 16.772 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.276 (accuracy: 39.385%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 25: 16.761 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.272 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 26: 16.833 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.271 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 27: 16.764 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.269 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 28: 16.752 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.269 (accuracy: 39.481%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 29: 16.946 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.271 (accuracy: 39.385%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 30: 16.981 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.273 (accuracy: 39.481%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 10 with minimum validation error = 1.2967309395472209\n",
      "19071.645 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0\n",
      "Epoch 1: 16.765 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.327 (accuracy: 32.949%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 2: 16.871 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.305 (accuracy: 36.119%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 3: 17.027 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.299 (accuracy: 39.289%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 4: 16.936 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.302 (accuracy: 36.023%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 5: 16.738 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.296 (accuracy: 38.232%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 6: 16.957 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.291 (accuracy: 39.385%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 7: 16.788 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.299 (accuracy: 38.040%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 8: 16.744 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.287 (accuracy: 36.599%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 9: 16.743 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 10: 16.810 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.292 (accuracy: 39.481%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 11: 16.788 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.286 (accuracy: 38.905%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 12: 16.715 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.296 (accuracy: 37.944%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 13: 16.762 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.284 (accuracy: 39.385%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 14: 16.754 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.293 (accuracy: 39.385%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 15: 16.765 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.287 (accuracy: 39.481%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 16: 16.797 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.293 (accuracy: 39.289%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 17: 16.803 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.289 (accuracy: 39.097%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 18: 17.048 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.284 (accuracy: 39.673%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 19: 16.733 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.285 (accuracy: 39.385%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 20: 16.770 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.280 (accuracy: 39.962%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 21: 16.938 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.284 (accuracy: 39.193%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 22: 16.738 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.284 (accuracy: 39.577%), validation loss = 1.281 (accuracy: 33.333%)\n",
      "Epoch 23: 16.911 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.287 (accuracy: 38.809%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 24: 16.822 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.286 (accuracy: 38.617%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 25: 16.862 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.282 (accuracy: 39.289%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 26: 16.742 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.285 (accuracy: 38.232%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 27: 16.790 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.285 (accuracy: 38.617%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 28: 16.823 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.282 (accuracy: 39.001%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 29: 16.732 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.281 (accuracy: 39.673%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 30: 16.775 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.281 (accuracy: 40.250%), validation loss = 1.290 (accuracy: 33.333%)\n",
      "Epoch 31: 16.751 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.280 (accuracy: 39.097%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 32: 16.788 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.288 (accuracy: 38.809%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 33: 16.756 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.287 (accuracy: 39.385%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 34: 16.744 seconds elapsed in epoch.\n",
      "Epoch 34: training loss = 1.284 (accuracy: 40.826%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 35: 16.841 seconds elapsed in epoch.\n",
      "Epoch 35: training loss = 1.280 (accuracy: 40.058%), validation loss = 1.286 (accuracy: 33.333%)\n",
      "Epoch 36: 17.036 seconds elapsed in epoch.\n",
      "Epoch 36: training loss = 1.280 (accuracy: 38.521%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 37: 16.700 seconds elapsed in epoch.\n",
      "Epoch 37: training loss = 1.286 (accuracy: 38.713%), validation loss = 1.285 (accuracy: 34.286%)\n",
      "Epoch 38: 16.724 seconds elapsed in epoch.\n",
      "Epoch 38: training loss = 1.279 (accuracy: 39.481%), validation loss = 1.285 (accuracy: 33.333%)\n",
      "Epoch 39: 16.831 seconds elapsed in epoch.\n",
      "Epoch 39: training loss = 1.285 (accuracy: 39.385%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 40: 16.762 seconds elapsed in epoch.\n",
      "Epoch 40: training loss = 1.282 (accuracy: 38.040%), validation loss = 1.292 (accuracy: 34.286%)\n",
      "Epoch 41: 16.741 seconds elapsed in epoch.\n",
      "Epoch 41: training loss = 1.284 (accuracy: 39.289%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 42: 16.726 seconds elapsed in epoch.\n",
      "Epoch 42: training loss = 1.282 (accuracy: 40.058%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 22 with minimum validation error = 1.2806908732368834\n",
      "19780.122 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0.1\n",
      "Epoch 1: 16.807 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.349 (accuracy: 31.700%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 2: 16.978 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.314 (accuracy: 34.102%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 3: 16.767 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.309 (accuracy: 35.831%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 4: 16.957 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.306 (accuracy: 35.831%), validation loss = 1.422 (accuracy: 33.333%)\n",
      "Epoch 5: 16.747 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.298 (accuracy: 38.232%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 6: 16.839 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.290 (accuracy: 39.001%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 7: 16.825 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.299 (accuracy: 37.560%), validation loss = 1.289 (accuracy: 33.333%)\n",
      "Epoch 8: 16.993 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.296 (accuracy: 38.040%), validation loss = 1.284 (accuracy: 33.333%)\n",
      "Epoch 9: 16.942 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.299 (accuracy: 37.944%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 10: 16.759 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.288 (accuracy: 38.136%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 11: 16.794 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.287 (accuracy: 39.097%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 12: 16.993 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.292 (accuracy: 38.040%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 13: 16.836 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.300 (accuracy: 37.560%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 14: 16.753 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.287 (accuracy: 40.058%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 15: 16.749 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.290 (accuracy: 37.464%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 16: 16.836 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.289 (accuracy: 39.481%), validation loss = 1.317 (accuracy: 33.333%)\n",
      "Epoch 17: 16.832 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.296 (accuracy: 39.481%), validation loss = 1.312 (accuracy: 33.333%)\n",
      "Epoch 18: 16.800 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.289 (accuracy: 38.521%), validation loss = 1.315 (accuracy: 33.333%)\n",
      "Epoch 19: 16.760 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.289 (accuracy: 38.136%), validation loss = 1.320 (accuracy: 33.333%)\n",
      "Epoch 20: 16.759 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.287 (accuracy: 38.425%), validation loss = 1.318 (accuracy: 33.333%)\n",
      "Epoch 21: 16.822 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.287 (accuracy: 39.289%), validation loss = 1.330 (accuracy: 33.333%)\n",
      "Epoch 22: 16.743 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.284 (accuracy: 38.809%), validation loss = 1.324 (accuracy: 33.333%)\n",
      "Epoch 23: 16.756 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.281 (accuracy: 39.866%), validation loss = 1.327 (accuracy: 33.333%)\n",
      "Epoch 24: 16.740 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.286 (accuracy: 38.617%), validation loss = 1.337 (accuracy: 33.333%)\n",
      "Epoch 25: 16.849 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.280 (accuracy: 39.001%), validation loss = 1.337 (accuracy: 33.333%)\n",
      "Epoch 26: 16.853 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.284 (accuracy: 39.001%), validation loss = 1.334 (accuracy: 33.333%)\n",
      "Epoch 27: 16.742 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.289 (accuracy: 39.673%), validation loss = 1.310 (accuracy: 33.333%)\n",
      "Epoch 28: 16.773 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.280 (accuracy: 39.769%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 8 with minimum validation error = 1.2836084558850243\n",
      "20253.051 total second elapsed\n",
      "Start training model: learning rate = 0.001, weight decay = 0.2\n",
      "Epoch 1: 16.850 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.324 (accuracy: 34.102%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 2: 17.092 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.310 (accuracy: 35.735%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 3: 17.058 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.302 (accuracy: 36.695%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 4: 16.842 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.301 (accuracy: 38.232%), validation loss = 1.293 (accuracy: 33.333%)\n",
      "Epoch 5: 17.013 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.305 (accuracy: 37.656%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 6: 16.762 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.298 (accuracy: 36.984%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 7: 16.801 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.297 (accuracy: 38.809%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 8: 16.843 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.297 (accuracy: 38.617%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 9: 16.779 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.293 (accuracy: 38.617%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 10: 16.813 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.294 (accuracy: 38.905%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 11: 16.832 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.288 (accuracy: 38.329%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 12: 16.890 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.289 (accuracy: 38.425%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 13: 16.774 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.282 (accuracy: 39.962%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 14: 16.788 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.295 (accuracy: 38.329%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 15: 16.719 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.283 (accuracy: 39.769%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 16: 16.794 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.284 (accuracy: 39.097%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 17: 16.830 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.282 (accuracy: 39.866%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 18: 16.725 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.287 (accuracy: 39.385%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 19: 16.832 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.288 (accuracy: 39.769%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 20: 16.848 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.290 (accuracy: 39.673%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 21: 17.007 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.288 (accuracy: 40.154%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 22: 16.861 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.289 (accuracy: 39.577%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 23: 16.756 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.278 (accuracy: 39.097%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 24: 16.750 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.289 (accuracy: 39.673%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 4 with minimum validation error = 1.2931355237960815\n",
      "20658.491 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0\n",
      "Epoch 1: 16.755 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.349 (accuracy: 32.757%), validation loss = 1.330 (accuracy: 33.333%)\n",
      "Epoch 2: 16.999 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.308 (accuracy: 37.176%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 3: 16.975 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.306 (accuracy: 37.656%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 4: 16.740 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.313 (accuracy: 35.831%), validation loss = 1.294 (accuracy: 33.333%)\n",
      "Epoch 5: 16.894 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.293 (accuracy: 38.232%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 6: 16.766 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.298 (accuracy: 37.464%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 7: 16.783 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.307 (accuracy: 36.599%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 8: 16.791 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.303 (accuracy: 37.272%), validation loss = 1.321 (accuracy: 33.333%)\n",
      "Epoch 9: 16.742 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.303 (accuracy: 37.464%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 10: 16.750 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.291 (accuracy: 37.848%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 11: 16.727 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.302 (accuracy: 37.848%), validation loss = 1.316 (accuracy: 33.333%)\n",
      "Epoch 12: 16.774 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.291 (accuracy: 39.193%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 13: 16.745 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.286 (accuracy: 39.673%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 14: 16.815 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.284 (accuracy: 39.962%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 15: 16.849 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.293 (accuracy: 37.368%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 16: 16.908 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.285 (accuracy: 39.481%), validation loss = 1.335 (accuracy: 33.333%)\n",
      "Epoch 17: 16.809 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.278 (accuracy: 39.673%), validation loss = 1.338 (accuracy: 33.333%)\n",
      "Epoch 18: 16.736 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.293 (accuracy: 38.521%), validation loss = 1.336 (accuracy: 33.333%)\n",
      "Epoch 19: 16.667 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.298 (accuracy: 37.464%), validation loss = 1.335 (accuracy: 33.333%)\n",
      "Epoch 20: 16.814 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.295 (accuracy: 37.944%), validation loss = 1.336 (accuracy: 33.333%)\n",
      "Epoch 21: 16.754 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.294 (accuracy: 39.097%), validation loss = 1.322 (accuracy: 33.333%)\n",
      "Epoch 22: 16.895 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.295 (accuracy: 38.809%), validation loss = 1.333 (accuracy: 33.333%)\n",
      "Epoch 23: 16.779 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.290 (accuracy: 38.905%), validation loss = 1.331 (accuracy: 33.333%)\n",
      "Epoch 24: 16.719 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.276 (accuracy: 39.481%), validation loss = 1.333 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 4 with minimum validation error = 1.2944348357972644\n",
      "21063.200 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.1\n",
      "Epoch 1: 16.785 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.343 (accuracy: 31.412%), validation loss = 1.330 (accuracy: 33.333%)\n",
      "Epoch 2: 16.933 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.308 (accuracy: 36.984%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 3: 16.999 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.295 (accuracy: 37.560%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 4: 16.903 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.303 (accuracy: 39.289%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 5: 16.962 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.296 (accuracy: 37.944%), validation loss = 1.311 (accuracy: 33.333%)\n",
      "Epoch 6: 16.756 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.289 (accuracy: 38.329%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 7: 17.065 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.296 (accuracy: 39.385%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 8: 17.036 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.298 (accuracy: 39.097%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 9: 16.791 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.302 (accuracy: 38.329%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 10: 17.025 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.299 (accuracy: 37.656%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 11: 16.742 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.290 (accuracy: 40.058%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 12: 16.803 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.296 (accuracy: 39.193%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 13: 16.828 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.286 (accuracy: 39.289%), validation loss = 1.292 (accuracy: 33.333%)\n",
      "Epoch 14: 16.954 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.294 (accuracy: 39.097%), validation loss = 1.295 (accuracy: 33.333%)\n",
      "Epoch 15: 16.752 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.289 (accuracy: 38.905%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 16: 16.812 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.289 (accuracy: 38.905%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 17: 16.821 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.292 (accuracy: 37.752%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 18: 16.762 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.279 (accuracy: 39.289%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 19: 16.756 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.291 (accuracy: 39.481%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 20: 16.805 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.281 (accuracy: 39.673%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 21: 16.776 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.297 (accuracy: 39.577%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 22: 16.825 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.290 (accuracy: 39.097%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 23: 16.721 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.290 (accuracy: 39.193%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 24: 16.762 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.283 (accuracy: 38.521%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 25: 16.820 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.293 (accuracy: 38.905%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 26: 16.788 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.284 (accuracy: 38.425%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 27: 16.895 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.286 (accuracy: 39.962%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 28: 16.932 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.288 (accuracy: 38.617%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 29: 16.882 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.290 (accuracy: 39.097%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 30: 16.765 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.286 (accuracy: 38.809%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Epoch 31: 16.786 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.284 (accuracy: 40.058%), validation loss = 1.308 (accuracy: 33.333%)\n",
      "Epoch 32: 16.729 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.288 (accuracy: 38.617%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 33: 16.782 seconds elapsed in epoch.\n",
      "Epoch 33: training loss = 1.283 (accuracy: 39.481%), validation loss = 1.314 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 13 with minimum validation error = 1.2923767021724155\n",
      "21621.971 total second elapsed\n",
      "Start training model: learning rate = 0.0005, weight decay = 0.2\n",
      "Epoch 1: 16.767 seconds elapsed in epoch.\n",
      "Epoch 1: training loss = 1.387 (accuracy: 28.722%), validation loss = 1.340 (accuracy: 34.286%)\n",
      "Epoch 2: 17.006 seconds elapsed in epoch.\n",
      "Epoch 2: training loss = 1.325 (accuracy: 36.311%), validation loss = 1.313 (accuracy: 33.333%)\n",
      "Epoch 3: 17.022 seconds elapsed in epoch.\n",
      "Epoch 3: training loss = 1.310 (accuracy: 36.599%), validation loss = 1.309 (accuracy: 33.333%)\n",
      "Epoch 4: 16.936 seconds elapsed in epoch.\n",
      "Epoch 4: training loss = 1.313 (accuracy: 35.255%), validation loss = 1.307 (accuracy: 33.333%)\n",
      "Epoch 5: 17.043 seconds elapsed in epoch.\n",
      "Epoch 5: training loss = 1.309 (accuracy: 36.503%), validation loss = 1.305 (accuracy: 33.333%)\n",
      "Epoch 6: 16.967 seconds elapsed in epoch.\n",
      "Epoch 6: training loss = 1.299 (accuracy: 37.464%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Epoch 7: 16.996 seconds elapsed in epoch.\n",
      "Epoch 7: training loss = 1.318 (accuracy: 37.176%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 8: 16.819 seconds elapsed in epoch.\n",
      "Epoch 8: training loss = 1.304 (accuracy: 36.023%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 9: 16.836 seconds elapsed in epoch.\n",
      "Epoch 9: training loss = 1.299 (accuracy: 38.905%), validation loss = 1.304 (accuracy: 33.333%)\n",
      "Epoch 10: 16.757 seconds elapsed in epoch.\n",
      "Epoch 10: training loss = 1.306 (accuracy: 36.215%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 11: 16.863 seconds elapsed in epoch.\n",
      "Epoch 11: training loss = 1.306 (accuracy: 37.848%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 12: 16.878 seconds elapsed in epoch.\n",
      "Epoch 12: training loss = 1.303 (accuracy: 37.848%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 13: 17.101 seconds elapsed in epoch.\n",
      "Epoch 13: training loss = 1.298 (accuracy: 38.329%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 14: 16.921 seconds elapsed in epoch.\n",
      "Epoch 14: training loss = 1.299 (accuracy: 40.730%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 15: 16.774 seconds elapsed in epoch.\n",
      "Epoch 15: training loss = 1.298 (accuracy: 39.193%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 16: 16.785 seconds elapsed in epoch.\n",
      "Epoch 16: training loss = 1.291 (accuracy: 38.809%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 17: 16.830 seconds elapsed in epoch.\n",
      "Epoch 17: training loss = 1.296 (accuracy: 39.385%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 18: 16.828 seconds elapsed in epoch.\n",
      "Epoch 18: training loss = 1.295 (accuracy: 38.617%), validation loss = 1.306 (accuracy: 33.333%)\n",
      "Epoch 19: 16.744 seconds elapsed in epoch.\n",
      "Epoch 19: training loss = 1.295 (accuracy: 37.752%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 20: 16.734 seconds elapsed in epoch.\n",
      "Epoch 20: training loss = 1.294 (accuracy: 39.289%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 21: 16.741 seconds elapsed in epoch.\n",
      "Epoch 21: training loss = 1.293 (accuracy: 39.289%), validation loss = 1.301 (accuracy: 33.333%)\n",
      "Epoch 22: 16.795 seconds elapsed in epoch.\n",
      "Epoch 22: training loss = 1.292 (accuracy: 39.673%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 23: 16.730 seconds elapsed in epoch.\n",
      "Epoch 23: training loss = 1.286 (accuracy: 38.905%), validation loss = 1.303 (accuracy: 33.333%)\n",
      "Epoch 24: 16.805 seconds elapsed in epoch.\n",
      "Epoch 24: training loss = 1.285 (accuracy: 39.866%), validation loss = 1.299 (accuracy: 33.333%)\n",
      "Epoch 25: 16.737 seconds elapsed in epoch.\n",
      "Epoch 25: training loss = 1.289 (accuracy: 39.289%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 26: 16.815 seconds elapsed in epoch.\n",
      "Epoch 26: training loss = 1.291 (accuracy: 38.809%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 27: 16.792 seconds elapsed in epoch.\n",
      "Epoch 27: training loss = 1.295 (accuracy: 39.769%), validation loss = 1.297 (accuracy: 33.333%)\n",
      "Epoch 28: 16.765 seconds elapsed in epoch.\n",
      "Epoch 28: training loss = 1.286 (accuracy: 39.962%), validation loss = 1.302 (accuracy: 33.333%)\n",
      "Epoch 29: 16.742 seconds elapsed in epoch.\n",
      "Epoch 29: training loss = 1.284 (accuracy: 39.097%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 30: 16.933 seconds elapsed in epoch.\n",
      "Epoch 30: training loss = 1.289 (accuracy: 39.481%), validation loss = 1.300 (accuracy: 33.333%)\n",
      "Epoch 31: 16.810 seconds elapsed in epoch.\n",
      "Epoch 31: training loss = 1.289 (accuracy: 39.289%), validation loss = 1.296 (accuracy: 33.333%)\n",
      "Epoch 32: 17.056 seconds elapsed in epoch.\n",
      "Epoch 32: training loss = 1.290 (accuracy: 39.481%), validation loss = 1.298 (accuracy: 33.333%)\n",
      "Early stopping!\n",
      "==================================================validation result==================================================\n",
      "the best epoch is 12 with minimum validation error = 1.296046309244065\n",
      "22164.343 total second elapsed\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.005, 0.001, 0.0005]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "min_valid_loss_list_Q4_SGD = []\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "for lr in lr_list:\n",
    "    for weight in weight_list:\n",
    "        save_file_name = \"/content/gdrive/My Drive/SLDL/hw5/Q4/SGD/resnet50_lr_\" + str(lr) + \"_weight_\" + str(weight) + \".pt\"\n",
    "        model = reset_model(isFreeze = False, isPretrained = False)\n",
    "        if train_on_gpu:\n",
    "            model = model.to('cuda')\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay = weight)\n",
    "        nepoch = 200\n",
    "        Q4_tune_model = Resnet50()\n",
    "        print(\"Start training model: learning rate = {}, weight decay = {}\".format(lr, weight))\n",
    "        model_finish = Q4_tune_model.train(train_on_gpu, model, nepoch, optimizer, save_file_name, dataloaders['train'], dataloaders['val'], verbose = True)\n",
    "        min_valid_loss_list_Q4_SGD.append(Q4_tune_model.best_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1610452299538,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "FP3_9CWr1bhe",
    "outputId": "7db05d6b-09fe-4467-bc76-db24f4867df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-axis: learning rate\n",
      "y-axis: weight decay\n",
      "Best hyperparameters with SGD optimizer : learning rate = 0.01, weight decay = 0\n",
      "       0.0100    0.0050    0.0010    0.0005\n",
      "0.0  1.244184  1.290267  1.280691  1.294435\n",
      "0.1  1.289611  1.276932  1.283608  1.292377\n",
      "0.2  1.299241  1.296731  1.293136  1.296046\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.005, 0.001, 0.0005]\n",
    "weight_list = [0, 0.1, 0.2]\n",
    "df = pd.DataFrame(index = weight_list)\n",
    "count = 0\n",
    "for lr in lr_list:\n",
    "    temp = []\n",
    "    for weight in weight_list:\n",
    "        temp.append(min_valid_loss_list_Q4_SGD[count])\n",
    "        count +=1 \n",
    "    df[lr] = temp\n",
    "index = np.unravel_index(np.argmin(df, axis=None), df.shape)\n",
    "row_index = index[0]\n",
    "column_index = index[1]\n",
    "print(\"x-axis: learning rate\")\n",
    "print(\"y-axis: weight decay\")\n",
    "print(\"Best hyperparameters with SGD optimizer : learning rate = {}, weight decay = {}\".format(lr_list[column_index], weight_list[row_index]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ny9lZx6_Al8"
   },
   "source": [
    "## Q4 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 42259,
     "status": "ok",
     "timestamp": 1610528677720,
     "user": {
      "displayName": "林聖硯",
      "photoUrl": "",
      "userId": "15123652174801872330"
     },
     "user_tz": -480
    },
    "id": "V6w0U3Jk_Bvl",
    "outputId": "0a9d1cc9-aeec-4289-ff4e-a68b104107bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q4 result==================================================\n",
      "when optimizer = Adam, learning rate = 0.0001, weight decay = 0, overall testing accuracy = 0.459\n",
      "label = blazer, per class accuracy = 0.0\n",
      "label = cardigan, per class accuracy = 0.5238095238095238\n",
      "label = coat, per class accuracy = 0.3023255813953488\n",
      "label = jacket, per class accuracy = 0.6153846153846154\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q4 result==================================================\n",
      "when optimizer = Adam, learning rate = 5e-05, weight decay = 0.1, overall testing accuracy = 0.438\n",
      "label = blazer, per class accuracy = 0.0\n",
      "label = cardigan, per class accuracy = 0.4523809523809524\n",
      "label = coat, per class accuracy = 0.23255813953488372\n",
      "label = jacket, per class accuracy = 0.6730769230769231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q4 result==================================================\n",
      "when optimizer = SGD, learning rate = 0.01, weight decay = 0, overall testing accuracy = 0.390\n",
      "label = blazer, per class accuracy = 0.0\n",
      "label = cardigan, per class accuracy = 0.5476190476190477\n",
      "label = coat, per class accuracy = 0.0\n",
      "label = jacket, per class accuracy = 0.6538461538461539\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================Q4 result==================================================\n",
      "when optimizer = SGD, learning rate = 0.001, weight decay = 0, overall testing accuracy = 0.356\n",
      "label = blazer, per class accuracy = 0.0\n",
      "label = cardigan, per class accuracy = 0.0\n",
      "label = coat, per class accuracy = 0.0\n",
      "label = jacket, per class accuracy = 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q4 Adam\n",
    "#lr = 0.0001, w = 0, lr = 0.00005, w = 0.1\n",
    "print_result(\"Q4\", \"Adam\", 0.0001, 0)\n",
    "print_result(\"Q4\", \"Adam\", 0.00005, 0.1)\n",
    "#Q4 SGD\n",
    "#lr = 0.01, w = 0, lr = 0.001. w = 0\n",
    "print_result(\"Q4\", \"SGD\", 0.01, 0)\n",
    "print_result(\"Q4\", \"SGD\", 0.001, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從Q2到Q4的結果可以觀察出，預測能力最好的情形由大到小分別為\n",
    "Pretrained Model + 訓練全部的Neuron -> Pretrained Model + 只訓練最後一層 -> 沒有經過Pretrained的Model。\n",
    "\n",
    "觀察列點如下：\n",
    "1. 有經過Pretrained的Model已經包含結果不錯的參數，所以想當然爾Testing的結果一定比較好。比較Q2及Q3的Model，有更新全部Layer的Model也一定比只訓練最後一層的Model還要好。\n",
    "\n",
    "2. Adam Optimizer對此次任務普遍來說比SGD Optimizer表現得要好 (除了Q3的結果以外)\n",
    "\n",
    "3. Jacket, coat, cardigan三個Label的預測準確度比較高，正如同一開始所猜想。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
